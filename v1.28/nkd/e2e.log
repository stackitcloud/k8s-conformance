  I0326 05:32:54.944049      19 e2e.go:117] Starting e2e run "1d6c2f50-9292-4192-97b8-6b9f8e6e7376" on Ginkgo node 1
  Mar 26 05:32:54.961: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1711431174 - will randomize all specs

Will run 380 of 7387 specs
------------------------------
[ReportBeforeSuite] 
test/e2e/e2e_test.go:153
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:77
  Mar 26 05:32:55.071: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:32:55.072: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
  Mar 26 05:32:55.090: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  Mar 26 05:32:55.092: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
  Mar 26 05:32:55.092: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
  Mar 26 05:32:55.092: INFO: e2e test version: v1.28.0
  Mar 26 05:32:55.093: INFO: kube-apiserver version: v1.28.0
  Mar 26 05:32:55.093: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:32:55.094: INFO: Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.023 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 03/26/24 05:32:55.266
  Mar 26 05:32:55.266: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename watch @ 03/26/24 05:32:55.266
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:32:55.276
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:32:55.277
  STEP: creating a watch on configmaps with a certain label @ 03/26/24 05:32:55.278
  STEP: creating a new configmap @ 03/26/24 05:32:55.278
  STEP: modifying the configmap once @ 03/26/24 05:32:55.281
  STEP: changing the label value of the configmap @ 03/26/24 05:32:55.287
  STEP: Expecting to observe a delete notification for the watched object @ 03/26/24 05:32:55.29
  Mar 26 05:32:55.290: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-681  13a86e28-0e54-4f18-ba47-36fbe9da5fba 67688 0 2024-03-26 05:32:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-03-26 05:32:55 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Mar 26 05:32:55.290: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-681  13a86e28-0e54-4f18-ba47-36fbe9da5fba 67691 0 2024-03-26 05:32:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-03-26 05:32:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Mar 26 05:32:55.290: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-681  13a86e28-0e54-4f18-ba47-36fbe9da5fba 67692 0 2024-03-26 05:32:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-03-26 05:32:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 03/26/24 05:32:55.29
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 03/26/24 05:32:55.293
  STEP: changing the label value of the configmap back @ 03/26/24 05:33:05.294
  STEP: modifying the configmap a third time @ 03/26/24 05:33:05.298
  STEP: deleting the configmap @ 03/26/24 05:33:05.3
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 03/26/24 05:33:05.302
  Mar 26 05:33:05.302: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-681  13a86e28-0e54-4f18-ba47-36fbe9da5fba 67712 0 2024-03-26 05:32:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-03-26 05:33:05 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Mar 26 05:33:05.302: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-681  13a86e28-0e54-4f18-ba47-36fbe9da5fba 67713 0 2024-03-26 05:32:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-03-26 05:33:05 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Mar 26 05:33:05.302: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-681  13a86e28-0e54-4f18-ba47-36fbe9da5fba 67714 0 2024-03-26 05:32:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-03-26 05:33:05 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Mar 26 05:33:05.302: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-681" for this suite. @ 03/26/24 05:33:05.304
• [10.040 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]
test/e2e/apimachinery/resource_quota.go:887
  STEP: Creating a kubernetes client @ 03/26/24 05:33:05.306
  Mar 26 05:33:05.306: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename resourcequota @ 03/26/24 05:33:05.307
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:33:05.312
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:33:05.313
  STEP: Creating a ResourceQuota @ 03/26/24 05:33:05.314
  STEP: Getting a ResourceQuota @ 03/26/24 05:33:05.316
  STEP: Updating a ResourceQuota @ 03/26/24 05:33:05.317
  STEP: Verifying a ResourceQuota was modified @ 03/26/24 05:33:05.32
  STEP: Deleting a ResourceQuota @ 03/26/24 05:33:05.32
  STEP: Verifying the deleted ResourceQuota @ 03/26/24 05:33:05.323
  Mar 26 05:33:05.324: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-456" for this suite. @ 03/26/24 05:33:05.325
• [0.021 seconds]
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance]
test/e2e/auth/service_accounts.go:275
  STEP: Creating a kubernetes client @ 03/26/24 05:33:05.327
  Mar 26 05:33:05.327: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename svcaccounts @ 03/26/24 05:33:05.328
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:33:05.333
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:33:05.334
  STEP: Creating a pod to test service account token:  @ 03/26/24 05:33:05.335
  STEP: Saw pod success @ 03/26/24 05:33:09.344
  Mar 26 05:33:09.346: INFO: Trying to get logs from node k8s-worker02 pod test-pod-63a17d4a-0ddc-49a7-be66-3529a51c1f87 container agnhost-container: <nil>
  STEP: delete the pod @ 03/26/24 05:33:09.354
  Mar 26 05:33:09.359: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-3226" for this suite. @ 03/26/24 05:33:09.361
• [4.036 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:194
  STEP: Creating a kubernetes client @ 03/26/24 05:33:09.367
  Mar 26 05:33:09.368: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 05:33:09.368
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:33:09.372
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:33:09.374
  STEP: Creating a pod to test downward API volume plugin @ 03/26/24 05:33:09.375
  STEP: Saw pod success @ 03/26/24 05:33:11.382
  Mar 26 05:33:11.383: INFO: Trying to get logs from node k8s-worker02 pod downwardapi-volume-e0123c02-5c18-4339-8dfb-842787d3f476 container client-container: <nil>
  STEP: delete the pod @ 03/26/24 05:33:11.385
  Mar 26 05:33:11.390: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9193" for this suite. @ 03/26/24 05:33:11.392
• [2.027 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]
test/e2e/apps/job.go:513
  STEP: Creating a kubernetes client @ 03/26/24 05:33:11.395
  Mar 26 05:33:11.395: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename job @ 03/26/24 05:33:11.395
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:33:11.401
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:33:11.402
  STEP: Creating a job @ 03/26/24 05:33:11.407
  STEP: Ensuring active pods == parallelism @ 03/26/24 05:33:11.41
  STEP: Orphaning one of the Job's Pods @ 03/26/24 05:33:13.413
  Mar 26 05:33:13.921: INFO: Successfully updated pod "adopt-release-b9mg6"
  STEP: Checking that the Job readopts the Pod @ 03/26/24 05:33:13.922
  STEP: Removing the labels from the Job's Pod @ 03/26/24 05:33:15.927
  Mar 26 05:33:16.432: INFO: Successfully updated pod "adopt-release-b9mg6"
  STEP: Checking that the Job releases the Pod @ 03/26/24 05:33:16.432
  Mar 26 05:33:18.436: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8629" for this suite. @ 03/26/24 05:33:18.437
• [7.045 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]
test/e2e/apimachinery/resource_quota.go:1013
  STEP: Creating a kubernetes client @ 03/26/24 05:33:18.441
  Mar 26 05:33:18.441: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename resourcequota @ 03/26/24 05:33:18.442
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:33:18.448
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:33:18.449
  STEP: Creating resourceQuota "e2e-rq-status-h4brw" @ 03/26/24 05:33:18.451
  Mar 26 05:33:18.454: INFO: Resource quota "e2e-rq-status-h4brw" reports spec: hard cpu limit of 500m
  Mar 26 05:33:18.454: INFO: Resource quota "e2e-rq-status-h4brw" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-h4brw" /status @ 03/26/24 05:33:18.454
  STEP: Confirm /status for "e2e-rq-status-h4brw" resourceQuota via watch @ 03/26/24 05:33:18.469
  Mar 26 05:33:18.470: INFO: observed resourceQuota "e2e-rq-status-h4brw" in namespace "resourcequota-7105" with hard status: v1.ResourceList(nil)
  Mar 26 05:33:18.470: INFO: Found resourceQuota "e2e-rq-status-h4brw" in namespace "resourcequota-7105" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Mar 26 05:33:18.470: INFO: ResourceQuota "e2e-rq-status-h4brw" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 03/26/24 05:33:18.471
  Mar 26 05:33:18.473: INFO: Resource quota "e2e-rq-status-h4brw" reports spec: hard cpu limit of 1
  Mar 26 05:33:18.473: INFO: Resource quota "e2e-rq-status-h4brw" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-h4brw" /status @ 03/26/24 05:33:18.473
  STEP: Confirm /status for "e2e-rq-status-h4brw" resourceQuota via watch @ 03/26/24 05:33:18.475
  Mar 26 05:33:18.475: INFO: observed resourceQuota "e2e-rq-status-h4brw" in namespace "resourcequota-7105" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Mar 26 05:33:18.475: INFO: Found resourceQuota "e2e-rq-status-h4brw" in namespace "resourcequota-7105" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  Mar 26 05:33:18.476: INFO: ResourceQuota "e2e-rq-status-h4brw" /status was patched
  STEP: Get "e2e-rq-status-h4brw" /status @ 03/26/24 05:33:18.476
  Mar 26 05:33:18.477: INFO: Resourcequota "e2e-rq-status-h4brw" reports status: hard cpu of 1
  Mar 26 05:33:18.477: INFO: Resourcequota "e2e-rq-status-h4brw" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-h4brw" /status before checking Spec is unchanged @ 03/26/24 05:33:18.478
  Mar 26 05:33:18.479: INFO: Resourcequota "e2e-rq-status-h4brw" reports status: hard cpu of 2
  Mar 26 05:33:18.480: INFO: Resourcequota "e2e-rq-status-h4brw" reports status: hard memory of 2Gi
  Mar 26 05:33:18.480: INFO: Found resourceQuota "e2e-rq-status-h4brw" in namespace "resourcequota-7105" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  Mar 26 05:33:23.485: INFO: ResourceQuota "e2e-rq-status-h4brw" Spec was unchanged and /status reset
  Mar 26 05:33:23.485: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7105" for this suite. @ 03/26/24 05:33:23.487
• [5.048 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:107
  STEP: Creating a kubernetes client @ 03/26/24 05:33:23.49
  Mar 26 05:33:23.490: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename pod-network-test @ 03/26/24 05:33:23.491
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:33:23.507
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:33:23.51
  STEP: Performing setup for networking test in namespace pod-network-test-9360 @ 03/26/24 05:33:23.511
  STEP: creating a selector @ 03/26/24 05:33:23.511
  STEP: Creating the service pods in kubernetes @ 03/26/24 05:33:23.511
  Mar 26 05:33:23.511: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 03/26/24 05:33:45.557
  Mar 26 05:33:47.570: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Mar 26 05:33:47.570: INFO: Going to poll 10.244.32.175 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Mar 26 05:33:47.571: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.32.175:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9360 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 05:33:47.571: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:33:47.571: INFO: ExecWithOptions: Clientset creation
  Mar 26 05:33:47.571: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9360/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.32.175%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Mar 26 05:33:47.614: INFO: Found all 1 expected endpoints: [netserver-0]
  Mar 26 05:33:47.614: INFO: Going to poll 10.244.79.73 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Mar 26 05:33:47.615: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.79.73:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9360 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 05:33:47.615: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:33:47.616: INFO: ExecWithOptions: Clientset creation
  Mar 26 05:33:47.616: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9360/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.79.73%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Mar 26 05:33:47.655: INFO: Found all 1 expected endpoints: [netserver-1]
  Mar 26 05:33:47.655: INFO: Going to poll 10.244.69.255 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Mar 26 05:33:47.656: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.69.255:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9360 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 05:33:47.656: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:33:47.656: INFO: ExecWithOptions: Clientset creation
  Mar 26 05:33:47.656: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9360/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.69.255%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Mar 26 05:33:47.700: INFO: Found all 1 expected endpoints: [netserver-2]
  Mar 26 05:33:47.700: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-9360" for this suite. @ 03/26/24 05:33:47.702
• [24.216 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]
test/e2e/common/node/configmap.go:138
  STEP: Creating a kubernetes client @ 03/26/24 05:33:47.711
  Mar 26 05:33:47.711: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename configmap @ 03/26/24 05:33:47.711
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:33:47.717
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:33:47.718
  STEP: Creating configMap that has name configmap-test-emptyKey-755e4b6b-6c71-4bbd-92ac-6dcfcac19826 @ 03/26/24 05:33:47.719
  Mar 26 05:33:47.720: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1425" for this suite. @ 03/26/24 05:33:47.722
• [0.013 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:213
  STEP: Creating a kubernetes client @ 03/26/24 05:33:47.724
  Mar 26 05:33:47.725: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 03/26/24 05:33:47.725
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:33:47.731
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:33:47.732
  STEP: create the container to handle the HTTPGet hook request. @ 03/26/24 05:33:47.736
  STEP: create the pod with lifecycle hook @ 03/26/24 05:33:49.744
  STEP: delete the pod with lifecycle hook @ 03/26/24 05:33:51.752
  STEP: check prestop hook @ 03/26/24 05:33:53.757
  Mar 26 05:33:53.760: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-4900" for this suite. @ 03/26/24 05:33:53.761
• [6.039 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]
test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 03/26/24 05:33:53.768
  Mar 26 05:33:53.768: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename disruption @ 03/26/24 05:33:53.769
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:33:53.774
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:33:53.776
  STEP: Waiting for the pdb to be processed @ 03/26/24 05:33:53.779
  STEP: Waiting for all pods to be running @ 03/26/24 05:33:55.799
  Mar 26 05:33:55.803: INFO: running pods: 0 < 3
  Mar 26 05:33:57.808: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-1750" for this suite. @ 03/26/24 05:33:57.81
• [4.046 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency should not be very high  [Conformance]
test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 03/26/24 05:33:57.816
  Mar 26 05:33:57.816: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename svc-latency @ 03/26/24 05:33:57.816
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:33:57.823
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:33:57.824
  Mar 26 05:33:57.826: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-8963 @ 03/26/24 05:33:57.827
  I0326 05:33:57.830864      19 runners.go:197] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8963, replica count: 1
  I0326 05:33:58.882133      19 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Mar 26 05:33:58.986: INFO: Created: latency-svc-pd44v
  Mar 26 05:33:58.989: INFO: Got endpoints: latency-svc-pd44v [7.689676ms]
  Mar 26 05:33:58.994: INFO: Created: latency-svc-9pq28
  Mar 26 05:33:58.997: INFO: Got endpoints: latency-svc-9pq28 [7.358079ms]
  Mar 26 05:33:59.024: INFO: Created: latency-svc-j2n6p
  Mar 26 05:33:59.024: INFO: Created: latency-svc-ltvmg
  Mar 26 05:33:59.025: INFO: Created: latency-svc-sgbc4
  Mar 26 05:33:59.025: INFO: Created: latency-svc-ndcwf
  Mar 26 05:33:59.025: INFO: Created: latency-svc-thw62
  Mar 26 05:33:59.032: INFO: Created: latency-svc-4d852
  Mar 26 05:33:59.032: INFO: Created: latency-svc-w7495
  Mar 26 05:33:59.032: INFO: Created: latency-svc-znt4f
  Mar 26 05:33:59.033: INFO: Got endpoints: latency-svc-ltvmg [42.782155ms]
  Mar 26 05:33:59.033: INFO: Created: latency-svc-wmnt7
  Mar 26 05:33:59.033: INFO: Created: latency-svc-n85sr
  Mar 26 05:33:59.033: INFO: Created: latency-svc-mwd4w
  Mar 26 05:33:59.033: INFO: Created: latency-svc-wrw5s
  Mar 26 05:33:59.033: INFO: Created: latency-svc-qc9z2
  Mar 26 05:33:59.033: INFO: Created: latency-svc-8jmqf
  Mar 26 05:33:59.033: INFO: Created: latency-svc-m52hg
  Mar 26 05:33:59.035: INFO: Got endpoints: latency-svc-j2n6p [45.378227ms]
  Mar 26 05:33:59.036: INFO: Got endpoints: latency-svc-sgbc4 [46.54873ms]
  Mar 26 05:33:59.036: INFO: Got endpoints: latency-svc-4d852 [46.571291ms]
  Mar 26 05:33:59.037: INFO: Got endpoints: latency-svc-thw62 [39.786182ms]
  Mar 26 05:33:59.037: INFO: Got endpoints: latency-svc-8jmqf [46.684252ms]
  Mar 26 05:33:59.042: INFO: Got endpoints: latency-svc-ndcwf [52.497368ms]
  Mar 26 05:33:59.045: INFO: Got endpoints: latency-svc-n85sr [55.194257ms]
  Mar 26 05:33:59.045: INFO: Got endpoints: latency-svc-m52hg [55.181024ms]
  Mar 26 05:33:59.045: INFO: Got endpoints: latency-svc-mwd4w [55.263508ms]
  Mar 26 05:33:59.045: INFO: Got endpoints: latency-svc-znt4f [55.491532ms]
  Mar 26 05:33:59.048: INFO: Got endpoints: latency-svc-wrw5s [57.698893ms]
  Mar 26 05:33:59.050: INFO: Got endpoints: latency-svc-wmnt7 [60.144511ms]
  Mar 26 05:33:59.051: INFO: Created: latency-svc-4wdk2
  Mar 26 05:33:59.051: INFO: Created: latency-svc-s29k2
  Mar 26 05:33:59.053: INFO: Got endpoints: latency-svc-qc9z2 [63.235528ms]
  Mar 26 05:33:59.053: INFO: Got endpoints: latency-svc-4wdk2 [20.802356ms]
  Mar 26 05:33:59.054: INFO: Got endpoints: latency-svc-w7495 [63.63333ms]
  Mar 26 05:33:59.059: INFO: Got endpoints: latency-svc-s29k2 [23.651927ms]
  Mar 26 05:33:59.064: INFO: Created: latency-svc-ppmx5
  Mar 26 05:33:59.066: INFO: Created: latency-svc-8s98z
  Mar 26 05:33:59.067: INFO: Got endpoints: latency-svc-ppmx5 [14.144376ms]
  Mar 26 05:33:59.069: INFO: Got endpoints: latency-svc-8s98z [32.55504ms]
  Mar 26 05:33:59.069: INFO: Created: latency-svc-9rgtw
  Mar 26 05:33:59.070: INFO: Got endpoints: latency-svc-9rgtw [33.476033ms]
  Mar 26 05:33:59.072: INFO: Created: latency-svc-gcl8l
  Mar 26 05:33:59.074: INFO: Got endpoints: latency-svc-gcl8l [36.993889ms]
  Mar 26 05:33:59.075: INFO: Created: latency-svc-b6v9c
  Mar 26 05:33:59.078: INFO: Got endpoints: latency-svc-b6v9c [35.817583ms]
  Mar 26 05:33:59.078: INFO: Created: latency-svc-26s2s
  Mar 26 05:33:59.080: INFO: Got endpoints: latency-svc-26s2s [34.680006ms]
  Mar 26 05:33:59.081: INFO: Created: latency-svc-8kszc
  Mar 26 05:33:59.084: INFO: Got endpoints: latency-svc-8kszc [38.584945ms]
  Mar 26 05:33:59.085: INFO: Created: latency-svc-xc8zm
  Mar 26 05:33:59.087: INFO: Created: latency-svc-klnn8
  Mar 26 05:33:59.088: INFO: Got endpoints: latency-svc-xc8zm [42.300225ms]
  Mar 26 05:33:59.090: INFO: Got endpoints: latency-svc-klnn8 [44.198752ms]
  Mar 26 05:33:59.090: INFO: Created: latency-svc-smxzk
  Mar 26 05:33:59.092: INFO: Got endpoints: latency-svc-smxzk [42.094346ms]
  Mar 26 05:33:59.093: INFO: Created: latency-svc-p2x2c
  Mar 26 05:33:59.095: INFO: Got endpoints: latency-svc-p2x2c [47.394661ms]
  Mar 26 05:33:59.096: INFO: Created: latency-svc-t4kfw
  Mar 26 05:33:59.098: INFO: Got endpoints: latency-svc-t4kfw [61.530678ms]
  Mar 26 05:33:59.099: INFO: Created: latency-svc-fx4ks
  Mar 26 05:33:59.101: INFO: Got endpoints: latency-svc-fx4ks [47.361873ms]
  Mar 26 05:33:59.101: INFO: Created: latency-svc-zssrb
  Mar 26 05:33:59.104: INFO: Created: latency-svc-hcqsb
  Mar 26 05:33:59.107: INFO: Created: latency-svc-j6zcs
  Mar 26 05:33:59.109: INFO: Created: latency-svc-rgrx2
  Mar 26 05:33:59.111: INFO: Created: latency-svc-zqt49
  Mar 26 05:33:59.113: INFO: Created: latency-svc-jjx9m
  Mar 26 05:33:59.115: INFO: Created: latency-svc-nt982
  Mar 26 05:33:59.117: INFO: Created: latency-svc-5tzm9
  Mar 26 05:33:59.118: INFO: Created: latency-svc-6qmwq
  Mar 26 05:33:59.120: INFO: Created: latency-svc-x768c
  Mar 26 05:33:59.123: INFO: Created: latency-svc-pscm8
  Mar 26 05:33:59.125: INFO: Created: latency-svc-8bqt4
  Mar 26 05:33:59.127: INFO: Created: latency-svc-wvdsk
  Mar 26 05:33:59.128: INFO: Created: latency-svc-9nh4z
  Mar 26 05:33:59.130: INFO: Created: latency-svc-wghlx
  Mar 26 05:33:59.139: INFO: Got endpoints: latency-svc-zssrb [85.114769ms]
  Mar 26 05:33:59.142: INFO: Created: latency-svc-4k4zv
  Mar 26 05:33:59.189: INFO: Got endpoints: latency-svc-hcqsb [129.626337ms]
  Mar 26 05:33:59.192: INFO: Created: latency-svc-ggsg8
  Mar 26 05:33:59.239: INFO: Got endpoints: latency-svc-j6zcs [172.101168ms]
  Mar 26 05:33:59.243: INFO: Created: latency-svc-wld5q
  Mar 26 05:33:59.289: INFO: Got endpoints: latency-svc-rgrx2 [220.311651ms]
  Mar 26 05:33:59.293: INFO: Created: latency-svc-hx8qq
  Mar 26 05:33:59.339: INFO: Got endpoints: latency-svc-zqt49 [268.500564ms]
  Mar 26 05:33:59.342: INFO: Created: latency-svc-dpqbg
  Mar 26 05:33:59.388: INFO: Got endpoints: latency-svc-jjx9m [314.58239ms]
  Mar 26 05:33:59.392: INFO: Created: latency-svc-w8lj6
  Mar 26 05:33:59.439: INFO: Got endpoints: latency-svc-nt982 [360.831435ms]
  Mar 26 05:33:59.443: INFO: Created: latency-svc-wdkbf
  Mar 26 05:33:59.488: INFO: Got endpoints: latency-svc-5tzm9 [408.527126ms]
  Mar 26 05:33:59.493: INFO: Created: latency-svc-sz9p7
  Mar 26 05:33:59.539: INFO: Got endpoints: latency-svc-6qmwq [455.428546ms]
  Mar 26 05:33:59.543: INFO: Created: latency-svc-c65nv
  Mar 26 05:33:59.589: INFO: Got endpoints: latency-svc-x768c [501.596107ms]
  Mar 26 05:33:59.593: INFO: Created: latency-svc-hplxk
  Mar 26 05:33:59.639: INFO: Got endpoints: latency-svc-pscm8 [549.661824ms]
  Mar 26 05:33:59.643: INFO: Created: latency-svc-84vhs
  Mar 26 05:33:59.688: INFO: Got endpoints: latency-svc-8bqt4 [596.142729ms]
  Mar 26 05:33:59.692: INFO: Created: latency-svc-bk2lg
  Mar 26 05:33:59.739: INFO: Got endpoints: latency-svc-wvdsk [643.471832ms]
  Mar 26 05:33:59.743: INFO: Created: latency-svc-xmwvx
  Mar 26 05:33:59.789: INFO: Got endpoints: latency-svc-9nh4z [691.165371ms]
  Mar 26 05:33:59.793: INFO: Created: latency-svc-5j2lz
  Mar 26 05:33:59.839: INFO: Got endpoints: latency-svc-wghlx [737.769661ms]
  Mar 26 05:33:59.842: INFO: Created: latency-svc-2vfgq
  Mar 26 05:33:59.889: INFO: Got endpoints: latency-svc-4k4zv [749.883619ms]
  Mar 26 05:33:59.892: INFO: Created: latency-svc-jxkz4
  Mar 26 05:33:59.940: INFO: Got endpoints: latency-svc-ggsg8 [750.976008ms]
  Mar 26 05:33:59.943: INFO: Created: latency-svc-g6hc9
  Mar 26 05:33:59.988: INFO: Got endpoints: latency-svc-wld5q [748.609832ms]
  Mar 26 05:33:59.993: INFO: Created: latency-svc-z6ccs
  Mar 26 05:34:00.039: INFO: Got endpoints: latency-svc-hx8qq [749.919023ms]
  Mar 26 05:34:00.043: INFO: Created: latency-svc-pzndq
  Mar 26 05:34:00.089: INFO: Got endpoints: latency-svc-dpqbg [750.370617ms]
  Mar 26 05:34:00.092: INFO: Created: latency-svc-2s95g
  Mar 26 05:34:00.139: INFO: Got endpoints: latency-svc-w8lj6 [750.465878ms]
  Mar 26 05:34:00.142: INFO: Created: latency-svc-zss29
  Mar 26 05:34:00.189: INFO: Got endpoints: latency-svc-wdkbf [750.497422ms]
  Mar 26 05:34:00.193: INFO: Created: latency-svc-pmd2s
  Mar 26 05:34:00.238: INFO: Got endpoints: latency-svc-sz9p7 [749.436758ms]
  Mar 26 05:34:00.242: INFO: Created: latency-svc-95w56
  Mar 26 05:34:00.288: INFO: Got endpoints: latency-svc-c65nv [748.844621ms]
  Mar 26 05:34:00.292: INFO: Created: latency-svc-xnrv8
  Mar 26 05:34:00.339: INFO: Got endpoints: latency-svc-hplxk [749.392959ms]
  Mar 26 05:34:00.342: INFO: Created: latency-svc-kl2c9
  Mar 26 05:34:00.389: INFO: Got endpoints: latency-svc-84vhs [749.85608ms]
  Mar 26 05:34:00.393: INFO: Created: latency-svc-jlltm
  Mar 26 05:34:00.439: INFO: Got endpoints: latency-svc-bk2lg [750.847239ms]
  Mar 26 05:34:00.442: INFO: Created: latency-svc-z5lhk
  Mar 26 05:34:00.489: INFO: Got endpoints: latency-svc-xmwvx [750.021063ms]
  Mar 26 05:34:00.492: INFO: Created: latency-svc-m4l5k
  Mar 26 05:34:00.538: INFO: Got endpoints: latency-svc-5j2lz [748.730649ms]
  Mar 26 05:34:00.543: INFO: Created: latency-svc-j7lh9
  Mar 26 05:34:00.589: INFO: Got endpoints: latency-svc-2vfgq [749.794724ms]
  Mar 26 05:34:00.593: INFO: Created: latency-svc-64bs4
  Mar 26 05:34:00.639: INFO: Got endpoints: latency-svc-jxkz4 [750.712694ms]
  Mar 26 05:34:00.643: INFO: Created: latency-svc-792gm
  Mar 26 05:34:00.688: INFO: Got endpoints: latency-svc-g6hc9 [748.650737ms]
  Mar 26 05:34:00.692: INFO: Created: latency-svc-qzmcc
  Mar 26 05:34:00.739: INFO: Got endpoints: latency-svc-z6ccs [751.121506ms]
  Mar 26 05:34:00.743: INFO: Created: latency-svc-vnzlv
  Mar 26 05:34:00.790: INFO: Got endpoints: latency-svc-pzndq [750.565618ms]
  Mar 26 05:34:00.794: INFO: Created: latency-svc-n5sw6
  Mar 26 05:34:00.839: INFO: Got endpoints: latency-svc-2s95g [749.646808ms]
  Mar 26 05:34:00.842: INFO: Created: latency-svc-4268v
  Mar 26 05:34:00.889: INFO: Got endpoints: latency-svc-zss29 [749.804212ms]
  Mar 26 05:34:00.893: INFO: Created: latency-svc-7j7gf
  Mar 26 05:34:00.939: INFO: Got endpoints: latency-svc-pmd2s [749.44069ms]
  Mar 26 05:34:00.943: INFO: Created: latency-svc-z5bn5
  Mar 26 05:34:00.988: INFO: Got endpoints: latency-svc-95w56 [750.460932ms]
  Mar 26 05:34:00.992: INFO: Created: latency-svc-rsp9l
  Mar 26 05:34:01.039: INFO: Got endpoints: latency-svc-xnrv8 [750.240697ms]
  Mar 26 05:34:01.042: INFO: Created: latency-svc-wpjwb
  Mar 26 05:34:01.089: INFO: Got endpoints: latency-svc-kl2c9 [750.767863ms]
  Mar 26 05:34:01.093: INFO: Created: latency-svc-69rn7
  Mar 26 05:34:01.138: INFO: Got endpoints: latency-svc-jlltm [748.721173ms]
  Mar 26 05:34:01.142: INFO: Created: latency-svc-gdnl2
  Mar 26 05:34:01.189: INFO: Got endpoints: latency-svc-z5lhk [749.952345ms]
  Mar 26 05:34:01.193: INFO: Created: latency-svc-wbb6f
  Mar 26 05:34:01.238: INFO: Got endpoints: latency-svc-m4l5k [749.665667ms]
  Mar 26 05:34:01.242: INFO: Created: latency-svc-jmr9s
  Mar 26 05:34:01.288: INFO: Got endpoints: latency-svc-j7lh9 [750.375918ms]
  Mar 26 05:34:01.293: INFO: Created: latency-svc-9cq9c
  Mar 26 05:34:01.339: INFO: Got endpoints: latency-svc-64bs4 [750.582246ms]
  Mar 26 05:34:01.343: INFO: Created: latency-svc-s94sz
  Mar 26 05:34:01.389: INFO: Got endpoints: latency-svc-792gm [749.957673ms]
  Mar 26 05:34:01.393: INFO: Created: latency-svc-hfl5c
  Mar 26 05:34:01.439: INFO: Got endpoints: latency-svc-qzmcc [750.628151ms]
  Mar 26 05:34:01.443: INFO: Created: latency-svc-ccqgb
  Mar 26 05:34:01.489: INFO: Got endpoints: latency-svc-vnzlv [749.65138ms]
  Mar 26 05:34:01.493: INFO: Created: latency-svc-68hb9
  Mar 26 05:34:01.540: INFO: Got endpoints: latency-svc-n5sw6 [750.287522ms]
  Mar 26 05:34:01.544: INFO: Created: latency-svc-8znnk
  Mar 26 05:34:01.589: INFO: Got endpoints: latency-svc-4268v [750.287097ms]
  Mar 26 05:34:01.593: INFO: Created: latency-svc-n9v47
  Mar 26 05:34:01.639: INFO: Got endpoints: latency-svc-7j7gf [750.557478ms]
  Mar 26 05:34:01.644: INFO: Created: latency-svc-qlcs7
  Mar 26 05:34:01.688: INFO: Got endpoints: latency-svc-z5bn5 [749.613917ms]
  Mar 26 05:34:01.693: INFO: Created: latency-svc-fms4q
  Mar 26 05:34:01.739: INFO: Got endpoints: latency-svc-rsp9l [750.750634ms]
  Mar 26 05:34:01.743: INFO: Created: latency-svc-277th
  Mar 26 05:34:01.793: INFO: Got endpoints: latency-svc-wpjwb [754.563895ms]
  Mar 26 05:34:01.801: INFO: Created: latency-svc-vtjww
  Mar 26 05:34:01.839: INFO: Got endpoints: latency-svc-69rn7 [749.154264ms]
  Mar 26 05:34:01.842: INFO: Created: latency-svc-7z5tl
  Mar 26 05:34:01.888: INFO: Got endpoints: latency-svc-gdnl2 [750.311263ms]
  Mar 26 05:34:01.892: INFO: Created: latency-svc-zqzmt
  Mar 26 05:34:01.939: INFO: Got endpoints: latency-svc-wbb6f [749.634268ms]
  Mar 26 05:34:01.943: INFO: Created: latency-svc-8zvtd
  Mar 26 05:34:01.988: INFO: Got endpoints: latency-svc-jmr9s [749.97978ms]
  Mar 26 05:34:01.993: INFO: Created: latency-svc-wgwxw
  Mar 26 05:34:02.040: INFO: Got endpoints: latency-svc-9cq9c [751.93324ms]
  Mar 26 05:34:02.044: INFO: Created: latency-svc-7c2qr
  Mar 26 05:34:02.089: INFO: Got endpoints: latency-svc-s94sz [749.337028ms]
  Mar 26 05:34:02.093: INFO: Created: latency-svc-qn64b
  Mar 26 05:34:02.139: INFO: Got endpoints: latency-svc-hfl5c [749.269574ms]
  Mar 26 05:34:02.143: INFO: Created: latency-svc-ss6zb
  Mar 26 05:34:02.189: INFO: Got endpoints: latency-svc-ccqgb [749.607087ms]
  Mar 26 05:34:02.193: INFO: Created: latency-svc-dpbtp
  Mar 26 05:34:02.238: INFO: Got endpoints: latency-svc-68hb9 [749.298068ms]
  Mar 26 05:34:02.242: INFO: Created: latency-svc-zjlwc
  Mar 26 05:34:02.289: INFO: Got endpoints: latency-svc-8znnk [748.823193ms]
  Mar 26 05:34:02.293: INFO: Created: latency-svc-9fjvl
  Mar 26 05:34:02.339: INFO: Got endpoints: latency-svc-n9v47 [749.270417ms]
  Mar 26 05:34:02.343: INFO: Created: latency-svc-k9vnv
  Mar 26 05:34:02.389: INFO: Got endpoints: latency-svc-qlcs7 [749.448901ms]
  Mar 26 05:34:02.394: INFO: Created: latency-svc-5xr7x
  Mar 26 05:34:02.439: INFO: Got endpoints: latency-svc-fms4q [750.299493ms]
  Mar 26 05:34:02.443: INFO: Created: latency-svc-bp5zr
  Mar 26 05:34:02.489: INFO: Got endpoints: latency-svc-277th [749.885723ms]
  Mar 26 05:34:02.493: INFO: Created: latency-svc-dx9q9
  Mar 26 05:34:02.539: INFO: Got endpoints: latency-svc-vtjww [745.636172ms]
  Mar 26 05:34:02.542: INFO: Created: latency-svc-zcb5c
  Mar 26 05:34:02.588: INFO: Got endpoints: latency-svc-7z5tl [749.550311ms]
  Mar 26 05:34:02.592: INFO: Created: latency-svc-6fz29
  Mar 26 05:34:02.638: INFO: Got endpoints: latency-svc-zqzmt [750.088604ms]
  Mar 26 05:34:02.643: INFO: Created: latency-svc-7t9d9
  Mar 26 05:34:02.688: INFO: Got endpoints: latency-svc-8zvtd [749.148365ms]
  Mar 26 05:34:02.692: INFO: Created: latency-svc-f2wwq
  Mar 26 05:34:02.738: INFO: Got endpoints: latency-svc-wgwxw [749.762892ms]
  Mar 26 05:34:02.742: INFO: Created: latency-svc-cq2bz
  Mar 26 05:34:02.789: INFO: Got endpoints: latency-svc-7c2qr [748.721376ms]
  Mar 26 05:34:02.793: INFO: Created: latency-svc-8z466
  Mar 26 05:34:02.844: INFO: Got endpoints: latency-svc-qn64b [755.711493ms]
  Mar 26 05:34:02.865: INFO: Created: latency-svc-wnn7h
  Mar 26 05:34:02.891: INFO: Got endpoints: latency-svc-ss6zb [752.483987ms]
  Mar 26 05:34:02.901: INFO: Created: latency-svc-bxr2j
  Mar 26 05:34:02.938: INFO: Got endpoints: latency-svc-dpbtp [749.816424ms]
  Mar 26 05:34:02.943: INFO: Created: latency-svc-snxpz
  Mar 26 05:34:02.989: INFO: Got endpoints: latency-svc-zjlwc [750.345136ms]
  Mar 26 05:34:02.993: INFO: Created: latency-svc-nqj9z
  Mar 26 05:34:03.041: INFO: Got endpoints: latency-svc-9fjvl [751.521292ms]
  Mar 26 05:34:03.049: INFO: Created: latency-svc-2cmqk
  Mar 26 05:34:03.089: INFO: Got endpoints: latency-svc-k9vnv [750.68931ms]
  Mar 26 05:34:03.098: INFO: Created: latency-svc-m8n7v
  Mar 26 05:34:03.139: INFO: Got endpoints: latency-svc-5xr7x [750.483439ms]
  Mar 26 05:34:03.143: INFO: Created: latency-svc-tv9bx
  Mar 26 05:34:03.189: INFO: Got endpoints: latency-svc-bp5zr [750.329532ms]
  Mar 26 05:34:03.193: INFO: Created: latency-svc-kv2p8
  Mar 26 05:34:03.239: INFO: Got endpoints: latency-svc-dx9q9 [749.692972ms]
  Mar 26 05:34:03.243: INFO: Created: latency-svc-pspcx
  Mar 26 05:34:03.289: INFO: Got endpoints: latency-svc-zcb5c [749.653284ms]
  Mar 26 05:34:03.292: INFO: Created: latency-svc-v2jxs
  Mar 26 05:34:03.338: INFO: Got endpoints: latency-svc-6fz29 [749.482886ms]
  Mar 26 05:34:03.343: INFO: Created: latency-svc-l5tnx
  Mar 26 05:34:03.389: INFO: Got endpoints: latency-svc-7t9d9 [750.686216ms]
  Mar 26 05:34:03.393: INFO: Created: latency-svc-gnnpm
  Mar 26 05:34:03.439: INFO: Got endpoints: latency-svc-f2wwq [750.897193ms]
  Mar 26 05:34:03.443: INFO: Created: latency-svc-tl9ql
  Mar 26 05:34:03.488: INFO: Got endpoints: latency-svc-cq2bz [749.981864ms]
  Mar 26 05:34:03.492: INFO: Created: latency-svc-tl9ws
  Mar 26 05:34:03.539: INFO: Got endpoints: latency-svc-8z466 [750.25245ms]
  Mar 26 05:34:03.543: INFO: Created: latency-svc-jrjq5
  Mar 26 05:34:03.589: INFO: Got endpoints: latency-svc-wnn7h [744.561116ms]
  Mar 26 05:34:03.594: INFO: Created: latency-svc-sdjbs
  Mar 26 05:34:03.639: INFO: Got endpoints: latency-svc-bxr2j [748.040529ms]
  Mar 26 05:34:03.643: INFO: Created: latency-svc-6nlsr
  Mar 26 05:34:03.688: INFO: Got endpoints: latency-svc-snxpz [749.396551ms]
  Mar 26 05:34:03.692: INFO: Created: latency-svc-s9g92
  Mar 26 05:34:03.739: INFO: Got endpoints: latency-svc-nqj9z [750.316045ms]
  Mar 26 05:34:03.743: INFO: Created: latency-svc-gbtwd
  Mar 26 05:34:03.791: INFO: Got endpoints: latency-svc-2cmqk [750.469334ms]
  Mar 26 05:34:03.795: INFO: Created: latency-svc-lbdxd
  Mar 26 05:34:03.838: INFO: Got endpoints: latency-svc-m8n7v [748.953261ms]
  Mar 26 05:34:03.842: INFO: Created: latency-svc-srklt
  Mar 26 05:34:03.889: INFO: Got endpoints: latency-svc-tv9bx [750.086113ms]
  Mar 26 05:34:03.893: INFO: Created: latency-svc-hw7b7
  Mar 26 05:34:03.940: INFO: Got endpoints: latency-svc-kv2p8 [751.379187ms]
  Mar 26 05:34:03.944: INFO: Created: latency-svc-778s5
  Mar 26 05:34:03.989: INFO: Got endpoints: latency-svc-pspcx [750.289282ms]
  Mar 26 05:34:03.993: INFO: Created: latency-svc-mjhm8
  Mar 26 05:34:04.039: INFO: Got endpoints: latency-svc-v2jxs [750.425601ms]
  Mar 26 05:34:04.044: INFO: Created: latency-svc-jnllf
  Mar 26 05:34:04.089: INFO: Got endpoints: latency-svc-l5tnx [750.514026ms]
  Mar 26 05:34:04.093: INFO: Created: latency-svc-z2zkw
  Mar 26 05:34:04.138: INFO: Got endpoints: latency-svc-gnnpm [748.759064ms]
  Mar 26 05:34:04.142: INFO: Created: latency-svc-2glzs
  Mar 26 05:34:04.189: INFO: Got endpoints: latency-svc-tl9ql [749.687619ms]
  Mar 26 05:34:04.193: INFO: Created: latency-svc-p2gdg
  Mar 26 05:34:04.239: INFO: Got endpoints: latency-svc-tl9ws [750.67579ms]
  Mar 26 05:34:04.244: INFO: Created: latency-svc-hhgqz
  Mar 26 05:34:04.289: INFO: Got endpoints: latency-svc-jrjq5 [749.503177ms]
  Mar 26 05:34:04.293: INFO: Created: latency-svc-7xnqq
  Mar 26 05:34:04.339: INFO: Got endpoints: latency-svc-sdjbs [749.769847ms]
  Mar 26 05:34:04.342: INFO: Created: latency-svc-p7h8q
  Mar 26 05:34:04.389: INFO: Got endpoints: latency-svc-6nlsr [749.396732ms]
  Mar 26 05:34:04.393: INFO: Created: latency-svc-t2hdz
  Mar 26 05:34:04.439: INFO: Got endpoints: latency-svc-s9g92 [751.49516ms]
  Mar 26 05:34:04.443: INFO: Created: latency-svc-w6xz9
  Mar 26 05:34:04.488: INFO: Got endpoints: latency-svc-gbtwd [749.354783ms]
  Mar 26 05:34:04.493: INFO: Created: latency-svc-tscxz
  Mar 26 05:34:04.539: INFO: Got endpoints: latency-svc-lbdxd [747.445488ms]
  Mar 26 05:34:04.543: INFO: Created: latency-svc-8889d
  Mar 26 05:34:04.589: INFO: Got endpoints: latency-svc-srklt [750.095548ms]
  Mar 26 05:34:04.593: INFO: Created: latency-svc-xzgjx
  Mar 26 05:34:04.638: INFO: Got endpoints: latency-svc-hw7b7 [748.794475ms]
  Mar 26 05:34:04.642: INFO: Created: latency-svc-hq49n
  Mar 26 05:34:04.689: INFO: Got endpoints: latency-svc-778s5 [748.126251ms]
  Mar 26 05:34:04.692: INFO: Created: latency-svc-rkdpg
  Mar 26 05:34:04.738: INFO: Got endpoints: latency-svc-mjhm8 [749.279223ms]
  Mar 26 05:34:04.742: INFO: Created: latency-svc-qtmq2
  Mar 26 05:34:04.789: INFO: Got endpoints: latency-svc-jnllf [750.117899ms]
  Mar 26 05:34:04.793: INFO: Created: latency-svc-h7wwk
  Mar 26 05:34:04.838: INFO: Got endpoints: latency-svc-z2zkw [749.464178ms]
  Mar 26 05:34:04.842: INFO: Created: latency-svc-ngpvn
  Mar 26 05:34:04.888: INFO: Got endpoints: latency-svc-2glzs [749.895033ms]
  Mar 26 05:34:04.892: INFO: Created: latency-svc-ffpdp
  Mar 26 05:34:04.939: INFO: Got endpoints: latency-svc-p2gdg [749.970466ms]
  Mar 26 05:34:04.943: INFO: Created: latency-svc-vmhhq
  Mar 26 05:34:04.989: INFO: Got endpoints: latency-svc-hhgqz [749.597867ms]
  Mar 26 05:34:04.996: INFO: Created: latency-svc-ncfhh
  Mar 26 05:34:05.039: INFO: Got endpoints: latency-svc-7xnqq [749.634193ms]
  Mar 26 05:34:05.043: INFO: Created: latency-svc-5ttz7
  Mar 26 05:34:05.090: INFO: Got endpoints: latency-svc-p7h8q [750.605043ms]
  Mar 26 05:34:05.094: INFO: Created: latency-svc-wf7qh
  Mar 26 05:34:05.139: INFO: Got endpoints: latency-svc-t2hdz [749.769958ms]
  Mar 26 05:34:05.143: INFO: Created: latency-svc-thv9t
  Mar 26 05:34:05.189: INFO: Got endpoints: latency-svc-w6xz9 [749.198731ms]
  Mar 26 05:34:05.192: INFO: Created: latency-svc-gvlhb
  Mar 26 05:34:05.238: INFO: Got endpoints: latency-svc-tscxz [749.41722ms]
  Mar 26 05:34:05.242: INFO: Created: latency-svc-9rs4s
  Mar 26 05:34:05.289: INFO: Got endpoints: latency-svc-8889d [749.584214ms]
  Mar 26 05:34:05.293: INFO: Created: latency-svc-d4qbb
  Mar 26 05:34:05.339: INFO: Got endpoints: latency-svc-xzgjx [749.309244ms]
  Mar 26 05:34:05.343: INFO: Created: latency-svc-85nnz
  Mar 26 05:34:05.389: INFO: Got endpoints: latency-svc-hq49n [750.087377ms]
  Mar 26 05:34:05.393: INFO: Created: latency-svc-n2kl8
  Mar 26 05:34:05.439: INFO: Got endpoints: latency-svc-rkdpg [750.29331ms]
  Mar 26 05:34:05.442: INFO: Created: latency-svc-gw48m
  Mar 26 05:34:05.489: INFO: Got endpoints: latency-svc-qtmq2 [750.076605ms]
  Mar 26 05:34:05.493: INFO: Created: latency-svc-kv84w
  Mar 26 05:34:05.539: INFO: Got endpoints: latency-svc-h7wwk [749.68464ms]
  Mar 26 05:34:05.543: INFO: Created: latency-svc-jdnrg
  Mar 26 05:34:05.589: INFO: Got endpoints: latency-svc-ngpvn [750.339213ms]
  Mar 26 05:34:05.593: INFO: Created: latency-svc-shkmd
  Mar 26 05:34:05.639: INFO: Got endpoints: latency-svc-ffpdp [750.662789ms]
  Mar 26 05:34:05.642: INFO: Created: latency-svc-cls7k
  Mar 26 05:34:05.688: INFO: Got endpoints: latency-svc-vmhhq [748.978123ms]
  Mar 26 05:34:05.692: INFO: Created: latency-svc-fwsnd
  Mar 26 05:34:05.739: INFO: Got endpoints: latency-svc-ncfhh [749.784321ms]
  Mar 26 05:34:05.742: INFO: Created: latency-svc-466pd
  Mar 26 05:34:05.788: INFO: Got endpoints: latency-svc-5ttz7 [749.734861ms]
  Mar 26 05:34:05.793: INFO: Created: latency-svc-82fb9
  Mar 26 05:34:05.839: INFO: Got endpoints: latency-svc-wf7qh [748.93317ms]
  Mar 26 05:34:05.842: INFO: Created: latency-svc-sw7jx
  Mar 26 05:34:05.889: INFO: Got endpoints: latency-svc-thv9t [749.206836ms]
  Mar 26 05:34:05.892: INFO: Created: latency-svc-5vx8x
  Mar 26 05:34:05.939: INFO: Got endpoints: latency-svc-gvlhb [750.147311ms]
  Mar 26 05:34:05.943: INFO: Created: latency-svc-qtnxc
  Mar 26 05:34:05.991: INFO: Got endpoints: latency-svc-9rs4s [752.803963ms]
  Mar 26 05:34:05.996: INFO: Created: latency-svc-mbkc2
  Mar 26 05:34:06.039: INFO: Got endpoints: latency-svc-d4qbb [750.17934ms]
  Mar 26 05:34:06.043: INFO: Created: latency-svc-x2l77
  Mar 26 05:34:06.089: INFO: Got endpoints: latency-svc-85nnz [750.251012ms]
  Mar 26 05:34:06.093: INFO: Created: latency-svc-7f87k
  Mar 26 05:34:06.140: INFO: Got endpoints: latency-svc-n2kl8 [751.629403ms]
  Mar 26 05:34:06.145: INFO: Created: latency-svc-zk68g
  Mar 26 05:34:06.189: INFO: Got endpoints: latency-svc-gw48m [749.872336ms]
  Mar 26 05:34:06.193: INFO: Created: latency-svc-rkslp
  Mar 26 05:34:06.239: INFO: Got endpoints: latency-svc-kv84w [750.682391ms]
  Mar 26 05:34:06.243: INFO: Created: latency-svc-sz6hd
  Mar 26 05:34:06.289: INFO: Got endpoints: latency-svc-jdnrg [749.753572ms]
  Mar 26 05:34:06.292: INFO: Created: latency-svc-nhph7
  Mar 26 05:34:06.338: INFO: Got endpoints: latency-svc-shkmd [749.203377ms]
  Mar 26 05:34:06.342: INFO: Created: latency-svc-jzvwv
  Mar 26 05:34:06.388: INFO: Got endpoints: latency-svc-cls7k [749.25526ms]
  Mar 26 05:34:06.392: INFO: Created: latency-svc-j4c22
  Mar 26 05:34:06.439: INFO: Got endpoints: latency-svc-fwsnd [751.058908ms]
  Mar 26 05:34:06.443: INFO: Created: latency-svc-x782q
  Mar 26 05:34:06.496: INFO: Got endpoints: latency-svc-466pd [757.878482ms]
  Mar 26 05:34:06.500: INFO: Created: latency-svc-gxvl2
  Mar 26 05:34:06.538: INFO: Got endpoints: latency-svc-82fb9 [749.995544ms]
  Mar 26 05:34:06.542: INFO: Created: latency-svc-kzklb
  Mar 26 05:34:06.588: INFO: Got endpoints: latency-svc-sw7jx [749.725048ms]
  Mar 26 05:34:06.592: INFO: Created: latency-svc-ksfbf
  Mar 26 05:34:06.638: INFO: Got endpoints: latency-svc-5vx8x [749.724746ms]
  Mar 26 05:34:06.642: INFO: Created: latency-svc-759gb
  Mar 26 05:34:06.690: INFO: Got endpoints: latency-svc-qtnxc [750.710167ms]
  Mar 26 05:34:06.693: INFO: Created: latency-svc-jx5j5
  Mar 26 05:34:06.739: INFO: Got endpoints: latency-svc-mbkc2 [747.844961ms]
  Mar 26 05:34:06.744: INFO: Created: latency-svc-qcs28
  Mar 26 05:34:06.788: INFO: Got endpoints: latency-svc-x2l77 [749.378033ms]
  Mar 26 05:34:06.794: INFO: Created: latency-svc-6884p
  Mar 26 05:34:06.839: INFO: Got endpoints: latency-svc-7f87k [749.592264ms]
  Mar 26 05:34:06.889: INFO: Got endpoints: latency-svc-zk68g [748.617434ms]
  Mar 26 05:34:06.939: INFO: Got endpoints: latency-svc-rkslp [750.204225ms]
  Mar 26 05:34:06.988: INFO: Got endpoints: latency-svc-sz6hd [749.165934ms]
  Mar 26 05:34:07.039: INFO: Got endpoints: latency-svc-nhph7 [750.139396ms]
  Mar 26 05:34:07.090: INFO: Got endpoints: latency-svc-jzvwv [751.411719ms]
  Mar 26 05:34:07.138: INFO: Got endpoints: latency-svc-j4c22 [750.078142ms]
  Mar 26 05:34:07.189: INFO: Got endpoints: latency-svc-x782q [749.356715ms]
  Mar 26 05:34:07.238: INFO: Got endpoints: latency-svc-gxvl2 [741.883674ms]
  Mar 26 05:34:07.288: INFO: Got endpoints: latency-svc-kzklb [750.002885ms]
  Mar 26 05:34:07.338: INFO: Got endpoints: latency-svc-ksfbf [749.627164ms]
  Mar 26 05:34:07.389: INFO: Got endpoints: latency-svc-759gb [750.656372ms]
  Mar 26 05:34:07.439: INFO: Got endpoints: latency-svc-jx5j5 [748.991095ms]
  Mar 26 05:34:07.489: INFO: Got endpoints: latency-svc-qcs28 [750.071095ms]
  Mar 26 05:34:07.539: INFO: Got endpoints: latency-svc-6884p [750.648272ms]
  Mar 26 05:34:07.539: INFO: Latencies: [7.358079ms 14.144376ms 20.802356ms 23.651927ms 32.55504ms 33.476033ms 34.680006ms 35.817583ms 36.993889ms 38.584945ms 39.786182ms 42.094346ms 42.300225ms 42.782155ms 44.198752ms 45.378227ms 46.54873ms 46.571291ms 46.684252ms 47.361873ms 47.394661ms 52.497368ms 55.181024ms 55.194257ms 55.263508ms 55.491532ms 57.698893ms 60.144511ms 61.530678ms 63.235528ms 63.63333ms 85.114769ms 129.626337ms 172.101168ms 220.311651ms 268.500564ms 314.58239ms 360.831435ms 408.527126ms 455.428546ms 501.596107ms 549.661824ms 596.142729ms 643.471832ms 691.165371ms 737.769661ms 741.883674ms 744.561116ms 745.636172ms 747.445488ms 747.844961ms 748.040529ms 748.126251ms 748.609832ms 748.617434ms 748.650737ms 748.721173ms 748.721376ms 748.730649ms 748.759064ms 748.794475ms 748.823193ms 748.844621ms 748.93317ms 748.953261ms 748.978123ms 748.991095ms 749.148365ms 749.154264ms 749.165934ms 749.198731ms 749.203377ms 749.206836ms 749.25526ms 749.269574ms 749.270417ms 749.279223ms 749.298068ms 749.309244ms 749.337028ms 749.354783ms 749.356715ms 749.378033ms 749.392959ms 749.396551ms 749.396732ms 749.41722ms 749.436758ms 749.44069ms 749.448901ms 749.464178ms 749.482886ms 749.503177ms 749.550311ms 749.584214ms 749.592264ms 749.597867ms 749.607087ms 749.613917ms 749.627164ms 749.634193ms 749.634268ms 749.646808ms 749.65138ms 749.653284ms 749.665667ms 749.68464ms 749.687619ms 749.692972ms 749.724746ms 749.725048ms 749.734861ms 749.753572ms 749.762892ms 749.769847ms 749.769958ms 749.784321ms 749.794724ms 749.804212ms 749.816424ms 749.85608ms 749.872336ms 749.883619ms 749.885723ms 749.895033ms 749.919023ms 749.952345ms 749.957673ms 749.970466ms 749.97978ms 749.981864ms 749.995544ms 750.002885ms 750.021063ms 750.071095ms 750.076605ms 750.078142ms 750.086113ms 750.087377ms 750.088604ms 750.095548ms 750.117899ms 750.139396ms 750.147311ms 750.17934ms 750.204225ms 750.240697ms 750.251012ms 750.25245ms 750.287097ms 750.287522ms 750.289282ms 750.29331ms 750.299493ms 750.311263ms 750.316045ms 750.329532ms 750.339213ms 750.345136ms 750.370617ms 750.375918ms 750.425601ms 750.460932ms 750.465878ms 750.469334ms 750.483439ms 750.497422ms 750.514026ms 750.557478ms 750.565618ms 750.582246ms 750.605043ms 750.628151ms 750.648272ms 750.656372ms 750.662789ms 750.67579ms 750.682391ms 750.686216ms 750.68931ms 750.710167ms 750.712694ms 750.750634ms 750.767863ms 750.847239ms 750.897193ms 750.976008ms 751.058908ms 751.121506ms 751.379187ms 751.411719ms 751.49516ms 751.521292ms 751.629403ms 751.93324ms 752.483987ms 752.803963ms 754.563895ms 755.711493ms 757.878482ms]
  Mar 26 05:34:07.539: INFO: 50 %ile: 749.634193ms
  Mar 26 05:34:07.539: INFO: 90 %ile: 750.710167ms
  Mar 26 05:34:07.539: INFO: 99 %ile: 755.711493ms
  Mar 26 05:34:07.539: INFO: Total sample count: 200
  Mar 26 05:34:07.539: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-8963" for this suite. @ 03/26/24 05:34:07.542
• [9.728 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
test/e2e/network/service.go:2187
  STEP: Creating a kubernetes client @ 03/26/24 05:34:07.545
  Mar 26 05:34:07.545: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename services @ 03/26/24 05:34:07.545
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:34:07.55
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:34:07.551
  STEP: creating service in namespace services-1946 @ 03/26/24 05:34:07.553
  STEP: creating service affinity-clusterip-transition in namespace services-1946 @ 03/26/24 05:34:07.553
  STEP: creating replication controller affinity-clusterip-transition in namespace services-1946 @ 03/26/24 05:34:07.556
  I0326 05:34:07.558811      19 runners.go:197] Created replication controller with name: affinity-clusterip-transition, namespace: services-1946, replica count: 3
  I0326 05:34:10.611025      19 runners.go:197] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Mar 26 05:34:10.613: INFO: Creating new exec pod
  Mar 26 05:34:13.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-1946 exec execpod-affinitywrfp4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  Mar 26 05:34:13.713: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  Mar 26 05:34:13.713: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Mar 26 05:34:13.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-1946 exec execpod-affinitywrfp4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.73.187 80'
  Mar 26 05:34:13.808: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.73.187 80\nConnection to 10.96.73.187 80 port [tcp/http] succeeded!\n"
  Mar 26 05:34:13.808: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Mar 26 05:34:13.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-1946 exec execpod-affinitywrfp4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.73.187:80/ ; done'
  Mar 26 05:34:13.926: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n"
  Mar 26 05:34:13.926: INFO: stdout: "\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k"
  Mar 26 05:34:13.926: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:13.926: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:13.926: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:13.926: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:13.926: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:13.926: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:13.926: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:13.926: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:13.926: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:13.926: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:13.926: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:13.926: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:13.926: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:13.926: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:13.926: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:13.926: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:43.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-1946 exec execpod-affinitywrfp4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.73.187:80/ ; done'
  Mar 26 05:34:44.047: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n"
  Mar 26 05:34:44.047: INFO: stdout: "\naffinity-clusterip-transition-zmzkg\naffinity-clusterip-transition-9424b\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-zmzkg\naffinity-clusterip-transition-9424b\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-9424b\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-zmzkg\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-zmzkg\naffinity-clusterip-transition-zmzkg\naffinity-clusterip-transition-zmzkg\naffinity-clusterip-transition-zmzkg\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-9424b"
  Mar 26 05:34:44.047: INFO: Received response from host: affinity-clusterip-transition-zmzkg
  Mar 26 05:34:44.047: INFO: Received response from host: affinity-clusterip-transition-9424b
  Mar 26 05:34:44.047: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:44.047: INFO: Received response from host: affinity-clusterip-transition-zmzkg
  Mar 26 05:34:44.047: INFO: Received response from host: affinity-clusterip-transition-9424b
  Mar 26 05:34:44.047: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:44.047: INFO: Received response from host: affinity-clusterip-transition-9424b
  Mar 26 05:34:44.047: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:44.047: INFO: Received response from host: affinity-clusterip-transition-zmzkg
  Mar 26 05:34:44.047: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:44.047: INFO: Received response from host: affinity-clusterip-transition-zmzkg
  Mar 26 05:34:44.047: INFO: Received response from host: affinity-clusterip-transition-zmzkg
  Mar 26 05:34:44.047: INFO: Received response from host: affinity-clusterip-transition-zmzkg
  Mar 26 05:34:44.047: INFO: Received response from host: affinity-clusterip-transition-zmzkg
  Mar 26 05:34:44.047: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:44.047: INFO: Received response from host: affinity-clusterip-transition-9424b
  Mar 26 05:34:44.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-1946 exec execpod-affinitywrfp4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.73.187:80/ ; done'
  Mar 26 05:34:44.162: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.73.187:80/\n"
  Mar 26 05:34:44.162: INFO: stdout: "\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k\naffinity-clusterip-transition-rw42k"
  Mar 26 05:34:44.162: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:44.162: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:44.162: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:44.162: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:44.162: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:44.162: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:44.162: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:44.162: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:44.162: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:44.162: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:44.162: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:44.162: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:44.162: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:44.162: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:44.162: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:44.162: INFO: Received response from host: affinity-clusterip-transition-rw42k
  Mar 26 05:34:44.162: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Mar 26 05:34:44.164: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-1946, will wait for the garbage collector to delete the pods @ 03/26/24 05:34:44.169
  Mar 26 05:34:44.224: INFO: Deleting ReplicationController affinity-clusterip-transition took: 1.810878ms
  Mar 26 05:34:44.324: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.056607ms
  STEP: Destroying namespace "services-1946" for this suite. @ 03/26/24 05:34:47.53
• [39.988 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:52
  STEP: Creating a kubernetes client @ 03/26/24 05:34:47.533
  Mar 26 05:34:47.533: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubelet-test @ 03/26/24 05:34:47.534
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:34:47.54
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:34:47.541
  Mar 26 05:34:49.552: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-1684" for this suite. @ 03/26/24 05:34:49.553
• [2.022 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]
test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 03/26/24 05:34:49.556
  Mar 26 05:34:49.556: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename tables @ 03/26/24 05:34:49.557
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:34:49.565
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:34:49.566
  Mar 26 05:34:49.567: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-1005" for this suite. @ 03/26/24 05:34:49.569
• [0.016 seconds]
------------------------------
S
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]
test/e2e/common/node/expansion.go:300
  STEP: Creating a kubernetes client @ 03/26/24 05:34:49.572
  Mar 26 05:34:49.572: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename var-expansion @ 03/26/24 05:34:49.573
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:34:49.577
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:34:49.578
  STEP: creating the pod @ 03/26/24 05:34:49.579
  STEP: waiting for pod running @ 03/26/24 05:34:49.582
  STEP: creating a file in subpath @ 03/26/24 05:34:51.585
  Mar 26 05:34:51.586: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-3255 PodName:var-expansion-07b64e11-9a70-4722-b022-f2bee0988d52 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 05:34:51.586: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:34:51.587: INFO: ExecWithOptions: Clientset creation
  Mar 26 05:34:51.587: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-3255/pods/var-expansion-07b64e11-9a70-4722-b022-f2bee0988d52/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 03/26/24 05:34:51.626
  Mar 26 05:34:51.627: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-3255 PodName:var-expansion-07b64e11-9a70-4722-b022-f2bee0988d52 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 05:34:51.627: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:34:51.627: INFO: ExecWithOptions: Clientset creation
  Mar 26 05:34:51.628: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-3255/pods/var-expansion-07b64e11-9a70-4722-b022-f2bee0988d52/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 03/26/24 05:34:51.661
  Mar 26 05:34:52.167: INFO: Successfully updated pod "var-expansion-07b64e11-9a70-4722-b022-f2bee0988d52"
  STEP: waiting for annotated pod running @ 03/26/24 05:34:52.167
  STEP: deleting the pod gracefully @ 03/26/24 05:34:52.17
  Mar 26 05:34:52.170: INFO: Deleting pod "var-expansion-07b64e11-9a70-4722-b022-f2bee0988d52" in namespace "var-expansion-3255"
  Mar 26 05:34:52.173: INFO: Wait up to 5m0s for pod "var-expansion-07b64e11-9a70-4722-b022-f2bee0988d52" to be fully deleted
  Mar 26 05:35:26.213: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3255" for this suite. @ 03/26/24 05:35:26.214
• [36.644 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]
test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 03/26/24 05:35:26.217
  Mar 26 05:35:26.217: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename certificates @ 03/26/24 05:35:26.217
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:35:26.224
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:35:26.225
  STEP: getting /apis @ 03/26/24 05:35:26.531
  STEP: getting /apis/certificates.k8s.io @ 03/26/24 05:35:26.534
  STEP: getting /apis/certificates.k8s.io/v1 @ 03/26/24 05:35:26.534
  STEP: creating @ 03/26/24 05:35:26.535
  STEP: getting @ 03/26/24 05:35:26.541
  STEP: listing @ 03/26/24 05:35:26.542
  STEP: watching @ 03/26/24 05:35:26.543
  Mar 26 05:35:26.543: INFO: starting watch
  STEP: patching @ 03/26/24 05:35:26.543
  STEP: updating @ 03/26/24 05:35:26.545
  Mar 26 05:35:26.548: INFO: waiting for watch events with expected annotations
  Mar 26 05:35:26.548: INFO: saw patched and updated annotations
  STEP: getting /approval @ 03/26/24 05:35:26.548
  STEP: patching /approval @ 03/26/24 05:35:26.549
  STEP: updating /approval @ 03/26/24 05:35:26.551
  STEP: getting /status @ 03/26/24 05:35:26.553
  STEP: patching /status @ 03/26/24 05:35:26.554
  STEP: updating /status @ 03/26/24 05:35:26.557
  STEP: deleting @ 03/26/24 05:35:26.559
  STEP: deleting a collection @ 03/26/24 05:35:26.563
  Mar 26 05:35:26.566: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-5206" for this suite. @ 03/26/24 05:35:26.568
• [0.353 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:47
  STEP: Creating a kubernetes client @ 03/26/24 05:35:26.57
  Mar 26 05:35:26.570: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 05:35:26.571
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:35:26.576
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:35:26.577
  STEP: Creating configMap with name projected-configmap-test-volume-7de8d640-151d-48c6-a4d1-f4810e45e900 @ 03/26/24 05:35:26.578
  STEP: Creating a pod to test consume configMaps @ 03/26/24 05:35:26.579
  STEP: Saw pod success @ 03/26/24 05:35:28.584
  Mar 26 05:35:28.585: INFO: Trying to get logs from node k8s-worker02 pod pod-projected-configmaps-62fe7712-7eed-4ed6-a898-7f4cda2431a0 container agnhost-container: <nil>
  STEP: delete the pod @ 03/26/24 05:35:28.587
  Mar 26 05:35:28.591: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5329" for this suite. @ 03/26/24 05:35:28.593
• [2.024 seconds]
------------------------------
S
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]
test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 03/26/24 05:35:28.594
  Mar 26 05:35:28.594: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename proxy @ 03/26/24 05:35:28.595
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:35:28.6
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:35:28.601
  STEP: starting an echo server on multiple ports @ 03/26/24 05:35:28.607
  STEP: creating replication controller proxy-service-58p5m in namespace proxy-613 @ 03/26/24 05:35:28.607
  I0326 05:35:28.610655      19 runners.go:197] Created replication controller with name: proxy-service-58p5m, namespace: proxy-613, replica count: 1
  I0326 05:35:29.662439      19 runners.go:197] proxy-service-58p5m Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
  I0326 05:35:30.662626      19 runners.go:197] proxy-service-58p5m Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Mar 26 05:35:30.664: INFO: setup took 2.060999524s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 03/26/24 05:35:30.664
  Mar 26 05:35:30.667: INFO: (0) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 3.504389ms)
  Mar 26 05:35:30.668: INFO: (0) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 3.947891ms)
  Mar 26 05:35:30.668: INFO: (0) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">test</... (200; 4.222834ms)
  Mar 26 05:35:30.668: INFO: (0) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/rewriteme">test</a> (200; 4.16081ms)
  Mar 26 05:35:30.668: INFO: (0) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 4.396765ms)
  Mar 26 05:35:30.668: INFO: (0) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">t... (200; 4.364138ms)
  Mar 26 05:35:30.668: INFO: (0) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 4.373977ms)
  Mar 26 05:35:30.670: INFO: (0) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname1/proxy/: foo (200; 5.870293ms)
  Mar 26 05:35:30.670: INFO: (0) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname2/proxy/: bar (200; 5.973289ms)
  Mar 26 05:35:30.670: INFO: (0) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname2/proxy/: bar (200; 5.911059ms)
  Mar 26 05:35:30.670: INFO: (0) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname1/proxy/: foo (200; 5.966487ms)
  Mar 26 05:35:30.671: INFO: (0) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/tlsrewriteme... (200; 6.894324ms)
  Mar 26 05:35:30.671: INFO: (0) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname2/proxy/: tls qux (200; 6.883531ms)
  Mar 26 05:35:30.671: INFO: (0) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:462/proxy/: tls qux (200; 6.986685ms)
  Mar 26 05:35:30.671: INFO: (0) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:460/proxy/: tls baz (200; 7.079763ms)
  Mar 26 05:35:30.671: INFO: (0) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname1/proxy/: tls baz (200; 7.141557ms)
  Mar 26 05:35:30.674: INFO: (1) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 2.973138ms)
  Mar 26 05:35:30.674: INFO: (1) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 3.087553ms)
  Mar 26 05:35:30.674: INFO: (1) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname1/proxy/: foo (200; 3.298615ms)
  Mar 26 05:35:30.674: INFO: (1) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/rewriteme">test</a> (200; 3.290223ms)
  Mar 26 05:35:30.675: INFO: (1) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 3.502653ms)
  Mar 26 05:35:30.675: INFO: (1) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/tlsrewriteme... (200; 3.335264ms)
  Mar 26 05:35:30.675: INFO: (1) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname2/proxy/: bar (200; 3.39676ms)
  Mar 26 05:35:30.675: INFO: (1) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">test</... (200; 3.448483ms)
  Mar 26 05:35:30.675: INFO: (1) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname2/proxy/: tls qux (200; 3.554907ms)
  Mar 26 05:35:30.675: INFO: (1) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 3.417391ms)
  Mar 26 05:35:30.675: INFO: (1) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">t... (200; 3.497351ms)
  Mar 26 05:35:30.675: INFO: (1) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname1/proxy/: tls baz (200; 3.62853ms)
  Mar 26 05:35:30.675: INFO: (1) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname2/proxy/: bar (200; 3.596748ms)
  Mar 26 05:35:30.675: INFO: (1) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:462/proxy/: tls qux (200; 3.501846ms)
  Mar 26 05:35:30.675: INFO: (1) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname1/proxy/: foo (200; 3.469787ms)
  Mar 26 05:35:30.675: INFO: (1) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:460/proxy/: tls baz (200; 3.656904ms)
  Mar 26 05:35:30.678: INFO: (2) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">test</... (200; 2.716657ms)
  Mar 26 05:35:30.678: INFO: (2) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/rewriteme">test</a> (200; 2.729029ms)
  Mar 26 05:35:30.678: INFO: (2) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 2.753007ms)
  Mar 26 05:35:30.678: INFO: (2) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/tlsrewriteme... (200; 2.798888ms)
  Mar 26 05:35:30.678: INFO: (2) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">t... (200; 2.828105ms)
  Mar 26 05:35:30.678: INFO: (2) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 2.959339ms)
  Mar 26 05:35:30.678: INFO: (2) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 3.04183ms)
  Mar 26 05:35:30.678: INFO: (2) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 3.034637ms)
  Mar 26 05:35:30.678: INFO: (2) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname2/proxy/: tls qux (200; 3.061932ms)
  Mar 26 05:35:30.678: INFO: (2) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname1/proxy/: foo (200; 3.103902ms)
  Mar 26 05:35:30.678: INFO: (2) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:460/proxy/: tls baz (200; 3.188075ms)
  Mar 26 05:35:30.678: INFO: (2) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:462/proxy/: tls qux (200; 3.105378ms)
  Mar 26 05:35:30.678: INFO: (2) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname1/proxy/: tls baz (200; 3.077045ms)
  Mar 26 05:35:30.678: INFO: (2) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname2/proxy/: bar (200; 3.14183ms)
  Mar 26 05:35:30.678: INFO: (2) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname2/proxy/: bar (200; 3.16174ms)
  Mar 26 05:35:30.678: INFO: (2) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname1/proxy/: foo (200; 3.288021ms)
  Mar 26 05:35:30.681: INFO: (3) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 2.25862ms)
  Mar 26 05:35:30.681: INFO: (3) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">t... (200; 2.33056ms)
  Mar 26 05:35:30.681: INFO: (3) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 2.265337ms)
  Mar 26 05:35:30.681: INFO: (3) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/rewriteme">test</a> (200; 2.449289ms)
  Mar 26 05:35:30.681: INFO: (3) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:462/proxy/: tls qux (200; 2.74848ms)
  Mar 26 05:35:30.681: INFO: (3) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 2.527862ms)
  Mar 26 05:35:30.681: INFO: (3) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/tlsrewriteme... (200; 2.478473ms)
  Mar 26 05:35:30.681: INFO: (3) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 2.745979ms)
  Mar 26 05:35:30.681: INFO: (3) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:460/proxy/: tls baz (200; 2.552259ms)
  Mar 26 05:35:30.681: INFO: (3) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">test</... (200; 2.672302ms)
  Mar 26 05:35:30.681: INFO: (3) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname2/proxy/: bar (200; 2.972442ms)
  Mar 26 05:35:30.681: INFO: (3) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname1/proxy/: foo (200; 2.889331ms)
  Mar 26 05:35:30.681: INFO: (3) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname1/proxy/: foo (200; 3.169968ms)
  Mar 26 05:35:30.681: INFO: (3) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname2/proxy/: tls qux (200; 3.11808ms)
  Mar 26 05:35:30.681: INFO: (3) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname1/proxy/: tls baz (200; 2.96453ms)
  Mar 26 05:35:30.681: INFO: (3) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname2/proxy/: bar (200; 2.927242ms)
  Mar 26 05:35:30.691: INFO: (4) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/rewriteme">test</a> (200; 9.296124ms)
  Mar 26 05:35:30.691: INFO: (4) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname2/proxy/: bar (200; 9.341385ms)
  Mar 26 05:35:30.691: INFO: (4) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 9.397864ms)
  Mar 26 05:35:30.691: INFO: (4) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname1/proxy/: foo (200; 9.319651ms)
  Mar 26 05:35:30.691: INFO: (4) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 9.479884ms)
  Mar 26 05:35:30.691: INFO: (4) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">t... (200; 9.524133ms)
  Mar 26 05:35:30.691: INFO: (4) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">test</... (200; 9.312036ms)
  Mar 26 05:35:30.691: INFO: (4) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/tlsrewriteme... (200; 9.398355ms)
  Mar 26 05:35:30.691: INFO: (4) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname1/proxy/: foo (200; 9.651648ms)
  Mar 26 05:35:30.691: INFO: (4) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:460/proxy/: tls baz (200; 9.585295ms)
  Mar 26 05:35:30.691: INFO: (4) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:462/proxy/: tls qux (200; 9.677684ms)
  Mar 26 05:35:30.691: INFO: (4) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 9.535804ms)
  Mar 26 05:35:30.691: INFO: (4) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname2/proxy/: tls qux (200; 9.53176ms)
  Mar 26 05:35:30.691: INFO: (4) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname1/proxy/: tls baz (200; 9.619617ms)
  Mar 26 05:35:30.691: INFO: (4) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname2/proxy/: bar (200; 9.699492ms)
  Mar 26 05:35:30.692: INFO: (4) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 10.288715ms)
  Mar 26 05:35:30.694: INFO: (5) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">test</... (200; 1.779337ms)
  Mar 26 05:35:30.694: INFO: (5) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:460/proxy/: tls baz (200; 2.35795ms)
  Mar 26 05:35:30.694: INFO: (5) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 2.301611ms)
  Mar 26 05:35:30.695: INFO: (5) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 2.55047ms)
  Mar 26 05:35:30.695: INFO: (5) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname2/proxy/: bar (200; 2.516887ms)
  Mar 26 05:35:30.695: INFO: (5) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname1/proxy/: foo (200; 2.73311ms)
  Mar 26 05:35:30.694: INFO: (5) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 2.153389ms)
  Mar 26 05:35:30.695: INFO: (5) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 2.259869ms)
  Mar 26 05:35:30.695: INFO: (5) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/rewriteme">test</a> (200; 2.367973ms)
  Mar 26 05:35:30.695: INFO: (5) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname2/proxy/: tls qux (200; 2.577247ms)
  Mar 26 05:35:30.695: INFO: (5) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/tlsrewriteme... (200; 2.335829ms)
  Mar 26 05:35:30.695: INFO: (5) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">t... (200; 2.534855ms)
  Mar 26 05:35:30.695: INFO: (5) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:462/proxy/: tls qux (200; 2.480509ms)
  Mar 26 05:35:30.695: INFO: (5) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname1/proxy/: tls baz (200; 2.670069ms)
  Mar 26 05:35:30.695: INFO: (5) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname2/proxy/: bar (200; 2.487829ms)
  Mar 26 05:35:30.695: INFO: (5) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname1/proxy/: foo (200; 2.953262ms)
  Mar 26 05:35:30.698: INFO: (6) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 3.001373ms)
  Mar 26 05:35:30.699: INFO: (6) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">test</... (200; 3.421654ms)
  Mar 26 05:35:30.699: INFO: (6) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 3.228973ms)
  Mar 26 05:35:30.699: INFO: (6) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">t... (200; 3.66307ms)
  Mar 26 05:35:30.699: INFO: (6) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 3.49024ms)
  Mar 26 05:35:30.699: INFO: (6) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname1/proxy/: foo (200; 3.458595ms)
  Mar 26 05:35:30.699: INFO: (6) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 3.799716ms)
  Mar 26 05:35:30.699: INFO: (6) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:460/proxy/: tls baz (200; 3.791693ms)
  Mar 26 05:35:30.699: INFO: (6) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:462/proxy/: tls qux (200; 3.569401ms)
  Mar 26 05:35:30.699: INFO: (6) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/tlsrewriteme... (200; 3.717929ms)
  Mar 26 05:35:30.699: INFO: (6) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname2/proxy/: bar (200; 3.734177ms)
  Mar 26 05:35:30.699: INFO: (6) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/rewriteme">test</a> (200; 3.857801ms)
  Mar 26 05:35:30.699: INFO: (6) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname2/proxy/: bar (200; 4.159712ms)
  Mar 26 05:35:30.700: INFO: (6) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname1/proxy/: tls baz (200; 3.998862ms)
  Mar 26 05:35:30.700: INFO: (6) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname2/proxy/: tls qux (200; 4.224706ms)
  Mar 26 05:35:30.700: INFO: (6) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname1/proxy/: foo (200; 4.089574ms)
  Mar 26 05:35:30.704: INFO: (7) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 4.07762ms)
  Mar 26 05:35:30.704: INFO: (7) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/tlsrewriteme... (200; 3.947948ms)
  Mar 26 05:35:30.704: INFO: (7) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname2/proxy/: bar (200; 3.857898ms)
  Mar 26 05:35:30.704: INFO: (7) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">t... (200; 4.238932ms)
  Mar 26 05:35:30.704: INFO: (7) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 4.012522ms)
  Mar 26 05:35:30.704: INFO: (7) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname1/proxy/: foo (200; 4.421166ms)
  Mar 26 05:35:30.704: INFO: (7) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:462/proxy/: tls qux (200; 4.129066ms)
  Mar 26 05:35:30.704: INFO: (7) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 4.104128ms)
  Mar 26 05:35:30.704: INFO: (7) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname2/proxy/: tls qux (200; 4.559136ms)
  Mar 26 05:35:30.704: INFO: (7) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">test</... (200; 4.551318ms)
  Mar 26 05:35:30.704: INFO: (7) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:460/proxy/: tls baz (200; 4.484082ms)
  Mar 26 05:35:30.704: INFO: (7) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/rewriteme">test</a> (200; 4.421422ms)
  Mar 26 05:35:30.704: INFO: (7) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 4.424485ms)
  Mar 26 05:35:30.704: INFO: (7) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname1/proxy/: tls baz (200; 4.510405ms)
  Mar 26 05:35:30.704: INFO: (7) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname1/proxy/: foo (200; 4.425298ms)
  Mar 26 05:35:30.704: INFO: (7) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname2/proxy/: bar (200; 4.59126ms)
  Mar 26 05:35:30.706: INFO: (8) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 1.087239ms)
  Mar 26 05:35:30.707: INFO: (8) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:462/proxy/: tls qux (200; 2.008437ms)
  Mar 26 05:35:30.707: INFO: (8) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">test</... (200; 2.070955ms)
  Mar 26 05:35:30.707: INFO: (8) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 2.077957ms)
  Mar 26 05:35:30.707: INFO: (8) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 2.105914ms)
  Mar 26 05:35:30.707: INFO: (8) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/tlsrewriteme... (200; 2.10411ms)
  Mar 26 05:35:30.707: INFO: (8) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 2.075236ms)
  Mar 26 05:35:30.707: INFO: (8) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname2/proxy/: tls qux (200; 3.036724ms)
  Mar 26 05:35:30.707: INFO: (8) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">t... (200; 2.95055ms)
  Mar 26 05:35:30.707: INFO: (8) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/rewriteme">test</a> (200; 2.945965ms)
  Mar 26 05:35:30.708: INFO: (8) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:460/proxy/: tls baz (200; 2.961663ms)
  Mar 26 05:35:30.708: INFO: (8) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname2/proxy/: bar (200; 3.001918ms)
  Mar 26 05:35:30.708: INFO: (8) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname1/proxy/: foo (200; 3.176366ms)
  Mar 26 05:35:30.708: INFO: (8) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname2/proxy/: bar (200; 3.160677ms)
  Mar 26 05:35:30.708: INFO: (8) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname1/proxy/: tls baz (200; 3.229593ms)
  Mar 26 05:35:30.708: INFO: (8) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname1/proxy/: foo (200; 3.240302ms)
  Mar 26 05:35:30.709: INFO: (9) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 914.388µs)
  Mar 26 05:35:30.709: INFO: (9) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/rewriteme">test</a> (200; 1.37726ms)
  Mar 26 05:35:30.710: INFO: (9) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:460/proxy/: tls baz (200; 1.875491ms)
  Mar 26 05:35:30.710: INFO: (9) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:462/proxy/: tls qux (200; 1.950179ms)
  Mar 26 05:35:30.710: INFO: (9) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname1/proxy/: tls baz (200; 2.190559ms)
  Mar 26 05:35:30.710: INFO: (9) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname2/proxy/: bar (200; 2.287979ms)
  Mar 26 05:35:30.710: INFO: (9) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/tlsrewriteme... (200; 2.252663ms)
  Mar 26 05:35:30.710: INFO: (9) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 2.317647ms)
  Mar 26 05:35:30.710: INFO: (9) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">test</... (200; 2.320016ms)
  Mar 26 05:35:30.710: INFO: (9) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">t... (200; 2.367408ms)
  Mar 26 05:35:30.710: INFO: (9) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 2.4249ms)
  Mar 26 05:35:30.710: INFO: (9) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 2.40154ms)
  Mar 26 05:35:30.711: INFO: (9) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname1/proxy/: foo (200; 3.011032ms)
  Mar 26 05:35:30.711: INFO: (9) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname2/proxy/: tls qux (200; 3.022046ms)
  Mar 26 05:35:30.711: INFO: (9) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname1/proxy/: foo (200; 2.987838ms)
  Mar 26 05:35:30.711: INFO: (9) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname2/proxy/: bar (200; 3.094351ms)
  Mar 26 05:35:30.713: INFO: (10) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:460/proxy/: tls baz (200; 2.280574ms)
  Mar 26 05:35:30.713: INFO: (10) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/tlsrewriteme... (200; 2.109225ms)
  Mar 26 05:35:30.713: INFO: (10) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:462/proxy/: tls qux (200; 2.037824ms)
  Mar 26 05:35:30.713: INFO: (10) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">test</... (200; 2.314691ms)
  Mar 26 05:35:30.713: INFO: (10) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 2.172242ms)
  Mar 26 05:35:30.713: INFO: (10) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 2.099832ms)
  Mar 26 05:35:30.713: INFO: (10) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 2.290388ms)
  Mar 26 05:35:30.713: INFO: (10) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">t... (200; 2.333589ms)
  Mar 26 05:35:30.713: INFO: (10) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 2.487583ms)
  Mar 26 05:35:30.713: INFO: (10) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/rewriteme">test</a> (200; 2.249413ms)
  Mar 26 05:35:30.714: INFO: (10) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname2/proxy/: bar (200; 2.901587ms)
  Mar 26 05:35:30.714: INFO: (10) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname2/proxy/: tls qux (200; 3.286358ms)
  Mar 26 05:35:30.714: INFO: (10) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname2/proxy/: bar (200; 3.324669ms)
  Mar 26 05:35:30.714: INFO: (10) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname1/proxy/: foo (200; 3.235274ms)
  Mar 26 05:35:30.714: INFO: (10) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname1/proxy/: foo (200; 2.980662ms)
  Mar 26 05:35:30.714: INFO: (10) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname1/proxy/: tls baz (200; 3.301937ms)
  Mar 26 05:35:30.717: INFO: (11) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 2.100205ms)
  Mar 26 05:35:30.717: INFO: (11) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:460/proxy/: tls baz (200; 2.141316ms)
  Mar 26 05:35:30.717: INFO: (11) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">test</... (200; 2.131639ms)
  Mar 26 05:35:30.717: INFO: (11) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 2.269958ms)
  Mar 26 05:35:30.717: INFO: (11) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/tlsrewriteme... (200; 2.247609ms)
  Mar 26 05:35:30.717: INFO: (11) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/rewriteme">test</a> (200; 2.194751ms)
  Mar 26 05:35:30.717: INFO: (11) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:462/proxy/: tls qux (200; 2.198604ms)
  Mar 26 05:35:30.717: INFO: (11) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 2.596641ms)
  Mar 26 05:35:30.717: INFO: (11) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 2.711808ms)
  Mar 26 05:35:30.717: INFO: (11) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">t... (200; 2.728272ms)
  Mar 26 05:35:30.718: INFO: (11) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname1/proxy/: foo (200; 3.135427ms)
  Mar 26 05:35:30.718: INFO: (11) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname2/proxy/: bar (200; 3.205083ms)
  Mar 26 05:35:30.718: INFO: (11) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname1/proxy/: foo (200; 3.203552ms)
  Mar 26 05:35:30.718: INFO: (11) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname2/proxy/: bar (200; 3.198195ms)
  Mar 26 05:35:30.718: INFO: (11) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname2/proxy/: tls qux (200; 3.27412ms)
  Mar 26 05:35:30.718: INFO: (11) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname1/proxy/: tls baz (200; 3.390201ms)
  Mar 26 05:35:30.722: INFO: (12) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:462/proxy/: tls qux (200; 3.593781ms)
  Mar 26 05:35:30.722: INFO: (12) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 3.541937ms)
  Mar 26 05:35:30.722: INFO: (12) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">test</... (200; 3.701503ms)
  Mar 26 05:35:30.722: INFO: (12) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 3.71528ms)
  Mar 26 05:35:30.722: INFO: (12) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 3.700129ms)
  Mar 26 05:35:30.722: INFO: (12) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 3.618794ms)
  Mar 26 05:35:30.722: INFO: (12) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname1/proxy/: foo (200; 4.028275ms)
  Mar 26 05:35:30.722: INFO: (12) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">t... (200; 3.898001ms)
  Mar 26 05:35:30.722: INFO: (12) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/tlsrewriteme... (200; 3.733542ms)
  Mar 26 05:35:30.722: INFO: (12) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/rewriteme">test</a> (200; 3.806757ms)
  Mar 26 05:35:30.722: INFO: (12) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:460/proxy/: tls baz (200; 3.884301ms)
  Mar 26 05:35:30.723: INFO: (12) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname1/proxy/: tls baz (200; 4.782099ms)
  Mar 26 05:35:30.723: INFO: (12) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname2/proxy/: bar (200; 4.989472ms)
  Mar 26 05:35:30.723: INFO: (12) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname2/proxy/: tls qux (200; 4.976716ms)
  Mar 26 05:35:30.723: INFO: (12) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname1/proxy/: foo (200; 4.875787ms)
  Mar 26 05:35:30.723: INFO: (12) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname2/proxy/: bar (200; 4.776424ms)
  Mar 26 05:35:30.726: INFO: (13) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 2.466386ms)
  Mar 26 05:35:30.726: INFO: (13) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">t... (200; 2.430569ms)
  Mar 26 05:35:30.726: INFO: (13) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:462/proxy/: tls qux (200; 2.518299ms)
  Mar 26 05:35:30.726: INFO: (13) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/rewriteme">test</a> (200; 2.946827ms)
  Mar 26 05:35:30.726: INFO: (13) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">test</... (200; 2.905862ms)
  Mar 26 05:35:30.726: INFO: (13) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:460/proxy/: tls baz (200; 2.878706ms)
  Mar 26 05:35:30.726: INFO: (13) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 2.984541ms)
  Mar 26 05:35:30.726: INFO: (13) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/tlsrewriteme... (200; 2.951374ms)
  Mar 26 05:35:30.726: INFO: (13) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 2.973816ms)
  Mar 26 05:35:30.726: INFO: (13) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 2.956641ms)
  Mar 26 05:35:30.727: INFO: (13) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname1/proxy/: foo (200; 3.286799ms)
  Mar 26 05:35:30.727: INFO: (13) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname2/proxy/: bar (200; 3.350994ms)
  Mar 26 05:35:30.727: INFO: (13) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname1/proxy/: foo (200; 3.310846ms)
  Mar 26 05:35:30.727: INFO: (13) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname2/proxy/: bar (200; 3.311847ms)
  Mar 26 05:35:30.727: INFO: (13) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname1/proxy/: tls baz (200; 3.343158ms)
  Mar 26 05:35:30.727: INFO: (13) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname2/proxy/: tls qux (200; 3.519168ms)
  Mar 26 05:35:30.728: INFO: (14) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 1.203875ms)
  Mar 26 05:35:30.728: INFO: (14) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">t... (200; 1.492011ms)
  Mar 26 05:35:30.728: INFO: (14) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 1.533311ms)
  Mar 26 05:35:30.729: INFO: (14) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 1.798439ms)
  Mar 26 05:35:30.729: INFO: (14) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/rewriteme">test</a> (200; 2.008331ms)
  Mar 26 05:35:30.729: INFO: (14) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:460/proxy/: tls baz (200; 2.232161ms)
  Mar 26 05:35:30.729: INFO: (14) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/tlsrewriteme... (200; 2.255429ms)
  Mar 26 05:35:30.729: INFO: (14) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:462/proxy/: tls qux (200; 2.1747ms)
  Mar 26 05:35:30.730: INFO: (14) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 2.70002ms)
  Mar 26 05:35:30.730: INFO: (14) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">test</... (200; 2.73599ms)
  Mar 26 05:35:30.730: INFO: (14) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname2/proxy/: bar (200; 2.804212ms)
  Mar 26 05:35:30.730: INFO: (14) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname1/proxy/: foo (200; 2.994622ms)
  Mar 26 05:35:30.730: INFO: (14) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname1/proxy/: foo (200; 2.866872ms)
  Mar 26 05:35:30.730: INFO: (14) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname2/proxy/: tls qux (200; 3.15018ms)
  Mar 26 05:35:30.730: INFO: (14) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname2/proxy/: bar (200; 3.224333ms)
  Mar 26 05:35:30.730: INFO: (14) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname1/proxy/: tls baz (200; 3.074797ms)
  Mar 26 05:35:30.732: INFO: (15) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 1.35362ms)
  Mar 26 05:35:30.732: INFO: (15) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:460/proxy/: tls baz (200; 1.339834ms)
  Mar 26 05:35:30.732: INFO: (15) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 1.438784ms)
  Mar 26 05:35:30.732: INFO: (15) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/rewriteme">test</a> (200; 1.6049ms)
  Mar 26 05:35:30.732: INFO: (15) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:462/proxy/: tls qux (200; 1.571991ms)
  Mar 26 05:35:30.732: INFO: (15) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/tlsrewriteme... (200; 1.859371ms)
  Mar 26 05:35:30.732: INFO: (15) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname2/proxy/: tls qux (200; 2.049755ms)
  Mar 26 05:35:30.732: INFO: (15) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 1.816946ms)
  Mar 26 05:35:30.732: INFO: (15) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 1.952038ms)
  Mar 26 05:35:30.733: INFO: (15) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">t... (200; 2.115065ms)
  Mar 26 05:35:30.733: INFO: (15) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname2/proxy/: bar (200; 2.264926ms)
  Mar 26 05:35:30.733: INFO: (15) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">test</... (200; 2.51858ms)
  Mar 26 05:35:30.733: INFO: (15) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname1/proxy/: foo (200; 2.619277ms)
  Mar 26 05:35:30.733: INFO: (15) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname1/proxy/: tls baz (200; 2.785695ms)
  Mar 26 05:35:30.733: INFO: (15) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname2/proxy/: bar (200; 2.76796ms)
  Mar 26 05:35:30.733: INFO: (15) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname1/proxy/: foo (200; 2.892266ms)
  Mar 26 05:35:30.735: INFO: (16) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 1.44521ms)
  Mar 26 05:35:30.735: INFO: (16) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/rewriteme">test</a> (200; 1.982078ms)
  Mar 26 05:35:30.736: INFO: (16) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname2/proxy/: bar (200; 2.404675ms)
  Mar 26 05:35:30.736: INFO: (16) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">t... (200; 2.531735ms)
  Mar 26 05:35:30.736: INFO: (16) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 2.547937ms)
  Mar 26 05:35:30.736: INFO: (16) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 2.682423ms)
  Mar 26 05:35:30.736: INFO: (16) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">test</... (200; 2.640993ms)
  Mar 26 05:35:30.736: INFO: (16) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 2.641726ms)
  Mar 26 05:35:30.736: INFO: (16) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:462/proxy/: tls qux (200; 2.783633ms)
  Mar 26 05:35:30.736: INFO: (16) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:460/proxy/: tls baz (200; 2.732414ms)
  Mar 26 05:35:30.736: INFO: (16) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/tlsrewriteme... (200; 2.7192ms)
  Mar 26 05:35:30.737: INFO: (16) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname2/proxy/: tls qux (200; 3.401164ms)
  Mar 26 05:35:30.737: INFO: (16) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname2/proxy/: bar (200; 3.473179ms)
  Mar 26 05:35:30.737: INFO: (16) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname1/proxy/: foo (200; 3.511683ms)
  Mar 26 05:35:30.737: INFO: (16) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname1/proxy/: tls baz (200; 3.521204ms)
  Mar 26 05:35:30.737: INFO: (16) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname1/proxy/: foo (200; 3.677556ms)
  Mar 26 05:35:30.740: INFO: (17) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 2.380761ms)
  Mar 26 05:35:30.740: INFO: (17) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">test</... (200; 2.427703ms)
  Mar 26 05:35:30.740: INFO: (17) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:460/proxy/: tls baz (200; 2.464044ms)
  Mar 26 05:35:30.740: INFO: (17) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:462/proxy/: tls qux (200; 2.482559ms)
  Mar 26 05:35:30.740: INFO: (17) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 2.476725ms)
  Mar 26 05:35:30.740: INFO: (17) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 2.570805ms)
  Mar 26 05:35:30.740: INFO: (17) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 2.653727ms)
  Mar 26 05:35:30.740: INFO: (17) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/tlsrewriteme... (200; 2.709679ms)
  Mar 26 05:35:30.740: INFO: (17) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/rewriteme">test</a> (200; 2.757929ms)
  Mar 26 05:35:30.740: INFO: (17) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">t... (200; 2.618009ms)
  Mar 26 05:35:30.741: INFO: (17) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname1/proxy/: foo (200; 3.560182ms)
  Mar 26 05:35:30.741: INFO: (17) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname1/proxy/: foo (200; 3.720107ms)
  Mar 26 05:35:30.741: INFO: (17) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname2/proxy/: bar (200; 3.694232ms)
  Mar 26 05:35:30.741: INFO: (17) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname1/proxy/: tls baz (200; 3.813911ms)
  Mar 26 05:35:30.741: INFO: (17) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname2/proxy/: tls qux (200; 3.744914ms)
  Mar 26 05:35:30.741: INFO: (17) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname2/proxy/: bar (200; 3.767011ms)
  Mar 26 05:35:30.743: INFO: (18) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/tlsrewriteme... (200; 1.656139ms)
  Mar 26 05:35:30.743: INFO: (18) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">t... (200; 1.868251ms)
  Mar 26 05:35:30.743: INFO: (18) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">test</... (200; 1.797543ms)
  Mar 26 05:35:30.743: INFO: (18) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/rewriteme">test</a> (200; 1.817728ms)
  Mar 26 05:35:30.743: INFO: (18) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 1.899187ms)
  Mar 26 05:35:30.743: INFO: (18) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 1.986576ms)
  Mar 26 05:35:30.743: INFO: (18) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 1.959689ms)
  Mar 26 05:35:30.743: INFO: (18) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:460/proxy/: tls baz (200; 2.025395ms)
  Mar 26 05:35:30.743: INFO: (18) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:462/proxy/: tls qux (200; 2.062327ms)
  Mar 26 05:35:30.743: INFO: (18) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 2.181699ms)
  Mar 26 05:35:30.744: INFO: (18) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname2/proxy/: bar (200; 2.672096ms)
  Mar 26 05:35:30.744: INFO: (18) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname2/proxy/: tls qux (200; 2.777994ms)
  Mar 26 05:35:30.744: INFO: (18) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname1/proxy/: foo (200; 2.80245ms)
  Mar 26 05:35:30.744: INFO: (18) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname2/proxy/: bar (200; 2.832213ms)
  Mar 26 05:35:30.744: INFO: (18) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname1/proxy/: tls baz (200; 2.873989ms)
  Mar 26 05:35:30.744: INFO: (18) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname1/proxy/: foo (200; 3.025657ms)
  Mar 26 05:35:30.746: INFO: (19) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:462/proxy/: tls qux (200; 1.381978ms)
  Mar 26 05:35:30.746: INFO: (19) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">test</... (200; 1.449883ms)
  Mar 26 05:35:30.747: INFO: (19) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:443/proxy/tlsrewriteme... (200; 2.569642ms)
  Mar 26 05:35:30.747: INFO: (19) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 2.576455ms)
  Mar 26 05:35:30.747: INFO: (19) /api/v1/namespaces/proxy-613/pods/https:proxy-service-58p5m-ffm7s:460/proxy/: tls baz (200; 2.72486ms)
  Mar 26 05:35:30.747: INFO: (19) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 2.741375ms)
  Mar 26 05:35:30.747: INFO: (19) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:1080/proxy/rewriteme">t... (200; 2.844449ms)
  Mar 26 05:35:30.747: INFO: (19) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname1/proxy/: foo (200; 3.089525ms)
  Mar 26 05:35:30.747: INFO: (19) /api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/: <a href="/api/v1/namespaces/proxy-613/pods/proxy-service-58p5m-ffm7s/proxy/rewriteme">test</a> (200; 2.999461ms)
  Mar 26 05:35:30.747: INFO: (19) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname2/proxy/: bar (200; 3.109849ms)
  Mar 26 05:35:30.747: INFO: (19) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:160/proxy/: foo (200; 3.236395ms)
  Mar 26 05:35:30.748: INFO: (19) /api/v1/namespaces/proxy-613/pods/http:proxy-service-58p5m-ffm7s:162/proxy/: bar (200; 3.237478ms)
  Mar 26 05:35:30.748: INFO: (19) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname2/proxy/: tls qux (200; 3.273113ms)
  Mar 26 05:35:30.748: INFO: (19) /api/v1/namespaces/proxy-613/services/http:proxy-service-58p5m:portname1/proxy/: foo (200; 3.260866ms)
  Mar 26 05:35:30.748: INFO: (19) /api/v1/namespaces/proxy-613/services/proxy-service-58p5m:portname2/proxy/: bar (200; 3.383968ms)
  Mar 26 05:35:30.748: INFO: (19) /api/v1/namespaces/proxy-613/services/https:proxy-service-58p5m:tlsportname1/proxy/: tls baz (200; 3.369974ms)
  Mar 26 05:35:30.748: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController proxy-service-58p5m in namespace proxy-613, will wait for the garbage collector to delete the pods @ 03/26/24 05:35:30.749
  Mar 26 05:35:30.803: INFO: Deleting ReplicationController proxy-service-58p5m took: 2.461364ms
  Mar 26 05:35:30.904: INFO: Terminating ReplicationController proxy-service-58p5m pods took: 101.014626ms
  STEP: Destroying namespace "proxy-613" for this suite. @ 03/26/24 05:35:33.605
• [5.012 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]
test/e2e/apimachinery/discovery.go:169
  STEP: Creating a kubernetes client @ 03/26/24 05:35:33.608
  Mar 26 05:35:33.608: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename discovery @ 03/26/24 05:35:33.608
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:35:33.614
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:35:33.615
  STEP: Setting up server cert @ 03/26/24 05:35:33.616
  STEP: Requesting APIResourceList from "/api/v1" @ 03/26/24 05:35:33.848
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 03/26/24 05:35:33.849
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 03/26/24 05:35:33.85
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 03/26/24 05:35:33.85
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 03/26/24 05:35:33.85
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 03/26/24 05:35:33.851
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 03/26/24 05:35:33.851
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 03/26/24 05:35:33.852
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 03/26/24 05:35:33.852
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 03/26/24 05:35:33.852
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 03/26/24 05:35:33.853
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 03/26/24 05:35:33.853
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 03/26/24 05:35:33.853
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 03/26/24 05:35:33.854
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 03/26/24 05:35:33.854
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 03/26/24 05:35:33.854
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 03/26/24 05:35:33.855
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 03/26/24 05:35:33.855
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 03/26/24 05:35:33.855
  Mar 26 05:35:33.856: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-1127" for this suite. @ 03/26/24 05:35:33.857
• [0.252 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance]
test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 03/26/24 05:35:33.86
  Mar 26 05:35:33.860: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename events @ 03/26/24 05:35:33.86
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:35:33.865
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:35:33.867
  STEP: Create set of events @ 03/26/24 05:35:33.868
  STEP: get a list of Events with a label in the current namespace @ 03/26/24 05:35:33.872
  STEP: delete a list of events @ 03/26/24 05:35:33.873
  Mar 26 05:35:33.873: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 03/26/24 05:35:33.883
  Mar 26 05:35:33.884: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-5592" for this suite. @ 03/26/24 05:35:33.885
• [0.028 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 03/26/24 05:35:33.888
  Mar 26 05:35:33.888: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename secrets @ 03/26/24 05:35:33.889
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:35:33.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:35:33.895
  STEP: Creating secret with name secret-test-map-aaba5516-9e64-4652-a793-68c6c921d79c @ 03/26/24 05:35:33.896
  STEP: Creating a pod to test consume secrets @ 03/26/24 05:35:33.898
  STEP: Saw pod success @ 03/26/24 05:35:35.906
  Mar 26 05:35:35.907: INFO: Trying to get logs from node k8s-worker02 pod pod-secrets-9cb6c33e-ee1e-49c0-9efd-209f0834215a container secret-volume-test: <nil>
  STEP: delete the pod @ 03/26/24 05:35:35.909
  Mar 26 05:35:35.913: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9093" for this suite. @ 03/26/24 05:35:35.915
• [2.028 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]
test/e2e/apps/cronjob.go:161
  STEP: Creating a kubernetes client @ 03/26/24 05:35:35.917
  Mar 26 05:35:35.917: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename cronjob @ 03/26/24 05:35:35.917
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:35:35.922
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:35:35.923
  STEP: Creating a ReplaceConcurrent cronjob @ 03/26/24 05:35:35.925
  STEP: Ensuring a job is scheduled @ 03/26/24 05:35:35.926
  STEP: Ensuring exactly one is scheduled @ 03/26/24 05:36:01.929
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 03/26/24 05:36:01.93
  STEP: Ensuring the job is replaced with a new one @ 03/26/24 05:36:01.931
  STEP: Removing cronjob @ 03/26/24 05:37:01.934
  Mar 26 05:37:01.936: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-2734" for this suite. @ 03/26/24 05:37:01.938
• [86.024 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 03/26/24 05:37:01.944
  Mar 26 05:37:01.944: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename containers @ 03/26/24 05:37:01.945
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:37:01.953
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:37:01.954
  Mar 26 05:37:03.966: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-92" for this suite. @ 03/26/24 05:37:03.968
• [2.027 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
test/e2e/apimachinery/garbage_collector.go:638
  STEP: Creating a kubernetes client @ 03/26/24 05:37:03.971
  Mar 26 05:37:03.971: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename gc @ 03/26/24 05:37:03.972
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:37:03.978
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:37:03.979
  STEP: create the rc @ 03/26/24 05:37:03.982
  W0326 05:37:03.983906      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: delete the rc @ 03/26/24 05:37:07.989
  STEP: wait for the rc to be deleted @ 03/26/24 05:37:08.003
  Mar 26 05:37:09.018: INFO: 80 pods remaining
  Mar 26 05:37:09.018: INFO: 80 pods has nil DeletionTimestamp
  Mar 26 05:37:09.018: INFO: 
  Mar 26 05:37:10.017: INFO: 70 pods remaining
  Mar 26 05:37:10.017: INFO: 70 pods has nil DeletionTimestamp
  Mar 26 05:37:10.017: INFO: 
  Mar 26 05:37:11.008: INFO: 60 pods remaining
  Mar 26 05:37:11.008: INFO: 60 pods has nil DeletionTimestamp
  Mar 26 05:37:11.008: INFO: 
  Mar 26 05:37:12.018: INFO: 40 pods remaining
  Mar 26 05:37:12.018: INFO: 40 pods has nil DeletionTimestamp
  Mar 26 05:37:12.018: INFO: 
  Mar 26 05:37:13.014: INFO: 31 pods remaining
  Mar 26 05:37:13.014: INFO: 30 pods has nil DeletionTimestamp
  Mar 26 05:37:13.014: INFO: 
  Mar 26 05:37:14.006: INFO: 20 pods remaining
  Mar 26 05:37:14.006: INFO: 20 pods has nil DeletionTimestamp
  Mar 26 05:37:14.006: INFO: 
  STEP: Gathering metrics @ 03/26/24 05:37:15.012
  Mar 26 05:37:15.089: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Mar 26 05:37:15.089: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5870" for this suite. @ 03/26/24 05:37:15.094
• [11.130 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 03/26/24 05:37:15.102
  Mar 26 05:37:15.102: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename secrets @ 03/26/24 05:37:15.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:37:15.112
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:37:15.114
  STEP: Creating secret with name secret-test-36b60429-6728-4849-bc13-c508fe560625 @ 03/26/24 05:37:15.116
  STEP: Creating a pod to test consume secrets @ 03/26/24 05:37:15.118
  STEP: Saw pod success @ 03/26/24 05:37:19.131
  Mar 26 05:37:19.132: INFO: Trying to get logs from node k8s-worker01 pod pod-secrets-7265942d-6acd-4a53-b191-4702205e8a52 container secret-volume-test: <nil>
  STEP: delete the pod @ 03/26/24 05:37:19.134
  Mar 26 05:37:19.139: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1952" for this suite. @ 03/26/24 05:37:19.141
• [4.041 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]
test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 03/26/24 05:37:19.144
  Mar 26 05:37:19.144: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename subpath @ 03/26/24 05:37:19.145
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:37:19.15
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:37:19.151
  STEP: Setting up data @ 03/26/24 05:37:19.152
  STEP: Creating pod pod-subpath-test-secret-pc2w @ 03/26/24 05:37:19.155
  STEP: Creating a pod to test atomic-volume-subpath @ 03/26/24 05:37:19.155
  STEP: Saw pod success @ 03/26/24 05:37:41.19
  Mar 26 05:37:41.192: INFO: Trying to get logs from node k8s-worker01 pod pod-subpath-test-secret-pc2w container test-container-subpath-secret-pc2w: <nil>
  STEP: delete the pod @ 03/26/24 05:37:41.194
  STEP: Deleting pod pod-subpath-test-secret-pc2w @ 03/26/24 05:37:41.2
  Mar 26 05:37:41.200: INFO: Deleting pod "pod-subpath-test-secret-pc2w" in namespace "subpath-3542"
  Mar 26 05:37:41.201: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3542" for this suite. @ 03/26/24 05:37:41.202
• [22.061 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
test/e2e/common/node/sysctl.go:123
  STEP: Creating a kubernetes client @ 03/26/24 05:37:41.205
  Mar 26 05:37:41.205: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename sysctl @ 03/26/24 05:37:41.206
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:37:41.211
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:37:41.212
  STEP: Creating a pod with one valid and two invalid sysctls @ 03/26/24 05:37:41.213
  Mar 26 05:37:41.216: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-9288" for this suite. @ 03/26/24 05:37:41.217
• [0.015 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]
test/e2e/kubectl/kubectl.go:1342
  STEP: Creating a kubernetes client @ 03/26/24 05:37:41.225
  Mar 26 05:37:41.225: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubectl @ 03/26/24 05:37:41.225
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:37:41.232
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:37:41.233
  Mar 26 05:37:41.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-5354 create -f -'
  Mar 26 05:37:41.393: INFO: stderr: ""
  Mar 26 05:37:41.393: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  Mar 26 05:37:41.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-5354 create -f -'
  Mar 26 05:37:41.524: INFO: stderr: ""
  Mar 26 05:37:41.524: INFO: stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 03/26/24 05:37:41.524
  Mar 26 05:37:42.526: INFO: Selector matched 1 pods for map[app:agnhost]
  Mar 26 05:37:42.526: INFO: Found 0 / 1
  Mar 26 05:37:43.525: INFO: Selector matched 1 pods for map[app:agnhost]
  Mar 26 05:37:43.525: INFO: Found 1 / 1
  Mar 26 05:37:43.526: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Mar 26 05:37:43.527: INFO: Selector matched 1 pods for map[app:agnhost]
  Mar 26 05:37:43.527: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Mar 26 05:37:43.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-5354 describe pod agnhost-primary-tnv69'
  Mar 26 05:37:43.570: INFO: stderr: ""
  Mar 26 05:37:43.570: INFO: stdout: "Name:             agnhost-primary-tnv69\nNamespace:        kubectl-5354\nPriority:         0\nService Account:  default\nNode:             k8s-worker02/192.168.132.15\nStart Time:       Tue, 26 Mar 2024 05:37:41 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: f3c0bd1dc6af68203891053017d25434bb191305fdf4dce860192a7fa9fb2569\n                  cni.projectcalico.org/podIP: 10.244.69.231/32\n                  cni.projectcalico.org/podIPs: 10.244.69.231/32\nStatus:           Running\nIP:               10.244.69.231\nIPs:\n  IP:           10.244.69.231\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   cri-o://a0436a597b0f7d89898a382ea6fe1669d339b82eceb0ef39de43f0f430b9a826\n    Image:          hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45\n    Image ID:       hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost@sha256:8f07c07228b54f5d644c14241ad3e483b999c5d3a78f7580a6252c8ab42f2b66\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 26 Mar 2024 05:37:41 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-tb5dx (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-tb5dx:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-5354/agnhost-primary-tnv69 to k8s-worker02\n  Normal  Pulled     2s    kubelet            Container image \"hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    2s    kubelet            Started container agnhost-primary\n"
  Mar 26 05:37:43.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-5354 describe rc agnhost-primary'
  Mar 26 05:37:43.613: INFO: stderr: ""
  Mar 26 05:37:43.613: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-5354\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-tnv69\n"
  Mar 26 05:37:43.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-5354 describe service agnhost-primary'
  Mar 26 05:37:43.654: INFO: stderr: ""
  Mar 26 05:37:43.654: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-5354\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.96.250.241\nIPs:               10.96.250.241\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.244.69.231:6379\nSession Affinity:  None\nEvents:            <none>\n"
  Mar 26 05:37:43.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-5354 describe node k8s-master01'
  Mar 26 05:37:43.713: INFO: stderr: ""
  Mar 26 05:37:43.713: INFO: stdout: "Name:               k8s-master01\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=k8s-master01\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/crio/crio.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 192.168.132.11/24\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.244.32.128\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 26 Mar 2024 01:40:03 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  k8s-master01\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 26 Mar 2024 05:37:43 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 26 Mar 2024 03:13:11 +0000   Tue, 26 Mar 2024 03:13:11 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Tue, 26 Mar 2024 05:36:00 +0000   Tue, 26 Mar 2024 01:40:01 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 26 Mar 2024 05:36:00 +0000   Tue, 26 Mar 2024 01:40:01 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 26 Mar 2024 05:36:00 +0000   Tue, 26 Mar 2024 01:40:01 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 26 Mar 2024 05:36:00 +0000   Tue, 26 Mar 2024 01:40:03 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.132.11\n  Hostname:    k8s-master01\nCapacity:\n  cpu:                    4\n  ephemeral-storage:      51893228Ki\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 8039012Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nAllocatable:\n  cpu:                    4\n  ephemeral-storage:      47824798846\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 7936612Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nSystem Info:\n  Machine ID:                 0f3cbb7bbdb44c5cbb9b82d6dd6648e7\n  System UUID:                0f3cbb7b-bdb4-4c5c-bb9b-82d6dd6648e7\n  Boot ID:                    eb99493d-bae3-4238-8774-272442f6dbc2\n  Kernel Version:             5.10.0-172.1.3.oe2203sp3.x86_64\n  OS Image:                   NestOS For Container 22.03LTS_SP3\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  cri-o://1.23.2\n  Kubelet Version:            v1.28.0\n  Kube-Proxy Version:         v1.28.0\nPodCIDR:                      10.244.0.0/24\nPodCIDRs:                     10.244.0.0/24\nNon-terminated Pods:          (10 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-kube-controllers-658d97c59c-j8hzg                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         3h57m\n  kube-system                 calico-node-ld9rp                                          250m (6%)     0 (0%)      0 (0%)           0 (0%)         3h57m\n  kube-system                 coredns-6554b8b87f-5qtsr                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     3h57m\n  kube-system                 coredns-6554b8b87f-745fg                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     3h57m\n  kube-system                 etcd-k8s-master01                                          100m (2%)     0 (0%)      100Mi (1%)       0 (0%)         3h57m\n  kube-system                 kube-apiserver-k8s-master01                                250m (6%)     0 (0%)      0 (0%)           0 (0%)         3h57m\n  kube-system                 kube-controller-manager-k8s-master01                       200m (5%)     0 (0%)      0 (0%)           0 (0%)         3h57m\n  kube-system                 kube-proxy-m9s5h                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         3h57m\n  kube-system                 kube-scheduler-k8s-master01                                100m (2%)     0 (0%)      0 (0%)           0 (0%)         3h57m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-c080bc1d82d24b52-pmc2w    0 (0%)        0 (0%)      0 (0%)           0 (0%)         4m49s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource               Requests     Limits\n  --------               --------     ------\n  cpu                    1100m (27%)  0 (0%)\n  memory                 240Mi (3%)   340Mi (4%)\n  ephemeral-storage      0 (0%)       0 (0%)\n  hugepages-1Gi          0 (0%)       0 (0%)\n  hugepages-2Mi          0 (0%)       0 (0%)\n  scheduling.k8s.io/foo  0            0\nEvents:                  <none>\n"
  Mar 26 05:37:43.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-5354 describe namespace kubectl-5354'
  Mar 26 05:37:43.755: INFO: stderr: ""
  Mar 26 05:37:43.755: INFO: stdout: "Name:         kubectl-5354\nLabels:       e2e-framework=kubectl\n              e2e-run=1d6c2f50-9292-4192-97b8-6b9f8e6e7376\n              kubernetes.io/metadata.name=kubectl-5354\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  Mar 26 05:37:43.755: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5354" for this suite. @ 03/26/24 05:37:43.756
• [2.534 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:104
  STEP: Creating a kubernetes client @ 03/26/24 05:37:43.759
  Mar 26 05:37:43.759: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename runtimeclass @ 03/26/24 05:37:43.76
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:37:43.767
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:37:43.768
  Mar 26 05:37:43.776: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-353" for this suite. @ 03/26/24 05:37:43.78
• [0.023 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]
test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 03/26/24 05:37:43.784
  Mar 26 05:37:43.784: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename daemonsets @ 03/26/24 05:37:43.784
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:37:43.789
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:37:43.79
  STEP: Creating a simple DaemonSet "daemon-set" @ 03/26/24 05:37:43.798
  STEP: Check that daemon pods launch on every node of the cluster. @ 03/26/24 05:37:43.801
  Mar 26 05:37:43.803: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Mar 26 05:37:43.803: INFO: Node k8s-master01 is running 0 daemon pod, expected 1
  Mar 26 05:37:44.807: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Mar 26 05:37:44.807: INFO: Node k8s-worker01 is running 0 daemon pod, expected 1
  Mar 26 05:37:45.807: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Mar 26 05:37:45.807: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 03/26/24 05:37:45.808
  Mar 26 05:37:45.817: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Mar 26 05:37:45.817: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 03/26/24 05:37:45.817
  STEP: Deleting DaemonSet "daemon-set" @ 03/26/24 05:37:46.823
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6561, will wait for the garbage collector to delete the pods @ 03/26/24 05:37:46.823
  Mar 26 05:37:46.877: INFO: Deleting DaemonSet.extensions daemon-set took: 1.848144ms
  Mar 26 05:37:46.978: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.102422ms
  Mar 26 05:37:49.179: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Mar 26 05:37:49.179: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Mar 26 05:37:49.180: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"73332"},"items":null}

  Mar 26 05:37:49.182: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"73332"},"items":null}

  Mar 26 05:37:49.186: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6561" for this suite. @ 03/26/24 05:37:49.188
• [5.406 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]
test/e2e/auth/service_accounts.go:647
  STEP: Creating a kubernetes client @ 03/26/24 05:37:49.202
  Mar 26 05:37:49.202: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename svcaccounts @ 03/26/24 05:37:49.202
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:37:49.208
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:37:49.209
  STEP: creating a ServiceAccount @ 03/26/24 05:37:49.211
  STEP: watching for the ServiceAccount to be added @ 03/26/24 05:37:49.213
  STEP: patching the ServiceAccount @ 03/26/24 05:37:49.214
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 03/26/24 05:37:49.216
  STEP: deleting the ServiceAccount @ 03/26/24 05:37:49.217
  Mar 26 05:37:49.220: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-178" for this suite. @ 03/26/24 05:37:49.222
• [0.023 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]
test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 03/26/24 05:37:49.226
  Mar 26 05:37:49.226: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename cronjob @ 03/26/24 05:37:49.226
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:37:49.232
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:37:49.233
  STEP: Creating a cronjob @ 03/26/24 05:37:49.234
  STEP: Ensuring more than one job is running at a time @ 03/26/24 05:37:49.236
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 03/26/24 05:39:01.238
  STEP: Removing cronjob @ 03/26/24 05:39:01.24
  Mar 26 05:39:01.242: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-9598" for this suite. @ 03/26/24 05:39:01.243
• [72.021 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 03/26/24 05:39:01.247
  Mar 26 05:39:01.247: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename container-runtime @ 03/26/24 05:39:01.248
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:39:01.257
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:39:01.259
  STEP: create the container @ 03/26/24 05:39:01.262
  W0326 05:39:01.266977      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 03/26/24 05:39:01.267
  STEP: get the container status @ 03/26/24 05:39:03.272
  STEP: the container should be terminated @ 03/26/24 05:39:03.273
  STEP: the termination message should be set @ 03/26/24 05:39:03.273
  Mar 26 05:39:03.273: INFO: Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 03/26/24 05:39:03.273
  Mar 26 05:39:03.277: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-1638" for this suite. @ 03/26/24 05:39:03.28
• [2.035 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]
test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 03/26/24 05:39:03.285
  Mar 26 05:39:03.285: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename daemonsets @ 03/26/24 05:39:03.285
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:39:03.29
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:39:03.292
  Mar 26 05:39:03.301: INFO: Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 03/26/24 05:39:03.303
  Mar 26 05:39:03.304: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Mar 26 05:39:03.304: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 03/26/24 05:39:03.304
  Mar 26 05:39:03.312: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Mar 26 05:39:03.312: INFO: Node k8s-worker02 is running 0 daemon pod, expected 1
  Mar 26 05:39:04.314: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Mar 26 05:39:04.314: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 03/26/24 05:39:04.316
  Mar 26 05:39:04.323: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Mar 26 05:39:04.323: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  Mar 26 05:39:05.325: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Mar 26 05:39:05.325: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 03/26/24 05:39:05.325
  Mar 26 05:39:05.330: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Mar 26 05:39:05.330: INFO: Node k8s-worker02 is running 0 daemon pod, expected 1
  Mar 26 05:39:06.332: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Mar 26 05:39:06.332: INFO: Node k8s-worker02 is running 0 daemon pod, expected 1
  Mar 26 05:39:07.331: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Mar 26 05:39:07.331: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 03/26/24 05:39:07.334
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5029, will wait for the garbage collector to delete the pods @ 03/26/24 05:39:07.334
  Mar 26 05:39:07.387: INFO: Deleting DaemonSet.extensions daemon-set took: 1.867007ms
  Mar 26 05:39:07.487: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.323332ms
  Mar 26 05:39:09.988: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Mar 26 05:39:09.988: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Mar 26 05:39:09.990: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"73661"},"items":null}

  Mar 26 05:39:09.991: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"73661"},"items":null}

  Mar 26 05:39:09.999: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-5029" for this suite. @ 03/26/24 05:39:10.003
• [6.721 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 03/26/24 05:39:10.006
  Mar 26 05:39:10.006: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 05:39:10.007
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:39:10.012
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:39:10.013
  STEP: Creating projection with secret that has name projected-secret-test-map-a446323d-7cc5-4e94-ad19-e9f19aa62c2f @ 03/26/24 05:39:10.015
  STEP: Creating a pod to test consume secrets @ 03/26/24 05:39:10.016
  STEP: Saw pod success @ 03/26/24 05:39:12.023
  Mar 26 05:39:12.024: INFO: Trying to get logs from node k8s-worker02 pod pod-projected-secrets-c7c7e5a5-7fb9-44e0-8589-c01b8d76074f container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 03/26/24 05:39:12.027
  Mar 26 05:39:12.032: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8468" for this suite. @ 03/26/24 05:39:12.034
• [2.029 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]
test/e2e/apimachinery/webhook.go:315
  STEP: Creating a kubernetes client @ 03/26/24 05:39:12.037
  Mar 26 05:39:12.037: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename webhook @ 03/26/24 05:39:12.037
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:39:12.043
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:39:12.045
  STEP: Setting up server cert @ 03/26/24 05:39:12.058
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 03/26/24 05:39:12.703
  STEP: Deploying the webhook pod @ 03/26/24 05:39:12.707
  STEP: Wait for the deployment to be ready @ 03/26/24 05:39:12.712
  Mar 26 05:39:12.715: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 03/26/24 05:39:14.72
  STEP: Verifying the service has paired with the endpoint @ 03/26/24 05:39:14.724
  Mar 26 05:39:15.724: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Mar 26 05:39:15.727: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8789-crds.webhook.example.com via the AdmissionRegistration API @ 03/26/24 05:39:16.233
  STEP: Creating a custom resource while v1 is storage version @ 03/26/24 05:39:16.241
  STEP: Patching Custom Resource Definition to set v2 as storage @ 03/26/24 05:39:18.265
  STEP: Patching the custom resource while v2 is storage version @ 03/26/24 05:39:18.269
  Mar 26 05:39:18.288: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7817" for this suite. @ 03/26/24 05:39:18.817
  STEP: Destroying namespace "webhook-markers-6038" for this suite. @ 03/26/24 05:39:18.82
• [6.786 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 03/26/24 05:39:18.822
  Mar 26 05:39:18.822: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename container-runtime @ 03/26/24 05:39:18.823
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:39:18.828
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:39:18.829
  STEP: create the container @ 03/26/24 05:39:18.83
  W0326 05:39:18.834220      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 03/26/24 05:39:18.834
  STEP: get the container status @ 03/26/24 05:39:22.843
  STEP: the container should be terminated @ 03/26/24 05:39:22.844
  STEP: the termination message should be set @ 03/26/24 05:39:22.844
  Mar 26 05:39:22.844: INFO: Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 03/26/24 05:39:22.844
  Mar 26 05:39:22.849: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-9748" for this suite. @ 03/26/24 05:39:22.852
• [4.032 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]
test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 03/26/24 05:39:22.856
  Mar 26 05:39:22.856: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename crd-watch @ 03/26/24 05:39:22.856
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:39:22.861
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:39:22.863
  Mar 26 05:39:22.865: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Creating first CR  @ 03/26/24 05:39:25.385
  Mar 26 05:39:25.387: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-03-26T05:39:25Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-03-26T05:39:25Z]] name:name1 resourceVersion:73851 uid:0f59767b-ee92-4198-8e1c-1b8f30586d9a] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Creating second CR @ 03/26/24 05:39:35.388
  Mar 26 05:39:35.391: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-03-26T05:39:35Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-03-26T05:39:35Z]] name:name2 resourceVersion:73891 uid:62631725-18bc-4116-970a-a815c43efbe0] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Modifying first CR @ 03/26/24 05:39:45.392
  Mar 26 05:39:45.396: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-03-26T05:39:25Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-03-26T05:39:45Z]] name:name1 resourceVersion:73909 uid:0f59767b-ee92-4198-8e1c-1b8f30586d9a] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Modifying second CR @ 03/26/24 05:39:55.397
  Mar 26 05:39:55.401: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-03-26T05:39:35Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-03-26T05:39:55Z]] name:name2 resourceVersion:73925 uid:62631725-18bc-4116-970a-a815c43efbe0] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Deleting first CR @ 03/26/24 05:40:05.402
  Mar 26 05:40:05.405: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-03-26T05:39:25Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-03-26T05:39:45Z]] name:name1 resourceVersion:73940 uid:0f59767b-ee92-4198-8e1c-1b8f30586d9a] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Deleting second CR @ 03/26/24 05:40:15.405
  Mar 26 05:40:15.409: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-03-26T05:39:35Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-03-26T05:39:55Z]] name:name2 resourceVersion:73956 uid:62631725-18bc-4116-970a-a815c43efbe0] num:map[num1:9223372036854775807 num2:1000000]]}
  Mar 26 05:40:25.915: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-6607" for this suite. @ 03/26/24 05:40:25.917
• [63.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:240
  STEP: Creating a kubernetes client @ 03/26/24 05:40:25.921
  Mar 26 05:40:25.921: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename configmap @ 03/26/24 05:40:25.921
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:40:25.928
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:40:25.929
  STEP: Creating configMap with name cm-test-opt-del-7dafd281-3fe4-4c8a-87e5-cf349ec60749 @ 03/26/24 05:40:25.931
  STEP: Creating configMap with name cm-test-opt-upd-6cee0e50-7114-429c-8fb8-0ee95b1fb567 @ 03/26/24 05:40:25.933
  STEP: Creating the pod @ 03/26/24 05:40:25.934
  STEP: Deleting configmap cm-test-opt-del-7dafd281-3fe4-4c8a-87e5-cf349ec60749 @ 03/26/24 05:40:27.95
  STEP: Updating configmap cm-test-opt-upd-6cee0e50-7114-429c-8fb8-0ee95b1fb567 @ 03/26/24 05:40:27.952
  STEP: Creating configMap with name cm-test-opt-create-b32c3f3d-6dcf-4c25-b3b4-d615097ff026 @ 03/26/24 05:40:27.954
  STEP: waiting to observe update in volume @ 03/26/24 05:40:27.956
  Mar 26 05:40:29.965: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2075" for this suite. @ 03/26/24 05:40:29.967
• [4.048 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:442
  STEP: Creating a kubernetes client @ 03/26/24 05:40:29.969
  Mar 26 05:40:29.969: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename crd-publish-openapi @ 03/26/24 05:40:29.97
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:40:29.975
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:40:29.977
  STEP: set up a multi version CRD @ 03/26/24 05:40:29.978
  Mar 26 05:40:29.978: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: mark a version not serverd @ 03/26/24 05:40:33.119
  STEP: check the unserved version gets removed @ 03/26/24 05:40:33.129
  STEP: check the other version is not changed @ 03/26/24 05:40:33.822
  Mar 26 05:40:36.283: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3180" for this suite. @ 03/26/24 05:40:36.288
• [6.322 seconds]
------------------------------
SSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]
test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 03/26/24 05:40:36.291
  Mar 26 05:40:36.291: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename conformance-tests @ 03/26/24 05:40:36.291
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:40:36.296
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:40:36.299
  STEP: Getting node addresses @ 03/26/24 05:40:36.301
  Mar 26 05:40:36.301: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  Mar 26 05:40:36.303: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-6503" for this suite. @ 03/26/24 05:40:36.304
• [0.015 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance]
test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 03/26/24 05:40:36.308
  Mar 26 05:40:36.308: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename pods @ 03/26/24 05:40:36.309
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:40:36.315
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:40:36.316
  STEP: Create set of pods @ 03/26/24 05:40:36.317
  Mar 26 05:40:36.320: INFO: created test-pod-1
  Mar 26 05:40:36.323: INFO: created test-pod-2
  Mar 26 05:40:36.327: INFO: created test-pod-3
  STEP: waiting for all 3 pods to be running @ 03/26/24 05:40:36.327
  STEP: waiting for all pods to be deleted @ 03/26/24 05:40:38.344
  Mar 26 05:40:38.347: INFO: Pod quantity 3 is different from expected quantity 0
  Mar 26 05:40:39.349: INFO: Pod quantity 3 is different from expected quantity 0
  Mar 26 05:40:40.349: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7822" for this suite. @ 03/26/24 05:40:40.351
• [4.045 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]
test/e2e/kubectl/kubectl.go:1781
  STEP: Creating a kubernetes client @ 03/26/24 05:40:40.353
  Mar 26 05:40:40.354: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubectl @ 03/26/24 05:40:40.355
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:40:40.359
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:40:40.361
  STEP: starting the proxy server @ 03/26/24 05:40:40.362
  Mar 26 05:40:40.362: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-642 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 03/26/24 05:40:40.393
  Mar 26 05:40:40.398: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-642" for this suite. @ 03/26/24 05:40:40.4
• [0.048 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:109
  STEP: Creating a kubernetes client @ 03/26/24 05:40:40.402
  Mar 26 05:40:40.402: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 05:40:40.402
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:40:40.407
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:40:40.409
  STEP: Creating configMap with name projected-configmap-test-volume-map-499fe14b-6b2f-4b06-a6f0-ccac32f33d4d @ 03/26/24 05:40:40.41
  STEP: Creating a pod to test consume configMaps @ 03/26/24 05:40:40.411
  STEP: Saw pod success @ 03/26/24 05:40:42.418
  Mar 26 05:40:42.419: INFO: Trying to get logs from node k8s-worker02 pod pod-projected-configmaps-54badd29-6207-428d-8ad4-9e3684969188 container agnhost-container: <nil>
  STEP: delete the pod @ 03/26/24 05:40:42.422
  Mar 26 05:40:42.427: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1156" for this suite. @ 03/26/24 05:40:42.428
• [2.029 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]
test/e2e/apps/rc.go:69
  STEP: Creating a kubernetes client @ 03/26/24 05:40:42.43
  Mar 26 05:40:42.430: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename replication-controller @ 03/26/24 05:40:42.431
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:40:42.436
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:40:42.437
  STEP: Creating replication controller my-hostname-basic-d1e221fb-a2c2-4836-913a-b78643cf7b94 @ 03/26/24 05:40:42.439
  Mar 26 05:40:42.443: INFO: Pod name my-hostname-basic-d1e221fb-a2c2-4836-913a-b78643cf7b94: Found 0 pods out of 1
  Mar 26 05:40:47.447: INFO: Pod name my-hostname-basic-d1e221fb-a2c2-4836-913a-b78643cf7b94: Found 1 pods out of 1
  Mar 26 05:40:47.447: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-d1e221fb-a2c2-4836-913a-b78643cf7b94" are running
  Mar 26 05:40:47.451: INFO: Pod "my-hostname-basic-d1e221fb-a2c2-4836-913a-b78643cf7b94-76r6j" is running and ready(conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-03-26 05:40:42 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-03-26 05:40:43 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-03-26 05:40:43 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-03-26 05:40:42 +0000 UTC Reason: Message:}])
  Mar 26 05:40:47.451: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 03/26/24 05:40:47.451
  Mar 26 05:40:47.455: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-19" for this suite. @ 03/26/24 05:40:47.457
• [5.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 03/26/24 05:40:47.461
  Mar 26 05:40:47.461: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename pods @ 03/26/24 05:40:47.462
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:40:47.468
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:40:47.47
  Mar 26 05:40:47.471: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: creating the pod @ 03/26/24 05:40:47.471
  STEP: submitting the pod to kubernetes @ 03/26/24 05:40:47.471
  Mar 26 05:40:49.485: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9632" for this suite. @ 03/26/24 05:40:49.486
• [2.028 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:236
  STEP: Creating a kubernetes client @ 03/26/24 05:40:49.49
  Mar 26 05:40:49.490: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename crd-publish-openapi @ 03/26/24 05:40:49.49
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:40:49.496
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:40:49.498
  Mar 26 05:40:49.499: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 03/26/24 05:40:50.716
  Mar 26 05:40:50.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-2787 --namespace=crd-publish-openapi-2787 create -f -'
  Mar 26 05:40:51.019: INFO: stderr: ""
  Mar 26 05:40:51.019: INFO: stdout: "e2e-test-crd-publish-openapi-1093-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Mar 26 05:40:51.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-2787 --namespace=crd-publish-openapi-2787 delete e2e-test-crd-publish-openapi-1093-crds test-cr'
  Mar 26 05:40:51.059: INFO: stderr: ""
  Mar 26 05:40:51.059: INFO: stdout: "e2e-test-crd-publish-openapi-1093-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  Mar 26 05:40:51.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-2787 --namespace=crd-publish-openapi-2787 apply -f -'
  Mar 26 05:40:51.151: INFO: stderr: ""
  Mar 26 05:40:51.151: INFO: stdout: "e2e-test-crd-publish-openapi-1093-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Mar 26 05:40:51.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-2787 --namespace=crd-publish-openapi-2787 delete e2e-test-crd-publish-openapi-1093-crds test-cr'
  Mar 26 05:40:51.191: INFO: stderr: ""
  Mar 26 05:40:51.191: INFO: stdout: "e2e-test-crd-publish-openapi-1093-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 03/26/24 05:40:51.191
  Mar 26 05:40:51.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-2787 explain e2e-test-crd-publish-openapi-1093-crds'
  Mar 26 05:40:51.278: INFO: stderr: ""
  Mar 26 05:40:51.278: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-1093-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  Mar 26 05:40:52.480: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2787" for this suite. @ 03/26/24 05:40:52.485
• [2.997 seconds]
------------------------------
SS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]
test/e2e/common/node/configmap.go:169
  STEP: Creating a kubernetes client @ 03/26/24 05:40:52.487
  Mar 26 05:40:52.487: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename configmap @ 03/26/24 05:40:52.487
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:40:52.494
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:40:52.496
  STEP: creating a ConfigMap @ 03/26/24 05:40:52.497
  STEP: fetching the ConfigMap @ 03/26/24 05:40:52.499
  STEP: patching the ConfigMap @ 03/26/24 05:40:52.501
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 03/26/24 05:40:52.503
  STEP: deleting the ConfigMap by collection with a label selector @ 03/26/24 05:40:52.505
  STEP: listing all ConfigMaps in test namespace @ 03/26/24 05:40:52.507
  Mar 26 05:40:52.508: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8888" for this suite. @ 03/26/24 05:40:52.51
• [0.025 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
test/e2e/apimachinery/aggregator.go:96
  STEP: Creating a kubernetes client @ 03/26/24 05:40:52.512
  Mar 26 05:40:52.512: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename aggregator @ 03/26/24 05:40:52.513
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:40:52.527
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:40:52.529
  Mar 26 05:40:52.530: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Registering the sample API server. @ 03/26/24 05:40:52.531
  Mar 26 05:40:52.622: INFO: Found ClusterRoles; assuming RBAC is enabled.
  Mar 26 05:40:52.632: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
  Mar 26 05:40:54.656: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-56f5bd7745\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Mar 26 05:40:56.657: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-56f5bd7745\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Mar 26 05:40:58.659: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-56f5bd7745\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Mar 26 05:41:00.658: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-56f5bd7745\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Mar 26 05:41:02.659: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-56f5bd7745\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Mar 26 05:41:04.659: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-56f5bd7745\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Mar 26 05:41:06.659: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-56f5bd7745\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Mar 26 05:41:08.658: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-56f5bd7745\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Mar 26 05:41:10.658: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-56f5bd7745\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Mar 26 05:41:12.659: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-56f5bd7745\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Mar 26 05:41:14.658: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 40, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-56f5bd7745\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Mar 26 05:41:16.766: INFO: Waited 105.157476ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 03/26/24 05:41:16.781
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 03/26/24 05:41:16.783
  STEP: List APIServices @ 03/26/24 05:41:16.785
  Mar 26 05:41:16.789: INFO: Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 03/26/24 05:41:16.789
  Mar 26 05:41:16.793: INFO: APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 03/26/24 05:41:16.793
  Mar 26 05:41:16.797: INFO: updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2024, time.March, 26, 5, 41, 16, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 03/26/24 05:41:16.797
  Mar 26 05:41:16.798: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2024-03-26 05:41:16 +0000 UTC Passed all checks passed}
  Mar 26 05:41:16.798: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Mar 26 05:41:16.798: INFO: Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 03/26/24 05:41:16.798
  Mar 26 05:41:16.802: INFO: Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete APIService "dynamic-flunder-184721639" @ 03/26/24 05:41:16.802
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 03/26/24 05:41:16.809
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 03/26/24 05:41:16.812
  STEP: Patch APIService Status @ 03/26/24 05:41:16.813
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 03/26/24 05:41:16.816
  Mar 26 05:41:16.817: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2024-03-26 05:41:16 +0000 UTC Passed all checks passed}
  Mar 26 05:41:16.817: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Mar 26 05:41:16.817: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  Mar 26 05:41:16.817: INFO: Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "e2e-apiservice=patched" @ 03/26/24 05:41:16.817
  STEP: Confirm that the generated APIService has been deleted @ 03/26/24 05:41:16.819
  Mar 26 05:41:16.819: INFO: Requesting list of APIServices to confirm quantity
  Mar 26 05:41:16.821: INFO: Found 0 APIService with label "e2e-apiservice=patched"
  Mar 26 05:41:16.821: INFO: APIService v1alpha1.wardle.example.com has been deleted.
  Mar 26 05:41:16.856: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-9102" for this suite. @ 03/26/24 05:41:16.866
• [24.356 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:272
  STEP: Creating a kubernetes client @ 03/26/24 05:41:16.869
  Mar 26 05:41:16.869: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename namespaces @ 03/26/24 05:41:16.869
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:41:16.876
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:41:16.878
  STEP: creating a Namespace @ 03/26/24 05:41:16.879
  STEP: patching the Namespace @ 03/26/24 05:41:16.885
  STEP: get the Namespace and ensuring it has the label @ 03/26/24 05:41:16.888
  Mar 26 05:41:16.889: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-4364" for this suite. @ 03/26/24 05:41:16.891
  STEP: Destroying namespace "nspatchtest-a941d77b-da65-411e-ab69-d3b323c00511-9681" for this suite. @ 03/26/24 05:41:16.894
• [0.028 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]
test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 03/26/24 05:41:16.898
  Mar 26 05:41:16.898: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename deployment @ 03/26/24 05:41:16.898
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:41:16.903
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:41:16.904
  Mar 26 05:41:16.906: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
  Mar 26 05:41:16.909: INFO: Pod name sample-pod: Found 0 pods out of 1
  Mar 26 05:41:21.911: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 03/26/24 05:41:21.911
  Mar 26 05:41:21.911: INFO: Creating deployment "test-rolling-update-deployment"
  Mar 26 05:41:21.914: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  Mar 26 05:41:21.916: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  Mar 26 05:41:23.920: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
  Mar 26 05:41:23.921: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  Mar 26 05:41:23.926: INFO: Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8285",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "60fcded8-dd5f-4a96-9a2c-5c6c03921e8b",
      ResourceVersion: (string) (len=5) "74518",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028481,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=55) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=83) "ReplicaSet \"test-rolling-update-deployment-84b6cfb759\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Mar 26 05:41:23.936: INFO: New ReplicaSet "test-rolling-update-deployment-84b6cfb759" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rolling-update-deployment-84b6cfb759",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8285",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fa86fea1-37d4-48df-9383-cc8a09afac6e",
      ResourceVersion: (string) (len=5) "74508",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028481,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "84b6cfb759"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "60fcded8-dd5f-4a96-9a2c-5c6c03921e8b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 36 30 66 63 64 65  64 38 2d 64 64 35 66 2d  |\"60fcded8-dd5f-|
              00000120  34 61 39 36 2d 39 61 32  63 2d 35 63 36 63 30 33  |4a96-9a2c-5c6c03|
              00000130  39 32 31 65 38 62 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |921e8b\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "84b6cfb759"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "84b6cfb759"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=55) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Mar 26 05:41:23.936: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
  Mar 26 05:41:23.937: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8285",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d40ba539-e81d-42c4-aa89-09abe8e3b721",
      ResourceVersion: (string) (len=5) "74517",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028476,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "60fcded8-dd5f-4a96-9a2c-5c6c03921e8b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028476,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 36 30 66 63 64 65 64  |"uid\":\"60fcded|
              000000b0  38 2d 64 64 35 66 2d 34  61 39 36 2d 39 61 32 63  |8-dd5f-4a96-9a2c|
              000000c0  2d 35 63 36 63 30 33 39  32 31 65 38 62 5c 22 7d  |-5c6c03921e8b\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Mar 26 05:41:23.942: INFO: Pod "test-rolling-update-deployment-84b6cfb759-6xcdj" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=47) "test-rolling-update-deployment-84b6cfb759-6xcdj",
      GenerateName: (string) (len=42) "test-rolling-update-deployment-84b6cfb759-",
      Namespace: (string) (len=15) "deployment-8285",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "de26f45f-a1bc-48ac-853c-0f454acb754c",
      ResourceVersion: (string) (len=5) "74507",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028481,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "84b6cfb759"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "10a7608dbc64c9099c690ecee9449baa1fe515aee5d9e29138c3ff8c3a4b7606",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "10.244.69.223/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "10.244.69.223/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=41) "test-rolling-update-deployment-84b6cfb759",
          UID: (types.UID) (len=36) "fa86fea1-37d4-48df-9383-cc8a09afac6e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 61  38 36 66 65 61 31 2d 33  |d\":\"fa86fea1-3|
              00000090  37 64 34 2d 34 38 64 66  2d 39 33 38 33 2d 63 63  |7d4-48df-9383-cc|
              000000a0  38 61 30 39 61 66 61 63  36 65 5c 22 7d 22 3a 7b  |8a09afac6e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028482,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 34 34 2e 36  39 2e 32 32 33 5c 22 7d  |10.244.69.223\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-kdhgv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=55) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-kdhgv",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028483,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.15",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.244.69.223",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.244.69.223"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028481,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63847028482,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=55) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45",
          ImageID: (string) (len=122) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost@sha256:8f07c07228b54f5d644c14241ad3e483b999c5d3a78f7580a6252c8ab42f2b66",
          ContainerID: (string) (len=72) "cri-o://15257de99e8261f77d49e20791107cb4fd706f17656b41b42977b7d8e86b858b",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 05:41:23.945: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-8285" for this suite. @ 03/26/24 05:41:23.948
• [7.054 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 03/26/24 05:41:23.956
  Mar 26 05:41:23.956: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 03/26/24 05:41:23.957
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:41:23.963
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:41:23.965
  STEP: Setting up the test @ 03/26/24 05:41:23.966
  STEP: Creating hostNetwork=false pod @ 03/26/24 05:41:23.966
  STEP: Creating hostNetwork=true pod @ 03/26/24 05:41:25.975
  STEP: Running the test @ 03/26/24 05:41:27.983
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 03/26/24 05:41:27.983
  Mar 26 05:41:27.983: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9474 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 05:41:27.983: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:41:27.984: INFO: ExecWithOptions: Clientset creation
  Mar 26 05:41:27.984: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9474/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Mar 26 05:41:28.021: INFO: Exec stderr: ""
  Mar 26 05:41:28.021: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9474 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 05:41:28.021: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:41:28.022: INFO: ExecWithOptions: Clientset creation
  Mar 26 05:41:28.022: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9474/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Mar 26 05:41:28.057: INFO: Exec stderr: ""
  Mar 26 05:41:28.057: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9474 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 05:41:28.057: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:41:28.058: INFO: ExecWithOptions: Clientset creation
  Mar 26 05:41:28.058: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9474/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Mar 26 05:41:28.095: INFO: Exec stderr: ""
  Mar 26 05:41:28.095: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9474 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 05:41:28.095: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:41:28.095: INFO: ExecWithOptions: Clientset creation
  Mar 26 05:41:28.095: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9474/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Mar 26 05:41:28.131: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 03/26/24 05:41:28.131
  Mar 26 05:41:28.132: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9474 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 05:41:28.132: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:41:28.132: INFO: ExecWithOptions: Clientset creation
  Mar 26 05:41:28.132: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9474/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Mar 26 05:41:28.169: INFO: Exec stderr: ""
  Mar 26 05:41:28.169: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9474 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 05:41:28.169: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:41:28.169: INFO: ExecWithOptions: Clientset creation
  Mar 26 05:41:28.169: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9474/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Mar 26 05:41:28.207: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 03/26/24 05:41:28.207
  Mar 26 05:41:28.207: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9474 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 05:41:28.207: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:41:28.207: INFO: ExecWithOptions: Clientset creation
  Mar 26 05:41:28.207: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9474/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Mar 26 05:41:28.250: INFO: Exec stderr: ""
  Mar 26 05:41:28.250: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9474 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 05:41:28.250: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:41:28.251: INFO: ExecWithOptions: Clientset creation
  Mar 26 05:41:28.251: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9474/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Mar 26 05:41:28.287: INFO: Exec stderr: ""
  Mar 26 05:41:28.287: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9474 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 05:41:28.287: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:41:28.288: INFO: ExecWithOptions: Clientset creation
  Mar 26 05:41:28.288: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9474/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Mar 26 05:41:28.323: INFO: Exec stderr: ""
  Mar 26 05:41:28.323: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9474 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 05:41:28.324: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:41:28.324: INFO: ExecWithOptions: Clientset creation
  Mar 26 05:41:28.324: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9474/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Mar 26 05:41:28.361: INFO: Exec stderr: ""
  Mar 26 05:41:28.361: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-9474" for this suite. @ 03/26/24 05:41:28.364
• [4.412 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:107
  STEP: Creating a kubernetes client @ 03/26/24 05:41:28.371
  Mar 26 05:41:28.372: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename container-probe @ 03/26/24 05:41:28.373
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:41:28.379
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:41:28.38
  Mar 26 05:42:28.387: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8943" for this suite. @ 03/26/24 05:42:28.388
• [60.020 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]
test/e2e/common/node/runtimeclass.go:189
  STEP: Creating a kubernetes client @ 03/26/24 05:42:28.393
  Mar 26 05:42:28.393: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename runtimeclass @ 03/26/24 05:42:28.394
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:42:28.401
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:42:28.402
  STEP: getting /apis @ 03/26/24 05:42:28.404
  STEP: getting /apis/node.k8s.io @ 03/26/24 05:42:28.406
  STEP: getting /apis/node.k8s.io/v1 @ 03/26/24 05:42:28.406
  STEP: creating @ 03/26/24 05:42:28.407
  STEP: watching @ 03/26/24 05:42:28.414
  Mar 26 05:42:28.414: INFO: starting watch
  STEP: getting @ 03/26/24 05:42:28.417
  STEP: listing @ 03/26/24 05:42:28.418
  STEP: patching @ 03/26/24 05:42:28.419
  STEP: updating @ 03/26/24 05:42:28.421
  Mar 26 05:42:28.422: INFO: waiting for watch events with expected annotations
  STEP: deleting @ 03/26/24 05:42:28.422
  STEP: deleting a collection @ 03/26/24 05:42:28.426
  Mar 26 05:42:28.433: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-3450" for this suite. @ 03/26/24 05:42:28.434
• [0.043 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]
test/e2e/apimachinery/resource_quota.go:232
  STEP: Creating a kubernetes client @ 03/26/24 05:42:28.438
  Mar 26 05:42:28.438: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename resourcequota @ 03/26/24 05:42:28.438
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:42:28.445
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:42:28.449
  STEP: Counting existing ResourceQuota @ 03/26/24 05:42:28.451
  STEP: Creating a ResourceQuota @ 03/26/24 05:42:33.453
  STEP: Ensuring resource quota status is calculated @ 03/26/24 05:42:33.455
  STEP: Creating a Pod that fits quota @ 03/26/24 05:42:35.458
  STEP: Ensuring ResourceQuota status captures the pod usage @ 03/26/24 05:42:35.464
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 03/26/24 05:42:37.467
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 03/26/24 05:42:37.468
  STEP: Ensuring a pod cannot update its resource requirements @ 03/26/24 05:42:37.469
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 03/26/24 05:42:37.471
  STEP: Deleting the pod @ 03/26/24 05:42:39.474
  STEP: Ensuring resource quota status released the pod usage @ 03/26/24 05:42:39.479
  Mar 26 05:42:41.482: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2802" for this suite. @ 03/26/24 05:42:41.484
• [13.049 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
test/e2e/apimachinery/garbage_collector.go:538
  STEP: Creating a kubernetes client @ 03/26/24 05:42:41.487
  Mar 26 05:42:41.487: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename gc @ 03/26/24 05:42:41.487
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:42:41.492
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:42:41.494
  STEP: create the deployment @ 03/26/24 05:42:41.495
  W0326 05:42:41.497581      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 03/26/24 05:42:41.497
  STEP: delete the deployment @ 03/26/24 05:42:42.001
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 03/26/24 05:42:42.003
  STEP: Gathering metrics @ 03/26/24 05:42:42.51
  Mar 26 05:42:42.560: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Mar 26 05:42:42.560: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8870" for this suite. @ 03/26/24 05:42:42.562
• [1.078 seconds]
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:357
  STEP: Creating a kubernetes client @ 03/26/24 05:42:42.564
  Mar 26 05:42:42.564: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename crd-publish-openapi @ 03/26/24 05:42:42.565
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:42:42.573
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:42:42.574
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 03/26/24 05:42:42.575
  Mar 26 05:42:42.576: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:42:43.787: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:42:48.736: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3250" for this suite. @ 03/26/24 05:42:48.742
• [6.179 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance]
test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 03/26/24 05:42:48.748
  Mar 26 05:42:48.748: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename dns @ 03/26/24 05:42:48.75
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:42:48.755
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:42:48.756
  STEP: Creating a test headless service @ 03/26/24 05:42:48.758
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2725.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-2725.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 03/26/24 05:42:48.759
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2725.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-2725.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 03/26/24 05:42:48.759
  STEP: creating a pod to probe DNS @ 03/26/24 05:42:48.76
  STEP: submitting the pod to kubernetes @ 03/26/24 05:42:48.76
  STEP: retrieving the pod @ 03/26/24 05:42:50.77
  STEP: looking for the results for each expected name from probers @ 03/26/24 05:42:50.772
  Mar 26 05:42:50.777: INFO: DNS probes using dns-2725/dns-test-9d46c9a8-7bb4-43ae-8528-6c9eeac8c737 succeeded

  Mar 26 05:42:50.777: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 03/26/24 05:42:50.78
  STEP: deleting the test headless service @ 03/26/24 05:42:50.785
  STEP: Destroying namespace "dns-2725" for this suite. @ 03/26/24 05:42:50.791
• [2.045 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]
test/e2e/apps/replica_set.go:131
  STEP: Creating a kubernetes client @ 03/26/24 05:42:50.794
  Mar 26 05:42:50.794: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename replicaset @ 03/26/24 05:42:50.795
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:42:50.8
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:42:50.801
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 03/26/24 05:42:50.803
  STEP: When a replicaset with a matching selector is created @ 03/26/24 05:42:52.811
  STEP: Then the orphan pod is adopted @ 03/26/24 05:42:52.813
  STEP: When the matched label of one of its pods change @ 03/26/24 05:42:53.818
  Mar 26 05:42:53.819: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 03/26/24 05:42:53.824
  Mar 26 05:42:54.828: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-9833" for this suite. @ 03/26/24 05:42:54.83
• [4.038 seconds]
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 03/26/24 05:42:54.833
  Mar 26 05:42:54.833: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename secrets @ 03/26/24 05:42:54.834
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:42:54.839
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:42:54.841
  STEP: Creating secret with name s-test-opt-del-eaf9aa75-6cff-4af2-aad9-d91e3bd5a82e @ 03/26/24 05:42:54.844
  STEP: Creating secret with name s-test-opt-upd-0cd9244c-183d-4ba8-a329-45d323895cbb @ 03/26/24 05:42:54.846
  STEP: Creating the pod @ 03/26/24 05:42:54.847
  STEP: Deleting secret s-test-opt-del-eaf9aa75-6cff-4af2-aad9-d91e3bd5a82e @ 03/26/24 05:42:56.862
  STEP: Updating secret s-test-opt-upd-0cd9244c-183d-4ba8-a329-45d323895cbb @ 03/26/24 05:42:56.864
  STEP: Creating secret with name s-test-opt-create-7ff21b1e-f821-49a7-bfd2-8258b31ddc8a @ 03/26/24 05:42:56.866
  STEP: waiting to observe update in volume @ 03/26/24 05:42:56.867
  Mar 26 05:44:25.045: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1062" for this suite. @ 03/26/24 05:44:25.047
• [90.217 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]
test/e2e/auth/service_accounts.go:78
  STEP: Creating a kubernetes client @ 03/26/24 05:44:25.05
  Mar 26 05:44:25.050: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename svcaccounts @ 03/26/24 05:44:25.051
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:44:25.061
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:44:25.062
  STEP: reading a file in the container @ 03/26/24 05:44:27.071
  Mar 26 05:44:27.071: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3635 pod-service-account-5d066232-a806-46ac-b854-2c66bb8129d5 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 03/26/24 05:44:27.149
  Mar 26 05:44:27.149: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3635 pod-service-account-5d066232-a806-46ac-b854-2c66bb8129d5 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 03/26/24 05:44:27.229
  Mar 26 05:44:27.229: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3635 pod-service-account-5d066232-a806-46ac-b854-2c66bb8129d5 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  Mar 26 05:44:27.309: INFO: Got root ca configmap in namespace "svcaccounts-3635"
  Mar 26 05:44:27.311: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-3635" for this suite. @ 03/26/24 05:44:27.312
• [2.264 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]
test/e2e/apps/rc.go:112
  STEP: Creating a kubernetes client @ 03/26/24 05:44:27.315
  Mar 26 05:44:27.315: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename replication-controller @ 03/26/24 05:44:27.315
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:44:27.32
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:44:27.322
  STEP: creating a ReplicationController @ 03/26/24 05:44:27.324
  STEP: waiting for RC to be added @ 03/26/24 05:44:27.326
  STEP: waiting for available Replicas @ 03/26/24 05:44:27.327
  STEP: patching ReplicationController @ 03/26/24 05:44:28.299
  STEP: waiting for RC to be modified @ 03/26/24 05:44:28.302
  STEP: patching ReplicationController status @ 03/26/24 05:44:28.302
  STEP: waiting for RC to be modified @ 03/26/24 05:44:28.304
  STEP: waiting for available Replicas @ 03/26/24 05:44:28.305
  STEP: fetching ReplicationController status @ 03/26/24 05:44:28.307
  STEP: patching ReplicationController scale @ 03/26/24 05:44:28.308
  STEP: waiting for RC to be modified @ 03/26/24 05:44:28.31
  STEP: waiting for ReplicationController's scale to be the max amount @ 03/26/24 05:44:28.31
  STEP: fetching ReplicationController; ensuring that it's patched @ 03/26/24 05:44:29.604
  STEP: updating ReplicationController status @ 03/26/24 05:44:29.605
  STEP: waiting for RC to be modified @ 03/26/24 05:44:29.608
  STEP: listing all ReplicationControllers @ 03/26/24 05:44:29.608
  STEP: checking that ReplicationController has expected values @ 03/26/24 05:44:29.609
  STEP: deleting ReplicationControllers by collection @ 03/26/24 05:44:29.609
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 03/26/24 05:44:29.612
  Mar 26 05:44:29.643: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0326 05:44:29.643239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-1838" for this suite. @ 03/26/24 05:44:29.645
• [2.332 seconds]
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 03/26/24 05:44:29.647
  Mar 26 05:44:29.647: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename dns @ 03/26/24 05:44:29.648
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:44:29.653
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:44:29.655
  STEP: Creating a test headless service @ 03/26/24 05:44:29.657
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4817 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4817;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4817 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4817;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4817.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4817.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4817.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4817.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4817.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4817.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4817.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4817.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4817.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4817.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4817.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4817.svc;check="$$(dig +notcp +noall +answer +search 32.247.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.247.32_udp@PTR;check="$$(dig +tcp +noall +answer +search 32.247.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.247.32_tcp@PTR;sleep 1; done
   @ 03/26/24 05:44:29.664
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4817 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4817;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4817 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4817;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4817.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4817.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4817.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4817.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4817.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4817.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4817.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4817.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4817.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4817.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4817.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4817.svc;check="$$(dig +notcp +noall +answer +search 32.247.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.247.32_udp@PTR;check="$$(dig +tcp +noall +answer +search 32.247.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.247.32_tcp@PTR;sleep 1; done
   @ 03/26/24 05:44:29.664
  STEP: creating a pod to probe DNS @ 03/26/24 05:44:29.664
  STEP: submitting the pod to kubernetes @ 03/26/24 05:44:29.664
  E0326 05:44:30.643902      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:31.644927      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 03/26/24 05:44:31.673
  STEP: looking for the results for each expected name from probers @ 03/26/24 05:44:31.675
  Mar 26 05:44:31.677: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:31.678: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:31.679: INFO: Unable to read wheezy_udp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:31.680: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:31.681: INFO: Unable to read wheezy_udp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:31.683: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:31.691: INFO: Unable to read jessie_udp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:31.692: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:31.693: INFO: Unable to read jessie_udp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:31.695: INFO: Unable to read jessie_tcp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:31.696: INFO: Unable to read jessie_udp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:31.697: INFO: Unable to read jessie_tcp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:31.705: INFO: Lookups using dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-4817 wheezy_tcp@dns-test-service.dns-4817 wheezy_udp@dns-test-service.dns-4817.svc wheezy_tcp@dns-test-service.dns-4817.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-4817 jessie_tcp@dns-test-service.dns-4817 jessie_udp@dns-test-service.dns-4817.svc jessie_tcp@dns-test-service.dns-4817.svc]

  Mar 26 05:44:31.708: INFO: Pod client logs for webserver: 
  Mar 26 05:44:31.710: INFO: Pod client logs for querier: 
  Mar 26 05:44:31.712: INFO: Pod client logs for jessie-querier: 
  E0326 05:44:32.645713      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:33.645886      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:34.646028      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:35.646074      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:36.646238      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:44:36.715: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:36.717: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:36.718: INFO: Unable to read wheezy_udp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:36.719: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:36.720: INFO: Unable to read wheezy_udp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:36.722: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:36.729: INFO: Unable to read jessie_udp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:36.730: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:36.731: INFO: Unable to read jessie_udp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:36.732: INFO: Unable to read jessie_tcp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:36.733: INFO: Unable to read jessie_udp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:36.733: INFO: Unable to read jessie_tcp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:36.739: INFO: Lookups using dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-4817 wheezy_tcp@dns-test-service.dns-4817 wheezy_udp@dns-test-service.dns-4817.svc wheezy_tcp@dns-test-service.dns-4817.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-4817 jessie_tcp@dns-test-service.dns-4817 jessie_udp@dns-test-service.dns-4817.svc jessie_tcp@dns-test-service.dns-4817.svc]

  Mar 26 05:44:36.741: INFO: Pod client logs for webserver: 
  Mar 26 05:44:36.743: INFO: Pod client logs for querier: 
  Mar 26 05:44:36.745: INFO: Pod client logs for jessie-querier: 
  E0326 05:44:37.647061      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:38.647269      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:39.647288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:40.647589      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:41.647708      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:44:41.714: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:41.715: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:41.717: INFO: Unable to read wheezy_udp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:41.718: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:41.719: INFO: Unable to read wheezy_udp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:41.720: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:41.728: INFO: Unable to read jessie_udp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:41.729: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:41.733: INFO: Unable to read jessie_udp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:41.734: INFO: Unable to read jessie_tcp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:41.735: INFO: Unable to read jessie_udp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:41.736: INFO: Unable to read jessie_tcp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:41.742: INFO: Lookups using dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-4817 wheezy_tcp@dns-test-service.dns-4817 wheezy_udp@dns-test-service.dns-4817.svc wheezy_tcp@dns-test-service.dns-4817.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-4817 jessie_tcp@dns-test-service.dns-4817 jessie_udp@dns-test-service.dns-4817.svc jessie_tcp@dns-test-service.dns-4817.svc]

  Mar 26 05:44:41.744: INFO: Pod client logs for webserver: 
  Mar 26 05:44:41.745: INFO: Pod client logs for querier: 
  Mar 26 05:44:41.754: INFO: Pod client logs for jessie-querier: 
  E0326 05:44:42.648698      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:43.648849      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:44.648980      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:45.649411      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:46.649508      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:44:46.715: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:46.717: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:46.718: INFO: Unable to read wheezy_udp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:46.720: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:46.721: INFO: Unable to read wheezy_udp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:46.722: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:46.729: INFO: Unable to read jessie_udp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:46.730: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:46.731: INFO: Unable to read jessie_udp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:46.732: INFO: Unable to read jessie_tcp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:46.733: INFO: Unable to read jessie_udp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:46.735: INFO: Unable to read jessie_tcp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:46.741: INFO: Lookups using dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-4817 wheezy_tcp@dns-test-service.dns-4817 wheezy_udp@dns-test-service.dns-4817.svc wheezy_tcp@dns-test-service.dns-4817.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-4817 jessie_tcp@dns-test-service.dns-4817 jessie_udp@dns-test-service.dns-4817.svc jessie_tcp@dns-test-service.dns-4817.svc]

  Mar 26 05:44:46.743: INFO: Pod client logs for webserver: 
  Mar 26 05:44:46.745: INFO: Pod client logs for querier: 
  Mar 26 05:44:46.747: INFO: Pod client logs for jessie-querier: 
  E0326 05:44:47.650309      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:48.651170      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:49.651468      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:50.651404      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:51.652539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:44:51.714: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:51.715: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:51.716: INFO: Unable to read wheezy_udp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:51.718: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:51.719: INFO: Unable to read wheezy_udp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:51.720: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:51.727: INFO: Unable to read jessie_udp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:51.728: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:51.729: INFO: Unable to read jessie_udp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:51.730: INFO: Unable to read jessie_tcp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:51.731: INFO: Unable to read jessie_udp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:51.732: INFO: Unable to read jessie_tcp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:51.738: INFO: Lookups using dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-4817 wheezy_tcp@dns-test-service.dns-4817 wheezy_udp@dns-test-service.dns-4817.svc wheezy_tcp@dns-test-service.dns-4817.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-4817 jessie_tcp@dns-test-service.dns-4817 jessie_udp@dns-test-service.dns-4817.svc jessie_tcp@dns-test-service.dns-4817.svc]

  Mar 26 05:44:51.740: INFO: Pod client logs for webserver: 
  Mar 26 05:44:51.742: INFO: Pod client logs for querier: 
  Mar 26 05:44:51.744: INFO: Pod client logs for jessie-querier: 
  E0326 05:44:52.652415      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:53.653279      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:54.653663      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:55.654041      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:56.654188      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:44:56.715: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:56.716: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:56.717: INFO: Unable to read wheezy_udp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:56.718: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:56.719: INFO: Unable to read wheezy_udp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:56.720: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:56.727: INFO: Unable to read jessie_udp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:56.728: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:56.729: INFO: Unable to read jessie_udp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:56.730: INFO: Unable to read jessie_tcp@dns-test-service.dns-4817 from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:56.732: INFO: Unable to read jessie_udp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:56.733: INFO: Unable to read jessie_tcp@dns-test-service.dns-4817.svc from pod dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3: the server could not find the requested resource (get pods dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3)
  Mar 26 05:44:56.739: INFO: Lookups using dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-4817 wheezy_tcp@dns-test-service.dns-4817 wheezy_udp@dns-test-service.dns-4817.svc wheezy_tcp@dns-test-service.dns-4817.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-4817 jessie_tcp@dns-test-service.dns-4817 jessie_udp@dns-test-service.dns-4817.svc jessie_tcp@dns-test-service.dns-4817.svc]

  Mar 26 05:44:56.742: INFO: Pod client logs for webserver: 
  Mar 26 05:44:56.744: INFO: Pod client logs for querier: 
  Mar 26 05:44:56.746: INFO: Pod client logs for jessie-querier: 
  E0326 05:44:57.654366      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:58.654403      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:44:59.654477      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:00.654553      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:01.655465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:45:01.735: INFO: DNS probes using dns-4817/dns-test-a0113d65-16ce-4bfb-ba72-4d43e56b75a3 succeeded

  Mar 26 05:45:01.735: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 03/26/24 05:45:01.737
  STEP: deleting the test service @ 03/26/24 05:45:01.743
  STEP: deleting the test headless service @ 03/26/24 05:45:01.755
  STEP: Destroying namespace "dns-4817" for this suite. @ 03/26/24 05:45:01.76
• [32.116 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:276
  STEP: Creating a kubernetes client @ 03/26/24 05:45:01.764
  Mar 26 05:45:01.764: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename crd-publish-openapi @ 03/26/24 05:45:01.764
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:45:01.771
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:45:01.773
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 03/26/24 05:45:01.774
  Mar 26 05:45:01.775: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  E0326 05:45:02.655741      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:45:03.014: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  E0326 05:45:03.656496      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:04.656548      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:05.656574      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:06.656610      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:07.656819      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:45:07.922: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5215" for this suite. @ 03/26/24 05:45:07.927
• [6.165 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:135
  STEP: Creating a kubernetes client @ 03/26/24 05:45:07.93
  Mar 26 05:45:07.930: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 03/26/24 05:45:07.93
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:45:07.935
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:45:07.936
  STEP: create the container to handle the HTTPGet hook request. @ 03/26/24 05:45:07.939
  E0326 05:45:08.657998      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:09.657474      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 03/26/24 05:45:09.948
  E0326 05:45:10.657998      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:11.658133      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 03/26/24 05:45:11.956
  STEP: delete the pod with lifecycle hook @ 03/26/24 05:45:11.958
  E0326 05:45:12.658242      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:13.658336      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:14.658432      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:15.659242      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:45:15.967: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-4220" for this suite. @ 03/26/24 05:45:15.969
• [8.041 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:391
  STEP: Creating a kubernetes client @ 03/26/24 05:45:15.971
  Mar 26 05:45:15.971: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename crd-publish-openapi @ 03/26/24 05:45:15.972
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:45:15.98
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:45:15.981
  STEP: set up a multi version CRD @ 03/26/24 05:45:15.982
  Mar 26 05:45:15.983: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  E0326 05:45:16.659790      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:17.660382      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:18.661165      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: rename a version @ 03/26/24 05:45:19.104
  STEP: check the new version name is served @ 03/26/24 05:45:19.112
  E0326 05:45:19.661913      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 03/26/24 05:45:19.81
  STEP: check the other version is not changed @ 03/26/24 05:45:20.441
  E0326 05:45:20.662259      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:21.662798      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:22.663686      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:45:22.933: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3475" for this suite. @ 03/26/24 05:45:22.938
• [6.969 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:262
  STEP: Creating a kubernetes client @ 03/26/24 05:45:22.94
  Mar 26 05:45:22.940: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename downward-api @ 03/26/24 05:45:22.941
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:45:22.948
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:45:22.95
  STEP: Creating a pod to test downward API volume plugin @ 03/26/24 05:45:22.951
  E0326 05:45:23.663839      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:24.663932      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:25.664400      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:26.664986      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 05:45:26.96
  Mar 26 05:45:26.961: INFO: Trying to get logs from node k8s-worker02 pod downwardapi-volume-023b280e-786a-4d50-bdd9-38398bc2dc85 container client-container: <nil>
  STEP: delete the pod @ 03/26/24 05:45:26.964
  Mar 26 05:45:26.969: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2056" for this suite. @ 03/26/24 05:45:26.971
• [4.033 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:99
  STEP: Creating a kubernetes client @ 03/26/24 05:45:26.975
  Mar 26 05:45:26.975: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename configmap @ 03/26/24 05:45:26.976
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:45:26.981
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:45:26.982
  STEP: Creating configMap with name configmap-test-volume-map-a1f113fb-ff0c-4ff5-a46f-785ce34a525e @ 03/26/24 05:45:26.984
  STEP: Creating a pod to test consume configMaps @ 03/26/24 05:45:26.986
  E0326 05:45:27.665956      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:28.666046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:29.666305      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:30.667418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 05:45:30.994
  Mar 26 05:45:30.995: INFO: Trying to get logs from node k8s-worker02 pod pod-configmaps-9e1eefae-cc67-4139-94f5-0f88765a9ca9 container agnhost-container: <nil>
  STEP: delete the pod @ 03/26/24 05:45:30.998
  Mar 26 05:45:31.004: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3793" for this suite. @ 03/26/24 05:45:31.006
• [4.034 seconds]
------------------------------
SS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance]
test/e2e/common/node/podtemplates.go:176
  STEP: Creating a kubernetes client @ 03/26/24 05:45:31.009
  Mar 26 05:45:31.009: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename podtemplate @ 03/26/24 05:45:31.009
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:45:31.015
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:45:31.016
  STEP: Create a pod template @ 03/26/24 05:45:31.018
  STEP: Replace a pod template @ 03/26/24 05:45:31.02
  Mar 26 05:45:31.022: INFO: Found updated podtemplate annotation: "true"

  Mar 26 05:45:31.023: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-1265" for this suite. @ 03/26/24 05:45:31.024
• [0.018 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]
test/e2e/common/node/podtemplates.go:53
  STEP: Creating a kubernetes client @ 03/26/24 05:45:31.028
  Mar 26 05:45:31.029: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename podtemplate @ 03/26/24 05:45:31.029
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:45:31.034
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:45:31.036
  Mar 26 05:45:31.046: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-5762" for this suite. @ 03/26/24 05:45:31.048
• [0.021 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]
test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 03/26/24 05:45:31.05
  Mar 26 05:45:31.050: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename watch @ 03/26/24 05:45:31.05
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:45:31.055
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:45:31.056
  STEP: creating a new configmap @ 03/26/24 05:45:31.058
  STEP: modifying the configmap once @ 03/26/24 05:45:31.059
  STEP: modifying the configmap a second time @ 03/26/24 05:45:31.061
  STEP: deleting the configmap @ 03/26/24 05:45:31.064
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 03/26/24 05:45:31.066
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 03/26/24 05:45:31.066
  Mar 26 05:45:31.066: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2753  826f7281-298a-476a-9c10-15f3aaeb1174 75689 0 2024-03-26 05:45:31 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-03-26 05:45:31 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Mar 26 05:45:31.066: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2753  826f7281-298a-476a-9c10-15f3aaeb1174 75690 0 2024-03-26 05:45:31 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-03-26 05:45:31 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Mar 26 05:45:31.066: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-2753" for this suite. @ 03/26/24 05:45:31.068
• [0.020 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]
test/e2e/apps/statefulset.go:983
  STEP: Creating a kubernetes client @ 03/26/24 05:45:31.072
  Mar 26 05:45:31.072: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename statefulset @ 03/26/24 05:45:31.073
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:45:31.081
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:45:31.082
  STEP: Creating service test in namespace statefulset-1366 @ 03/26/24 05:45:31.083
  STEP: Creating statefulset ss in namespace statefulset-1366 @ 03/26/24 05:45:31.087
  Mar 26 05:45:31.092: INFO: Found 0 stateful pods, waiting for 1
  E0326 05:45:31.667484      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:32.667591      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:33.667740      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:34.667904      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:35.668255      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:36.669186      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:37.669259      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:38.669356      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:39.669518      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:40.670016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:45:41.094: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 03/26/24 05:45:41.096
  STEP: Getting /status @ 03/26/24 05:45:41.099
  Mar 26 05:45:41.102: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 03/26/24 05:45:41.102
  Mar 26 05:45:41.105: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 03/26/24 05:45:41.105
  Mar 26 05:45:41.107: INFO: Observed &StatefulSet event: ADDED
  Mar 26 05:45:41.107: INFO: Found Statefulset ss in namespace statefulset-1366 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Mar 26 05:45:41.107: INFO: Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 03/26/24 05:45:41.107
  Mar 26 05:45:41.107: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Mar 26 05:45:41.110: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 03/26/24 05:45:41.11
  Mar 26 05:45:41.111: INFO: Observed &StatefulSet event: ADDED
  Mar 26 05:45:41.111: INFO: Observed Statefulset ss in namespace statefulset-1366 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Mar 26 05:45:41.111: INFO: Observed &StatefulSet event: MODIFIED
  Mar 26 05:45:41.111: INFO: Deleting all statefulset in ns statefulset-1366
  Mar 26 05:45:41.112: INFO: Scaling statefulset ss to 0
  E0326 05:45:41.670841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:42.670988      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:43.671145      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:44.671275      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:45.671376      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:46.671469      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:47.671853      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:48.672883      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:49.673221      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:50.673463      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:45:51.119: INFO: Waiting for statefulset status.replicas updated to 0
  Mar 26 05:45:51.121: INFO: Deleting statefulset ss
  Mar 26 05:45:51.125: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1366" for this suite. @ 03/26/24 05:45:51.126
• [20.056 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]
test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 03/26/24 05:45:51.129
  Mar 26 05:45:51.129: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename watch @ 03/26/24 05:45:51.13
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:45:51.136
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:45:51.137
  STEP: creating a watch on configmaps with label A @ 03/26/24 05:45:51.139
  STEP: creating a watch on configmaps with label B @ 03/26/24 05:45:51.14
  STEP: creating a watch on configmaps with label A or B @ 03/26/24 05:45:51.14
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 03/26/24 05:45:51.141
  Mar 26 05:45:51.143: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3450  9491c1af-1683-4965-b1ed-70305c18e729 75808 0 2024-03-26 05:45:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-03-26 05:45:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Mar 26 05:45:51.143: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3450  9491c1af-1683-4965-b1ed-70305c18e729 75808 0 2024-03-26 05:45:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-03-26 05:45:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 03/26/24 05:45:51.143
  Mar 26 05:45:51.146: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3450  9491c1af-1683-4965-b1ed-70305c18e729 75809 0 2024-03-26 05:45:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-03-26 05:45:51 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Mar 26 05:45:51.146: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3450  9491c1af-1683-4965-b1ed-70305c18e729 75809 0 2024-03-26 05:45:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-03-26 05:45:51 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 03/26/24 05:45:51.146
  Mar 26 05:45:51.149: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3450  9491c1af-1683-4965-b1ed-70305c18e729 75810 0 2024-03-26 05:45:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-03-26 05:45:51 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Mar 26 05:45:51.149: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3450  9491c1af-1683-4965-b1ed-70305c18e729 75810 0 2024-03-26 05:45:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-03-26 05:45:51 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 03/26/24 05:45:51.149
  Mar 26 05:45:51.151: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3450  9491c1af-1683-4965-b1ed-70305c18e729 75811 0 2024-03-26 05:45:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-03-26 05:45:51 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Mar 26 05:45:51.151: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3450  9491c1af-1683-4965-b1ed-70305c18e729 75811 0 2024-03-26 05:45:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-03-26 05:45:51 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 03/26/24 05:45:51.151
  Mar 26 05:45:51.153: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3450  0a7dbf1b-0eae-491d-951e-2397257190d7 75812 0 2024-03-26 05:45:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-03-26 05:45:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Mar 26 05:45:51.153: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3450  0a7dbf1b-0eae-491d-951e-2397257190d7 75812 0 2024-03-26 05:45:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-03-26 05:45:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0326 05:45:51.673560      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:52.674012      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:53.674145      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:54.674260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:55.674330      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:56.674420      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:57.674640      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:58.675296      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:45:59.675493      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:00.675915      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 03/26/24 05:46:01.153
  Mar 26 05:46:01.156: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3450  0a7dbf1b-0eae-491d-951e-2397257190d7 75842 0 2024-03-26 05:45:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-03-26 05:45:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Mar 26 05:46:01.157: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3450  0a7dbf1b-0eae-491d-951e-2397257190d7 75842 0 2024-03-26 05:45:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-03-26 05:45:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0326 05:46:01.676593      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:02.676739      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:03.676884      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:04.677050      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:05.677493      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:06.678008      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:07.678171      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:08.678348      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:09.678530      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:10.679103      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:46:11.157: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3450" for this suite. @ 03/26/24 05:46:11.16
• [20.033 seconds]
------------------------------
SSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]
test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 03/26/24 05:46:11.163
  Mar 26 05:46:11.163: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 03/26/24 05:46:11.164
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:46:11.173
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:46:11.174
  STEP: creating a target pod @ 03/26/24 05:46:11.175
  E0326 05:46:11.679950      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:12.680188      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 03/26/24 05:46:13.183
  E0326 05:46:13.680261      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:14.680456      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:15.681487      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:16.681689      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 03/26/24 05:46:17.194
  Mar 26 05:46:17.194: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-7077 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 05:46:17.194: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:46:17.194: INFO: ExecWithOptions: Clientset creation
  Mar 26 05:46:17.194: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/ephemeral-containers-test-7077/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Mar 26 05:46:17.230: INFO: Exec stderr: ""
  Mar 26 05:46:17.232: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-7077" for this suite. @ 03/26/24 05:46:17.234
• [6.075 seconds]
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]
test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 03/26/24 05:46:17.238
  Mar 26 05:46:17.238: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename subpath @ 03/26/24 05:46:17.239
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:46:17.244
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:46:17.245
  STEP: Setting up data @ 03/26/24 05:46:17.247
  STEP: Creating pod pod-subpath-test-configmap-9674 @ 03/26/24 05:46:17.25
  STEP: Creating a pod to test atomic-volume-subpath @ 03/26/24 05:46:17.25
  E0326 05:46:17.682211      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:18.682292      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:19.683013      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:20.683372      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:21.683580      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:22.683665      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:23.684530      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:24.684614      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:25.684699      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:26.684788      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:27.685087      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:28.685256      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:29.685931      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:30.686784      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:31.687143      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:32.687243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:33.688146      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:34.688240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:35.688953      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:36.689091      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:37.689486      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:38.689686      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 05:46:39.276
  Mar 26 05:46:39.277: INFO: Trying to get logs from node k8s-worker01 pod pod-subpath-test-configmap-9674 container test-container-subpath-configmap-9674: <nil>
  STEP: delete the pod @ 03/26/24 05:46:39.28
  STEP: Deleting pod pod-subpath-test-configmap-9674 @ 03/26/24 05:46:39.285
  Mar 26 05:46:39.285: INFO: Deleting pod "pod-subpath-test-configmap-9674" in namespace "subpath-1654"
  Mar 26 05:46:39.286: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-1654" for this suite. @ 03/26/24 05:46:39.289
• [22.054 seconds]
------------------------------
SSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
test/e2e/network/endpointslice.go:104
  STEP: Creating a kubernetes client @ 03/26/24 05:46:39.292
  Mar 26 05:46:39.292: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename endpointslice @ 03/26/24 05:46:39.292
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:46:39.298
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:46:39.299
  E0326 05:46:39.690530      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:40.691159      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:46:41.319: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-788" for this suite. @ 03/26/24 05:46:41.321
• [2.033 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance]
test/e2e/common/node/podtemplates.go:122
  STEP: Creating a kubernetes client @ 03/26/24 05:46:41.324
  Mar 26 05:46:41.324: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename podtemplate @ 03/26/24 05:46:41.325
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:46:41.33
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:46:41.331
  STEP: Create set of pod templates @ 03/26/24 05:46:41.332
  Mar 26 05:46:41.334: INFO: created test-podtemplate-1
  Mar 26 05:46:41.339: INFO: created test-podtemplate-2
  Mar 26 05:46:41.342: INFO: created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 03/26/24 05:46:41.342
  STEP: delete collection of pod templates @ 03/26/24 05:46:41.344
  Mar 26 05:46:41.344: INFO: requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 03/26/24 05:46:41.348
  Mar 26 05:46:41.348: INFO: requesting list of pod templates to confirm quantity
  Mar 26 05:46:41.349: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-8943" for this suite. @ 03/26/24 05:46:41.351
• [0.028 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
test/e2e/common/node/expansion.go:189
  STEP: Creating a kubernetes client @ 03/26/24 05:46:41.353
  Mar 26 05:46:41.353: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename var-expansion @ 03/26/24 05:46:41.354
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:46:41.361
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:46:41.362
  E0326 05:46:41.691162      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:42.691263      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:46:43.369: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Mar 26 05:46:43.371: INFO: Deleting pod "var-expansion-bef12ea8-9de1-46d9-9ca1-27cd02a9b5c1" in namespace "var-expansion-9748"
  Mar 26 05:46:43.374: INFO: Wait up to 5m0s for pod "var-expansion-bef12ea8-9de1-46d9-9ca1-27cd02a9b5c1" to be fully deleted
  E0326 05:46:43.691407      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:44.691792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:45.692958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:46.693078      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "var-expansion-9748" for this suite. @ 03/26/24 05:46:47.38
• [6.029 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:137
  STEP: Creating a kubernetes client @ 03/26/24 05:46:47.382
  Mar 26 05:46:47.382: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename emptydir @ 03/26/24 05:46:47.383
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:46:47.388
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:46:47.389
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 03/26/24 05:46:47.39
  E0326 05:46:47.693156      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:48.694173      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:49.694899      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:50.694992      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 05:46:51.4
  Mar 26 05:46:51.401: INFO: Trying to get logs from node k8s-worker01 pod pod-038cf120-cb9b-4fd6-ba52-0e24f6a99106 container test-container: <nil>
  STEP: delete the pod @ 03/26/24 05:46:51.405
  Mar 26 05:46:51.411: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-391" for this suite. @ 03/26/24 05:46:51.413
• [4.033 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 03/26/24 05:46:51.416
  Mar 26 05:46:51.416: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename container-runtime @ 03/26/24 05:46:51.416
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:46:51.423
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:46:51.425
  STEP: create the container @ 03/26/24 05:46:51.426
  W0326 05:46:51.430049      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 03/26/24 05:46:51.43
  E0326 05:46:51.695995      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:52.696100      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:53.696869      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 03/26/24 05:46:54.438
  STEP: the container should be terminated @ 03/26/24 05:46:54.439
  STEP: the termination message should be set @ 03/26/24 05:46:54.439
  Mar 26 05:46:54.439: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 03/26/24 05:46:54.439
  Mar 26 05:46:54.442: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7552" for this suite. @ 03/26/24 05:46:54.448
• [3.037 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:97
  STEP: Creating a kubernetes client @ 03/26/24 05:46:54.454
  Mar 26 05:46:54.454: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename emptydir @ 03/26/24 05:46:54.455
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:46:54.46
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:46:54.462
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 03/26/24 05:46:54.463
  E0326 05:46:54.697690      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:55.698072      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:56.698535      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:57.698644      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 05:46:58.473
  Mar 26 05:46:58.474: INFO: Trying to get logs from node k8s-worker02 pod pod-b03fa383-0b8a-4a36-9281-0069e486abb8 container test-container: <nil>
  STEP: delete the pod @ 03/26/24 05:46:58.476
  Mar 26 05:46:58.482: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2340" for this suite. @ 03/26/24 05:46:58.483
• [4.032 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:217
  STEP: Creating a kubernetes client @ 03/26/24 05:46:58.486
  Mar 26 05:46:58.486: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename emptydir @ 03/26/24 05:46:58.487
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:46:58.491
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:46:58.492
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 03/26/24 05:46:58.494
  E0326 05:46:58.698994      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:46:59.699129      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:00.699212      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:01.699348      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 05:47:02.503
  Mar 26 05:47:02.504: INFO: Trying to get logs from node k8s-worker02 pod pod-07a6efc2-6820-4335-bc09-7afdfc736e42 container test-container: <nil>
  STEP: delete the pod @ 03/26/24 05:47:02.506
  Mar 26 05:47:02.512: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6170" for this suite. @ 03/26/24 05:47:02.513
• [4.029 seconds]
------------------------------
S
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance]
test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 03/26/24 05:47:02.515
  Mar 26 05:47:02.515: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename deployment @ 03/26/24 05:47:02.516
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:47:02.522
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:47:02.523
  Mar 26 05:47:02.527: INFO: Pod name rollover-pod: Found 0 pods out of 1
  E0326 05:47:02.700304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:03.700472      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:04.700613      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:05.700709      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:06.700913      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:47:07.530: INFO: Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 03/26/24 05:47:07.53
  Mar 26 05:47:07.530: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E0326 05:47:07.701717      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:08.701874      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:47:09.532: INFO: Creating deployment "test-rollover-deployment"
  Mar 26 05:47:09.536: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
  E0326 05:47:09.702789      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:10.702976      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:47:11.539: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
  Mar 26 05:47:11.542: INFO: Ensure that both replica sets have 1 created replica
  Mar 26 05:47:11.544: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  Mar 26 05:47:11.548: INFO: Updating deployment test-rollover-deployment
  Mar 26 05:47:11.548: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E0326 05:47:11.703700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:12.703826      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:47:13.551: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
  Mar 26 05:47:13.554: INFO: Make sure deployment "test-rollover-deployment" is complete
  Mar 26 05:47:13.556: INFO: all replica sets need to contain the pod-template-hash label
  Mar 26 05:47:13.556: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 5, 47, 9, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 47, 9, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 5, 47, 12, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 47, 9, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-df7c4dd5d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0326 05:47:13.704692      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:14.704826      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:47:15.560: INFO: all replica sets need to contain the pod-template-hash label
  Mar 26 05:47:15.560: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 5, 47, 9, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 47, 9, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 5, 47, 12, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 47, 9, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-df7c4dd5d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0326 05:47:15.705447      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:16.705540      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:47:17.559: INFO: all replica sets need to contain the pod-template-hash label
  Mar 26 05:47:17.559: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 5, 47, 9, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 47, 9, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 5, 47, 12, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 47, 9, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-df7c4dd5d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0326 05:47:17.705703      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:18.705820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:47:19.559: INFO: all replica sets need to contain the pod-template-hash label
  Mar 26 05:47:19.559: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 5, 47, 9, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 47, 9, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 5, 47, 12, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 47, 9, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-df7c4dd5d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0326 05:47:19.705878      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:20.706058      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:47:21.560: INFO: all replica sets need to contain the pod-template-hash label
  Mar 26 05:47:21.560: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 5, 47, 9, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 47, 9, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 5, 47, 12, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 5, 47, 9, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-df7c4dd5d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0326 05:47:21.706111      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:22.706270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:47:23.560: INFO: 
  Mar 26 05:47:23.560: INFO: Ensure that both old replica sets have no replicas
  Mar 26 05:47:23.564: INFO: Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3836",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fc4abc21-86d7-4150-8dbf-312618588c9d",
      ResourceVersion: (string) (len=5) "76324",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028829,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028831,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028842,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=55) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028829,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028829,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028842,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028829,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=76) "ReplicaSet \"test-rollover-deployment-df7c4dd5d\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Mar 26 05:47:23.568: INFO: New ReplicaSet "test-rollover-deployment-df7c4dd5d" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-rollover-deployment-df7c4dd5d",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3836",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5c253de0-8f6d-404e-934a-548a557e6e87",
      ResourceVersion: (string) (len=5) "76314",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028831,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=9) "df7c4dd5d"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "fc4abc21-86d7-4150-8dbf-312618588c9d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028831,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 66 63 34 61 62 63  32 31 2d 38 36 64 37 2d  |\"fc4abc21-86d7-|
              00000120  34 31 35 30 2d 38 64 62  66 2d 33 31 32 36 31 38  |4150-8dbf-312618|
              00000130  35 38 38 63 39 64 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |588c9d\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028842,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=9) "df7c4dd5d"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=9) "df7c4dd5d"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=55) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Mar 26 05:47:23.568: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
  Mar 26 05:47:23.569: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3836",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "95372a91-d179-460c-8a32-686468a2baaf",
      ResourceVersion: (string) (len=5) "76323",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028822,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "fc4abc21-86d7-4150-8dbf-312618588c9d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028822,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028842,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  66 63 34 61 62 63 32 31  2d 38 36 64 37 2d 34 31  |fc4abc21-86d7-41|
              000000c0  35 30 2d 38 64 62 66 2d  33 31 32 36 31 38 35 38  |50-8dbf-31261858|
              000000d0  38 63 39 64 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |8c9d\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028842,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "pod": (string) (len=5) "httpd",
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Mar 26 05:47:23.570: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-664fc6c874",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3836",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "00ebfa79-8aab-40a0-9688-1dc3866ba7e8",
      ResourceVersion: (string) (len=5) "76280",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028829,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "fc4abc21-86d7-4150-8dbf-312618588c9d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028831,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 66 63 34 61 62 63  32 31 2d 38 36 64 37 2d  |\"fc4abc21-86d7-|
              00000120  34 31 35 30 2d 38 64 62  66 2d 33 31 32 36 31 38  |4150-8dbf-312618|
              00000130  35 38 38 63 39 64 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |588c9d\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028831,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Mar 26 05:47:23.574: INFO: Pod "test-rollover-deployment-df7c4dd5d-54hrd" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-rollover-deployment-df7c4dd5d-54hrd",
      GenerateName: (string) (len=35) "test-rollover-deployment-df7c4dd5d-",
      Namespace: (string) (len=15) "deployment-3836",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "35f26383-3f77-476c-aba0-6d78d1f285b3",
      ResourceVersion: (string) (len=5) "76291",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028831,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=9) "df7c4dd5d"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "10.244.79.110/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "10.244.79.110/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "d0791922322bb674abe67df45850a620582dabe6159c9b4f9e027abfc321f376"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-rollover-deployment-df7c4dd5d",
          UID: (types.UID) (len=36) "5c253de0-8f6d-404e-934a-548a557e6e87",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028831,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028831,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 63  32 35 33 64 65 30 2d 38  |d\":\"5c253de0-8|
              00000090  66 36 64 2d 34 30 34 65  2d 39 33 34 61 2d 35 34  |f6d-404e-934a-54|
              000000a0  38 61 35 35 37 65 36 65  38 37 5c 22 7d 22 3a 7b  |8a557e6e87\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 34 34 2e 37  39 2e 31 31 30 5c 22 7d  |10.244.79.110\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-zdfgd",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=55) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-zdfgd",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028831,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028832,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028831,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.14",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.244.79.110",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.244.79.110"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028831,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63847028832,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=55) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45",
          ImageID: (string) (len=122) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost@sha256:8f07c07228b54f5d644c14241ad3e483b999c5d3a78f7580a6252c8ab42f2b66",
          ContainerID: (string) (len=72) "cri-o://1eac937ca8f72a99be8961b28169f8659682aaa54592eeca25064113c78addb6",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 05:47:23.576: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3836" for this suite. @ 03/26/24 05:47:23.579
• [21.070 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
test/e2e/apps/job.go:370
  STEP: Creating a kubernetes client @ 03/26/24 05:47:23.586
  Mar 26 05:47:23.586: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename job @ 03/26/24 05:47:23.587
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:47:23.593
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:47:23.595
  STEP: Creating Indexed job @ 03/26/24 05:47:23.596
  STEP: Ensuring job reaches completions @ 03/26/24 05:47:23.599
  E0326 05:47:23.706614      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:24.707656      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:25.708345      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:26.709042      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:27.709425      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:28.709626      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring pods with index for job exist @ 03/26/24 05:47:29.6
  Mar 26 05:47:29.602: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1672" for this suite. @ 03/26/24 05:47:29.604
• [6.020 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:176
  STEP: Creating a kubernetes client @ 03/26/24 05:47:29.608
  Mar 26 05:47:29.609: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename crd-webhook @ 03/26/24 05:47:29.609
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:47:29.614
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:47:29.617
  STEP: Setting up server cert @ 03/26/24 05:47:29.618
  E0326 05:47:29.710205      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 03/26/24 05:47:29.857
  STEP: Deploying the custom resource conversion webhook pod @ 03/26/24 05:47:29.861
  STEP: Wait for the deployment to be ready @ 03/26/24 05:47:29.866
  Mar 26 05:47:29.869: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0326 05:47:30.710981      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:31.711196      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 03/26/24 05:47:31.873
  STEP: Verifying the service has paired with the endpoint @ 03/26/24 05:47:31.878
  E0326 05:47:32.711732      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:47:32.879: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Mar 26 05:47:32.882: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  E0326 05:47:33.712619      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:34.712725      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 03/26/24 05:47:35.417
  STEP: Create a v2 custom resource @ 03/26/24 05:47:35.424
  STEP: List CRs in v1 @ 03/26/24 05:47:35.443
  STEP: List CRs in v2 @ 03/26/24 05:47:35.444
  Mar 26 05:47:35.446: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0326 05:47:35.713741      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "crd-webhook-833" for this suite. @ 03/26/24 05:47:35.974
• [6.371 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:347
  STEP: Creating a kubernetes client @ 03/26/24 05:47:35.98
  Mar 26 05:47:35.980: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename security-context-test @ 03/26/24 05:47:35.981
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:47:35.988
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:47:35.99
  E0326 05:47:36.713904      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:37.714005      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:47:37.999: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-913" for this suite. @ 03/26/24 05:47:38.001
• [2.024 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]
test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 03/26/24 05:47:38.004
  Mar 26 05:47:38.004: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename deployment @ 03/26/24 05:47:38.005
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:47:38.009
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:47:38.011
  STEP: creating a Deployment @ 03/26/24 05:47:38.014
  STEP: waiting for Deployment to be created @ 03/26/24 05:47:38.016
  STEP: waiting for all Replicas to be Ready @ 03/26/24 05:47:38.016
  Mar 26 05:47:38.017: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Mar 26 05:47:38.018: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Mar 26 05:47:38.020: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Mar 26 05:47:38.021: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Mar 26 05:47:38.026: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Mar 26 05:47:38.026: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Mar 26 05:47:38.037: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Mar 26 05:47:38.037: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Mar 26 05:47:38.555: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Mar 26 05:47:38.555: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  E0326 05:47:38.714097      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:47:38.837: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 03/26/24 05:47:38.837
  Mar 26 05:47:38.841: INFO: observed event type ADDED
  STEP: waiting for Replicas to scale @ 03/26/24 05:47:38.841
  Mar 26 05:47:38.842: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 0
  Mar 26 05:47:38.842: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 0
  Mar 26 05:47:38.842: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 0
  Mar 26 05:47:38.842: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 0
  Mar 26 05:47:38.842: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 0
  Mar 26 05:47:38.842: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 0
  Mar 26 05:47:38.842: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 0
  Mar 26 05:47:38.842: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 0
  Mar 26 05:47:38.842: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1
  Mar 26 05:47:38.842: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1
  Mar 26 05:47:38.842: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 2
  Mar 26 05:47:38.842: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 2
  Mar 26 05:47:38.842: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 2
  Mar 26 05:47:38.842: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 2
  Mar 26 05:47:38.845: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 2
  Mar 26 05:47:38.845: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 2
  Mar 26 05:47:38.851: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 2
  Mar 26 05:47:38.851: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 2
  Mar 26 05:47:38.860: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1
  Mar 26 05:47:38.860: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1
  Mar 26 05:47:38.865: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1
  Mar 26 05:47:38.865: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1
  Mar 26 05:47:39.564: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 2
  Mar 26 05:47:39.564: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 2
  Mar 26 05:47:39.571: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1
  STEP: listing Deployments @ 03/26/24 05:47:39.572
  Mar 26 05:47:39.573: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 03/26/24 05:47:39.573
  Mar 26 05:47:39.578: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 03/26/24 05:47:39.578
  Mar 26 05:47:39.581: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Mar 26 05:47:39.584: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Mar 26 05:47:39.589: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Mar 26 05:47:39.596: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Mar 26 05:47:39.602: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Mar 26 05:47:39.604: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E0326 05:47:39.715152      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:47:40.572: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Mar 26 05:47:40.578: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Mar 26 05:47:40.582: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Mar 26 05:47:40.592: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Mar 26 05:47:40.597: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0326 05:47:40.715238      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:41.715399      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:47:41.849: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 03/26/24 05:47:41.858
  STEP: fetching the DeploymentStatus @ 03/26/24 05:47:41.861
  Mar 26 05:47:41.864: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1
  Mar 26 05:47:41.864: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1
  Mar 26 05:47:41.864: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1
  Mar 26 05:47:41.864: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1
  Mar 26 05:47:41.864: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1
  Mar 26 05:47:41.864: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 1
  Mar 26 05:47:41.864: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 2
  Mar 26 05:47:41.864: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 2
  Mar 26 05:47:41.864: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 2
  Mar 26 05:47:41.864: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 2
  Mar 26 05:47:41.865: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 2
  Mar 26 05:47:41.865: INFO: observed Deployment test-deployment in namespace deployment-2411 with ReadyReplicas 3
  STEP: deleting the Deployment @ 03/26/24 05:47:41.865
  Mar 26 05:47:41.868: INFO: observed event type MODIFIED
  Mar 26 05:47:41.868: INFO: observed event type MODIFIED
  Mar 26 05:47:41.868: INFO: observed event type MODIFIED
  Mar 26 05:47:41.868: INFO: observed event type MODIFIED
  Mar 26 05:47:41.868: INFO: observed event type MODIFIED
  Mar 26 05:47:41.868: INFO: observed event type MODIFIED
  Mar 26 05:47:41.868: INFO: observed event type MODIFIED
  Mar 26 05:47:41.868: INFO: observed event type MODIFIED
  Mar 26 05:47:41.868: INFO: observed event type MODIFIED
  Mar 26 05:47:41.868: INFO: observed event type MODIFIED
  Mar 26 05:47:41.868: INFO: observed event type MODIFIED
  Mar 26 05:47:41.868: INFO: observed event type MODIFIED
  Mar 26 05:47:41.868: INFO: observed event type MODIFIED
  Mar 26 05:47:41.868: INFO: observed event type MODIFIED
  Mar 26 05:47:41.868: INFO: observed event type MODIFIED
  Mar 26 05:47:41.869: INFO: Log out all the ReplicaSets if there is no deployment created
  Mar 26 05:47:41.870: INFO: ReplicaSet "test-deployment-66574fbd5":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=25) "test-deployment-66574fbd5",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2411",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "749b5e17-9cdd-4aa4-b484-0055b07f428e",
      ResourceVersion: (string) (len=5) "76763",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028859,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "66574fbd5",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "3"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "9bfc8081-b1e4-44bd-8f8e-4ea264433351",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 39 62 66 63  38 30 38 31 2d 62 31 65  |":\"9bfc8081-b1e|
              00000130  34 2d 34 34 62 64 2d 38  66 38 65 2d 34 65 61 32  |4-44bd-8f8e-4ea2|
              00000140  36 34 34 33 33 33 35 31  5c 22 7d 22 3a 7b 7d 7d  |64433351\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=22) "test-deployment-static": (string) (len=4) "true",
          (string) (len=17) "pod-template-hash": (string) (len=9) "66574fbd5"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=22) "test-deployment-static": (string) (len=4) "true",
            (string) (len=17) "pod-template-hash": (string) (len=9) "66574fbd5"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 2,
      FullyLabeledReplicas: (int32) 2,
      ReadyReplicas: (int32) 2,
      AvailableReplicas: (int32) 2,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  Mar 26 05:47:41.874: INFO: pod: "test-deployment-66574fbd5-85lqv":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "test-deployment-66574fbd5-85lqv",
      GenerateName: (string) (len=26) "test-deployment-66574fbd5-",
      Namespace: (string) (len=15) "deployment-2411",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "508c7a28-4329-4a71-acf4-b60086cc55e1",
      ResourceVersion: (string) (len=5) "76762",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028860,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=22) "test-deployment-static": (string) (len=4) "true",
        (string) (len=17) "pod-template-hash": (string) (len=9) "66574fbd5"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=15) "10.244.79.91/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "1d7ae30a1fd75e38b7ae50e1e274be8ebb81d7990d25a375018f43bf52c34b51",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=15) "10.244.79.91/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=25) "test-deployment-66574fbd5",
          UID: (types.UID) (len=36) "749b5e17-9cdd-4aa4-b484-0055b07f428e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  37 34 39 62 35 65 31 37  |uid\":\"749b5e17|
              000000a0  2d 39 63 64 64 2d 34 61  61 34 2d 62 34 38 34 2d  |-9cdd-4aa4-b484-|
              000000b0  30 30 35 35 62 30 37 66  34 32 38 65 5c 22 7d 22  |0055b07f428e\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=519) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 34 34 2e 37  39 2e 39 31 5c 22 7d 22  |10.244.79.91\"}"|
              000001e0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              000001f0  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000200  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-p8hlf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-p8hlf",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.14",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=12) "10.244.79.91",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.79.91"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028860,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63847028861,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          ImageID: (string) (len=120) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://1b108716630b1581e7739b0e918130d5d828110cf25919a640c23e64bfda0520",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  Mar 26 05:47:41.877: INFO: pod: "test-deployment-66574fbd5-t8847":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "test-deployment-66574fbd5-t8847",
      GenerateName: (string) (len=26) "test-deployment-66574fbd5-",
      Namespace: (string) (len=15) "deployment-2411",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a9df204f-9a44-49eb-b2f1-89871c6178f3",
      ResourceVersion: (string) (len=5) "76708",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028859,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "66574fbd5",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "80685e4f36e13b345aa72c13193e11d7395f0e29b0fb1f3d5f0778ec8e230219",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "10.244.69.214/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "10.244.69.214/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=25) "test-deployment-66574fbd5",
          UID: (types.UID) (len=36) "749b5e17-9cdd-4aa4-b484-0055b07f428e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  37 34 39 62 35 65 31 37  |uid\":\"749b5e17|
              000000a0  2d 39 63 64 64 2d 34 61  61 34 2d 62 34 38 34 2d  |-9cdd-4aa4-b484-|
              000000b0  30 30 35 35 62 30 37 66  34 32 38 65 5c 22 7d 22  |0055b07f428e\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 34 34 2e 36  39 2e 32 31 34 5c 22 7d  |10.244.69.214\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-8bs7s",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-8bs7s",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.15",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.244.69.214",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.244.69.214"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028859,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63847028860,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          ImageID: (string) (len=120) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://eb0ed2613b70df916af8f1c9ffd7166d85fb98766198a9ba0ce4b59c4b0c79c9",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  Mar 26 05:47:41.881: INFO: ReplicaSet "test-deployment-7678fcd584":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-7678fcd584",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2411",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "eaefd092-e483-439f-a912-6f23e529cc55",
      ResourceVersion: (string) (len=5) "76665",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "7678fcd584",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "9bfc8081-b1e4-44bd-8f8e-4ea264433351",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 39 62 66 63  38 30 38 31 2d 62 31 65  |":\"9bfc8081-b1e|
              00000130  34 2d 34 34 62 64 2d 38  66 38 65 2d 34 65 61 32  |4-44bd-8f8e-4ea2|
              00000140  36 34 34 33 33 33 35 31  5c 22 7d 22 3a 7b 7d 7d  |64433351\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=22) "test-deployment-static": (string) (len=4) "true",
          (string) (len=17) "pod-template-hash": (string) (len=10) "7678fcd584"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "7678fcd584",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=55) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 3,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  Mar 26 05:47:41.886: INFO: ReplicaSet "test-deployment-7ff8d686dd":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-7ff8d686dd",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2411",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ddc005d5-2029-41dc-b060-89bde3a1ebff",
      ResourceVersion: (string) (len=5) "76774",
      Generation: (int64) 4,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "7ff8d686dd",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "9bfc8081-b1e4-44bd-8f8e-4ea264433351",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 39 62 66 63  38 30 38 31 2d 62 31 65  |":\"9bfc8081-b1e|
              00000130  34 2d 34 34 62 64 2d 38  66 38 65 2d 34 65 61 32  |4-44bd-8f8e-4ea2|
              00000140  36 34 34 33 33 33 35 31  5c 22 7d 22 3a 7b 7d 7d  |64433351\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "7ff8d686dd",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "7ff8d686dd",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=52) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/pause:3.9",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(2),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 4,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  Mar 26 05:47:41.898: INFO: pod: "test-deployment-7ff8d686dd-mvjc4":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-7ff8d686dd-mvjc4",
      GenerateName: (string) (len=27) "test-deployment-7ff8d686dd-",
      Namespace: (string) (len=15) "deployment-2411",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c4f0094a-290c-4ade-a344-1b36d00e67ee",
      ResourceVersion: (string) (len=5) "76768",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028863,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(2),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "7ff8d686dd",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "10.244.69.215/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "07ab33155d8fab4c4d96942857f7d5bdbdfa7b1ac937b1254f6909d996af7775",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "10.244.69.215/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-7ff8d686dd",
          UID: (types.UID) (len=36) "ddc005d5-2029-41dc-b060-89bde3a1ebff",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  64 64 63 30 30 35 64 35  |uid\":\"ddc005d5|
              000000a0  2d 32 30 32 39 2d 34 31  64 63 2d 62 30 36 30 2d  |-2029-41dc-b060-|
              000000b0  38 39 62 64 65 33 61 31  65 62 66 66 5c 22 7d 22  |89bde3a1ebff\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 34 34 2e 36  39 2e 32 31 35 5c 22 7d  |10.244.69.215\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-grbfx",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=52) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/pause:3.9",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-grbfx",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(2),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.15",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.244.69.215",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.244.69.215"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63847028859,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=52) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/pause:3.9",
          ImageID: (string) (len=120) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/pause@sha256:0fc1f3b764be56f7c881a69cbd553ae25a2b5523c6901fbacb8270307c29d0c4",
          ContainerID: (string) (len=72) "cri-o://03cd294fa7f1e254f57d79c5ef167693a6dcadb369c535259c4a97c9ef1e4afa",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  Mar 26 05:47:41.900: INFO: pod: "test-deployment-7ff8d686dd-z97wk":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-7ff8d686dd-z97wk",
      GenerateName: (string) (len=27) "test-deployment-7ff8d686dd-",
      Namespace: (string) (len=15) "deployment-2411",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0975c67f-8924-4e76-ac0a-e6eb4999aa6f",
      ResourceVersion: (string) (len=5) "76736",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028859,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028862,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(2),
      Labels: (map[string]string) (len=2) {
        (string) (len=22) "test-deployment-static": (string) (len=4) "true",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7ff8d686dd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "a89e818073d261860918d9e89712367fbfa44cc1342757fb419f10b485ee1755",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=15) "10.244.79.96/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=15) "10.244.79.96/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-7ff8d686dd",
          UID: (types.UID) (len=36) "ddc005d5-2029-41dc-b060-89bde3a1ebff",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  64 64 63 30 30 35 64 35  |uid\":\"ddc005d5|
              000000a0  2d 32 30 32 39 2d 34 31  64 63 2d 62 30 36 30 2d  |-2029-41dc-b060-|
              000000b0  38 39 62 64 65 33 61 31  65 62 66 66 5c 22 7d 22  |89bde3a1ebff\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=519) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 34 34 2e 37  39 2e 39 36 5c 22 7d 22  |10.244.79.96\"}"|
              000001e0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              000001f0  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000200  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-frvm6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=52) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/pause:3.9",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-frvm6",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(2),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847028859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.14",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=12) "10.244.79.96",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.79.96"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847028859,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63847028860,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=52) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/pause:3.9",
          ImageID: (string) (len=120) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/pause@sha256:0fc1f3b764be56f7c881a69cbd553ae25a2b5523c6901fbacb8270307c29d0c4",
          ContainerID: (string) (len=72) "cri-o://171d5a7ee60b7484fede902fc8f559435710fe2292fb12a03409c0d7bdab9294",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  Mar 26 05:47:41.902: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2411" for this suite. @ 03/26/24 05:47:41.905
• [3.904 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance]
test/e2e/apimachinery/field_validation.go:622
  STEP: Creating a kubernetes client @ 03/26/24 05:47:41.909
  Mar 26 05:47:41.909: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename field-validation @ 03/26/24 05:47:41.91
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:47:41.916
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:47:41.917
  Mar 26 05:47:41.918: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  E0326 05:47:42.715407      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:43.715503      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0326 05:47:44.442124      19 warnings.go:70] unknown field "alpha"
  W0326 05:47:44.442136      19 warnings.go:70] unknown field "beta"
  W0326 05:47:44.442139      19 warnings.go:70] unknown field "delta"
  W0326 05:47:44.442142      19 warnings.go:70] unknown field "epsilon"
  W0326 05:47:44.442144      19 warnings.go:70] unknown field "gamma"
  E0326 05:47:44.716279      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:47:44.951: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-259" for this suite. @ 03/26/24 05:47:44.956
• [3.049 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]
test/e2e/apimachinery/resource_quota.go:946
  STEP: Creating a kubernetes client @ 03/26/24 05:47:44.958
  Mar 26 05:47:44.958: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename resourcequota @ 03/26/24 05:47:44.959
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:47:44.964
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:47:44.965
  STEP: Creating a ResourceQuota @ 03/26/24 05:47:44.966
  STEP: Getting a ResourceQuota @ 03/26/24 05:47:44.968
  STEP: Listing all ResourceQuotas with LabelSelector @ 03/26/24 05:47:44.969
  STEP: Patching the ResourceQuota @ 03/26/24 05:47:44.97
  STEP: Deleting a Collection of ResourceQuotas @ 03/26/24 05:47:44.972
  STEP: Verifying the deleted ResourceQuota @ 03/26/24 05:47:44.974
  Mar 26 05:47:44.975: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8755" for this suite. @ 03/26/24 05:47:44.977
• [0.020 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:134
  STEP: Creating a kubernetes client @ 03/26/24 05:47:44.978
  Mar 26 05:47:44.978: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename container-probe @ 03/26/24 05:47:44.979
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:47:44.983
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:47:44.985
  STEP: Creating pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856 @ 03/26/24 05:47:44.986
  E0326 05:47:45.717152      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:46.717284      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 03/26/24 05:47:46.993
  Mar 26 05:47:46.994: INFO: Initial restart count of pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c is 0
  Mar 26 05:47:46.995: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:47:47.718325      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:48.718475      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:47:48.997: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:47:49.719337      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:50.719517      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:47:50.999: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:47:51.719697      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:52.719792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:47:53.001: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:47:53.720146      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:54.720308      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:47:55.003: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:47:55.720440      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:56.720542      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:47:57.005: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:47:57.721378      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:47:58.721524      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:47:59.007: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:47:59.722584      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:00.723036      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:48:01.010: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:48:01.723182      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:02.723430      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:48:03.012: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:48:03.723541      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:04.723669      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:48:05.015: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:48:05.724177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:06.724618      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:48:07.017: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:48:07.725482      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:08.725666      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:48:09.019: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:48:09.726639      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:10.726939      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:48:11.022: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:48:11.727207      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:12.727419      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:48:13.024: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:48:13.728361      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:14.728583      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:48:15.026: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:48:15.728628      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:16.728797      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:48:17.028: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:48:17.729124      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:18.729226      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:48:19.031: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:48:19.729531      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:20.729856      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:48:21.034: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:48:21.729946      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:22.730103      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:48:23.036: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:48:23.730798      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:24.730951      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:48:25.038: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:48:25.730996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:26.731105      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:48:27.039: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:48:27.731735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:28.731855      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:48:29.041: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:48:29.731964      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:30.732045      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:48:31.042: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:48:31.732145      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:32.732240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:48:33.045: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:48:33.733060      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:34.733192      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:48:35.047: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  E0326 05:48:35.734252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:36.734324      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:48:37.050: INFO: Get pod busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c in namespace container-probe-856
  Mar 26 05:48:37.050: INFO: Restart count of pod container-probe-856/busybox-f3b6d75b-3e10-4046-bbc2-4ce88f50260c is now 1 (50.055980943s elapsed)
  Mar 26 05:48:37.050: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 03/26/24 05:48:37.051
  STEP: Destroying namespace "container-probe-856" for this suite. @ 03/26/24 05:48:37.056
• [52.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]
test/e2e/apimachinery/webhook.go:371
  STEP: Creating a kubernetes client @ 03/26/24 05:48:37.06
  Mar 26 05:48:37.060: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename webhook @ 03/26/24 05:48:37.062
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:48:37.071
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:48:37.072
  STEP: Setting up server cert @ 03/26/24 05:48:37.08
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 03/26/24 05:48:37.367
  STEP: Deploying the webhook pod @ 03/26/24 05:48:37.37
  STEP: Wait for the deployment to be ready @ 03/26/24 05:48:37.374
  Mar 26 05:48:37.376: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0326 05:48:37.734504      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:38.734617      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 03/26/24 05:48:39.379
  STEP: Verifying the service has paired with the endpoint @ 03/26/24 05:48:39.384
  E0326 05:48:39.735189      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:48:40.385: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 03/26/24 05:48:40.387
  STEP: Registering slow webhook via the AdmissionRegistration API @ 03/26/24 05:48:40.387
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 03/26/24 05:48:40.394
  E0326 05:48:40.735313      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 03/26/24 05:48:41.399
  STEP: Registering slow webhook via the AdmissionRegistration API @ 03/26/24 05:48:41.399
  E0326 05:48:41.736371      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 03/26/24 05:48:42.41
  STEP: Registering slow webhook via the AdmissionRegistration API @ 03/26/24 05:48:42.41
  E0326 05:48:42.736836      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:43.736933      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:44.737079      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:45.737166      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:46.737323      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 03/26/24 05:48:47.425
  STEP: Registering slow webhook via the AdmissionRegistration API @ 03/26/24 05:48:47.425
  E0326 05:48:47.737571      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:48.737725      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:49.738806      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:50.739146      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:51.739289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:48:52.435: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-481" for this suite. @ 03/26/24 05:48:52.456
  STEP: Destroying namespace "webhook-markers-195" for this suite. @ 03/26/24 05:48:52.458
• [15.401 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]
test/e2e/apimachinery/resource_quota.go:328
  STEP: Creating a kubernetes client @ 03/26/24 05:48:52.463
  Mar 26 05:48:52.464: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename resourcequota @ 03/26/24 05:48:52.464
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:48:52.469
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:48:52.471
  E0326 05:48:52.739939      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:53.740110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:54.740191      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:55.740349      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:56.740955      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:57.741272      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:58.742264      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:48:59.743311      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:00.744244      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:01.744455      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:02.745462      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:03.745931      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:04.746733      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:05.747656      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:06.748550      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:07.749367      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:08.750108      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 03/26/24 05:49:09.474
  E0326 05:49:09.750596      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:10.751390      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:11.752022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:12.752864      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:13.753588      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 03/26/24 05:49:14.475
  STEP: Ensuring resource quota status is calculated @ 03/26/24 05:49:14.477
  E0326 05:49:14.754096      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:15.755067      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 03/26/24 05:49:16.479
  STEP: Ensuring resource quota status captures configMap creation @ 03/26/24 05:49:16.484
  E0326 05:49:16.755924      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:17.756114      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 03/26/24 05:49:18.487
  STEP: Ensuring resource quota status released usage @ 03/26/24 05:49:18.489
  E0326 05:49:18.756908      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:19.757106      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:49:20.491: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-60" for this suite. @ 03/26/24 05:49:20.493
• [28.031 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]
test/e2e/apimachinery/webhook.go:238
  STEP: Creating a kubernetes client @ 03/26/24 05:49:20.495
  Mar 26 05:49:20.495: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename webhook @ 03/26/24 05:49:20.496
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:49:20.502
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:49:20.504
  STEP: Setting up server cert @ 03/26/24 05:49:20.511
  E0326 05:49:20.757877      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 03/26/24 05:49:20.802
  STEP: Deploying the webhook pod @ 03/26/24 05:49:20.806
  STEP: Wait for the deployment to be ready @ 03/26/24 05:49:20.81
  Mar 26 05:49:20.812: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0326 05:49:21.758806      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:22.758945      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 03/26/24 05:49:22.817
  STEP: Verifying the service has paired with the endpoint @ 03/26/24 05:49:22.821
  E0326 05:49:23.759304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:49:23.821: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 03/26/24 05:49:23.824
  STEP: create a namespace for the webhook @ 03/26/24 05:49:23.833
  STEP: create a configmap should be unconditionally rejected by the webhook @ 03/26/24 05:49:23.839
  Mar 26 05:49:23.843: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-293" for this suite. @ 03/26/24 05:49:23.862
  STEP: Destroying namespace "webhook-markers-8734" for this suite. @ 03/26/24 05:49:23.866
  STEP: Destroying namespace "fail-closed-namespace-2695" for this suite. @ 03/26/24 05:49:23.867
• [3.374 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:184
  STEP: Creating a kubernetes client @ 03/26/24 05:49:23.871
  Mar 26 05:49:23.871: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubelet-test @ 03/26/24 05:49:23.872
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:49:23.878
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:49:23.88
  E0326 05:49:24.759668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:25.760264      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:49:25.891: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-197" for this suite. @ 03/26/24 05:49:25.893
• [2.025 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]
test/e2e/kubectl/kubectl.go:1741
  STEP: Creating a kubernetes client @ 03/26/24 05:49:25.898
  Mar 26 05:49:25.898: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubectl @ 03/26/24 05:49:25.898
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:49:25.903
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:49:25.904
  STEP: running the image hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4 @ 03/26/24 05:49:25.905
  Mar 26 05:49:25.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-3138 run e2e-test-httpd-pod --image=hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Mar 26 05:49:25.952: INFO: stderr: ""
  Mar 26 05:49:25.952: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 03/26/24 05:49:25.952
  E0326 05:49:26.760938      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:27.761461      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:28.761660      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:29.762101      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:30.762682      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 03/26/24 05:49:31.004
  Mar 26 05:49:31.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-3138 get pod e2e-test-httpd-pod -o json'
  Mar 26 05:49:31.045: INFO: stderr: ""
  Mar 26 05:49:31.045: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"deb3ff790f29c2eaad3eebb1c955a92dd950b78a6761783e25761c7f7a52ae2e\",\n            \"cni.projectcalico.org/podIP\": \"10.244.69.227/32\",\n            \"cni.projectcalico.org/podIPs\": \"10.244.69.227/32\"\n        },\n        \"creationTimestamp\": \"2024-03-26T05:49:25Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-3138\",\n        \"resourceVersion\": \"77286\",\n        \"uid\": \"9023f964-a798-4d47-8111-53f8cdab215a\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-hd875\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"k8s-worker02\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-hd875\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-03-26T05:49:25Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-03-26T05:49:26Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-03-26T05:49:26Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-03-26T05:49:25Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"cri-o://8416378523f6636ffe53148efca91ed49439af08c9aaddc84527b3138621dc27\",\n                \"image\": \"hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4\",\n                \"imageID\": \"hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2024-03-26T05:49:26Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.132.15\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.69.227\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.244.69.227\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2024-03-26T05:49:25Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 03/26/24 05:49:31.046
  Mar 26 05:49:31.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-3138 replace -f -'
  Mar 26 05:49:31.416: INFO: stderr: ""
  Mar 26 05:49:31.416: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image hub.oepkgs.net/nestos/nestos-test/sonobuoy/busybox:1.29-4 @ 03/26/24 05:49:31.416
  Mar 26 05:49:31.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-3138 delete pods e2e-test-httpd-pod'
  E0326 05:49:31.763513      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:49:32.718: INFO: stderr: ""
  Mar 26 05:49:32.718: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Mar 26 05:49:32.718: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3138" for this suite. @ 03/26/24 05:49:32.72
• [6.824 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 03/26/24 05:49:32.722
  Mar 26 05:49:32.722: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 05:49:32.722
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:49:32.729
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:49:32.73
  STEP: Creating secret with name projected-secret-test-d374afaa-18db-44fa-9497-b82249b47b25 @ 03/26/24 05:49:32.731
  STEP: Creating a pod to test consume secrets @ 03/26/24 05:49:32.733
  E0326 05:49:32.764070      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:33.765205      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:34.765745      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:35.766123      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 05:49:36.741
  Mar 26 05:49:36.743: INFO: Trying to get logs from node k8s-worker01 pod pod-projected-secrets-b2168179-2255-4d60-a8e2-d42664af993a container secret-volume-test: <nil>
  STEP: delete the pod @ 03/26/24 05:49:36.746
  Mar 26 05:49:36.751: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3908" for this suite. @ 03/26/24 05:49:36.753
• [4.033 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]
test/e2e/apps/statefulset.go:318
  STEP: Creating a kubernetes client @ 03/26/24 05:49:36.755
  Mar 26 05:49:36.755: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename statefulset @ 03/26/24 05:49:36.756
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:49:36.761
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:49:36.762
  STEP: Creating service test in namespace statefulset-6419 @ 03/26/24 05:49:36.764
  E0326 05:49:36.766507      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a new StatefulSet @ 03/26/24 05:49:36.767
  Mar 26 05:49:36.771: INFO: Found 0 stateful pods, waiting for 3
  E0326 05:49:37.767129      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:38.767307      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:39.767487      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:40.767745      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:41.767896      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:42.767975      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:43.768109      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:44.768232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:45.768590      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:46.769018      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:49:46.773: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Mar 26 05:49:46.773: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Mar 26 05:49:46.773: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  Mar 26 05:49:46.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=statefulset-6419 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Mar 26 05:49:46.856: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Mar 26 05:49:46.856: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Mar 26 05:49:46.856: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0326 05:49:47.769117      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:48.769203      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:49.769293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:50.769386      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:51.770491      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:52.770615      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:53.770750      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:54.770960      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:55.771041      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:56.771133      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4 to hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.39-4 @ 03/26/24 05:49:56.862
  Mar 26 05:49:56.875: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 03/26/24 05:49:56.875
  E0326 05:49:57.772006      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:58.772150      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:49:59.772267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:00.773115      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:01.773306      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:02.773516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:03.773607      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:04.773695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:05.773776      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:06.773871      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 03/26/24 05:50:06.882
  Mar 26 05:50:06.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=statefulset-6419 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Mar 26 05:50:06.962: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Mar 26 05:50:06.962: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Mar 26 05:50:06.962: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0326 05:50:07.774789      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:08.775614      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:09.775719      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:10.775811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:11.776091      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:12.776232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:13.776743      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:14.776836      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:15.776941      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:16.777081      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 03/26/24 05:50:16.971
  Mar 26 05:50:16.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=statefulset-6419 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Mar 26 05:50:17.050: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Mar 26 05:50:17.050: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Mar 26 05:50:17.050: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0326 05:50:17.777181      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:18.777321      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:19.777452      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:20.777540      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:21.777647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:22.777739      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:23.777840      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:24.777953      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:25.778325      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:26.778621      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:50:27.069: INFO: Updating stateful set ss2
  E0326 05:50:27.778699      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:28.778794      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:29.778944      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:30.779338      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:31.779484      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:32.779570      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:33.779659      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:34.779742      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:35.779832      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:36.779930      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 03/26/24 05:50:37.076
  Mar 26 05:50:37.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=statefulset-6419 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Mar 26 05:50:37.163: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Mar 26 05:50:37.163: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Mar 26 05:50:37.163: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0326 05:50:37.780704      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:38.780870      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:39.780998      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:40.781083      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:41.781221      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:42.782563      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:43.781907      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:44.782046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:45.782117      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:46.782225      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:50:47.172: INFO: Deleting all statefulset in ns statefulset-6419
  Mar 26 05:50:47.173: INFO: Scaling statefulset ss2 to 0
  E0326 05:50:47.783187      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:48.783333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:49.783477      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:50.783732      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:51.784572      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:52.784639      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:53.784727      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:54.785020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:55.785446      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:56.785567      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:50:57.180: INFO: Waiting for statefulset status.replicas updated to 0
  Mar 26 05:50:57.181: INFO: Deleting statefulset ss2
  Mar 26 05:50:57.185: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-6419" for this suite. @ 03/26/24 05:50:57.188
• [80.435 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:151
  STEP: Creating a kubernetes client @ 03/26/24 05:50:57.191
  Mar 26 05:50:57.191: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename container-probe @ 03/26/24 05:50:57.192
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:50:57.2
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:50:57.201
  STEP: Creating pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140 @ 03/26/24 05:50:57.202
  E0326 05:50:57.785945      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:50:58.786075      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 03/26/24 05:50:59.208
  Mar 26 05:50:59.210: INFO: Initial restart count of pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e is 0
  Mar 26 05:50:59.211: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:50:59.787080      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:00.787394      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:01.213: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:01.788200      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:02.788323      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:03.215: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:03.788419      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:04.789548      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:05.218: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:05.789620      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:06.789758      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:07.220: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:07.789838      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:08.789980      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:09.222: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:09.790885      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:10.791060      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:11.224: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:11.791900      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:12.792044      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:13.225: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:13.792724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:14.793045      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:15.228: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:15.793998      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:16.794525      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:17.230: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:17.795016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:18.796023      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:19.233: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:19.796933      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:20.797112      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:21.235: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:21.797787      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:22.797942      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:23.237: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:23.798174      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:24.799088      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:25.238: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:25.799471      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:26.799583      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:27.241: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:27.799750      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:28.799947      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:29.242: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:29.800599      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:30.800842      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:31.244: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:31.801645      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:32.802026      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:33.247: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:33.803011      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:34.803046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:35.249: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:35.804016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:36.804142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:37.251: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:37.805021      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:38.805106      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:39.253: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:39.805855      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:40.806022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:41.255: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:41.806771      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:42.806958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:43.257: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:43.806971      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:44.807262      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:45.259: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:45.807363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:46.807958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:47.261: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:47.808267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:48.808380      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:49.263: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:49.809030      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:50.809329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:51.265: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:51.809802      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:52.809892      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:53.267: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:53.810673      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:54.811459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:55.268: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:55.812224      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:56.812353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:57.270: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:57.812465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:51:58.813168      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:51:59.273: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:51:59.813853      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:00.813938      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:01.274: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:01.814045      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:02.814227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:03.276: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:03.814304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:04.815163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:05.278: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:05.815658      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:06.815829      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:07.281: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:07.815943      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:08.816032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:09.282: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:09.816108      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:10.816350      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:11.285: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:11.817059      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:12.817166      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:13.287: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:13.817810      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:14.817911      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:15.289: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:15.818717      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:16.818870      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:17.291: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:17.819097      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:18.819231      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:19.293: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:19.819906      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:20.820071      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:21.295: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:21.820507      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:22.820649      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:23.298: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:23.820997      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:24.821158      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:25.300: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:25.822105      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:26.822239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:27.302: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:27.823262      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:28.823456      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:29.304: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:29.823801      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:30.823911      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:31.305: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:31.824518      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:32.824592      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:33.307: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:33.825417      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:34.825617      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:35.310: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:35.825774      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:36.826171      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:37.312: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:37.827149      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:38.827332      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:39.314: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:39.827905      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:40.828092      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:41.315: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:41.828475      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:42.828586      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:43.320: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:43.828654      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:44.828940      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:45.322: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:45.829869      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:46.830020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:47.324: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:47.830304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:48.830437      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:49.326: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:49.831394      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:50.831917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:51.329: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:51.832529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:52.832729      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:53.331: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:53.832889      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:54.832978      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:55.333: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:55.834069      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:56.835086      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:57.335: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:57.835141      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:52:58.835225      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:52:59.337: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:52:59.836064      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:00.836166      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:01.339: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:01.837113      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:02.837309      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:03.341: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:03.837569      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:04.837741      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:05.344: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:05.838724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:06.838955      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:07.346: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:07.839820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:08.840011      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:09.348: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:09.840742      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:10.841027      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:11.350: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:11.841659      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:12.841790      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:13.352: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:13.842569      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:14.843028      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:15.354: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:15.843799      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:16.843901      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:17.356: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:17.844290      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:18.844419      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:19.358: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:19.844523      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:20.844612      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:21.361: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:21.844663      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:22.844746      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:23.363: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:23.845052      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:24.845046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:25.364: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:25.845075      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:26.845206      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:27.368: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:27.845847      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:28.845961      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:29.370: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:29.846636      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:30.846931      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:31.371: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:31.847046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:32.847151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:33.373: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:33.847295      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:34.847387      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:35.375: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:35.848110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:36.848197      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:37.377: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:37.849130      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:38.849208      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:39.379: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:39.849868      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:40.850062      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:41.382: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:41.850655      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:42.850949      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:43.384: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:43.851424      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:44.851540      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:45.386: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:45.851996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:46.852110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:47.388: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:47.852303      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:48.852509      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:49.390: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:49.853125      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:50.853356      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:51.393: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:51.853657      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:52.853778      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:53.395: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:53.854524      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:54.854785      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:55.397: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:55.855790      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:56.856879      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:57.399: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:57.856940      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:53:58.857066      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:53:59.401: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:53:59.857666      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:00.857968      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:01.403: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:01.858831      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:02.859534      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:03.405: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:03.860374      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:04.860418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:05.408: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:05.860427      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:06.860605      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:07.411: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:07.861484      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:08.861606      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:09.413: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:09.862049      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:10.862283      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:11.415: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:11.862294      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:12.862465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:13.417: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:13.862999      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:14.863112      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:15.419: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:15.863938      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:16.864059      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:17.421: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:17.864295      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:18.864426      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:19.423: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:19.865098      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:20.866170      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:21.426: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:21.866245      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:22.866333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:23.428: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:23.867209      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:24.867437      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:25.430: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:25.868305      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:26.868437      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:27.433: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:27.868692      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:28.868811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:29.435: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:29.869619      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:30.869711      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:31.437: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:31.869992      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:32.870153      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:33.439: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:33.871024      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:34.871116      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:35.440: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:35.871197      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:36.871289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:37.443: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:37.872255      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:38.872343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:39.445: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:39.873131      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:40.874055      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:41.447: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:41.874577      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:42.874664      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:43.450: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:43.875493      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:44.875629      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:45.451: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:45.875970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:46.876048      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:47.453: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:47.876116      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:48.876248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:49.455: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:49.876898      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:50.877151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:51.457: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:51.877924      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:52.878057      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:53.460: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:53.878755      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:54.878893      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:55.461: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:55.879267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:56.880027      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:57.464: INFO: Get pod busybox-85d3c91c-aa84-4795-9a3b-5381a261cd3e in namespace container-probe-9140
  E0326 05:54:57.880255      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:54:58.880835      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:54:59.464: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 03/26/24 05:54:59.467
  STEP: Destroying namespace "container-probe-9140" for this suite. @ 03/26/24 05:54:59.473
• [242.284 seconds]
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:187
  STEP: Creating a kubernetes client @ 03/26/24 05:54:59.476
  Mar 26 05:54:59.476: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename emptydir @ 03/26/24 05:54:59.477
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:54:59.483
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:54:59.485
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 03/26/24 05:54:59.486
  E0326 05:54:59.880968      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:00.881085      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 05:55:01.494
  Mar 26 05:55:01.496: INFO: Trying to get logs from node k8s-worker02 pod pod-1d030ce3-0183-48ad-b6df-8009aec6ac80 container test-container: <nil>
  STEP: delete the pod @ 03/26/24 05:55:01.5
  Mar 26 05:55:01.505: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6337" for this suite. @ 03/26/24 05:55:01.507
• [2.033 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 03/26/24 05:55:01.51
  Mar 26 05:55:01.510: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename pods @ 03/26/24 05:55:01.51
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:55:01.515
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:55:01.517
  STEP: creating the pod @ 03/26/24 05:55:01.518
  STEP: submitting the pod to kubernetes @ 03/26/24 05:55:01.518
  STEP: verifying QOS class is set on the pod @ 03/26/24 05:55:01.521
  Mar 26 05:55:01.522: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2298" for this suite. @ 03/26/24 05:55:01.524
• [0.018 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]
test/e2e/common/storage/configmap_volume.go:504
  STEP: Creating a kubernetes client @ 03/26/24 05:55:01.527
  Mar 26 05:55:01.527: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename configmap @ 03/26/24 05:55:01.528
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:55:01.533
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:55:01.534
  Mar 26 05:55:01.547: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5490" for this suite. @ 03/26/24 05:55:01.548
• [0.023 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]
test/e2e/apps/statefulset.go:914
  STEP: Creating a kubernetes client @ 03/26/24 05:55:01.55
  Mar 26 05:55:01.550: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename statefulset @ 03/26/24 05:55:01.551
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:55:01.556
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:55:01.558
  STEP: Creating service test in namespace statefulset-1080 @ 03/26/24 05:55:01.559
  Mar 26 05:55:01.565: INFO: Found 0 stateful pods, waiting for 1
  E0326 05:55:01.881480      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:02.881642      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:03.882030      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:04.882175      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:05.882287      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:06.883062      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:07.883310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:08.883380      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:09.883462      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:10.883555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:55:11.567: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 03/26/24 05:55:11.57
  W0326 05:55:11.573752      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  Mar 26 05:55:11.576: INFO: Found 1 stateful pods, waiting for 2
  E0326 05:55:11.883877      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:12.884017      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:13.885147      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:14.885468      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:15.885497      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:16.885608      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:17.885701      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:18.885764      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:19.885856      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:20.886151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:55:21.578: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Mar 26 05:55:21.578: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 03/26/24 05:55:21.581
  STEP: Delete all of the StatefulSets @ 03/26/24 05:55:21.582
  STEP: Verify that StatefulSets have been deleted @ 03/26/24 05:55:21.584
  Mar 26 05:55:21.585: INFO: Deleting all statefulset in ns statefulset-1080
  Mar 26 05:55:21.593: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1080" for this suite. @ 03/26/24 05:55:21.598
• [20.052 seconds]
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance]
test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 03/26/24 05:55:21.602
  Mar 26 05:55:21.602: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename field-validation @ 03/26/24 05:55:21.603
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:55:21.61
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:55:21.616
  STEP: apply creating a deployment @ 03/26/24 05:55:21.617
  Mar 26 05:55:21.618: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-1445" for this suite. @ 03/26/24 05:55:21.624
• [0.025 seconds]
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:85
  STEP: Creating a kubernetes client @ 03/26/24 05:55:21.627
  Mar 26 05:55:21.627: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 05:55:21.627
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:55:21.633
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:55:21.634
  STEP: Creating a pod to test downward API volume plugin @ 03/26/24 05:55:21.635
  E0326 05:55:21.886207      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:22.886310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:23.886543      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:24.886483      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 05:55:25.644
  Mar 26 05:55:25.645: INFO: Trying to get logs from node k8s-worker02 pod downwardapi-volume-2f671396-b190-4800-b58f-38c15f252fce container client-container: <nil>
  STEP: delete the pod @ 03/26/24 05:55:25.647
  Mar 26 05:55:25.653: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9035" for this suite. @ 03/26/24 05:55:25.655
• [4.030 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:107
  STEP: Creating a kubernetes client @ 03/26/24 05:55:25.658
  Mar 26 05:55:25.658: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename emptydir @ 03/26/24 05:55:25.658
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:55:25.664
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:55:25.665
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 03/26/24 05:55:25.666
  E0326 05:55:25.886924      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:26.887093      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:27.887178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:28.887328      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 05:55:29.674
  Mar 26 05:55:29.675: INFO: Trying to get logs from node k8s-worker02 pod pod-2ede5d39-7b0b-49e5-80d4-e789cc4f61a3 container test-container: <nil>
  STEP: delete the pod @ 03/26/24 05:55:29.677
  Mar 26 05:55:29.683: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4063" for this suite. @ 03/26/24 05:55:29.684
• [4.029 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
test/e2e/common/node/expansion.go:155
  STEP: Creating a kubernetes client @ 03/26/24 05:55:29.689
  Mar 26 05:55:29.689: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename var-expansion @ 03/26/24 05:55:29.689
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:55:29.695
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:55:29.697
  E0326 05:55:29.887836      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:30.888114      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:55:31.705: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Mar 26 05:55:31.706: INFO: Deleting pod "var-expansion-cca04a4f-895b-4cf9-80f6-6f01774ca333" in namespace "var-expansion-5637"
  Mar 26 05:55:31.709: INFO: Wait up to 5m0s for pod "var-expansion-cca04a4f-895b-4cf9-80f6-6f01774ca333" to be fully deleted
  E0326 05:55:31.888604      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:32.888729      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "var-expansion-5637" for this suite. @ 03/26/24 05:55:33.713
• [4.027 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]
test/e2e/apps/replica_set.go:176
  STEP: Creating a kubernetes client @ 03/26/24 05:55:33.716
  Mar 26 05:55:33.716: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename replicaset @ 03/26/24 05:55:33.717
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:55:33.723
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:55:33.724
  STEP: Create a Replicaset @ 03/26/24 05:55:33.727
  STEP: Verify that the required pods have come up. @ 03/26/24 05:55:33.729
  Mar 26 05:55:33.730: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0326 05:55:33.889008      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:34.889322      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:35.889854      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:36.890005      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:37.890135      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:55:38.732: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 03/26/24 05:55:38.733
  STEP: Getting /status @ 03/26/24 05:55:38.733
  Mar 26 05:55:38.734: INFO: Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 03/26/24 05:55:38.734
  Mar 26 05:55:38.738: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 03/26/24 05:55:38.738
  Mar 26 05:55:38.739: INFO: Observed &ReplicaSet event: ADDED
  Mar 26 05:55:38.739: INFO: Observed &ReplicaSet event: MODIFIED
  Mar 26 05:55:38.739: INFO: Observed &ReplicaSet event: MODIFIED
  Mar 26 05:55:38.739: INFO: Observed &ReplicaSet event: MODIFIED
  Mar 26 05:55:38.740: INFO: Found replicaset test-rs in namespace replicaset-9217 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Mar 26 05:55:38.740: INFO: Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 03/26/24 05:55:38.74
  Mar 26 05:55:38.740: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Mar 26 05:55:38.743: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 03/26/24 05:55:38.743
  Mar 26 05:55:38.744: INFO: Observed &ReplicaSet event: ADDED
  Mar 26 05:55:38.744: INFO: Observed &ReplicaSet event: MODIFIED
  Mar 26 05:55:38.744: INFO: Observed &ReplicaSet event: MODIFIED
  Mar 26 05:55:38.745: INFO: Observed &ReplicaSet event: MODIFIED
  Mar 26 05:55:38.745: INFO: Observed replicaset test-rs in namespace replicaset-9217 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Mar 26 05:55:38.745: INFO: Observed &ReplicaSet event: MODIFIED
  Mar 26 05:55:38.745: INFO: Found replicaset test-rs in namespace replicaset-9217 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  Mar 26 05:55:38.745: INFO: Replicaset test-rs has a patched status
  Mar 26 05:55:38.745: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-9217" for this suite. @ 03/26/24 05:55:38.746
• [5.034 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for services  [Conformance]
test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 03/26/24 05:55:38.754
  Mar 26 05:55:38.754: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename dns @ 03/26/24 05:55:38.755
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:55:38.76
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:55:38.761
  STEP: Creating a test headless service @ 03/26/24 05:55:38.762
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8966.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8966.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8966.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8966.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8966.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8966.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8966.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8966.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8966.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8966.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 53.15.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.15.53_udp@PTR;check="$$(dig +tcp +noall +answer +search 53.15.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.15.53_tcp@PTR;sleep 1; done
   @ 03/26/24 05:55:38.769
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8966.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8966.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8966.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8966.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8966.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8966.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8966.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8966.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8966.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8966.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 53.15.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.15.53_udp@PTR;check="$$(dig +tcp +noall +answer +search 53.15.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.15.53_tcp@PTR;sleep 1; done
   @ 03/26/24 05:55:38.769
  STEP: creating a pod to probe DNS @ 03/26/24 05:55:38.769
  STEP: submitting the pod to kubernetes @ 03/26/24 05:55:38.769
  E0326 05:55:38.890834      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:39.891471      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 03/26/24 05:55:40.779
  STEP: looking for the results for each expected name from probers @ 03/26/24 05:55:40.781
  Mar 26 05:55:40.784: INFO: Unable to read wheezy_udp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:40.785: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:40.786: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:40.787: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:40.793: INFO: Unable to read jessie_udp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:40.794: INFO: Unable to read jessie_tcp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:40.796: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:40.797: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:40.801: INFO: Lookups using dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8 failed for: [wheezy_udp@dns-test-service.dns-8966.svc.cluster.local wheezy_tcp@dns-test-service.dns-8966.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local jessie_udp@dns-test-service.dns-8966.svc.cluster.local jessie_tcp@dns-test-service.dns-8966.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local]

  Mar 26 05:55:40.804: INFO: Pod client logs for webserver: 
  Mar 26 05:55:40.806: INFO: Pod client logs for querier: 
  Mar 26 05:55:40.808: INFO: Pod client logs for jessie-querier: 
  E0326 05:55:40.891516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:41.891643      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:42.891748      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:43.891959      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:44.892070      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:55:45.810: INFO: Unable to read wheezy_udp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:45.812: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:45.813: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:45.814: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:45.819: INFO: Unable to read jessie_udp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:45.820: INFO: Unable to read jessie_tcp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:45.822: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:45.823: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:45.826: INFO: Lookups using dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8 failed for: [wheezy_udp@dns-test-service.dns-8966.svc.cluster.local wheezy_tcp@dns-test-service.dns-8966.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local jessie_udp@dns-test-service.dns-8966.svc.cluster.local jessie_tcp@dns-test-service.dns-8966.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local]

  Mar 26 05:55:45.829: INFO: Pod client logs for webserver: 
  Mar 26 05:55:45.830: INFO: Pod client logs for querier: 
  Mar 26 05:55:45.832: INFO: Pod client logs for jessie-querier: 
  E0326 05:55:45.892918      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:46.893047      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:47.893185      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:48.893324      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:49.893466      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:55:50.810: INFO: Unable to read wheezy_udp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:50.811: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:50.813: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:50.814: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:50.819: INFO: Unable to read jessie_udp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:50.820: INFO: Unable to read jessie_tcp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:50.821: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:50.822: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:50.826: INFO: Lookups using dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8 failed for: [wheezy_udp@dns-test-service.dns-8966.svc.cluster.local wheezy_tcp@dns-test-service.dns-8966.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local jessie_udp@dns-test-service.dns-8966.svc.cluster.local jessie_tcp@dns-test-service.dns-8966.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local]

  Mar 26 05:55:50.828: INFO: Pod client logs for webserver: 
  Mar 26 05:55:50.830: INFO: Pod client logs for querier: 
  Mar 26 05:55:50.831: INFO: Pod client logs for jessie-querier: 
  E0326 05:55:50.893961      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:51.894585      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:52.894681      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:53.895038      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:54.896232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:55:55.810: INFO: Unable to read wheezy_udp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:55.812: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:55.813: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:55.814: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:55.820: INFO: Unable to read jessie_udp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:55.821: INFO: Unable to read jessie_tcp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:55.822: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:55.823: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:55:55.828: INFO: Lookups using dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8 failed for: [wheezy_udp@dns-test-service.dns-8966.svc.cluster.local wheezy_tcp@dns-test-service.dns-8966.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local jessie_udp@dns-test-service.dns-8966.svc.cluster.local jessie_tcp@dns-test-service.dns-8966.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local]

  Mar 26 05:55:55.830: INFO: Pod client logs for webserver: 
  Mar 26 05:55:55.832: INFO: Pod client logs for querier: 
  Mar 26 05:55:55.834: INFO: Pod client logs for jessie-querier: 
  E0326 05:55:55.896570      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:56.897026      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:57.897163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:58.897983      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:55:59.898561      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:56:00.810: INFO: Unable to read wheezy_udp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:56:00.811: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:56:00.813: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:56:00.814: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:56:00.820: INFO: Unable to read jessie_udp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:56:00.821: INFO: Unable to read jessie_tcp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:56:00.823: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:56:00.824: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:56:00.828: INFO: Lookups using dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8 failed for: [wheezy_udp@dns-test-service.dns-8966.svc.cluster.local wheezy_tcp@dns-test-service.dns-8966.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local jessie_udp@dns-test-service.dns-8966.svc.cluster.local jessie_tcp@dns-test-service.dns-8966.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local]

  Mar 26 05:56:00.830: INFO: Pod client logs for webserver: 
  Mar 26 05:56:00.833: INFO: Pod client logs for querier: 
  Mar 26 05:56:00.836: INFO: Pod client logs for jessie-querier: 
  E0326 05:56:00.899164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:01.899296      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:02.899396      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:03.899486      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:04.900025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:56:05.810: INFO: Unable to read wheezy_udp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:56:05.811: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:56:05.813: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:56:05.814: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:56:05.820: INFO: Unable to read jessie_udp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:56:05.821: INFO: Unable to read jessie_tcp@dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:56:05.822: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:56:05.823: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local from pod dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8: the server could not find the requested resource (get pods dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8)
  Mar 26 05:56:05.827: INFO: Lookups using dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8 failed for: [wheezy_udp@dns-test-service.dns-8966.svc.cluster.local wheezy_tcp@dns-test-service.dns-8966.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local jessie_udp@dns-test-service.dns-8966.svc.cluster.local jessie_tcp@dns-test-service.dns-8966.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8966.svc.cluster.local]

  Mar 26 05:56:05.829: INFO: Pod client logs for webserver: 
  Mar 26 05:56:05.830: INFO: Pod client logs for querier: 
  Mar 26 05:56:05.832: INFO: Pod client logs for jessie-querier: 
  E0326 05:56:05.900966      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:06.901901      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:07.902043      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:08.903075      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:09.903842      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:56:10.826: INFO: DNS probes using dns-8966/dns-test-2c2c639f-ba42-4750-a6ac-ca0b384802e8 succeeded

  Mar 26 05:56:10.826: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 03/26/24 05:56:10.828
  STEP: deleting the test service @ 03/26/24 05:56:10.836
  STEP: deleting the test headless service @ 03/26/24 05:56:10.851
  STEP: Destroying namespace "dns-8966" for this suite. @ 03/26/24 05:56:10.855
• [32.104 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance]
test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 03/26/24 05:56:10.859
  Mar 26 05:56:10.859: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 03/26/24 05:56:10.86
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:56:10.865
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:56:10.866
  STEP: creating a target pod @ 03/26/24 05:56:10.868
  E0326 05:56:10.904331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:11.904465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 03/26/24 05:56:12.876
  E0326 05:56:12.905412      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:13.906033      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:14.906628      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:15.907104      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 03/26/24 05:56:16.887
  Mar 26 05:56:16.887: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-6560 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 05:56:16.887: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:56:16.887: INFO: ExecWithOptions: Clientset creation
  Mar 26 05:56:16.887: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/ephemeral-containers-test-6560/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  E0326 05:56:16.907288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:56:16.926: INFO: Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 03/26/24 05:56:16.928
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 03/26/24 05:56:16.93
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 03/26/24 05:56:16.934
  Mar 26 05:56:16.937: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-6560" for this suite. @ 03/26/24 05:56:16.94
• [6.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance]
test/e2e/instrumentation/core_events.go:57
  STEP: Creating a kubernetes client @ 03/26/24 05:56:16.943
  Mar 26 05:56:16.943: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename events @ 03/26/24 05:56:16.944
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:56:16.949
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:56:16.95
  STEP: creating a test event @ 03/26/24 05:56:16.951
  STEP: listing all events in all namespaces @ 03/26/24 05:56:16.953
  STEP: patching the test event @ 03/26/24 05:56:16.955
  STEP: fetching the test event @ 03/26/24 05:56:16.957
  STEP: updating the test event @ 03/26/24 05:56:16.958
  STEP: getting the test event @ 03/26/24 05:56:16.961
  STEP: deleting the test event @ 03/26/24 05:56:16.962
  STEP: listing all events in all namespaces @ 03/26/24 05:56:16.964
  Mar 26 05:56:16.965: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-9135" for this suite. @ 03/26/24 05:56:16.967
• [0.025 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:84
  STEP: Creating a kubernetes client @ 03/26/24 05:56:16.969
  Mar 26 05:56:16.969: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename pod-network-test @ 03/26/24 05:56:16.97
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:56:16.976
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:56:16.977
  STEP: Performing setup for networking test in namespace pod-network-test-728 @ 03/26/24 05:56:16.978
  STEP: creating a selector @ 03/26/24 05:56:16.978
  STEP: Creating the service pods in kubernetes @ 03/26/24 05:56:16.978
  Mar 26 05:56:16.978: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0326 05:56:17.908186      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:18.908327      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:19.908580      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:20.908658      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:21.909961      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:22.910111      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:23.910192      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:24.910394      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:25.910724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:26.910882      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:27.910972      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:28.911111      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 03/26/24 05:56:29.014
  E0326 05:56:29.911214      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:30.911391      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:56:31.022: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Mar 26 05:56:31.022: INFO: Breadth first check of 10.244.32.177 on host 192.168.132.11...
  Mar 26 05:56:31.023: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.79.104:9080/dial?request=hostname&protocol=http&host=10.244.32.177&port=8083&tries=1'] Namespace:pod-network-test-728 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 05:56:31.023: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:56:31.024: INFO: ExecWithOptions: Clientset creation
  Mar 26 05:56:31.024: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-728/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.79.104%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.32.177%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Mar 26 05:56:31.076: INFO: Waiting for responses: map[]
  Mar 26 05:56:31.076: INFO: reached 10.244.32.177 after 0/1 tries
  Mar 26 05:56:31.076: INFO: Breadth first check of 10.244.79.90 on host 192.168.132.14...
  Mar 26 05:56:31.078: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.79.104:9080/dial?request=hostname&protocol=http&host=10.244.79.90&port=8083&tries=1'] Namespace:pod-network-test-728 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 05:56:31.078: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:56:31.079: INFO: ExecWithOptions: Clientset creation
  Mar 26 05:56:31.079: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-728/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.79.104%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.79.90%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Mar 26 05:56:31.119: INFO: Waiting for responses: map[]
  Mar 26 05:56:31.119: INFO: reached 10.244.79.90 after 0/1 tries
  Mar 26 05:56:31.120: INFO: Breadth first check of 10.244.69.246 on host 192.168.132.15...
  Mar 26 05:56:31.121: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.79.104:9080/dial?request=hostname&protocol=http&host=10.244.69.246&port=8083&tries=1'] Namespace:pod-network-test-728 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 05:56:31.121: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 05:56:31.122: INFO: ExecWithOptions: Clientset creation
  Mar 26 05:56:31.122: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-728/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.79.104%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.69.246%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Mar 26 05:56:31.164: INFO: Waiting for responses: map[]
  Mar 26 05:56:31.164: INFO: reached 10.244.69.246 after 0/1 tries
  Mar 26 05:56:31.164: INFO: Going to retry 0 out of 3 pods....
  Mar 26 05:56:31.164: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-728" for this suite. @ 03/26/24 05:56:31.167
• [14.201 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]
test/e2e/auth/service_accounts.go:161
  STEP: Creating a kubernetes client @ 03/26/24 05:56:31.172
  Mar 26 05:56:31.172: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename svcaccounts @ 03/26/24 05:56:31.173
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:56:31.18
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:56:31.181
  Mar 26 05:56:31.190: INFO: created pod pod-service-account-defaultsa
  Mar 26 05:56:31.190: INFO: pod pod-service-account-defaultsa service account token volume mount: true
  Mar 26 05:56:31.193: INFO: created pod pod-service-account-mountsa
  Mar 26 05:56:31.193: INFO: pod pod-service-account-mountsa service account token volume mount: true
  Mar 26 05:56:31.196: INFO: created pod pod-service-account-nomountsa
  Mar 26 05:56:31.196: INFO: pod pod-service-account-nomountsa service account token volume mount: false
  Mar 26 05:56:31.199: INFO: created pod pod-service-account-defaultsa-mountspec
  Mar 26 05:56:31.199: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  Mar 26 05:56:31.203: INFO: created pod pod-service-account-mountsa-mountspec
  Mar 26 05:56:31.203: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
  Mar 26 05:56:31.208: INFO: created pod pod-service-account-nomountsa-mountspec
  Mar 26 05:56:31.208: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  Mar 26 05:56:31.214: INFO: created pod pod-service-account-defaultsa-nomountspec
  Mar 26 05:56:31.214: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  Mar 26 05:56:31.218: INFO: created pod pod-service-account-mountsa-nomountspec
  Mar 26 05:56:31.218: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  Mar 26 05:56:31.223: INFO: created pod pod-service-account-nomountsa-nomountspec
  Mar 26 05:56:31.224: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  Mar 26 05:56:31.224: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-1569" for this suite. @ 03/26/24 05:56:31.228
• [0.060 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance]
test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 03/26/24 05:56:31.232
  Mar 26 05:56:31.232: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename csiinlinevolumes @ 03/26/24 05:56:31.234
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:56:31.244
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:56:31.249
  STEP: Creating two CSIDrivers @ 03/26/24 05:56:31.25
  STEP: Getting "inline-driver-72b7f965-6a50-4fe4-829c-7fb193027984" & "inline-driver-67cf967f-5c86-4b34-82c0-e095e5297da9" @ 03/26/24 05:56:31.264
  STEP: Patching the CSIDriver "inline-driver-67cf967f-5c86-4b34-82c0-e095e5297da9" @ 03/26/24 05:56:31.269
  STEP: Updating the CSIDriver "inline-driver-67cf967f-5c86-4b34-82c0-e095e5297da9" @ 03/26/24 05:56:31.273
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-8497" @ 03/26/24 05:56:31.277
  STEP: Deleting CSIDriver "inline-driver-72b7f965-6a50-4fe4-829c-7fb193027984" @ 03/26/24 05:56:31.279
  STEP: Confirm deletion of CSIDriver "inline-driver-72b7f965-6a50-4fe4-829c-7fb193027984" @ 03/26/24 05:56:31.282
  STEP: Deleting CSIDriver "inline-driver-67cf967f-5c86-4b34-82c0-e095e5297da9" via DeleteCollection @ 03/26/24 05:56:31.284
  STEP: Confirm deletion of CSIDriver "inline-driver-67cf967f-5c86-4b34-82c0-e095e5297da9" @ 03/26/24 05:56:31.286
  Mar 26 05:56:31.287: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-8497" for this suite. @ 03/26/24 05:56:31.289
• [0.060 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:289
  STEP: Creating a kubernetes client @ 03/26/24 05:56:31.292
  Mar 26 05:56:31.292: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename field-validation @ 03/26/24 05:56:31.293
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:56:31.301
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:56:31.305
  Mar 26 05:56:31.306: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  E0326 05:56:31.912196      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:32.912400      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:33.913006      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:56:34.346: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-5244" for this suite. @ 03/26/24 05:56:34.353
• [3.063 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:198
  STEP: Creating a kubernetes client @ 03/26/24 05:56:34.355
  Mar 26 05:56:34.355: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename container-probe @ 03/26/24 05:56:34.356
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:56:34.361
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:56:34.363
  STEP: Creating pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065 @ 03/26/24 05:56:34.364
  E0326 05:56:34.913135      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:35.913222      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 03/26/24 05:56:36.375
  Mar 26 05:56:36.384: INFO: Initial restart count of pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 is 0
  Mar 26 05:56:36.386: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:56:36.914262      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:37.915012      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:56:38.389: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:56:38.915181      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:39.915649      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:56:40.391: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:56:40.916562      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:41.916706      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:56:42.393: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:56:42.917390      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:43.917534      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:56:44.395: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:56:44.918288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:45.918504      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:56:46.397: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:56:46.919163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:47.919298      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:56:48.399: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:56:48.920381      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:49.921003      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:56:50.401: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:56:50.921112      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:51.921208      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:56:52.403: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:56:52.922117      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:53.922319      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:56:54.405: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:56:54.922427      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:55.922880      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:56:56.406: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  Mar 26 05:56:56.406: INFO: Restart count of pod container-probe-4065/liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 is now 1 (20.022809489s elapsed)
  E0326 05:56:56.923516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:57.923626      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:56:58.409: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:56:58.923716      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:56:59.923804      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:00.411: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:00.924406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:01.924974      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:02.413: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:02.925556      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:03.925792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:04.415: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:04.926740      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:05.927114      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:06.417: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:06.928168      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:07.928287      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:08.420: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:08.928725      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:09.928820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:10.422: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:10.929896      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:11.929987      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:12.424: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:12.931019      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:13.931167      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:14.426: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:14.932048      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:15.932451      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:16.428: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  Mar 26 05:57:16.429: INFO: Restart count of pod container-probe-4065/liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 is now 2 (40.044838586s elapsed)
  E0326 05:57:16.933239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:17.934139      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:18.432: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:18.934632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:19.935101      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:20.434: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:20.935329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:21.935403      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:22.436: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:22.936221      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:23.936507      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:24.438: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:24.937252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:25.937502      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:26.440: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:26.938358      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:27.938539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:28.443: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:28.938595      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:29.938723      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:30.445: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:30.939648      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:31.940480      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:32.446: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:32.941241      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:33.942023      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:34.448: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:34.942634      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:35.942726      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:36.450: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  Mar 26 05:57:36.450: INFO: Restart count of pod container-probe-4065/liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 is now 3 (1m0.066240658s elapsed)
  E0326 05:57:36.942806      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:37.942917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:38.452: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:38.943137      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:39.943316      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:40.454: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:40.944230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:41.944410      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:42.456: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:42.944977      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:43.946023      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:44.458: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:44.946926      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:45.946963      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:46.459: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:46.947040      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:47.947185      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:48.462: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:48.947623      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:49.947813      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:50.464: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:50.947898      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:51.947955      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:52.466: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:52.948754      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:53.949037      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:54.468: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:54.949058      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:55.949114      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:56.469: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  Mar 26 05:57:56.469: INFO: Restart count of pod container-probe-4065/liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 is now 4 (1m20.085712859s elapsed)
  E0326 05:57:56.949209      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:57.950089      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:57:58.472: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:57:58.950468      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:57:59.951518      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:00.474: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:00.952016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:01.952042      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:02.477: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:02.952785      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:03.953918      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:04.479: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:04.954451      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:05.954493      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:06.481: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:06.955187      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:07.955289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:08.483: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:08.955342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:09.955652      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:10.485: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:10.956486      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:11.957056      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:12.487: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:12.958143      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:13.959164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:14.489: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:14.959897      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:15.959991      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:16.490: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:16.960048      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:17.960155      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:18.494: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:18.960367      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:19.960659      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:20.496: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:20.961687      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:21.961845      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:22.498: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:22.961958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:23.962125      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:24.500: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:24.962813      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:25.962993      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:26.502: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:26.963688      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:27.964641      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:28.504: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:28.964850      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:29.965175      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:30.506: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:30.965465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:31.965808      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:32.509: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:32.965871      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:33.965967      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:34.511: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:34.966068      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:35.966291      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:36.513: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:36.967315      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:37.967479      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:38.516: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:38.967846      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:39.967899      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:40.519: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:40.968644      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:41.968774      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:42.521: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:42.968770      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:43.968889      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:44.523: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:44.969886      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:45.969965      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:46.525: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:46.970666      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:47.970758      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:48.527: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:48.970846      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:49.971125      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:50.529: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:50.971768      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:51.971914      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:52.531: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:52.972908      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:53.973030      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:54.533: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  E0326 05:58:54.973874      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:55.974759      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:58:56.534: INFO: Get pod liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 in namespace container-probe-4065
  Mar 26 05:58:56.534: INFO: Restart count of pod container-probe-4065/liveness-629d1f56-4ea9-469f-b6ac-e4cf11a42506 is now 5 (2m20.150651361s elapsed)
  Mar 26 05:58:56.534: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 03/26/24 05:58:56.536
  STEP: Destroying namespace "container-probe-4065" for this suite. @ 03/26/24 05:58:56.54
• [142.187 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
test/e2e/apps/statefulset.go:703
  STEP: Creating a kubernetes client @ 03/26/24 05:58:56.542
  Mar 26 05:58:56.542: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename statefulset @ 03/26/24 05:58:56.543
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:58:56.549
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:58:56.55
  STEP: Creating service test in namespace statefulset-470 @ 03/26/24 05:58:56.551
  STEP: Creating stateful set ss in namespace statefulset-470 @ 03/26/24 05:58:56.555
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-470 @ 03/26/24 05:58:56.557
  Mar 26 05:58:56.558: INFO: Found 0 stateful pods, waiting for 1
  E0326 05:58:56.975623      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:57.975721      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:58.975797      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:58:59.976335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:00.976416      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:01.976504      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:02.976610      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:03.976695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:04.976976      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:05.977067      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:06.561: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 03/26/24 05:59:06.561
  Mar 26 05:59:06.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=statefulset-470 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Mar 26 05:59:06.637: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Mar 26 05:59:06.637: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Mar 26 05:59:06.637: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Mar 26 05:59:06.639: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0326 05:59:06.977912      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:07.977944      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:08.978927      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:09.979400      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:10.979539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:11.979617      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:12.979708      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:13.979802      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:14.980245      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:15.980342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:16.641: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Mar 26 05:59:16.641: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Mar 26 05:59:16.646: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
  Mar 26 05:59:16.646: INFO: ss-0  k8s-worker02  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:58:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:59:06 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:59:06 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:58:56 +0000 UTC  }]
  Mar 26 05:59:16.646: INFO: 
  Mar 26 05:59:16.646: INFO: StatefulSet ss has not reached scale 3, at 1
  E0326 05:59:16.981022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:17.649: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997855906s
  E0326 05:59:17.981956      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:18.652: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994923346s
  E0326 05:59:18.982050      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:19.655: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.991802398s
  E0326 05:59:19.983043      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:20.657: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.989971149s
  E0326 05:59:20.983141      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:21.659: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.98777925s
  E0326 05:59:21.983160      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:22.663: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.984744326s
  E0326 05:59:22.983237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:23.666: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.981641486s
  E0326 05:59:23.983502      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:24.668: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.979414694s
  E0326 05:59:24.983754      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:25.670: INFO: Verifying statefulset ss doesn't scale past 3 for another 977.420309ms
  E0326 05:59:25.983797      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-470 @ 03/26/24 05:59:26.67
  Mar 26 05:59:26.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=statefulset-470 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Mar 26 05:59:26.750: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Mar 26 05:59:26.750: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Mar 26 05:59:26.750: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Mar 26 05:59:26.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=statefulset-470 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Mar 26 05:59:26.833: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Mar 26 05:59:26.833: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Mar 26 05:59:26.833: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Mar 26 05:59:26.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=statefulset-470 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Mar 26 05:59:26.921: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Mar 26 05:59:26.921: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Mar 26 05:59:26.921: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Mar 26 05:59:26.923: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Mar 26 05:59:26.923: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Mar 26 05:59:26.923: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 03/26/24 05:59:26.923
  Mar 26 05:59:26.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=statefulset-470 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0326 05:59:26.984367      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:27.011: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Mar 26 05:59:27.011: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Mar 26 05:59:27.011: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Mar 26 05:59:27.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=statefulset-470 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Mar 26 05:59:27.101: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Mar 26 05:59:27.101: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Mar 26 05:59:27.101: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Mar 26 05:59:27.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=statefulset-470 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Mar 26 05:59:27.188: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Mar 26 05:59:27.188: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Mar 26 05:59:27.188: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Mar 26 05:59:27.188: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Mar 26 05:59:27.190: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 3
  E0326 05:59:27.985029      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:28.985158      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:29.985395      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:30.985521      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:31.985658      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:32.985746      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:33.985889      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:34.986232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:35.986353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:36.986496      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:37.194: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Mar 26 05:59:37.194: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Mar 26 05:59:37.194: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Mar 26 05:59:37.199: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
  Mar 26 05:59:37.199: INFO: ss-0  k8s-worker02  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:58:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:59:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:59:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:58:56 +0000 UTC  }]
  Mar 26 05:59:37.199: INFO: ss-1  k8s-master01  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:59:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:59:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:59:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:59:16 +0000 UTC  }]
  Mar 26 05:59:37.199: INFO: ss-2  k8s-worker01  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:59:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:59:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:59:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:59:16 +0000 UTC  }]
  Mar 26 05:59:37.199: INFO: 
  Mar 26 05:59:37.199: INFO: StatefulSet ss has not reached scale 0, at 3
  E0326 05:59:37.987421      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:38.202: INFO: POD   NODE          PHASE      GRACE  CONDITIONS
  Mar 26 05:59:38.202: INFO: ss-0  k8s-worker02  Succeeded  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:58:56 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:59:27 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:59:27 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:58:56 +0000 UTC  }]
  Mar 26 05:59:38.202: INFO: ss-1  k8s-master01  Succeeded  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:59:16 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:59:27 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:59:27 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-03-26 05:59:16 +0000 UTC  }]
  Mar 26 05:59:38.203: INFO: 
  Mar 26 05:59:38.203: INFO: StatefulSet ss has not reached scale 0, at 2
  E0326 05:59:38.988191      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:39.205: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.994774054s
  E0326 05:59:39.989101      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:40.206: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.992849609s
  E0326 05:59:40.989192      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:41.209: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.990752043s
  E0326 05:59:41.990060      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:42.211: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.988935274s
  E0326 05:59:42.991115      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:43.213: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.986883302s
  E0326 05:59:43.992141      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:44.215: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.984858122s
  E0326 05:59:44.993105      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:45.216: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.982831417s
  E0326 05:59:45.993561      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 05:59:46.219: INFO: Verifying statefulset ss doesn't scale past 0 for another 980.555975ms
  E0326 05:59:46.993669      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-470 @ 03/26/24 05:59:47.219
  Mar 26 05:59:47.222: INFO: Scaling statefulset ss to 0
  Mar 26 05:59:47.226: INFO: Waiting for statefulset status.replicas updated to 0
  Mar 26 05:59:47.227: INFO: Deleting all statefulset in ns statefulset-470
  Mar 26 05:59:47.228: INFO: Scaling statefulset ss to 0
  Mar 26 05:59:47.232: INFO: Waiting for statefulset status.replicas updated to 0
  Mar 26 05:59:47.233: INFO: Deleting statefulset ss
  Mar 26 05:59:47.237: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-470" for this suite. @ 03/26/24 05:59:47.242
• [50.705 seconds]
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]
test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 03/26/24 05:59:47.247
  Mar 26 05:59:47.247: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename sched-preemption @ 03/26/24 05:59:47.248
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 05:59:47.255
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 05:59:47.257
  Mar 26 05:59:47.263: INFO: Waiting up to 1m0s for all nodes to be ready
  E0326 05:59:47.994629      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:48.994728      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:49.995217      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:50.995304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:51.995989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:52.996307      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:53.997227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:54.998103      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:55.998487      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:56.998763      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:57.998957      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 05:59:58.999114      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:00.000086      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:01.000217      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:02.000807      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:03.000871      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:04.001837      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:05.002011      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:06.003031      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:07.003239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:08.004150      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:09.004267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:10.004289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:11.004392      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:12.005271      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:13.006020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:14.006962      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:15.007288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:16.007687      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:17.008098      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:18.009062      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:19.008950      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:20.009323      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:21.009429      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:22.009508      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:23.009638      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:24.010018      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:25.010296      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:26.011308      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:27.011943      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:28.012019      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:29.012079      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:30.012376      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:31.012502      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:32.013171      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:33.013246      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:34.013324      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:35.014249      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:36.014772      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:37.014882      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:38.015529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:39.015681      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:40.016538      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:41.016652      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:42.016775      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:43.016963      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:44.017647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:45.018031      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:46.018380      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:47.018433      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:00:47.281: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 03/26/24 06:00:47.282
  Mar 26 06:00:47.282: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename sched-preemption-path @ 03/26/24 06:00:47.283
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:00:47.289
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:00:47.291
  STEP: Finding an available node @ 03/26/24 06:00:47.292
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 03/26/24 06:00:47.292
  E0326 06:00:48.018764      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:49.018808      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 03/26/24 06:00:49.3
  Mar 26 06:00:49.304: INFO: found a healthy node: k8s-worker02
  E0326 06:00:50.019167      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:51.020074      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:52.020948      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:53.021070      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:54.021969      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:55.022613      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:00:55.330: INFO: pods created so far: [1 1 1]
  Mar 26 06:00:55.330: INFO: length of pods created so far: 3
  E0326 06:00:56.023049      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:57.023216      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:00:57.335: INFO: pods created so far: [2 2 1]
  E0326 06:00:58.024175      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:00:59.024481      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:00.025243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:01.025420      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:02.025487      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:03.025569      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:04.025664      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:01:04.337: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Mar 26 06:01:04.352: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-4195" for this suite. @ 03/26/24 06:01:04.374
  STEP: Destroying namespace "sched-preemption-875" for this suite. @ 03/26/24 06:01:04.377
• [77.131 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]
test/e2e/apps/replica_set.go:143
  STEP: Creating a kubernetes client @ 03/26/24 06:01:04.379
  Mar 26 06:01:04.379: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename replicaset @ 03/26/24 06:01:04.38
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:01:04.386
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:01:04.387
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 03/26/24 06:01:04.389
  Mar 26 06:01:04.391: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0326 06:01:05.026588      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:06.027583      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:07.027599      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:08.027850      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:09.028479      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:01:09.393: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 03/26/24 06:01:09.394
  STEP: getting scale subresource @ 03/26/24 06:01:09.394
  STEP: updating a scale subresource @ 03/26/24 06:01:09.395
  STEP: verifying the replicaset Spec.Replicas was modified @ 03/26/24 06:01:09.397
  STEP: Patch a scale subresource @ 03/26/24 06:01:09.4
  Mar 26 06:01:09.408: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-2227" for this suite. @ 03/26/24 06:01:09.409
• [5.035 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]
test/e2e/apimachinery/resource_quota.go:101
  STEP: Creating a kubernetes client @ 03/26/24 06:01:09.415
  Mar 26 06:01:09.415: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename resourcequota @ 03/26/24 06:01:09.416
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:01:09.421
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:01:09.422
  STEP: Counting existing ResourceQuota @ 03/26/24 06:01:09.424
  E0326 06:01:10.029504      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:11.030294      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:12.031357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:13.032114      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:14.032817      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 03/26/24 06:01:14.426
  STEP: Ensuring resource quota status is calculated @ 03/26/24 06:01:14.429
  E0326 06:01:15.033099      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:16.033516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 03/26/24 06:01:16.431
  STEP: Creating a NodePort Service @ 03/26/24 06:01:16.437
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 03/26/24 06:01:16.445
  STEP: Ensuring resource quota status captures service creation @ 03/26/24 06:01:16.451
  E0326 06:01:17.033993      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:18.034146      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 03/26/24 06:01:18.453
  STEP: Ensuring resource quota status released usage @ 03/26/24 06:01:18.467
  E0326 06:01:19.035165      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:20.035388      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:01:20.469: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3497" for this suite. @ 03/26/24 06:01:20.471
• [11.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]
test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 03/26/24 06:01:20.475
  Mar 26 06:01:20.475: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename cronjob @ 03/26/24 06:01:20.476
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:01:20.483
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:01:20.484
  STEP: Creating a suspended cronjob @ 03/26/24 06:01:20.485
  STEP: Ensuring no jobs are scheduled @ 03/26/24 06:01:20.487
  E0326 06:01:21.036336      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:22.036570      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:23.037303      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:24.037982      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:25.039020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:26.039655      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:27.039823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:28.039912      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:29.040486      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:30.040747      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:31.041454      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:32.041688      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:33.042693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:34.042871      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:35.043790      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:36.043942      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:37.044328      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:38.044427      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:39.045086      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:40.045258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:41.045740      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:42.045892      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:43.047003      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:44.047045      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:45.047073      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:46.047176      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:47.047257      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:48.047389      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:49.048367      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:50.048373      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:51.048469      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:52.048559      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:53.048670      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:54.048819      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:55.049090      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:56.049206      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:57.049314      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:58.049399      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:01:59.050318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:00.050619      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:01.051364      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:02.051500      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:03.051579      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:04.051726      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:05.052573      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:06.052683      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:07.052771      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:08.053525      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:09.053988      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:10.054923      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:11.055691      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:12.055975      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:13.056841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:14.056904      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:15.056957      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:16.057089      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:17.057148      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:18.057270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:19.058298      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:20.058409      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:21.059073      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:22.059214      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:23.059337      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:24.060259      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:25.061179      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:26.061405      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:27.062062      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:28.062619      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:29.063591      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:30.063851      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:31.064632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:32.065555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:33.066276      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:34.066369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:35.067223      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:36.067412      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:37.067967      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:38.068115      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:39.068286      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:40.068392      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:41.068480      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:42.068808      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:43.069589      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:44.069887      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:45.069964      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:46.070450      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:47.070543      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:48.070578      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:49.070938      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:50.071177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:51.071631      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:52.073363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:53.072899      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:54.073032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:55.073795      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:56.073868      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:57.074285      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:58.074366      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:02:59.074755      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:00.075095      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:01.075160      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:02.075292      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:03.076030      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:04.076167      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:05.076931      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:06.077063      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:07.077577      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:08.077792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:09.078690      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:10.079021      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:11.079211      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:12.080353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:13.080159      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:14.081046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:15.081972      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:16.082132      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:17.082961      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:18.083423      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:19.084196      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:20.084582      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:21.084900      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:22.084981      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:23.085660      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:24.085923      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:25.086749      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:26.086945      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:27.087331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:28.087390      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:29.088237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:30.088333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:31.088412      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:32.088718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:33.089764      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:34.089850      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:35.089943      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:36.090033      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:37.090113      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:38.091020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:39.091894      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:40.092221      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:41.092677      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:42.093532      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:43.094022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:44.094235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:45.095025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:46.095102      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:47.095581      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:48.095673      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:49.096109      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:50.096287      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:51.096384      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:52.096517      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:53.097037      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:54.097208      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:55.097870      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:56.097948      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:57.098419      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:58.098516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:03:59.098775      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:00.099477      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:01.099921      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:02.100102      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:03.100205      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:04.100344      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:05.101182      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:06.101685      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:07.102501      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:08.102635      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:09.102721      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:10.102916      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:11.103936      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:12.103963      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:13.103976      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:14.104259      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:15.105637      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:16.105849      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:17.106782      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:18.106947      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:19.107854      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:20.108869      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:21.109760      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:22.109894      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:23.110688      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:24.110773      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:25.111442      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:26.111634      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:27.111719      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:28.111812      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:29.111954      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:30.112586      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:31.113312      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:32.113522      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:33.113607      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:34.113820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:35.114095      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:36.114297      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:37.115205      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:38.115366      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:39.115970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:40.116398      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:41.116499      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:42.116622      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:43.117448      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:44.117572      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:45.118202      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:46.118355      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:47.119425      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:48.119392      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:49.120383      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:50.120568      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:51.121592      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:52.121740      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:53.122097      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:54.122314      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:55.123251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:56.123418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:57.123996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:58.124173      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:04:59.124958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:00.125300      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:01.125902      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:02.126111      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:03.126160      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:04.126400      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:05.127268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:06.127502      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:07.128237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:08.128381      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:09.129209      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:10.129486      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:11.129781      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:12.129878      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:13.130632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:14.130771      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:15.131067      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:16.131160      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:17.131721      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:18.131853      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:19.131953      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:20.132923      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:21.132949      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:22.133071      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:23.133717      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:24.133774      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:25.134451      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:26.134531      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:27.135440      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:28.136251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:29.136294      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:30.137015      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:31.137609      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:32.138076      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:33.138917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:34.140038      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:35.139973      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:36.141018      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:37.141874      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:38.142139      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:39.142916      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:40.143490      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:41.144358      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:42.144454      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:43.144551      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:44.144632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:45.145108      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:46.145240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:47.145323      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:48.145658      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:49.145777      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:50.146004      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:51.146819      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:52.146912      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:53.147015      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:54.147110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:55.148142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:56.148236      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:57.149110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:58.149237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:05:59.150087      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:00.150348      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:01.151022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:02.151371      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:03.151398      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:04.151790      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:05.152703      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:06.152853      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:07.153244      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:08.153360      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:09.154328      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:10.155162      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:11.156001      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:12.155988      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:13.156747      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:14.156838      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:15.156928      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:16.156981      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:17.157875      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:18.158245      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:19.159317      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:20.159499      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 03/26/24 06:06:20.49
  STEP: Removing cronjob @ 03/26/24 06:06:20.491
  Mar 26 06:06:20.493: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-4607" for this suite. @ 03/26/24 06:06:20.495
• [300.022 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 03/26/24 06:06:20.499
  Mar 26 06:06:20.499: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename pods @ 03/26/24 06:06:20.499
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:06:20.505
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:06:20.507
  STEP: creating pod @ 03/26/24 06:06:20.508
  E0326 06:06:21.160241      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:22.160401      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:06:22.516: INFO: Pod pod-hostip-d126d3b8-b7e0-4f76-9f39-23d9bdcf31b0 has hostIP: 192.168.132.15
  Mar 26 06:06:22.516: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-98" for this suite. @ 03/26/24 06:06:22.518
• [2.022 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance]
test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 03/26/24 06:06:22.52
  Mar 26 06:06:22.520: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename csiinlinevolumes @ 03/26/24 06:06:22.521
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:06:22.526
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:06:22.527
  STEP: creating @ 03/26/24 06:06:22.529
  STEP: getting @ 03/26/24 06:06:22.535
  STEP: listing in namespace @ 03/26/24 06:06:22.538
  STEP: patching @ 03/26/24 06:06:22.539
  STEP: deleting @ 03/26/24 06:06:22.546
  Mar 26 06:06:22.550: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-8408" for this suite. @ 03/26/24 06:06:22.552
• [0.034 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:74
  STEP: Creating a kubernetes client @ 03/26/24 06:06:22.555
  Mar 26 06:06:22.555: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename configmap @ 03/26/24 06:06:22.556
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:06:22.561
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:06:22.562
  STEP: Creating configMap with name configmap-test-volume-95b3d208-f8a2-4aea-bd0e-1e8861e283a1 @ 03/26/24 06:06:22.564
  STEP: Creating a pod to test consume configMaps @ 03/26/24 06:06:22.566
  E0326 06:06:23.161423      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:24.162242      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:06:24.572
  Mar 26 06:06:24.573: INFO: Trying to get logs from node k8s-worker01 pod pod-configmaps-d2a4ac5c-6ea9-47fe-bfe1-e80378a9e8ab container agnhost-container: <nil>
  STEP: delete the pod @ 03/26/24 06:06:24.577
  Mar 26 06:06:24.582: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-743" for this suite. @ 03/26/24 06:06:24.583
• [2.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 03/26/24 06:06:24.587
  Mar 26 06:06:24.587: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename secrets @ 03/26/24 06:06:24.588
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:06:24.592
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:06:24.594
  STEP: Creating secret with name secret-test-ae6a3b45-c30e-424a-a9aa-683b29ff89e4 @ 03/26/24 06:06:24.6
  STEP: Creating a pod to test consume secrets @ 03/26/24 06:06:24.602
  E0326 06:06:25.163090      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:26.164170      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:06:26.608
  Mar 26 06:06:26.609: INFO: Trying to get logs from node k8s-worker01 pod pod-secrets-014fb1dc-43c5-497c-912b-1373838a5c2a container secret-volume-test: <nil>
  STEP: delete the pod @ 03/26/24 06:06:26.611
  Mar 26 06:06:26.616: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8476" for this suite. @ 03/26/24 06:06:26.618
  STEP: Destroying namespace "secret-namespace-9771" for this suite. @ 03/26/24 06:06:26.621
• [2.036 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]
test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 03/26/24 06:06:26.623
  Mar 26 06:06:26.623: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename disruption @ 03/26/24 06:06:26.624
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:06:26.629
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:06:26.63
  STEP: creating the pdb @ 03/26/24 06:06:26.631
  STEP: Waiting for the pdb to be processed @ 03/26/24 06:06:26.633
  E0326 06:06:27.165073      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:28.165059      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pdb @ 03/26/24 06:06:28.636
  STEP: Waiting for the pdb to be processed @ 03/26/24 06:06:28.639
  E0326 06:06:29.165334      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:30.165754      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching the pdb @ 03/26/24 06:06:30.643
  STEP: Waiting for the pdb to be processed @ 03/26/24 06:06:30.647
  E0326 06:06:31.166491      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:32.166635      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be deleted @ 03/26/24 06:06:32.651
  Mar 26 06:06:32.653: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-1689" for this suite. @ 03/26/24 06:06:32.654
• [6.033 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:147
  STEP: Creating a kubernetes client @ 03/26/24 06:06:32.657
  Mar 26 06:06:32.657: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename emptydir @ 03/26/24 06:06:32.658
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:06:32.665
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:06:32.666
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 03/26/24 06:06:32.668
  E0326 06:06:33.167059      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:34.167151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:35.167228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:36.168275      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:06:36.676
  Mar 26 06:06:36.677: INFO: Trying to get logs from node k8s-worker02 pod pod-008a2ffc-83fa-4b7d-8e8e-bdc4fe5b3abb container test-container: <nil>
  STEP: delete the pod @ 03/26/24 06:06:36.681
  Mar 26 06:06:36.687: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9262" for this suite. @ 03/26/24 06:06:36.688
• [4.033 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:69
  STEP: Creating a kubernetes client @ 03/26/24 06:06:36.692
  Mar 26 06:06:36.692: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename crd-publish-openapi @ 03/26/24 06:06:36.693
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:06:36.698
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:06:36.7
  Mar 26 06:06:36.701: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  E0326 06:06:37.169058      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 03/26/24 06:06:37.918
  Mar 26 06:06:37.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-5093 --namespace=crd-publish-openapi-5093 create -f -'
  E0326 06:06:38.169488      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:06:38.269: INFO: stderr: ""
  Mar 26 06:06:38.269: INFO: stdout: "e2e-test-crd-publish-openapi-1865-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Mar 26 06:06:38.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-5093 --namespace=crd-publish-openapi-5093 delete e2e-test-crd-publish-openapi-1865-crds test-foo'
  Mar 26 06:06:38.312: INFO: stderr: ""
  Mar 26 06:06:38.312: INFO: stdout: "e2e-test-crd-publish-openapi-1865-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  Mar 26 06:06:38.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-5093 --namespace=crd-publish-openapi-5093 apply -f -'
  Mar 26 06:06:38.415: INFO: stderr: ""
  Mar 26 06:06:38.415: INFO: stdout: "e2e-test-crd-publish-openapi-1865-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Mar 26 06:06:38.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-5093 --namespace=crd-publish-openapi-5093 delete e2e-test-crd-publish-openapi-1865-crds test-foo'
  Mar 26 06:06:38.459: INFO: stderr: ""
  Mar 26 06:06:38.459: INFO: stdout: "e2e-test-crd-publish-openapi-1865-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 03/26/24 06:06:38.459
  Mar 26 06:06:38.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-5093 --namespace=crd-publish-openapi-5093 create -f -'
  Mar 26 06:06:38.557: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 03/26/24 06:06:38.557
  Mar 26 06:06:38.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-5093 --namespace=crd-publish-openapi-5093 create -f -'
  Mar 26 06:06:38.647: INFO: rc: 1
  Mar 26 06:06:38.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-5093 --namespace=crd-publish-openapi-5093 apply -f -'
  Mar 26 06:06:38.737: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 03/26/24 06:06:38.737
  Mar 26 06:06:38.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-5093 --namespace=crd-publish-openapi-5093 create -f -'
  Mar 26 06:06:38.826: INFO: rc: 1
  Mar 26 06:06:38.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-5093 --namespace=crd-publish-openapi-5093 apply -f -'
  Mar 26 06:06:38.917: INFO: rc: 1
  STEP: kubectl explain works to explain CR properties @ 03/26/24 06:06:38.917
  Mar 26 06:06:38.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-5093 explain e2e-test-crd-publish-openapi-1865-crds'
  Mar 26 06:06:39.003: INFO: stderr: ""
  Mar 26 06:06:39.003: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-1865-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 03/26/24 06:06:39.003
  Mar 26 06:06:39.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-5093 explain e2e-test-crd-publish-openapi-1865-crds.metadata'
  Mar 26 06:06:39.094: INFO: stderr: ""
  Mar 26 06:06:39.094: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-1865-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  Mar 26 06:06:39.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-5093 explain e2e-test-crd-publish-openapi-1865-crds.spec'
  E0326 06:06:39.170720      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:06:39.184: INFO: stderr: ""
  Mar 26 06:06:39.184: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-1865-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  Mar 26 06:06:39.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-5093 explain e2e-test-crd-publish-openapi-1865-crds.spec.bars'
  Mar 26 06:06:39.275: INFO: stderr: ""
  Mar 26 06:06:39.275: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-1865-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 03/26/24 06:06:39.275
  Mar 26 06:06:39.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-5093 explain e2e-test-crd-publish-openapi-1865-crds.spec.bars2'
  Mar 26 06:06:39.363: INFO: rc: 1
  E0326 06:06:40.171309      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:06:40.562: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5093" for this suite. @ 03/26/24 06:06:40.567
• [3.877 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 03/26/24 06:06:40.57
  Mar 26 06:06:40.570: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename containers @ 03/26/24 06:06:40.571
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:06:40.626
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:06:40.628
  STEP: Creating a pod to test override arguments @ 03/26/24 06:06:40.629
  E0326 06:06:41.171396      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:42.172015      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:43.172080      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:44.172174      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:06:44.637
  Mar 26 06:06:44.638: INFO: Trying to get logs from node k8s-worker02 pod client-containers-241ab1ee-4eb0-4719-aea8-71e4fc1f1e2a container agnhost-container: <nil>
  STEP: delete the pod @ 03/26/24 06:06:44.64
  Mar 26 06:06:44.646: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-7860" for this suite. @ 03/26/24 06:06:44.648
• [4.080 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]
test/e2e/common/node/secrets.go:46
  STEP: Creating a kubernetes client @ 03/26/24 06:06:44.652
  Mar 26 06:06:44.652: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename secrets @ 03/26/24 06:06:44.653
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:06:44.658
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:06:44.661
  STEP: Creating secret with name secret-test-5a92d232-b0f4-4ac7-aaea-1a55928c142b @ 03/26/24 06:06:44.662
  STEP: Creating a pod to test consume secrets @ 03/26/24 06:06:44.664
  E0326 06:06:45.172288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:46.173339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:47.173441      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:48.173582      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:06:48.672
  Mar 26 06:06:48.674: INFO: Trying to get logs from node k8s-worker02 pod pod-secrets-d24764ae-bde1-46a8-8b31-5e4ebd14bb76 container secret-env-test: <nil>
  STEP: delete the pod @ 03/26/24 06:06:48.677
  Mar 26 06:06:48.682: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-90" for this suite. @ 03/26/24 06:06:48.684
• [4.034 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]
test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 03/26/24 06:06:48.69
  Mar 26 06:06:48.690: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename dns @ 03/26/24 06:06:48.69
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:06:48.697
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:06:48.698
  STEP: Creating a test headless service @ 03/26/24 06:06:48.699
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3975.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-3975.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3975.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-3975.svc.cluster.local;sleep 1; done
   @ 03/26/24 06:06:48.701
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3975.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-3975.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3975.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-3975.svc.cluster.local;sleep 1; done
   @ 03/26/24 06:06:48.701
  STEP: creating a pod to probe DNS @ 03/26/24 06:06:48.702
  STEP: submitting the pod to kubernetes @ 03/26/24 06:06:48.702
  E0326 06:06:49.173704      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:50.174529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 03/26/24 06:06:50.709
  STEP: looking for the results for each expected name from probers @ 03/26/24 06:06:50.711
  Mar 26 06:06:50.713: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:06:50.714: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:06:50.717: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:06:50.718: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:06:50.719: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:06:50.721: INFO: Unable to read jessie_udp@dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:06:50.722: INFO: Lookups using dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-3975.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local jessie_udp@dns-test-service-2.dns-3975.svc.cluster.local]

  Mar 26 06:06:50.724: INFO: Pod client logs for webserver: 
  Mar 26 06:06:50.726: INFO: Pod client logs for querier: 
  Mar 26 06:06:50.729: INFO: Pod client logs for jessie-querier: 
  E0326 06:06:51.175615      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:52.176256      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:53.176390      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:54.176502      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:55.176883      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:06:55.730: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:06:55.732: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:06:55.746: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:06:55.750: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:06:55.760: INFO: Lookups using dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local]

  Mar 26 06:06:55.765: INFO: Pod client logs for webserver: 
  Mar 26 06:06:55.774: INFO: Pod client logs for querier: 
  Mar 26 06:06:55.776: INFO: Pod client logs for jessie-querier: 
  E0326 06:06:56.176945      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:57.177079      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:58.178055      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:06:59.178892      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:00.178488      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:07:00.730: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:07:00.732: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:07:00.735: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:07:00.737: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:07:00.739: INFO: Lookups using dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local]

  Mar 26 06:07:00.741: INFO: Pod client logs for webserver: 
  Mar 26 06:07:00.744: INFO: Pod client logs for querier: 
  Mar 26 06:07:00.746: INFO: Pod client logs for jessie-querier: 
  E0326 06:07:01.179087      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:02.179217      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:03.179372      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:04.179485      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:05.179900      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:07:05.732: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:07:05.733: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:07:05.737: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:07:05.739: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:07:05.742: INFO: Lookups using dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local]

  Mar 26 06:07:05.744: INFO: Pod client logs for webserver: 
  Mar 26 06:07:05.747: INFO: Pod client logs for querier: 
  Mar 26 06:07:05.750: INFO: Pod client logs for jessie-querier: 
  E0326 06:07:06.180608      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:07.180941      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:08.181083      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:09.181302      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:10.181392      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:07:10.730: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:07:10.732: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:07:10.735: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:07:10.737: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:07:10.739: INFO: Lookups using dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local]

  Mar 26 06:07:10.741: INFO: Pod client logs for webserver: 
  Mar 26 06:07:10.744: INFO: Pod client logs for querier: 
  Mar 26 06:07:10.746: INFO: Pod client logs for jessie-querier: 
  E0326 06:07:11.181949      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:12.182025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:13.182225      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:14.182322      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:15.182491      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:07:15.731: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:07:15.733: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:07:15.737: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:07:15.738: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local from pod dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73: the server could not find the requested resource (get pods dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73)
  Mar 26 06:07:15.740: INFO: Lookups using dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3975.svc.cluster.local]

  Mar 26 06:07:15.743: INFO: Pod client logs for webserver: 
  Mar 26 06:07:15.745: INFO: Pod client logs for querier: 
  Mar 26 06:07:15.747: INFO: Pod client logs for jessie-querier: 
  E0326 06:07:16.183102      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:17.183204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:18.183543      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:19.184679      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:20.185551      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:07:20.739: INFO: DNS probes using dns-3975/dns-test-155ca2e8-a0bb-4a36-a5c0-5cf461982b73 succeeded

  Mar 26 06:07:20.739: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 03/26/24 06:07:20.741
  STEP: deleting the test headless service @ 03/26/24 06:07:20.748
  STEP: Destroying namespace "dns-3975" for this suite. @ 03/26/24 06:07:20.761
• [32.075 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance]
test/e2e/common/node/lease.go:72
  STEP: Creating a kubernetes client @ 03/26/24 06:07:20.766
  Mar 26 06:07:20.766: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename lease-test @ 03/26/24 06:07:20.766
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:07:20.774
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:07:20.775
  Mar 26 06:07:20.801: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-5095" for this suite. @ 03/26/24 06:07:20.803
• [0.041 seconds]
------------------------------
S
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
test/e2e/network/service.go:2165
  STEP: Creating a kubernetes client @ 03/26/24 06:07:20.806
  Mar 26 06:07:20.807: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename services @ 03/26/24 06:07:20.807
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:07:20.812
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:07:20.814
  STEP: creating service in namespace services-5126 @ 03/26/24 06:07:20.815
  STEP: creating service affinity-clusterip in namespace services-5126 @ 03/26/24 06:07:20.815
  STEP: creating replication controller affinity-clusterip in namespace services-5126 @ 03/26/24 06:07:20.819
  I0326 06:07:20.822031      19 runners.go:197] Created replication controller with name: affinity-clusterip, namespace: services-5126, replica count: 3
  E0326 06:07:21.185622      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:22.186241      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:23.187072      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0326 06:07:23.873996      19 runners.go:197] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Mar 26 06:07:23.876: INFO: Creating new exec pod
  E0326 06:07:24.187960      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:25.187981      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:26.188586      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:07:26.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-5126 exec execpod-affinitym58pf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  Mar 26 06:07:26.969: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  Mar 26 06:07:26.969: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Mar 26 06:07:26.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-5126 exec execpod-affinitym58pf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.47.188 80'
  Mar 26 06:07:27.048: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.47.188 80\nConnection to 10.96.47.188 80 port [tcp/http] succeeded!\n"
  Mar 26 06:07:27.048: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Mar 26 06:07:27.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-5126 exec execpod-affinitym58pf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.47.188:80/ ; done'
  Mar 26 06:07:27.160: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.47.188:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.47.188:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.47.188:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.47.188:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.47.188:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.47.188:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.47.188:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.47.188:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.47.188:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.47.188:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.47.188:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.47.188:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.47.188:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.47.188:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.47.188:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.47.188:80/\n"
  Mar 26 06:07:27.160: INFO: stdout: "\naffinity-clusterip-lvtr5\naffinity-clusterip-lvtr5\naffinity-clusterip-lvtr5\naffinity-clusterip-lvtr5\naffinity-clusterip-lvtr5\naffinity-clusterip-lvtr5\naffinity-clusterip-lvtr5\naffinity-clusterip-lvtr5\naffinity-clusterip-lvtr5\naffinity-clusterip-lvtr5\naffinity-clusterip-lvtr5\naffinity-clusterip-lvtr5\naffinity-clusterip-lvtr5\naffinity-clusterip-lvtr5\naffinity-clusterip-lvtr5\naffinity-clusterip-lvtr5"
  Mar 26 06:07:27.160: INFO: Received response from host: affinity-clusterip-lvtr5
  Mar 26 06:07:27.160: INFO: Received response from host: affinity-clusterip-lvtr5
  Mar 26 06:07:27.160: INFO: Received response from host: affinity-clusterip-lvtr5
  Mar 26 06:07:27.160: INFO: Received response from host: affinity-clusterip-lvtr5
  Mar 26 06:07:27.160: INFO: Received response from host: affinity-clusterip-lvtr5
  Mar 26 06:07:27.160: INFO: Received response from host: affinity-clusterip-lvtr5
  Mar 26 06:07:27.160: INFO: Received response from host: affinity-clusterip-lvtr5
  Mar 26 06:07:27.160: INFO: Received response from host: affinity-clusterip-lvtr5
  Mar 26 06:07:27.160: INFO: Received response from host: affinity-clusterip-lvtr5
  Mar 26 06:07:27.160: INFO: Received response from host: affinity-clusterip-lvtr5
  Mar 26 06:07:27.160: INFO: Received response from host: affinity-clusterip-lvtr5
  Mar 26 06:07:27.160: INFO: Received response from host: affinity-clusterip-lvtr5
  Mar 26 06:07:27.160: INFO: Received response from host: affinity-clusterip-lvtr5
  Mar 26 06:07:27.160: INFO: Received response from host: affinity-clusterip-lvtr5
  Mar 26 06:07:27.160: INFO: Received response from host: affinity-clusterip-lvtr5
  Mar 26 06:07:27.160: INFO: Received response from host: affinity-clusterip-lvtr5
  Mar 26 06:07:27.160: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Mar 26 06:07:27.162: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-5126, will wait for the garbage collector to delete the pods @ 03/26/24 06:07:27.173
  E0326 06:07:27.189416      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:07:27.227: INFO: Deleting ReplicationController affinity-clusterip took: 2.190136ms
  Mar 26 06:07:27.328: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.10688ms
  E0326 06:07:28.190191      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:29.190361      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:30.191000      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-5126" for this suite. @ 03/26/24 06:07:30.335
• [9.530 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]
test/e2e/kubectl/kubectl.go:1027
  STEP: Creating a kubernetes client @ 03/26/24 06:07:30.337
  Mar 26 06:07:30.337: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubectl @ 03/26/24 06:07:30.337
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:07:30.342
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:07:30.343
  STEP: running the image hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4 @ 03/26/24 06:07:30.344
  Mar 26 06:07:30.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-3904 run e2e-test-httpd-pod --image=hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Mar 26 06:07:30.387: INFO: stderr: ""
  Mar 26 06:07:30.387: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 03/26/24 06:07:30.387
  Mar 26 06:07:30.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-3904 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "hub.oepkgs.net/nestos/nestos-test/sonobuoy/busybox:1.29-4"}]}} --dry-run=server'
  Mar 26 06:07:30.428: INFO: stderr: ""
  Mar 26 06:07:30.428: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4 @ 03/26/24 06:07:30.428
  Mar 26 06:07:30.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-3904 delete pods e2e-test-httpd-pod'
  E0326 06:07:31.191705      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:07:32.035: INFO: stderr: ""
  Mar 26 06:07:32.035: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Mar 26 06:07:32.035: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3904" for this suite. @ 03/26/24 06:07:32.037
• [1.702 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance]
test/e2e/apimachinery/server_version.go:40
  STEP: Creating a kubernetes client @ 03/26/24 06:07:32.039
  Mar 26 06:07:32.039: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename server-version @ 03/26/24 06:07:32.04
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:07:32.046
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:07:32.047
  STEP: Request ServerVersion @ 03/26/24 06:07:32.049
  STEP: Confirm major version @ 03/26/24 06:07:32.049
  Mar 26 06:07:32.049: INFO: Major version: 1
  STEP: Confirm minor version @ 03/26/24 06:07:32.049
  Mar 26 06:07:32.049: INFO: cleanMinorVersion: 28
  Mar 26 06:07:32.049: INFO: Minor version: 28
  Mar 26 06:07:32.049: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-9260" for this suite. @ 03/26/24 06:07:32.05
• [0.013 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]
test/e2e/apps/rc.go:85
  STEP: Creating a kubernetes client @ 03/26/24 06:07:32.054
  Mar 26 06:07:32.054: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename replication-controller @ 03/26/24 06:07:32.055
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:07:32.06
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:07:32.063
  Mar 26 06:07:32.064: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
  E0326 06:07:32.192033      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 03/26/24 06:07:33.068
  STEP: Checking rc "condition-test" has the desired failure condition set @ 03/26/24 06:07:33.07
  E0326 06:07:33.192127      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 03/26/24 06:07:34.073
  Mar 26 06:07:34.076: INFO: Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 03/26/24 06:07:34.077
  E0326 06:07:34.192335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:07:35.079: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-1789" for this suite. @ 03/26/24 06:07:35.081
• [3.029 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:174
  STEP: Creating a kubernetes client @ 03/26/24 06:07:35.084
  Mar 26 06:07:35.084: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 06:07:35.084
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:07:35.091
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:07:35.092
  STEP: Creating configMap with name cm-test-opt-del-9d74a79d-a1fd-41ad-8d46-f760e69cc15a @ 03/26/24 06:07:35.095
  STEP: Creating configMap with name cm-test-opt-upd-6cee8357-cf77-47d0-9c49-e35aa4c4376f @ 03/26/24 06:07:35.096
  STEP: Creating the pod @ 03/26/24 06:07:35.098
  E0326 06:07:35.193156      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:36.193334      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-9d74a79d-a1fd-41ad-8d46-f760e69cc15a @ 03/26/24 06:07:37.114
  STEP: Updating configmap cm-test-opt-upd-6cee8357-cf77-47d0-9c49-e35aa4c4376f @ 03/26/24 06:07:37.117
  STEP: Creating configMap with name cm-test-opt-create-9c928f0f-4ab6-41d0-bc91-797c8b0914cd @ 03/26/24 06:07:37.12
  STEP: waiting to observe update in volume @ 03/26/24 06:07:37.123
  E0326 06:07:37.194209      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:38.194330      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:07:39.132: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5794" for this suite. @ 03/26/24 06:07:39.134
• [4.052 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]
test/e2e/apimachinery/webhook.go:332
  STEP: Creating a kubernetes client @ 03/26/24 06:07:39.136
  Mar 26 06:07:39.136: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename webhook @ 03/26/24 06:07:39.137
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:07:39.144
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:07:39.145
  STEP: Setting up server cert @ 03/26/24 06:07:39.153
  E0326 06:07:39.194730      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 03/26/24 06:07:39.443
  STEP: Deploying the webhook pod @ 03/26/24 06:07:39.446
  STEP: Wait for the deployment to be ready @ 03/26/24 06:07:39.45
  Mar 26 06:07:39.455: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0326 06:07:40.195777      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:41.195959      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 03/26/24 06:07:41.458
  STEP: Verifying the service has paired with the endpoint @ 03/26/24 06:07:41.461
  E0326 06:07:42.196491      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:07:42.461: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Mar 26 06:07:42.464: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6181-crds.webhook.example.com via the AdmissionRegistration API @ 03/26/24 06:07:42.969
  STEP: Creating a custom resource that should be mutated by the webhook @ 03/26/24 06:07:42.977
  E0326 06:07:43.197080      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:44.198135      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:07:44.986: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0326 06:07:45.198198      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-9216" for this suite. @ 03/26/24 06:07:45.515
  STEP: Destroying namespace "webhook-markers-7332" for this suite. @ 03/26/24 06:07:45.517
• [6.386 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 03/26/24 06:07:45.524
  Mar 26 06:07:45.524: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename cronjob @ 03/26/24 06:07:45.525
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:07:45.53
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:07:45.531
  STEP: Creating a ForbidConcurrent cronjob @ 03/26/24 06:07:45.532
  STEP: Ensuring a job is scheduled @ 03/26/24 06:07:45.535
  E0326 06:07:46.198295      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:47.198382      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:48.199402      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:49.199551      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:50.200478      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:51.200688      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:52.200960      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:53.201070      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:54.201875      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:55.202410      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:56.203441      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:57.203570      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:58.204388      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:07:59.204552      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:00.204823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:01.205304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 03/26/24 06:08:01.537
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 03/26/24 06:08:01.539
  STEP: Ensuring no more jobs are scheduled @ 03/26/24 06:08:01.54
  E0326 06:08:02.205510      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:03.206471      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:04.206650      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:05.207254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:06.208017      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:07.208156      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:08.208720      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:09.208797      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:10.208868      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:11.208972      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:12.210040      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:13.210185      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:14.211008      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:15.211138      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:16.212032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:17.212201      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:18.212237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:19.212377      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:20.212483      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:21.212577      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:22.212663      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:23.212801      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:24.213723      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:25.214160      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:26.214245      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:27.214323      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:28.215187      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:29.215287      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:30.216163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:31.216649      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:32.217021      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:33.217164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:34.217273      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:35.218276      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:36.219073      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:37.220039      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:38.220910      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:39.221055      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:40.222001      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:41.222141      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:42.222244      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:43.222379      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:44.222823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:45.223230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:46.223829      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:47.224020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:48.224660      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:49.224806      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:50.225565      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:51.225691      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:52.226408      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:53.226475      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:54.227570      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:55.227476      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:56.228035      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:57.228184      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:58.228871      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:08:59.228958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:00.229663      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:01.229686      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:02.229790      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:03.230021      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:04.230865      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:05.231320      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:06.232011      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:07.232142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:08.232714      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:09.233047      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:10.234106      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:11.234242      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:12.235497      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:13.235669      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:14.236032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:15.236164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:16.236974      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:17.237163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:18.237237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:19.238559      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:20.238545      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:21.239026      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:22.239047      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:23.239212      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:24.240136      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:25.241066      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:26.241313      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:27.241542      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:28.242253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:29.243021      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:30.243713      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:31.243866      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:32.244769      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:33.245707      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:34.245784      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:35.245931      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:36.246555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:37.246770      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:38.247718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:39.247854      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:40.248407      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:41.248422      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:42.249356      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:43.249433      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:44.249520      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:45.250206      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:46.250795      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:47.250899      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:48.250980      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:49.251255      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:50.252105      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:51.252252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:52.252647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:53.252785      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:54.252889      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:55.253508      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:56.253596      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:57.253731      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:58.253802      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:09:59.253905      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:00.253944      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:01.254030      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:02.254124      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:03.254215      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:04.254565      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:05.255288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:06.255369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:07.255449      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:08.255545      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:09.255637      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:10.256342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:11.257368      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:12.258187      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:13.259090      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:14.259870      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:15.259964      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:16.260054      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:17.260139      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:18.260737      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:19.260835      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:20.261157      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:21.261244      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:22.261337      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:23.262021      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:24.262868      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:25.263801      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:26.264390      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:27.264524      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:28.264621      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:29.265581      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:30.266094      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:31.266226      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:32.266317      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:33.266407      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:34.267561      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:35.268114      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:36.268599      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:37.268724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:38.269234      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:39.269575      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:40.269771      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:41.270068      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:42.270822      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:43.270958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:44.271407      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:45.271891      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:46.272472      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:47.273141      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:48.273638      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:49.273771      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:50.274854      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:51.274855      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:52.275842      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:53.275959      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:54.276577      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:55.276945      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:56.277976      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:57.277974      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:58.278937      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:10:59.279350      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:00.279620      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:01.279796      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:02.280689      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:03.280819      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:04.281391      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:05.281682      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:06.282118      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:07.282243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:08.282319      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:09.282461      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:10.283099      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:11.283232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:12.283365      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:13.283489      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:14.284533      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:15.285362      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:16.285902      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:17.286033      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:18.286403      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:19.286487      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:20.287338      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:21.287699      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:22.288150      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:23.289029      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:24.289702      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:25.289787      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:26.289889      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:27.290092      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:28.290950      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:29.291037      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:30.291781      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:31.291950      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:32.292571      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:33.292819      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:34.293569      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:35.294569      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:36.295205      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:37.295282      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:38.295367      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:39.296417      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:40.297077      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:41.297173      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:42.297575      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:43.297646      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:44.298292      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:45.298998      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:46.299080      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:47.300139      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:48.300181      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:49.300322      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:50.301319      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:51.301411      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:52.302332      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:53.303076      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:54.303257      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:55.303307      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:56.303440      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:57.303516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:58.304502      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:11:59.304596      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:00.305661      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:01.306069      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:02.306144      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:03.307064      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:04.307235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:05.307324      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:06.308082      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:07.308189      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:08.308233      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:09.308376      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:10.309454      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:11.309698      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:12.310230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:13.310322      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:14.311081      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:15.311190      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:16.311490      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:17.311626      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:18.311718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:19.311811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:20.312658      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:21.312920      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:22.313810      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:23.313935      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:24.314829      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:25.314943      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:26.315028      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:27.315237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:28.315402      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:29.315494      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:30.316332      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:31.317019      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:32.317671      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:33.317766      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:34.318765      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:35.319061      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:36.319685      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:37.319816      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:38.320728      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:39.321288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:40.321819      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:41.321958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:42.322840      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:43.322967      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:44.324243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:45.324654      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:46.324881      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:47.325024      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:48.325118      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:49.326012      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:50.326938      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:51.327077      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:52.327968      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:53.328051      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:54.329004      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:55.329294      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:56.329388      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:57.329535      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:58.329850      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:12:59.329987      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:00.330698      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:01.330837      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 03/26/24 06:13:01.544
  Mar 26 06:13:01.546: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-7662" for this suite. @ 03/26/24 06:13:01.548
• [316.028 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]
test/e2e/kubectl/kubectl.go:354
  STEP: Creating a kubernetes client @ 03/26/24 06:13:01.553
  Mar 26 06:13:01.554: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubectl @ 03/26/24 06:13:01.554
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:13:01.566
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:13:01.567
  STEP: creating a replication controller @ 03/26/24 06:13:01.569
  Mar 26 06:13:01.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 create -f -'
  Mar 26 06:13:01.911: INFO: stderr: ""
  Mar 26 06:13:01.911: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 03/26/24 06:13:01.911
  Mar 26 06:13:01.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Mar 26 06:13:01.957: INFO: stderr: ""
  Mar 26 06:13:01.957: INFO: stdout: "update-demo-nautilus-6l2bn update-demo-nautilus-cxg86 "
  Mar 26 06:13:01.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 get pods update-demo-nautilus-6l2bn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Mar 26 06:13:01.995: INFO: stderr: ""
  Mar 26 06:13:01.995: INFO: stdout: ""
  Mar 26 06:13:01.995: INFO: update-demo-nautilus-6l2bn is created but not running
  E0326 06:13:02.330979      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:03.332029      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:04.332178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:05.332270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:06.332356      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:13:06.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Mar 26 06:13:07.038: INFO: stderr: ""
  Mar 26 06:13:07.038: INFO: stdout: "update-demo-nautilus-6l2bn update-demo-nautilus-cxg86 "
  Mar 26 06:13:07.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 get pods update-demo-nautilus-6l2bn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Mar 26 06:13:07.077: INFO: stderr: ""
  Mar 26 06:13:07.077: INFO: stdout: "true"
  Mar 26 06:13:07.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 get pods update-demo-nautilus-6l2bn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Mar 26 06:13:07.118: INFO: stderr: ""
  Mar 26 06:13:07.118: INFO: stdout: "hub.oepkgs.net/nestos/nestos-test/sonobuoy/nautilus:1.7"
  Mar 26 06:13:07.118: INFO: validating pod update-demo-nautilus-6l2bn
  Mar 26 06:13:07.120: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Mar 26 06:13:07.120: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Mar 26 06:13:07.120: INFO: update-demo-nautilus-6l2bn is verified up and running
  Mar 26 06:13:07.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 get pods update-demo-nautilus-cxg86 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Mar 26 06:13:07.160: INFO: stderr: ""
  Mar 26 06:13:07.160: INFO: stdout: "true"
  Mar 26 06:13:07.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 get pods update-demo-nautilus-cxg86 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Mar 26 06:13:07.199: INFO: stderr: ""
  Mar 26 06:13:07.199: INFO: stdout: "hub.oepkgs.net/nestos/nestos-test/sonobuoy/nautilus:1.7"
  Mar 26 06:13:07.199: INFO: validating pod update-demo-nautilus-cxg86
  Mar 26 06:13:07.201: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Mar 26 06:13:07.201: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Mar 26 06:13:07.201: INFO: update-demo-nautilus-cxg86 is verified up and running
  STEP: scaling down the replication controller @ 03/26/24 06:13:07.201
  Mar 26 06:13:07.201: INFO: scanned /root for discovery docs: <nil>
  Mar 26 06:13:07.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E0326 06:13:07.333330      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:13:08.248: INFO: stderr: ""
  Mar 26 06:13:08.248: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 03/26/24 06:13:08.248
  Mar 26 06:13:08.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Mar 26 06:13:08.291: INFO: stderr: ""
  Mar 26 06:13:08.291: INFO: stdout: "update-demo-nautilus-6l2bn update-demo-nautilus-cxg86 "
  STEP: Replicas for name=update-demo: expected=1 actual=2 @ 03/26/24 06:13:08.291
  E0326 06:13:08.333787      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:09.333925      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:10.334684      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:11.334824      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:12.334997      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:13:13.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0326 06:13:13.335228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:13:13.345: INFO: stderr: ""
  Mar 26 06:13:13.345: INFO: stdout: "update-demo-nautilus-6l2bn "
  Mar 26 06:13:13.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 get pods update-demo-nautilus-6l2bn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Mar 26 06:13:13.384: INFO: stderr: ""
  Mar 26 06:13:13.384: INFO: stdout: "true"
  Mar 26 06:13:13.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 get pods update-demo-nautilus-6l2bn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Mar 26 06:13:13.422: INFO: stderr: ""
  Mar 26 06:13:13.422: INFO: stdout: "hub.oepkgs.net/nestos/nestos-test/sonobuoy/nautilus:1.7"
  Mar 26 06:13:13.422: INFO: validating pod update-demo-nautilus-6l2bn
  Mar 26 06:13:13.424: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Mar 26 06:13:13.424: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Mar 26 06:13:13.424: INFO: update-demo-nautilus-6l2bn is verified up and running
  STEP: scaling up the replication controller @ 03/26/24 06:13:13.424
  Mar 26 06:13:13.425: INFO: scanned /root for discovery docs: <nil>
  Mar 26 06:13:13.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E0326 06:13:14.335578      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:13:14.471: INFO: stderr: ""
  Mar 26 06:13:14.472: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 03/26/24 06:13:14.472
  Mar 26 06:13:14.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Mar 26 06:13:14.514: INFO: stderr: ""
  Mar 26 06:13:14.514: INFO: stdout: "update-demo-nautilus-6l2bn update-demo-nautilus-nq8xz "
  Mar 26 06:13:14.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 get pods update-demo-nautilus-6l2bn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Mar 26 06:13:14.553: INFO: stderr: ""
  Mar 26 06:13:14.553: INFO: stdout: "true"
  Mar 26 06:13:14.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 get pods update-demo-nautilus-6l2bn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Mar 26 06:13:14.592: INFO: stderr: ""
  Mar 26 06:13:14.592: INFO: stdout: "hub.oepkgs.net/nestos/nestos-test/sonobuoy/nautilus:1.7"
  Mar 26 06:13:14.592: INFO: validating pod update-demo-nautilus-6l2bn
  Mar 26 06:13:14.593: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Mar 26 06:13:14.593: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Mar 26 06:13:14.593: INFO: update-demo-nautilus-6l2bn is verified up and running
  Mar 26 06:13:14.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 get pods update-demo-nautilus-nq8xz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Mar 26 06:13:14.632: INFO: stderr: ""
  Mar 26 06:13:14.633: INFO: stdout: "true"
  Mar 26 06:13:14.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 get pods update-demo-nautilus-nq8xz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Mar 26 06:13:14.671: INFO: stderr: ""
  Mar 26 06:13:14.671: INFO: stdout: "hub.oepkgs.net/nestos/nestos-test/sonobuoy/nautilus:1.7"
  Mar 26 06:13:14.671: INFO: validating pod update-demo-nautilus-nq8xz
  Mar 26 06:13:14.673: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Mar 26 06:13:14.673: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Mar 26 06:13:14.673: INFO: update-demo-nautilus-nq8xz is verified up and running
  STEP: using delete to clean up resources @ 03/26/24 06:13:14.673
  Mar 26 06:13:14.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 delete --grace-period=0 --force -f -'
  Mar 26 06:13:14.714: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Mar 26 06:13:14.714: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Mar 26 06:13:14.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 get rc,svc -l name=update-demo --no-headers'
  Mar 26 06:13:14.762: INFO: stderr: "No resources found in kubectl-621 namespace.\n"
  Mar 26 06:13:14.762: INFO: stdout: ""
  Mar 26 06:13:14.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-621 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Mar 26 06:13:14.804: INFO: stderr: ""
  Mar 26 06:13:14.804: INFO: stdout: ""
  Mar 26 06:13:14.804: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-621" for this suite. @ 03/26/24 06:13:14.806
• [13.255 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 03/26/24 06:13:14.809
  Mar 26 06:13:14.809: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 06:13:14.809
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:13:14.816
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:13:14.817
  STEP: Creating projection with secret that has name projected-secret-test-map-bdfa4387-4549-49f8-a5e4-36c1e047d85e @ 03/26/24 06:13:14.818
  STEP: Creating a pod to test consume secrets @ 03/26/24 06:13:14.82
  E0326 06:13:15.335937      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:16.335961      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:13:16.826
  Mar 26 06:13:16.827: INFO: Trying to get logs from node k8s-worker02 pod pod-projected-secrets-1dca6d74-a619-4fe3-b233-36ffb061e4b8 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 03/26/24 06:13:16.831
  Mar 26 06:13:16.835: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3347" for this suite. @ 03/26/24 06:13:16.837
• [2.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 03/26/24 06:13:16.839
  Mar 26 06:13:16.839: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename pods @ 03/26/24 06:13:16.84
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:13:16.847
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:13:16.849
  STEP: creating the pod @ 03/26/24 06:13:16.85
  STEP: submitting the pod to kubernetes @ 03/26/24 06:13:16.85
  W0326 06:13:16.853337      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E0326 06:13:17.336061      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:18.337097      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 03/26/24 06:13:18.857
  STEP: updating the pod @ 03/26/24 06:13:18.858
  E0326 06:13:19.337097      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:13:19.363: INFO: Successfully updated pod "pod-update-activedeadlineseconds-1b9606cd-d229-4993-b978-271327d90efd"
  E0326 06:13:20.337792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:21.338109      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:22.338081      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:23.338165      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:13:23.370: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-384" for this suite. @ 03/26/24 06:13:23.372
• [6.536 seconds]
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]
test/e2e/common/node/secrets.go:95
  STEP: Creating a kubernetes client @ 03/26/24 06:13:23.375
  Mar 26 06:13:23.375: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename secrets @ 03/26/24 06:13:23.376
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:13:23.382
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:13:23.383
  STEP: creating secret secrets-3173/secret-test-6b4c47c7-432c-4e46-8f4c-900a0d8e1c2b @ 03/26/24 06:13:23.385
  STEP: Creating a pod to test consume secrets @ 03/26/24 06:13:23.386
  E0326 06:13:24.338253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:25.338340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:26.338437      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:27.338528      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:13:27.395
  Mar 26 06:13:27.396: INFO: Trying to get logs from node k8s-worker02 pod pod-configmaps-0ca02f68-005e-424e-bbc8-1d34d8ec7de2 container env-test: <nil>
  STEP: delete the pod @ 03/26/24 06:13:27.399
  Mar 26 06:13:27.403: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3173" for this suite. @ 03/26/24 06:13:27.405
• [4.032 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:141
  STEP: Creating a kubernetes client @ 03/26/24 06:13:27.407
  Mar 26 06:13:27.407: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename crd-webhook @ 03/26/24 06:13:27.408
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:13:27.413
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:13:27.414
  STEP: Setting up server cert @ 03/26/24 06:13:27.415
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 03/26/24 06:13:27.684
  STEP: Deploying the custom resource conversion webhook pod @ 03/26/24 06:13:27.687
  STEP: Wait for the deployment to be ready @ 03/26/24 06:13:27.691
  Mar 26 06:13:27.692: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
  E0326 06:13:28.338711      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:29.338997      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 03/26/24 06:13:29.696
  STEP: Verifying the service has paired with the endpoint @ 03/26/24 06:13:29.7
  E0326 06:13:30.339023      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:13:30.700: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Mar 26 06:13:30.703: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  E0326 06:13:31.339688      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:32.339871      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 03/26/24 06:13:33.236
  STEP: v2 custom resource should be converted @ 03/26/24 06:13:33.238
  Mar 26 06:13:33.240: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0326 06:13:33.340832      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "crd-webhook-2336" for this suite. @ 03/26/24 06:13:33.763
• [6.359 seconds]
------------------------------
SS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance]
test/e2e/instrumentation/core_events.go:175
  STEP: Creating a kubernetes client @ 03/26/24 06:13:33.767
  Mar 26 06:13:33.767: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename events @ 03/26/24 06:13:33.767
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:13:33.773
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:13:33.776
  STEP: Create set of events @ 03/26/24 06:13:33.777
  Mar 26 06:13:33.779: INFO: created test-event-1
  Mar 26 06:13:33.781: INFO: created test-event-2
  Mar 26 06:13:33.783: INFO: created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 03/26/24 06:13:33.783
  STEP: delete collection of events @ 03/26/24 06:13:33.784
  Mar 26 06:13:33.784: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 03/26/24 06:13:33.788
  Mar 26 06:13:33.788: INFO: requesting list of events to confirm quantity
  Mar 26 06:13:33.788: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-2623" for this suite. @ 03/26/24 06:13:33.79
• [0.025 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]
test/e2e/network/ingressclass.go:266
  STEP: Creating a kubernetes client @ 03/26/24 06:13:33.792
  Mar 26 06:13:33.792: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename ingressclass @ 03/26/24 06:13:33.793
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:13:33.799
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:13:33.8
  STEP: getting /apis @ 03/26/24 06:13:33.802
  STEP: getting /apis/networking.k8s.io @ 03/26/24 06:13:33.804
  STEP: getting /apis/networking.k8s.iov1 @ 03/26/24 06:13:33.804
  STEP: creating @ 03/26/24 06:13:33.805
  STEP: getting @ 03/26/24 06:13:33.81
  STEP: listing @ 03/26/24 06:13:33.811
  STEP: watching @ 03/26/24 06:13:33.812
  Mar 26 06:13:33.812: INFO: starting watch
  STEP: patching @ 03/26/24 06:13:33.812
  STEP: updating @ 03/26/24 06:13:33.814
  Mar 26 06:13:33.816: INFO: waiting for watch events with expected annotations
  Mar 26 06:13:33.816: INFO: saw patched and updated annotations
  STEP: deleting @ 03/26/24 06:13:33.816
  STEP: deleting a collection @ 03/26/24 06:13:33.819
  Mar 26 06:13:33.822: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-30" for this suite. @ 03/26/24 06:13:33.823
• [0.033 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]
test/e2e/apimachinery/discovery.go:125
  STEP: Creating a kubernetes client @ 03/26/24 06:13:33.826
  Mar 26 06:13:33.826: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename discovery @ 03/26/24 06:13:33.826
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:13:33.831
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:13:33.833
  STEP: Setting up server cert @ 03/26/24 06:13:33.834
  Mar 26 06:13:34.054: INFO: Checking APIGroup: apiregistration.k8s.io
  Mar 26 06:13:34.055: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  Mar 26 06:13:34.055: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
  Mar 26 06:13:34.055: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  Mar 26 06:13:34.055: INFO: Checking APIGroup: apps
  Mar 26 06:13:34.055: INFO: PreferredVersion.GroupVersion: apps/v1
  Mar 26 06:13:34.055: INFO: Versions found [{apps/v1 v1}]
  Mar 26 06:13:34.055: INFO: apps/v1 matches apps/v1
  Mar 26 06:13:34.055: INFO: Checking APIGroup: events.k8s.io
  Mar 26 06:13:34.056: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
  Mar 26 06:13:34.056: INFO: Versions found [{events.k8s.io/v1 v1}]
  Mar 26 06:13:34.056: INFO: events.k8s.io/v1 matches events.k8s.io/v1
  Mar 26 06:13:34.056: INFO: Checking APIGroup: authentication.k8s.io
  Mar 26 06:13:34.056: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
  Mar 26 06:13:34.056: INFO: Versions found [{authentication.k8s.io/v1 v1}]
  Mar 26 06:13:34.056: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
  Mar 26 06:13:34.056: INFO: Checking APIGroup: authorization.k8s.io
  Mar 26 06:13:34.057: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
  Mar 26 06:13:34.057: INFO: Versions found [{authorization.k8s.io/v1 v1}]
  Mar 26 06:13:34.057: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
  Mar 26 06:13:34.057: INFO: Checking APIGroup: autoscaling
  Mar 26 06:13:34.057: INFO: PreferredVersion.GroupVersion: autoscaling/v2
  Mar 26 06:13:34.057: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  Mar 26 06:13:34.057: INFO: autoscaling/v2 matches autoscaling/v2
  Mar 26 06:13:34.057: INFO: Checking APIGroup: batch
  Mar 26 06:13:34.058: INFO: PreferredVersion.GroupVersion: batch/v1
  Mar 26 06:13:34.058: INFO: Versions found [{batch/v1 v1}]
  Mar 26 06:13:34.058: INFO: batch/v1 matches batch/v1
  Mar 26 06:13:34.058: INFO: Checking APIGroup: certificates.k8s.io
  Mar 26 06:13:34.058: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
  Mar 26 06:13:34.058: INFO: Versions found [{certificates.k8s.io/v1 v1}]
  Mar 26 06:13:34.058: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
  Mar 26 06:13:34.059: INFO: Checking APIGroup: networking.k8s.io
  Mar 26 06:13:34.059: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
  Mar 26 06:13:34.059: INFO: Versions found [{networking.k8s.io/v1 v1}]
  Mar 26 06:13:34.059: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
  Mar 26 06:13:34.059: INFO: Checking APIGroup: policy
  Mar 26 06:13:34.060: INFO: PreferredVersion.GroupVersion: policy/v1
  Mar 26 06:13:34.060: INFO: Versions found [{policy/v1 v1}]
  Mar 26 06:13:34.060: INFO: policy/v1 matches policy/v1
  Mar 26 06:13:34.060: INFO: Checking APIGroup: rbac.authorization.k8s.io
  Mar 26 06:13:34.060: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  Mar 26 06:13:34.060: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
  Mar 26 06:13:34.060: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  Mar 26 06:13:34.060: INFO: Checking APIGroup: storage.k8s.io
  Mar 26 06:13:34.061: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
  Mar 26 06:13:34.061: INFO: Versions found [{storage.k8s.io/v1 v1}]
  Mar 26 06:13:34.061: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
  Mar 26 06:13:34.061: INFO: Checking APIGroup: admissionregistration.k8s.io
  Mar 26 06:13:34.061: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  Mar 26 06:13:34.061: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
  Mar 26 06:13:34.061: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  Mar 26 06:13:34.061: INFO: Checking APIGroup: apiextensions.k8s.io
  Mar 26 06:13:34.062: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  Mar 26 06:13:34.062: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
  Mar 26 06:13:34.062: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  Mar 26 06:13:34.062: INFO: Checking APIGroup: scheduling.k8s.io
  Mar 26 06:13:34.063: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  Mar 26 06:13:34.063: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
  Mar 26 06:13:34.063: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  Mar 26 06:13:34.063: INFO: Checking APIGroup: coordination.k8s.io
  Mar 26 06:13:34.063: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
  Mar 26 06:13:34.063: INFO: Versions found [{coordination.k8s.io/v1 v1}]
  Mar 26 06:13:34.063: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
  Mar 26 06:13:34.063: INFO: Checking APIGroup: node.k8s.io
  Mar 26 06:13:34.064: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
  Mar 26 06:13:34.064: INFO: Versions found [{node.k8s.io/v1 v1}]
  Mar 26 06:13:34.064: INFO: node.k8s.io/v1 matches node.k8s.io/v1
  Mar 26 06:13:34.064: INFO: Checking APIGroup: discovery.k8s.io
  Mar 26 06:13:34.064: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
  Mar 26 06:13:34.064: INFO: Versions found [{discovery.k8s.io/v1 v1}]
  Mar 26 06:13:34.064: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
  Mar 26 06:13:34.064: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
  Mar 26 06:13:34.065: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta3
  Mar 26 06:13:34.065: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta3 v1beta3} {flowcontrol.apiserver.k8s.io/v1beta2 v1beta2}]
  Mar 26 06:13:34.065: INFO: flowcontrol.apiserver.k8s.io/v1beta3 matches flowcontrol.apiserver.k8s.io/v1beta3
  Mar 26 06:13:34.065: INFO: Checking APIGroup: crd.projectcalico.org
  Mar 26 06:13:34.065: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
  Mar 26 06:13:34.065: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
  Mar 26 06:13:34.065: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
  Mar 26 06:13:34.065: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-1999" for this suite. @ 03/26/24 06:13:34.067
• [0.244 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance]
test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 03/26/24 06:13:34.07
  Mar 26 06:13:34.070: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename subjectreview @ 03/26/24 06:13:34.071
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:13:34.076
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:13:34.078
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-34" @ 03/26/24 06:13:34.079
  Mar 26 06:13:34.081: INFO: saUsername: "system:serviceaccount:subjectreview-34:e2e"
  Mar 26 06:13:34.081: INFO: saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-34"}
  Mar 26 06:13:34.081: INFO: saUID: "72ea5927-cd05-4806-b418-5bac8f55971a"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-34:e2e" @ 03/26/24 06:13:34.081
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-34:e2e" @ 03/26/24 06:13:34.081
  Mar 26 06:13:34.082: INFO: sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-34:e2e" api 'list' configmaps in "subjectreview-34" namespace @ 03/26/24 06:13:34.082
  Mar 26 06:13:34.083: INFO: SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-34:e2e" @ 03/26/24 06:13:34.083
  Mar 26 06:13:34.084: INFO: lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  Mar 26 06:13:34.084: INFO: LocalSubjectAccessReview has been verified
  Mar 26 06:13:34.084: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-34" for this suite. @ 03/26/24 06:13:34.086
• [0.017 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:167
  STEP: Creating a kubernetes client @ 03/26/24 06:13:34.088
  Mar 26 06:13:34.088: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename downward-api @ 03/26/24 06:13:34.088
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:13:34.093
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:13:34.094
  STEP: Creating a pod to test downward api env vars @ 03/26/24 06:13:34.095
  E0326 06:13:34.341302      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:35.342138      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:36.342578      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:37.342808      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:13:38.103
  Mar 26 06:13:38.105: INFO: Trying to get logs from node k8s-worker02 pod downward-api-bee13d65-6478-4073-87ca-d09ca174156e container dapi-container: <nil>
  STEP: delete the pod @ 03/26/24 06:13:38.107
  Mar 26 06:13:38.113: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6065" for this suite. @ 03/26/24 06:13:38.114
• [4.028 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance]
test/e2e/network/service.go:3326
  STEP: Creating a kubernetes client @ 03/26/24 06:13:38.118
  Mar 26 06:13:38.118: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename services @ 03/26/24 06:13:38.118
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:13:38.124
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:13:38.125
  STEP: creating a Service @ 03/26/24 06:13:38.127
  STEP: watching for the Service to be added @ 03/26/24 06:13:38.13
  Mar 26 06:13:38.132: INFO: Found Service test-service-brb22 in namespace services-9681 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
  Mar 26 06:13:38.132: INFO: Service test-service-brb22 created
  STEP: Getting /status @ 03/26/24 06:13:38.132
  Mar 26 06:13:38.133: INFO: Service test-service-brb22 has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 03/26/24 06:13:38.133
  STEP: watching for the Service to be patched @ 03/26/24 06:13:38.135
  Mar 26 06:13:38.136: INFO: observed Service test-service-brb22 in namespace services-9681 with annotations: map[] & LoadBalancer: {[]}
  Mar 26 06:13:38.136: INFO: Found Service test-service-brb22 in namespace services-9681 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
  Mar 26 06:13:38.136: INFO: Service test-service-brb22 has service status patched
  STEP: updating the ServiceStatus @ 03/26/24 06:13:38.136
  Mar 26 06:13:38.142: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 03/26/24 06:13:38.142
  Mar 26 06:13:38.142: INFO: Observed Service test-service-brb22 in namespace services-9681 with annotations: map[] & Conditions: {[]}
  Mar 26 06:13:38.142: INFO: Observed event: &Service{ObjectMeta:{test-service-brb22  services-9681  cf156576-9374-4fa0-94b9-b2a4c928b19b 82473 0 2024-03-26 06:13:38 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2024-03-26 06:13:38 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2024-03-26 06:13:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.96.79.220,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.96.79.220],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  Mar 26 06:13:38.142: INFO: Found Service test-service-brb22 in namespace services-9681 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Mar 26 06:13:38.142: INFO: Service test-service-brb22 has service status updated
  STEP: patching the service @ 03/26/24 06:13:38.142
  STEP: watching for the Service to be patched @ 03/26/24 06:13:38.145
  Mar 26 06:13:38.146: INFO: observed Service test-service-brb22 in namespace services-9681 with labels: map[test-service-static:true]
  Mar 26 06:13:38.146: INFO: observed Service test-service-brb22 in namespace services-9681 with labels: map[test-service-static:true]
  Mar 26 06:13:38.146: INFO: observed Service test-service-brb22 in namespace services-9681 with labels: map[test-service-static:true]
  Mar 26 06:13:38.146: INFO: Found Service test-service-brb22 in namespace services-9681 with labels: map[test-service:patched test-service-static:true]
  Mar 26 06:13:38.146: INFO: Service test-service-brb22 patched
  STEP: deleting the service @ 03/26/24 06:13:38.146
  STEP: watching for the Service to be deleted @ 03/26/24 06:13:38.151
  Mar 26 06:13:38.152: INFO: Observed event: ADDED
  Mar 26 06:13:38.152: INFO: Observed event: MODIFIED
  Mar 26 06:13:38.152: INFO: Observed event: MODIFIED
  Mar 26 06:13:38.153: INFO: Observed event: MODIFIED
  Mar 26 06:13:38.153: INFO: Found Service test-service-brb22 in namespace services-9681 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  Mar 26 06:13:38.153: INFO: Service test-service-brb22 deleted
  Mar 26 06:13:38.153: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9681" for this suite. @ 03/26/24 06:13:38.155
• [0.039 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]
test/e2e/network/service.go:1416
  STEP: Creating a kubernetes client @ 03/26/24 06:13:38.158
  Mar 26 06:13:38.158: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename services @ 03/26/24 06:13:38.158
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:13:38.164
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:13:38.166
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-6904 @ 03/26/24 06:13:38.167
  STEP: changing the ExternalName service to type=ClusterIP @ 03/26/24 06:13:38.169
  STEP: creating replication controller externalname-service in namespace services-6904 @ 03/26/24 06:13:38.177
  I0326 06:13:38.179963      19 runners.go:197] Created replication controller with name: externalname-service, namespace: services-6904, replica count: 2
  E0326 06:13:38.343873      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:39.344792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:40.344877      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0326 06:13:41.230605      19 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Mar 26 06:13:41.230: INFO: Creating new exec pod
  E0326 06:13:41.345633      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:42.346685      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:43.347216      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:13:44.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-6904 exec execpodhpksq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Mar 26 06:13:44.317: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Mar 26 06:13:44.317: INFO: stdout: "externalname-service-57d4g"
  Mar 26 06:13:44.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-6904 exec execpodhpksq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.69.213 80'
  E0326 06:13:44.348260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:13:44.391: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.69.213 80\nConnection to 10.96.69.213 80 port [tcp/http] succeeded!\n"
  Mar 26 06:13:44.391: INFO: stdout: ""
  E0326 06:13:45.348318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:13:45.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-6904 exec execpodhpksq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.69.213 80'
  Mar 26 06:13:45.478: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.69.213 80\nConnection to 10.96.69.213 80 port [tcp/http] succeeded!\n"
  Mar 26 06:13:45.478: INFO: stdout: "externalname-service-57d4g"
  Mar 26 06:13:45.478: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Mar 26 06:13:45.480: INFO: Cleaning up the ExternalName to ClusterIP test service
  STEP: Destroying namespace "services-6904" for this suite. @ 03/26/24 06:13:45.492
• [7.337 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]
test/e2e/kubectl/kubectl.go:1575
  STEP: Creating a kubernetes client @ 03/26/24 06:13:45.494
  Mar 26 06:13:45.494: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubectl @ 03/26/24 06:13:45.495
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:13:45.5
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:13:45.501
  STEP: creating the pod @ 03/26/24 06:13:45.503
  Mar 26 06:13:45.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-6259 create -f -'
  Mar 26 06:13:45.637: INFO: stderr: ""
  Mar 26 06:13:45.637: INFO: stdout: "pod/pause created\n"
  E0326 06:13:46.349306      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:47.349474      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 03/26/24 06:13:47.641
  Mar 26 06:13:47.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-6259 label pods pause testing-label=testing-label-value'
  Mar 26 06:13:47.685: INFO: stderr: ""
  Mar 26 06:13:47.685: INFO: stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 03/26/24 06:13:47.685
  Mar 26 06:13:47.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-6259 get pod pause -L testing-label'
  Mar 26 06:13:47.723: INFO: stderr: ""
  Mar 26 06:13:47.723: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 03/26/24 06:13:47.723
  Mar 26 06:13:47.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-6259 label pods pause testing-label-'
  Mar 26 06:13:47.768: INFO: stderr: ""
  Mar 26 06:13:47.768: INFO: stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 03/26/24 06:13:47.768
  Mar 26 06:13:47.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-6259 get pod pause -L testing-label'
  Mar 26 06:13:47.812: INFO: stderr: ""
  Mar 26 06:13:47.812: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
  STEP: using delete to clean up resources @ 03/26/24 06:13:47.812
  Mar 26 06:13:47.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-6259 delete --grace-period=0 --force -f -'
  Mar 26 06:13:47.853: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Mar 26 06:13:47.853: INFO: stdout: "pod \"pause\" force deleted\n"
  Mar 26 06:13:47.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-6259 get rc,svc -l name=pause --no-headers'
  Mar 26 06:13:47.895: INFO: stderr: "No resources found in kubectl-6259 namespace.\n"
  Mar 26 06:13:47.895: INFO: stdout: ""
  Mar 26 06:13:47.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-6259 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Mar 26 06:13:47.934: INFO: stderr: ""
  Mar 26 06:13:47.934: INFO: stdout: ""
  Mar 26 06:13:47.934: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6259" for this suite. @ 03/26/24 06:13:47.936
• [2.444 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:262
  STEP: Creating a kubernetes client @ 03/26/24 06:13:47.942
  Mar 26 06:13:47.942: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 06:13:47.942
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:13:47.947
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:13:47.948
  STEP: Creating a pod to test downward API volume plugin @ 03/26/24 06:13:47.949
  E0326 06:13:48.349994      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:49.350136      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:13:49.956
  Mar 26 06:13:49.957: INFO: Trying to get logs from node k8s-worker01 pod downwardapi-volume-5a27971c-fc49-40da-888d-c3ce3437662b container client-container: <nil>
  STEP: delete the pod @ 03/26/24 06:13:49.96
  Mar 26 06:13:49.965: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5958" for this suite. @ 03/26/24 06:13:49.966
• [2.027 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:398
  STEP: Creating a kubernetes client @ 03/26/24 06:13:49.969
  Mar 26 06:13:49.969: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename namespaces @ 03/26/24 06:13:49.969
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:13:49.974
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:13:49.975
  STEP: Creating namespace "e2e-ns-vf6kf" @ 03/26/24 06:13:49.976
  Mar 26 06:13:49.983: INFO: Namespace "e2e-ns-vf6kf-9211" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-vf6kf-9211" @ 03/26/24 06:13:49.983
  Mar 26 06:13:49.985: INFO: Namespace "e2e-ns-vf6kf-9211" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-vf6kf-9211" @ 03/26/24 06:13:49.985
  Mar 26 06:13:49.989: INFO: Namespace "e2e-ns-vf6kf-9211" has []v1.FinalizerName{"kubernetes"}
  Mar 26 06:13:49.989: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-9531" for this suite. @ 03/26/24 06:13:49.99
  STEP: Destroying namespace "e2e-ns-vf6kf-9211" for this suite. @ 03/26/24 06:13:49.992
• [0.025 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 03/26/24 06:13:49.995
  Mar 26 06:13:49.995: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 06:13:49.996
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:13:50
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:13:50.001
  STEP: Creating projection with secret that has name projected-secret-test-82de0f26-fc84-4aa7-9631-bef694aa4cd8 @ 03/26/24 06:13:50.003
  STEP: Creating a pod to test consume secrets @ 03/26/24 06:13:50.004
  E0326 06:13:50.350955      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:51.351333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:52.352380      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:53.353241      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:13:54.011
  Mar 26 06:13:54.013: INFO: Trying to get logs from node k8s-worker02 pod pod-projected-secrets-915906aa-47a0-4e8a-b65c-c71b65620d57 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 03/26/24 06:13:54.015
  Mar 26 06:13:54.020: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6520" for this suite. @ 03/26/24 06:13:54.022
• [4.029 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:148
  STEP: Creating a kubernetes client @ 03/26/24 06:13:54.024
  Mar 26 06:13:54.024: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubelet-test @ 03/26/24 06:13:54.024
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:13:54.029
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:13:54.031
  STEP: Waiting for pod completion @ 03/26/24 06:13:54.036
  E0326 06:13:54.353873      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:55.354455      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:56.355007      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:57.355176      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:13:58.043: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-8826" for this suite. @ 03/26/24 06:13:58.045
• [4.024 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance]
test/e2e/scheduling/limit_range.go:239
  STEP: Creating a kubernetes client @ 03/26/24 06:13:58.048
  Mar 26 06:13:58.048: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename limitrange @ 03/26/24 06:13:58.049
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:13:58.053
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:13:58.055
  STEP: Creating LimitRange "e2e-limitrange-h5nb2" in namespace "limitrange-1145" @ 03/26/24 06:13:58.056
  STEP: Creating another limitRange in another namespace @ 03/26/24 06:13:58.058
  Mar 26 06:13:58.062: INFO: Namespace "e2e-limitrange-h5nb2-2625" created
  Mar 26 06:13:58.062: INFO: Creating LimitRange "e2e-limitrange-h5nb2" in namespace "e2e-limitrange-h5nb2-2625"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-h5nb2" @ 03/26/24 06:13:58.064
  Mar 26 06:13:58.066: INFO: Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-h5nb2" in "limitrange-1145" namespace @ 03/26/24 06:13:58.066
  Mar 26 06:13:58.068: INFO: LimitRange "e2e-limitrange-h5nb2" has been patched
  STEP: Delete LimitRange "e2e-limitrange-h5nb2" by Collection with labelSelector: "e2e-limitrange-h5nb2=patched" @ 03/26/24 06:13:58.068
  STEP: Confirm that the limitRange "e2e-limitrange-h5nb2" has been deleted @ 03/26/24 06:13:58.07
  Mar 26 06:13:58.070: INFO: Requesting list of LimitRange to confirm quantity
  Mar 26 06:13:58.071: INFO: Found 0 LimitRange with label "e2e-limitrange-h5nb2=patched"
  Mar 26 06:13:58.071: INFO: LimitRange "e2e-limitrange-h5nb2" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-h5nb2" @ 03/26/24 06:13:58.071
  Mar 26 06:13:58.072: INFO: Found 1 limitRange
  Mar 26 06:13:58.072: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-1145" for this suite. @ 03/26/24 06:13:58.073
  STEP: Destroying namespace "e2e-limitrange-h5nb2-2625" for this suite. @ 03/26/24 06:13:58.075
• [0.029 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
test/e2e/apps/job.go:430
  STEP: Creating a kubernetes client @ 03/26/24 06:13:58.078
  Mar 26 06:13:58.078: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename job @ 03/26/24 06:13:58.079
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:13:58.083
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:13:58.085
  STEP: Creating a job @ 03/26/24 06:13:58.087
  STEP: Ensuring job reaches completions @ 03/26/24 06:13:58.089
  E0326 06:13:58.355796      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:13:59.356575      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:00.357018      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:01.357125      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:02.357542      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:03.357624      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:04.358516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:05.358906      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:06.359892      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:07.360024      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:14:08.091: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4570" for this suite. @ 03/26/24 06:14:08.093
• [10.017 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:110
  STEP: Creating a kubernetes client @ 03/26/24 06:14:08.096
  Mar 26 06:14:08.096: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubelet-test @ 03/26/24 06:14:08.098
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:14:08.104
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:14:08.105
  E0326 06:14:08.360359      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:09.361415      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:10.361639      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:11.361761      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:14:12.116: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-4846" for this suite. @ 03/26/24 06:14:12.117
• [4.024 seconds]
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:85
  STEP: Creating a kubernetes client @ 03/26/24 06:14:12.12
  Mar 26 06:14:12.120: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename custom-resource-definition @ 03/26/24 06:14:12.121
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:14:12.127
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:14:12.128
  Mar 26 06:14:12.129: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  E0326 06:14:12.361989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:13.363073      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:14.363521      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:15.364183      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:16.364489      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:17.365259      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:14:18.235: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-436" for this suite. @ 03/26/24 06:14:18.237
• [6.119 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:45
  STEP: Creating a kubernetes client @ 03/26/24 06:14:18.241
  Mar 26 06:14:18.241: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename downward-api @ 03/26/24 06:14:18.242
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:14:18.247
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:14:18.249
  STEP: Creating a pod to test downward api env vars @ 03/26/24 06:14:18.25
  E0326 06:14:18.365757      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:19.365950      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:20.366253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:21.366386      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:14:22.258
  Mar 26 06:14:22.259: INFO: Trying to get logs from node k8s-worker02 pod downward-api-4434a182-8417-4230-81ee-06307f7c8e0e container dapi-container: <nil>
  STEP: delete the pod @ 03/26/24 06:14:22.263
  Mar 26 06:14:22.267: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9803" for this suite. @ 03/26/24 06:14:22.269
• [4.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance]
test/e2e/apimachinery/field_validation.go:474
  STEP: Creating a kubernetes client @ 03/26/24 06:14:22.275
  Mar 26 06:14:22.275: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename field-validation @ 03/26/24 06:14:22.276
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:14:22.282
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:14:22.283
  Mar 26 06:14:22.284: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  E0326 06:14:22.366379      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:23.367442      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:24.367606      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0326 06:14:24.811138      19 warnings.go:70] unknown field "alpha"
  W0326 06:14:24.811155      19 warnings.go:70] unknown field "beta"
  W0326 06:14:24.811158      19 warnings.go:70] unknown field "delta"
  W0326 06:14:24.811160      19 warnings.go:70] unknown field "epsilon"
  W0326 06:14:24.811163      19 warnings.go:70] unknown field "gamma"
  Mar 26 06:14:25.327: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6105" for this suite. @ 03/26/24 06:14:25.334
• [3.061 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]
test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 03/26/24 06:14:25.338
  Mar 26 06:14:25.338: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename subpath @ 03/26/24 06:14:25.338
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:14:25.345
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:14:25.347
  STEP: Setting up data @ 03/26/24 06:14:25.349
  STEP: Creating pod pod-subpath-test-projected-wrz7 @ 03/26/24 06:14:25.353
  STEP: Creating a pod to test atomic-volume-subpath @ 03/26/24 06:14:25.353
  E0326 06:14:25.367924      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:26.368079      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:27.368793      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:28.368849      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:29.369492      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:30.369979      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:31.370976      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:32.370962      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:33.371970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:34.372985      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:35.373319      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:36.373884      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:37.374683      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:38.375662      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:39.376627      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:40.376704      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:41.376789      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:42.376996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:43.376970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:44.378067      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:45.378578      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:46.378581      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:47.378700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:48.378762      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:49.378917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:14:49.383
  Mar 26 06:14:49.385: INFO: Trying to get logs from node k8s-worker02 pod pod-subpath-test-projected-wrz7 container test-container-subpath-projected-wrz7: <nil>
  STEP: delete the pod @ 03/26/24 06:14:49.391
  STEP: Deleting pod pod-subpath-test-projected-wrz7 @ 03/26/24 06:14:49.397
  Mar 26 06:14:49.397: INFO: Deleting pod "pod-subpath-test-projected-wrz7" in namespace "subpath-7790"
  Mar 26 06:14:49.398: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-7790" for this suite. @ 03/26/24 06:14:49.4
• [24.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:145
  STEP: Creating a kubernetes client @ 03/26/24 06:14:49.404
  Mar 26 06:14:49.404: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename custom-resource-definition @ 03/26/24 06:14:49.405
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:14:49.41
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:14:49.411
  Mar 26 06:14:49.413: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 06:14:49.930: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-1554" for this suite. @ 03/26/24 06:14:49.933
• [0.531 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:135
  STEP: Creating a kubernetes client @ 03/26/24 06:14:49.936
  Mar 26 06:14:49.936: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubelet-test @ 03/26/24 06:14:49.937
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:14:49.945
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:14:49.946
  Mar 26 06:14:49.959: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-6975" for this suite. @ 03/26/24 06:14:49.961
• [0.027 seconds]
------------------------------
SSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 03/26/24 06:14:49.963
  Mar 26 06:14:49.963: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename init-container @ 03/26/24 06:14:49.964
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:14:49.969
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:14:49.97
  STEP: creating the pod @ 03/26/24 06:14:49.971
  Mar 26 06:14:49.971: INFO: PodSpec: initContainers in spec.initContainers
  E0326 06:14:50.379310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:51.379890      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:52.379988      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:53.380406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:54.380512      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:55.381094      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:56.381976      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:57.382907      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:58.383397      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:14:59.384555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:00.384791      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:01.385002      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:02.385068      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:03.385149      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:04.385478      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:05.385969      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:06.386084      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:07.386407      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:08.386561      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:09.386759      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:10.386975      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:11.387128      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:12.387254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:13.387403      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:14.387499      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:15.388432      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:16.388521      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:17.388686      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:18.389608      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:19.390529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:20.390771      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:21.391033      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:22.391098      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:23.391248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:24.391421      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:25.391800      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:26.391982      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:27.392177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:28.392310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:29.392442      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:30.392629      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:31.393023      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:32.393145      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:15:32.620: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-1e95381c-a460-4a59-8b40-0adc137e01af", GenerateName:"", Namespace:"init-container-5099", SelfLink:"", UID:"c230434f-331b-4147-ab51-581a27d49534", ResourceVersion:"83338", Generation:0, CreationTimestamp:time.Date(2024, time.March, 26, 6, 14, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"971706240"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"1088cdbf076eef97d2e0a016091cc5e019725b8d7700428a0725b73d7f5958c8", "cni.projectcalico.org/podIP":"10.244.69.198/32", "cni.projectcalico.org/podIPs":"10.244.69.198/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.March, 26, 6, 14, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00519c168), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.March, 26, 6, 14, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00519c198), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.March, 26, 6, 15, 32, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00519c1c8), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-6jl92", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc00573eb60), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"hub.oepkgs.net/nestos/nestos-test/sonobuoy/busybox:1.29-4", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-6jl92", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"hub.oepkgs.net/nestos/nestos-test/sonobuoy/busybox:1.29-4", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-6jl92", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"hub.oepkgs.net/nestos/nestos-test/sonobuoy/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-6jl92", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00516e448), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-worker02", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc005328000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00516e4d0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00516e4f0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00516e4f8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00516e4fc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000cd9800), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.March, 26, 6, 14, 49, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.March, 26, 6, 14, 49, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.March, 26, 6, 14, 49, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.March, 26, 6, 14, 49, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.132.15", HostIPs:[]v1.HostIP(nil), PodIP:"10.244.69.198", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.244.69.198"}}, StartTime:time.Date(2024, time.March, 26, 6, 14, 49, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0053280e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc005328150)}, Ready:false, RestartCount:3, Image:"hub.oepkgs.net/nestos/nestos-test/sonobuoy/busybox:1.29-4", ImageID:"hub.oepkgs.net/nestos/nestos-test/sonobuoy/busybox@sha256:7ddd6b83e44b8f6e2f1fccace9562f5600b71e7717515ebd2131bdb94ad8634c", ContainerID:"cri-o://5f5647cee4e7227674799fc9548951df49e05c7562b5a1e08b10ae8d4d04b953", Started:(*bool)(0xc00516e59f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00573ebe0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"hub.oepkgs.net/nestos/nestos-test/sonobuoy/busybox:1.29-4", ImageID:"", ContainerID:"", Started:(*bool)(0xc00516e5a5), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00573ebc0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"hub.oepkgs.net/nestos/nestos-test/sonobuoy/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc00516e574), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  Mar 26 06:15:32.620: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-5099" for this suite. @ 03/26/24 06:15:32.623
• [42.662 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:168
  STEP: Creating a kubernetes client @ 03/26/24 06:15:32.629
  Mar 26 06:15:32.629: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename container-probe @ 03/26/24 06:15:32.629
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:15:32.636
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:15:32.637
  STEP: Creating pod liveness-0bb64888-7d2e-4b42-81e6-39c2b566e5b3 in namespace container-probe-9639 @ 03/26/24 06:15:32.639
  E0326 06:15:33.394016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:34.394147      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 03/26/24 06:15:34.645
  Mar 26 06:15:34.646: INFO: Initial restart count of pod liveness-0bb64888-7d2e-4b42-81e6-39c2b566e5b3 is 0
  Mar 26 06:15:34.647: INFO: Get pod liveness-0bb64888-7d2e-4b42-81e6-39c2b566e5b3 in namespace container-probe-9639
  E0326 06:15:35.394980      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:36.395118      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:15:36.650: INFO: Get pod liveness-0bb64888-7d2e-4b42-81e6-39c2b566e5b3 in namespace container-probe-9639
  E0326 06:15:37.396096      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:38.396204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:15:38.651: INFO: Get pod liveness-0bb64888-7d2e-4b42-81e6-39c2b566e5b3 in namespace container-probe-9639
  E0326 06:15:39.396686      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:40.396837      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:15:40.654: INFO: Get pod liveness-0bb64888-7d2e-4b42-81e6-39c2b566e5b3 in namespace container-probe-9639
  E0326 06:15:41.396954      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:42.398038      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:15:42.657: INFO: Get pod liveness-0bb64888-7d2e-4b42-81e6-39c2b566e5b3 in namespace container-probe-9639
  E0326 06:15:43.399021      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:44.399149      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:15:44.659: INFO: Get pod liveness-0bb64888-7d2e-4b42-81e6-39c2b566e5b3 in namespace container-probe-9639
  E0326 06:15:45.399257      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:46.399374      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:15:46.661: INFO: Get pod liveness-0bb64888-7d2e-4b42-81e6-39c2b566e5b3 in namespace container-probe-9639
  E0326 06:15:47.400426      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:48.400882      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:15:48.664: INFO: Get pod liveness-0bb64888-7d2e-4b42-81e6-39c2b566e5b3 in namespace container-probe-9639
  E0326 06:15:49.401067      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:50.401481      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:15:50.666: INFO: Get pod liveness-0bb64888-7d2e-4b42-81e6-39c2b566e5b3 in namespace container-probe-9639
  E0326 06:15:51.402169      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:52.402319      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:15:52.669: INFO: Get pod liveness-0bb64888-7d2e-4b42-81e6-39c2b566e5b3 in namespace container-probe-9639
  E0326 06:15:53.403154      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:54.404262      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:15:54.671: INFO: Get pod liveness-0bb64888-7d2e-4b42-81e6-39c2b566e5b3 in namespace container-probe-9639
  Mar 26 06:15:54.671: INFO: Restart count of pod container-probe-9639/liveness-0bb64888-7d2e-4b42-81e6-39c2b566e5b3 is now 1 (20.024479163s elapsed)
  Mar 26 06:15:54.671: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 03/26/24 06:15:54.673
  STEP: Destroying namespace "container-probe-9639" for this suite. @ 03/26/24 06:15:54.678
• [22.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]
test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 03/26/24 06:15:54.686
  Mar 26 06:15:54.686: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename disruption @ 03/26/24 06:15:54.686
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:15:54.694
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:15:54.698
  STEP: Creating a kubernetes client @ 03/26/24 06:15:54.7
  Mar 26 06:15:54.700: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename disruption-2 @ 03/26/24 06:15:54.7
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:15:54.705
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:15:54.707
  STEP: Waiting for the pdb to be processed @ 03/26/24 06:15:54.71
  E0326 06:15:55.404423      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:56.405425      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 03/26/24 06:15:56.716
  E0326 06:15:57.405684      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:15:58.405974      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 03/26/24 06:15:58.722
  E0326 06:15:59.406733      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:00.407899      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: listing a collection of PDBs across all namespaces @ 03/26/24 06:16:00.725
  STEP: listing a collection of PDBs in namespace disruption-3946 @ 03/26/24 06:16:00.727
  STEP: deleting a collection of PDBs @ 03/26/24 06:16:00.728
  STEP: Waiting for the PDB collection to be deleted @ 03/26/24 06:16:00.732
  Mar 26 06:16:00.733: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Mar 26 06:16:00.735: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-9074" for this suite. @ 03/26/24 06:16:00.737
  STEP: Destroying namespace "disruption-3946" for this suite. @ 03/26/24 06:16:00.74
• [6.057 seconds]
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:124
  STEP: Creating a kubernetes client @ 03/26/24 06:16:00.743
  Mar 26 06:16:00.744: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename configmap @ 03/26/24 06:16:00.744
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:16:00.749
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:16:00.751
  STEP: Creating configMap with name configmap-test-upd-af1a8b8e-00ef-4b74-aca2-3d4573e89b49 @ 03/26/24 06:16:00.754
  STEP: Creating the pod @ 03/26/24 06:16:00.755
  E0326 06:16:01.408029      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:02.408401      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap configmap-test-upd-af1a8b8e-00ef-4b74-aca2-3d4573e89b49 @ 03/26/24 06:16:02.766
  STEP: waiting to observe update in volume @ 03/26/24 06:16:02.768
  E0326 06:16:03.408527      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:04.408663      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:05.409435      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:06.409529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:07.409649      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:08.409813      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:09.410699      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:10.410903      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:11.410958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:12.411062      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:13.411082      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:14.411294      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:15.412135      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:16.412228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:17.412571      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:18.412697      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:19.413270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:20.413583      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:21.413998      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:22.414171      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:23.415147      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:24.415328      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:25.415444      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:26.415581      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:27.415987      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:28.416150      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:29.416438      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:30.416693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:31.417088      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:32.418090      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:33.418180      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:34.418351      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:35.418470      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:36.418663      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:37.419680      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:38.420555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:39.420831      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:40.421898      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:41.422886      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:42.422992      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:43.423418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:44.424488      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:45.424537      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:46.424565      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:47.425537      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:48.426370      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:49.426600      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:50.426707      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:51.427446      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:52.427539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:53.428570      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:54.429418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:55.430388      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:56.430506      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:57.431387      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:58.431525      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:16:59.432175      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:00.432246      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:01.433189      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:02.433337      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:03.433632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:04.433740      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:05.434410      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:06.435295      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:07.436197      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:08.436296      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:09.437132      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:10.437218      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:11.438174      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:12.438184      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:13.438286      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:14.438388      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:15.438480      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:16.438567      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:17.439011      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:18.440232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:19.441077      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:20.441607      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:21.441961      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:22.442157      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:23.443069      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:24.443239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:25.443384      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:26.443555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:27.444333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:28.445372      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:29.446110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:30.446463      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:31.446530      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:32.446658      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:33.446751      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:34.446868      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:17:34.944: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6158" for this suite. @ 03/26/24 06:17:34.946
• [94.205 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]
test/e2e/kubectl/kubectl.go:1806
  STEP: Creating a kubernetes client @ 03/26/24 06:17:34.95
  Mar 26 06:17:34.950: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubectl @ 03/26/24 06:17:34.951
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:17:34.958
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:17:34.959
  STEP: Starting the proxy @ 03/26/24 06:17:34.961
  Mar 26 06:17:34.962: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-2609 proxy --unix-socket=/tmp/kubectl-proxy-unix3551729872/test'
  STEP: retrieving proxy /api/ output @ 03/26/24 06:17:34.999
  Mar 26 06:17:34.999: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2609" for this suite. @ 03/26/24 06:17:35.001
• [0.053 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance]
test/e2e/network/service.go:1280
  STEP: Creating a kubernetes client @ 03/26/24 06:17:35.004
  Mar 26 06:17:35.004: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename services @ 03/26/24 06:17:35.005
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:17:35.01
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:17:35.012
  STEP: creating service nodeport-test with type=NodePort in namespace services-6237 @ 03/26/24 06:17:35.013
  STEP: creating replication controller nodeport-test in namespace services-6237 @ 03/26/24 06:17:35.017
  I0326 06:17:35.022122      19 runners.go:197] Created replication controller with name: nodeport-test, namespace: services-6237, replica count: 2
  E0326 06:17:35.448153      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:36.448209      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:37.448298      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0326 06:17:38.074040      19 runners.go:197] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Mar 26 06:17:38.074: INFO: Creating new exec pod
  E0326 06:17:38.448985      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:39.449210      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:40.449983      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:17:41.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-6237 exec execpodp9k2f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  Mar 26 06:17:41.170: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  Mar 26 06:17:41.170: INFO: stdout: "nodeport-test-98tkt"
  Mar 26 06:17:41.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-6237 exec execpodp9k2f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.166.90 80'
  Mar 26 06:17:41.256: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.166.90 80\nConnection to 10.96.166.90 80 port [tcp/http] succeeded!\n"
  Mar 26 06:17:41.256: INFO: stdout: "nodeport-test-5nrnn"
  Mar 26 06:17:41.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-6237 exec execpodp9k2f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.132.15 31554'
  Mar 26 06:17:41.336: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.132.15 31554\nConnection to 192.168.132.15 31554 port [tcp/*] succeeded!\n"
  Mar 26 06:17:41.336: INFO: stdout: "nodeport-test-98tkt"
  Mar 26 06:17:41.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-6237 exec execpodp9k2f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.132.11 31554'
  Mar 26 06:17:41.425: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.132.11 31554\nConnection to 192.168.132.11 31554 port [tcp/*] succeeded!\n"
  Mar 26 06:17:41.425: INFO: stdout: ""
  E0326 06:17:41.451012      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:17:42.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-6237 exec execpodp9k2f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.132.11 31554'
  E0326 06:17:42.451846      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:17:42.511: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.132.11 31554\nConnection to 192.168.132.11 31554 port [tcp/*] succeeded!\n"
  Mar 26 06:17:42.511: INFO: stdout: "nodeport-test-5nrnn"
  Mar 26 06:17:42.511: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6237" for this suite. @ 03/26/24 06:17:42.514
• [7.513 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:87
  STEP: Creating a kubernetes client @ 03/26/24 06:17:42.517
  Mar 26 06:17:42.517: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename emptydir @ 03/26/24 06:17:42.518
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:17:42.523
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:17:42.524
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 03/26/24 06:17:42.526
  E0326 06:17:43.451933      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:44.452159      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:45.453091      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:46.453977      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:17:46.534
  Mar 26 06:17:46.535: INFO: Trying to get logs from node k8s-worker02 pod pod-e6619a0e-c322-48fb-8974-098e1c3b4cb7 container test-container: <nil>
  STEP: delete the pod @ 03/26/24 06:17:46.537
  Mar 26 06:17:46.542: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8223" for this suite. @ 03/26/24 06:17:46.544
• [4.028 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:57
  STEP: Creating a kubernetes client @ 03/26/24 06:17:46.546
  Mar 26 06:17:46.546: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename configmap @ 03/26/24 06:17:46.546
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:17:46.552
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:17:46.554
  STEP: Creating configMap with name configmap-test-volume-8c3fdc76-08dc-4de1-8b96-75f0c7c6f04f @ 03/26/24 06:17:46.556
  STEP: Creating a pod to test consume configMaps @ 03/26/24 06:17:46.558
  E0326 06:17:47.455019      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:48.455572      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:49.455880      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:50.456784      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:17:50.567
  Mar 26 06:17:50.568: INFO: Trying to get logs from node k8s-worker02 pod pod-configmaps-56630f79-f4e0-4ed7-a890-22efffefb511 container agnhost-container: <nil>
  STEP: delete the pod @ 03/26/24 06:17:50.57
  Mar 26 06:17:50.575: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2329" for this suite. @ 03/26/24 06:17:50.577
• [4.034 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:370
  STEP: Creating a kubernetes client @ 03/26/24 06:17:50.58
  Mar 26 06:17:50.580: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename namespaces @ 03/26/24 06:17:50.581
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:17:50.585
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:17:50.587
  STEP: Updating Namespace "namespaces-6922" @ 03/26/24 06:17:50.588
  Mar 26 06:17:50.591: INFO: Namespace "namespaces-6922" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"1d6c2f50-9292-4192-97b8-6b9f8e6e7376", "kubernetes.io/metadata.name":"namespaces-6922", "namespaces-6922":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  Mar 26 06:17:50.591: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6922" for this suite. @ 03/26/24 06:17:50.596
• [0.018 seconds]
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]
test/e2e/apimachinery/resource_quota.go:395
  STEP: Creating a kubernetes client @ 03/26/24 06:17:50.598
  Mar 26 06:17:50.598: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename resourcequota @ 03/26/24 06:17:50.599
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:17:50.604
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:17:50.605
  STEP: Counting existing ResourceQuota @ 03/26/24 06:17:50.606
  E0326 06:17:51.457733      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:52.458959      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:53.459294      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:54.459905      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:55.460014      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 03/26/24 06:17:55.608
  STEP: Ensuring resource quota status is calculated @ 03/26/24 06:17:55.61
  E0326 06:17:56.460260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:57.461389      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicationController @ 03/26/24 06:17:57.612
  STEP: Ensuring resource quota status captures replication controller creation @ 03/26/24 06:17:57.617
  E0326 06:17:58.461641      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:17:59.461811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicationController @ 03/26/24 06:17:59.619
  STEP: Ensuring resource quota status released usage @ 03/26/24 06:17:59.622
  E0326 06:18:00.462622      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:01.463462      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:18:01.624: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9837" for this suite. @ 03/26/24 06:18:01.626
• [11.030 seconds]
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:117
  STEP: Creating a kubernetes client @ 03/26/24 06:18:01.628
  Mar 26 06:18:01.628: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename emptydir @ 03/26/24 06:18:01.629
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:18:01.635
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:18:01.636
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 03/26/24 06:18:01.638
  E0326 06:18:02.464516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:03.464606      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:04.464714      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:05.465124      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:18:05.646
  Mar 26 06:18:05.648: INFO: Trying to get logs from node k8s-worker02 pod pod-54d27704-1792-4efe-b49b-ed8f0fb553ad container test-container: <nil>
  STEP: delete the pod @ 03/26/24 06:18:05.65
  Mar 26 06:18:05.663: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2391" for this suite. @ 03/26/24 06:18:05.664
• [4.038 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]
test/e2e/network/endpointslice.go:355
  STEP: Creating a kubernetes client @ 03/26/24 06:18:05.666
  Mar 26 06:18:05.666: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename endpointslice @ 03/26/24 06:18:05.667
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:18:05.673
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:18:05.674
  STEP: getting /apis @ 03/26/24 06:18:05.676
  STEP: getting /apis/discovery.k8s.io @ 03/26/24 06:18:05.677
  STEP: getting /apis/discovery.k8s.iov1 @ 03/26/24 06:18:05.678
  STEP: creating @ 03/26/24 06:18:05.679
  STEP: getting @ 03/26/24 06:18:05.684
  STEP: listing @ 03/26/24 06:18:05.685
  STEP: watching @ 03/26/24 06:18:05.687
  Mar 26 06:18:05.687: INFO: starting watch
  STEP: cluster-wide listing @ 03/26/24 06:18:05.687
  STEP: cluster-wide watching @ 03/26/24 06:18:05.689
  Mar 26 06:18:05.689: INFO: starting watch
  STEP: patching @ 03/26/24 06:18:05.689
  STEP: updating @ 03/26/24 06:18:05.691
  Mar 26 06:18:05.695: INFO: waiting for watch events with expected annotations
  Mar 26 06:18:05.695: INFO: saw patched and updated annotations
  STEP: deleting @ 03/26/24 06:18:05.695
  STEP: deleting a collection @ 03/26/24 06:18:05.698
  Mar 26 06:18:05.703: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-4474" for this suite. @ 03/26/24 06:18:05.705
• [0.041 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:47
  STEP: Creating a kubernetes client @ 03/26/24 06:18:05.708
  Mar 26 06:18:05.708: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename configmap @ 03/26/24 06:18:05.708
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:18:05.713
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:18:05.714
  STEP: Creating configMap with name configmap-test-volume-acd84c9f-164c-452a-ba2e-72bcf2d1488e @ 03/26/24 06:18:05.715
  STEP: Creating a pod to test consume configMaps @ 03/26/24 06:18:05.717
  E0326 06:18:06.465663      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:07.465778      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:08.466437      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:09.466537      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:18:09.726
  Mar 26 06:18:09.727: INFO: Trying to get logs from node k8s-worker02 pod pod-configmaps-82aeaf3c-f20d-4311-a661-de3801c2f058 container agnhost-container: <nil>
  STEP: delete the pod @ 03/26/24 06:18:09.729
  Mar 26 06:18:09.735: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9227" for this suite. @ 03/26/24 06:18:09.736
• [4.031 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]
test/e2e/apps/controller_revision.go:124
  STEP: Creating a kubernetes client @ 03/26/24 06:18:09.739
  Mar 26 06:18:09.739: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename controllerrevisions @ 03/26/24 06:18:09.739
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:18:09.745
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:18:09.747
  STEP: Creating DaemonSet "e2e-nx4rm-daemon-set" @ 03/26/24 06:18:09.755
  STEP: Check that daemon pods launch on every node of the cluster. @ 03/26/24 06:18:09.756
  Mar 26 06:18:09.759: INFO: Number of nodes with available pods controlled by daemonset e2e-nx4rm-daemon-set: 0
  Mar 26 06:18:09.759: INFO: Node k8s-master01 is running 0 daemon pod, expected 1
  E0326 06:18:10.466607      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:18:10.763: INFO: Number of nodes with available pods controlled by daemonset e2e-nx4rm-daemon-set: 0
  Mar 26 06:18:10.763: INFO: Node k8s-master01 is running 0 daemon pod, expected 1
  E0326 06:18:11.466694      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:18:11.764: INFO: Number of nodes with available pods controlled by daemonset e2e-nx4rm-daemon-set: 3
  Mar 26 06:18:11.764: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-nx4rm-daemon-set
  STEP: Confirm DaemonSet "e2e-nx4rm-daemon-set" successfully created with "daemonset-name=e2e-nx4rm-daemon-set" label @ 03/26/24 06:18:11.765
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-nx4rm-daemon-set" @ 03/26/24 06:18:11.767
  Mar 26 06:18:11.769: INFO: Located ControllerRevision: "e2e-nx4rm-daemon-set-6b44f66d65"
  STEP: Patching ControllerRevision "e2e-nx4rm-daemon-set-6b44f66d65" @ 03/26/24 06:18:11.77
  Mar 26 06:18:11.772: INFO: e2e-nx4rm-daemon-set-6b44f66d65 has been patched
  STEP: Create a new ControllerRevision @ 03/26/24 06:18:11.772
  Mar 26 06:18:11.775: INFO: Created ControllerRevision: e2e-nx4rm-daemon-set-7c49554b97
  STEP: Confirm that there are two ControllerRevisions @ 03/26/24 06:18:11.775
  Mar 26 06:18:11.775: INFO: Requesting list of ControllerRevisions to confirm quantity
  Mar 26 06:18:11.776: INFO: Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-nx4rm-daemon-set-6b44f66d65" @ 03/26/24 06:18:11.776
  STEP: Confirm that there is only one ControllerRevision @ 03/26/24 06:18:11.778
  Mar 26 06:18:11.778: INFO: Requesting list of ControllerRevisions to confirm quantity
  Mar 26 06:18:11.779: INFO: Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-nx4rm-daemon-set-7c49554b97" @ 03/26/24 06:18:11.779
  Mar 26 06:18:11.782: INFO: e2e-nx4rm-daemon-set-7c49554b97 has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 03/26/24 06:18:11.782
  W0326 06:18:11.785708      19 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 03/26/24 06:18:11.785
  Mar 26 06:18:11.786: INFO: Requesting list of ControllerRevisions to confirm quantity
  E0326 06:18:12.467604      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:18:12.787: INFO: Requesting list of ControllerRevisions to confirm quantity
  Mar 26 06:18:12.789: INFO: Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-nx4rm-daemon-set-7c49554b97=updated" @ 03/26/24 06:18:12.789
  STEP: Confirm that there is only one ControllerRevision @ 03/26/24 06:18:12.791
  Mar 26 06:18:12.791: INFO: Requesting list of ControllerRevisions to confirm quantity
  Mar 26 06:18:12.792: INFO: Found 1 ControllerRevisions
  Mar 26 06:18:12.793: INFO: ControllerRevision "e2e-nx4rm-daemon-set-c6ddb7c84" has revision 3
  STEP: Deleting DaemonSet "e2e-nx4rm-daemon-set" @ 03/26/24 06:18:12.794
  STEP: deleting DaemonSet.extensions e2e-nx4rm-daemon-set in namespace controllerrevisions-8465, will wait for the garbage collector to delete the pods @ 03/26/24 06:18:12.794
  Mar 26 06:18:12.848: INFO: Deleting DaemonSet.extensions e2e-nx4rm-daemon-set took: 2.099199ms
  Mar 26 06:18:12.949: INFO: Terminating DaemonSet.extensions e2e-nx4rm-daemon-set pods took: 101.078929ms
  E0326 06:18:13.468431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:18:14.051: INFO: Number of nodes with available pods controlled by daemonset e2e-nx4rm-daemon-set: 0
  Mar 26 06:18:14.051: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-nx4rm-daemon-set
  Mar 26 06:18:14.052: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"84064"},"items":null}

  Mar 26 06:18:14.053: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"84064"},"items":null}

  Mar 26 06:18:14.057: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-8465" for this suite. @ 03/26/24 06:18:14.059
• [4.323 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]
test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 03/26/24 06:18:14.064
  Mar 26 06:18:14.064: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename disruption @ 03/26/24 06:18:14.064
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:18:14.069
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:18:14.07
  STEP: Waiting for the pdb to be processed @ 03/26/24 06:18:14.073
  E0326 06:18:14.468983      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:15.469251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 03/26/24 06:18:16.077
  STEP: Waiting for all pods to be running @ 03/26/24 06:18:16.081
  Mar 26 06:18:16.084: INFO: running pods: 0 < 1
  E0326 06:18:16.470000      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:17.470178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 03/26/24 06:18:18.086
  STEP: Waiting for the pdb to be processed @ 03/26/24 06:18:18.09
  STEP: Patching PodDisruptionBudget status @ 03/26/24 06:18:18.093
  STEP: Waiting for the pdb to be processed @ 03/26/24 06:18:18.097
  Mar 26 06:18:18.098: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-7886" for this suite. @ 03/26/24 06:18:18.1
• [4.038 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]
test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 03/26/24 06:18:18.102
  Mar 26 06:18:18.102: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename subpath @ 03/26/24 06:18:18.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:18:18.11
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:18:18.111
  STEP: Setting up data @ 03/26/24 06:18:18.113
  STEP: Creating pod pod-subpath-test-downwardapi-ss4q @ 03/26/24 06:18:18.116
  STEP: Creating a pod to test atomic-volume-subpath @ 03/26/24 06:18:18.116
  E0326 06:18:18.470365      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:19.470558      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:20.471248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:21.471411      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:22.471411      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:23.472184      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:24.472232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:25.472561      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:26.472856      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:27.473043      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:28.474017      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:29.474725      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:30.475300      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:31.475370      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:32.475471      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:33.475610      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:34.476206      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:35.476261      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:36.477340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:37.477403      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:38.477996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:39.478083      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:18:40.144
  Mar 26 06:18:40.145: INFO: Trying to get logs from node k8s-worker02 pod pod-subpath-test-downwardapi-ss4q container test-container-subpath-downwardapi-ss4q: <nil>
  STEP: delete the pod @ 03/26/24 06:18:40.149
  STEP: Deleting pod pod-subpath-test-downwardapi-ss4q @ 03/26/24 06:18:40.153
  Mar 26 06:18:40.153: INFO: Deleting pod "pod-subpath-test-downwardapi-ss4q" in namespace "subpath-4010"
  Mar 26 06:18:40.154: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-4010" for this suite. @ 03/26/24 06:18:40.155
• [22.055 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]
test/e2e/apimachinery/garbage_collector.go:379
  STEP: Creating a kubernetes client @ 03/26/24 06:18:40.157
  Mar 26 06:18:40.158: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename gc @ 03/26/24 06:18:40.158
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:18:40.163
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:18:40.165
  STEP: create the rc @ 03/26/24 06:18:40.167
  W0326 06:18:40.170041      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0326 06:18:40.478553      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:41.480106      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:42.480289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:43.480356      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 03/26/24 06:18:44.181
  STEP: wait for the rc to be deleted @ 03/26/24 06:18:44.196
  E0326 06:18:44.481447      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:45.482097      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:46.482174      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:47.482331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:48.482438      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 03/26/24 06:18:49.198
  E0326 06:18:49.483265      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:50.483401      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:51.484023      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:52.484135      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:53.484269      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:54.484377      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:55.484452      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:56.484561      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:57.484693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:58.485427      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:18:59.485464      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:00.485538      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:01.485741      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:02.485791      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:03.486115      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:04.486204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:05.486304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:06.486423      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:07.486552      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:08.487957      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:09.487956      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:10.488059      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:11.488142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:12.488274      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:13.488385      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:14.489040      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:15.489966      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:16.490104      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:17.490237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:18.491337      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 03/26/24 06:19:19.206
  Mar 26 06:19:19.256: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Mar 26 06:19:19.256: INFO: Deleting pod "simpletest.rc-279tn" in namespace "gc-1940"
  Mar 26 06:19:19.267: INFO: Deleting pod "simpletest.rc-2d8jl" in namespace "gc-1940"
  Mar 26 06:19:19.276: INFO: Deleting pod "simpletest.rc-2g2ds" in namespace "gc-1940"
  Mar 26 06:19:19.285: INFO: Deleting pod "simpletest.rc-2jm2b" in namespace "gc-1940"
  Mar 26 06:19:19.290: INFO: Deleting pod "simpletest.rc-2z5m6" in namespace "gc-1940"
  Mar 26 06:19:19.303: INFO: Deleting pod "simpletest.rc-4cf5s" in namespace "gc-1940"
  Mar 26 06:19:19.311: INFO: Deleting pod "simpletest.rc-4f5vw" in namespace "gc-1940"
  Mar 26 06:19:19.325: INFO: Deleting pod "simpletest.rc-4k4zq" in namespace "gc-1940"
  Mar 26 06:19:19.338: INFO: Deleting pod "simpletest.rc-4rtzm" in namespace "gc-1940"
  Mar 26 06:19:19.353: INFO: Deleting pod "simpletest.rc-4zs5p" in namespace "gc-1940"
  Mar 26 06:19:19.369: INFO: Deleting pod "simpletest.rc-5b7h4" in namespace "gc-1940"
  Mar 26 06:19:19.400: INFO: Deleting pod "simpletest.rc-5bmsb" in namespace "gc-1940"
  Mar 26 06:19:19.414: INFO: Deleting pod "simpletest.rc-5j8vh" in namespace "gc-1940"
  Mar 26 06:19:19.427: INFO: Deleting pod "simpletest.rc-5zwzj" in namespace "gc-1940"
  Mar 26 06:19:19.438: INFO: Deleting pod "simpletest.rc-6br9g" in namespace "gc-1940"
  Mar 26 06:19:19.454: INFO: Deleting pod "simpletest.rc-6bspp" in namespace "gc-1940"
  Mar 26 06:19:19.470: INFO: Deleting pod "simpletest.rc-6l4jw" in namespace "gc-1940"
  E0326 06:19:19.492224      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:19:19.517: INFO: Deleting pod "simpletest.rc-6vgnq" in namespace "gc-1940"
  Mar 26 06:19:19.541: INFO: Deleting pod "simpletest.rc-769qn" in namespace "gc-1940"
  Mar 26 06:19:19.560: INFO: Deleting pod "simpletest.rc-7f9cm" in namespace "gc-1940"
  Mar 26 06:19:19.585: INFO: Deleting pod "simpletest.rc-7gchn" in namespace "gc-1940"
  Mar 26 06:19:19.600: INFO: Deleting pod "simpletest.rc-7kk27" in namespace "gc-1940"
  Mar 26 06:19:19.641: INFO: Deleting pod "simpletest.rc-7tgbr" in namespace "gc-1940"
  Mar 26 06:19:19.684: INFO: Deleting pod "simpletest.rc-7w9b7" in namespace "gc-1940"
  Mar 26 06:19:19.716: INFO: Deleting pod "simpletest.rc-86gmx" in namespace "gc-1940"
  Mar 26 06:19:19.740: INFO: Deleting pod "simpletest.rc-8flfv" in namespace "gc-1940"
  Mar 26 06:19:19.768: INFO: Deleting pod "simpletest.rc-8ft6p" in namespace "gc-1940"
  Mar 26 06:19:19.793: INFO: Deleting pod "simpletest.rc-8r267" in namespace "gc-1940"
  Mar 26 06:19:19.808: INFO: Deleting pod "simpletest.rc-8vcwt" in namespace "gc-1940"
  Mar 26 06:19:19.838: INFO: Deleting pod "simpletest.rc-99z2x" in namespace "gc-1940"
  Mar 26 06:19:19.884: INFO: Deleting pod "simpletest.rc-9ckkp" in namespace "gc-1940"
  Mar 26 06:19:19.917: INFO: Deleting pod "simpletest.rc-9dfcm" in namespace "gc-1940"
  Mar 26 06:19:19.957: INFO: Deleting pod "simpletest.rc-9g69w" in namespace "gc-1940"
  Mar 26 06:19:19.993: INFO: Deleting pod "simpletest.rc-9htbv" in namespace "gc-1940"
  Mar 26 06:19:20.025: INFO: Deleting pod "simpletest.rc-9w764" in namespace "gc-1940"
  Mar 26 06:19:20.088: INFO: Deleting pod "simpletest.rc-bs4mf" in namespace "gc-1940"
  Mar 26 06:19:20.144: INFO: Deleting pod "simpletest.rc-bxp8j" in namespace "gc-1940"
  Mar 26 06:19:20.173: INFO: Deleting pod "simpletest.rc-c4j8k" in namespace "gc-1940"
  Mar 26 06:19:20.213: INFO: Deleting pod "simpletest.rc-c7fnv" in namespace "gc-1940"
  Mar 26 06:19:20.239: INFO: Deleting pod "simpletest.rc-cbdc7" in namespace "gc-1940"
  Mar 26 06:19:20.248: INFO: Deleting pod "simpletest.rc-csltj" in namespace "gc-1940"
  Mar 26 06:19:20.275: INFO: Deleting pod "simpletest.rc-cv9dv" in namespace "gc-1940"
  Mar 26 06:19:20.304: INFO: Deleting pod "simpletest.rc-d4ptv" in namespace "gc-1940"
  Mar 26 06:19:20.319: INFO: Deleting pod "simpletest.rc-dqfxh" in namespace "gc-1940"
  Mar 26 06:19:20.333: INFO: Deleting pod "simpletest.rc-f4tp2" in namespace "gc-1940"
  Mar 26 06:19:20.343: INFO: Deleting pod "simpletest.rc-ffbwd" in namespace "gc-1940"
  Mar 26 06:19:20.369: INFO: Deleting pod "simpletest.rc-fx54n" in namespace "gc-1940"
  Mar 26 06:19:20.384: INFO: Deleting pod "simpletest.rc-g2k96" in namespace "gc-1940"
  Mar 26 06:19:20.400: INFO: Deleting pod "simpletest.rc-h2d9m" in namespace "gc-1940"
  Mar 26 06:19:20.417: INFO: Deleting pod "simpletest.rc-h7c92" in namespace "gc-1940"
  Mar 26 06:19:20.457: INFO: Deleting pod "simpletest.rc-j5zxn" in namespace "gc-1940"
  Mar 26 06:19:20.479: INFO: Deleting pod "simpletest.rc-j7p52" in namespace "gc-1940"
  E0326 06:19:20.492446      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:19:20.505: INFO: Deleting pod "simpletest.rc-jmn29" in namespace "gc-1940"
  Mar 26 06:19:20.529: INFO: Deleting pod "simpletest.rc-jp7cx" in namespace "gc-1940"
  Mar 26 06:19:20.548: INFO: Deleting pod "simpletest.rc-jxf5h" in namespace "gc-1940"
  Mar 26 06:19:20.573: INFO: Deleting pod "simpletest.rc-k6lkn" in namespace "gc-1940"
  Mar 26 06:19:20.618: INFO: Deleting pod "simpletest.rc-k95sv" in namespace "gc-1940"
  Mar 26 06:19:20.642: INFO: Deleting pod "simpletest.rc-kh6zf" in namespace "gc-1940"
  Mar 26 06:19:20.662: INFO: Deleting pod "simpletest.rc-kjhmw" in namespace "gc-1940"
  Mar 26 06:19:20.685: INFO: Deleting pod "simpletest.rc-l8kmq" in namespace "gc-1940"
  Mar 26 06:19:20.722: INFO: Deleting pod "simpletest.rc-lmkt9" in namespace "gc-1940"
  Mar 26 06:19:20.759: INFO: Deleting pod "simpletest.rc-m5j6s" in namespace "gc-1940"
  Mar 26 06:19:20.784: INFO: Deleting pod "simpletest.rc-mhkn9" in namespace "gc-1940"
  Mar 26 06:19:20.818: INFO: Deleting pod "simpletest.rc-mqp6k" in namespace "gc-1940"
  Mar 26 06:19:20.845: INFO: Deleting pod "simpletest.rc-mrths" in namespace "gc-1940"
  Mar 26 06:19:20.874: INFO: Deleting pod "simpletest.rc-msxwd" in namespace "gc-1940"
  Mar 26 06:19:20.897: INFO: Deleting pod "simpletest.rc-mtxgs" in namespace "gc-1940"
  Mar 26 06:19:20.926: INFO: Deleting pod "simpletest.rc-nf64x" in namespace "gc-1940"
  Mar 26 06:19:20.949: INFO: Deleting pod "simpletest.rc-ngl58" in namespace "gc-1940"
  Mar 26 06:19:20.973: INFO: Deleting pod "simpletest.rc-nvhw6" in namespace "gc-1940"
  Mar 26 06:19:20.999: INFO: Deleting pod "simpletest.rc-p488n" in namespace "gc-1940"
  Mar 26 06:19:21.010: INFO: Deleting pod "simpletest.rc-pmjf5" in namespace "gc-1940"
  Mar 26 06:19:21.032: INFO: Deleting pod "simpletest.rc-pnzb4" in namespace "gc-1940"
  Mar 26 06:19:21.053: INFO: Deleting pod "simpletest.rc-pp7ng" in namespace "gc-1940"
  Mar 26 06:19:21.115: INFO: Deleting pod "simpletest.rc-qq7ms" in namespace "gc-1940"
  Mar 26 06:19:21.139: INFO: Deleting pod "simpletest.rc-qrz44" in namespace "gc-1940"
  Mar 26 06:19:21.192: INFO: Deleting pod "simpletest.rc-qtr4s" in namespace "gc-1940"
  Mar 26 06:19:21.208: INFO: Deleting pod "simpletest.rc-qxmrn" in namespace "gc-1940"
  Mar 26 06:19:21.229: INFO: Deleting pod "simpletest.rc-r4pj8" in namespace "gc-1940"
  Mar 26 06:19:21.270: INFO: Deleting pod "simpletest.rc-r5bkl" in namespace "gc-1940"
  Mar 26 06:19:21.282: INFO: Deleting pod "simpletest.rc-rqj7f" in namespace "gc-1940"
  Mar 26 06:19:21.297: INFO: Deleting pod "simpletest.rc-rwp2m" in namespace "gc-1940"
  Mar 26 06:19:21.328: INFO: Deleting pod "simpletest.rc-rwz44" in namespace "gc-1940"
  Mar 26 06:19:21.346: INFO: Deleting pod "simpletest.rc-s22l5" in namespace "gc-1940"
  Mar 26 06:19:21.367: INFO: Deleting pod "simpletest.rc-sqbbs" in namespace "gc-1940"
  Mar 26 06:19:21.402: INFO: Deleting pod "simpletest.rc-srx55" in namespace "gc-1940"
  Mar 26 06:19:21.441: INFO: Deleting pod "simpletest.rc-svdvv" in namespace "gc-1940"
  Mar 26 06:19:21.457: INFO: Deleting pod "simpletest.rc-t2hbf" in namespace "gc-1940"
  Mar 26 06:19:21.483: INFO: Deleting pod "simpletest.rc-tfbdp" in namespace "gc-1940"
  Mar 26 06:19:21.499: INFO: Deleting pod "simpletest.rc-tfw25" in namespace "gc-1940"
  E0326 06:19:21.500465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:19:21.530: INFO: Deleting pod "simpletest.rc-v2g5d" in namespace "gc-1940"
  Mar 26 06:19:21.565: INFO: Deleting pod "simpletest.rc-vn4cm" in namespace "gc-1940"
  Mar 26 06:19:21.612: INFO: Deleting pod "simpletest.rc-w8rl4" in namespace "gc-1940"
  Mar 26 06:19:21.626: INFO: Deleting pod "simpletest.rc-wbstp" in namespace "gc-1940"
  Mar 26 06:19:21.644: INFO: Deleting pod "simpletest.rc-wnfhh" in namespace "gc-1940"
  Mar 26 06:19:21.668: INFO: Deleting pod "simpletest.rc-ws7cj" in namespace "gc-1940"
  Mar 26 06:19:21.718: INFO: Deleting pod "simpletest.rc-wsswh" in namespace "gc-1940"
  Mar 26 06:19:21.767: INFO: Deleting pod "simpletest.rc-x4ft8" in namespace "gc-1940"
  Mar 26 06:19:21.817: INFO: Deleting pod "simpletest.rc-xvlst" in namespace "gc-1940"
  Mar 26 06:19:21.868: INFO: Deleting pod "simpletest.rc-z4l7j" in namespace "gc-1940"
  Mar 26 06:19:21.939: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1940" for this suite. @ 03/26/24 06:19:21.958
• [41.855 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 03/26/24 06:19:22.015
  Mar 26 06:19:22.015: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename pods @ 03/26/24 06:19:22.016
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:19:22.031
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:19:22.036
  E0326 06:19:22.494362      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:23.495033      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:24.495877      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:25.496638      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:26.496730      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:27.497797      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:19:28.068
  Mar 26 06:19:28.069: INFO: Trying to get logs from node k8s-worker02 pod client-envvars-18b7ecbd-2cba-4813-b7ea-7619a377bb2c container env3cont: <nil>
  STEP: delete the pod @ 03/26/24 06:19:28.072
  Mar 26 06:19:28.077: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5301" for this suite. @ 03/26/24 06:19:28.079
• [6.073 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs  [Conformance]
test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 03/26/24 06:19:28.091
  Mar 26 06:19:28.091: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubectl-logs @ 03/26/24 06:19:28.091
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:19:28.097
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:19:28.098
  STEP: creating an pod @ 03/26/24 06:19:28.1
  Mar 26 06:19:28.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-logs-6016 run logs-generator --image=hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  Mar 26 06:19:28.142: INFO: stderr: ""
  Mar 26 06:19:28.142: INFO: stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 03/26/24 06:19:28.142
  Mar 26 06:19:28.142: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E0326 06:19:28.498401      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:29.498889      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:19:30.147: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 03/26/24 06:19:30.147
  Mar 26 06:19:30.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-logs-6016 logs logs-generator logs-generator'
  Mar 26 06:19:30.192: INFO: stderr: ""
  Mar 26 06:19:30.192: INFO: stdout: "I0326 06:19:28.619844       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/x5hx 546\nI0326 06:19:28.819918       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/6zq 528\nI0326 06:19:29.020451       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/wjjr 230\nI0326 06:19:29.220752       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/k4q 294\nI0326 06:19:29.419936       1 logs_generator.go:76] 4 POST /api/v1/namespaces/default/pods/vrf 477\nI0326 06:19:29.620239       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/88xp 405\nI0326 06:19:29.820536       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/9vs4 539\nI0326 06:19:30.020838       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/nw8t 434\n"
  STEP: limiting log lines @ 03/26/24 06:19:30.192
  Mar 26 06:19:30.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-logs-6016 logs logs-generator logs-generator --tail=1'
  Mar 26 06:19:30.235: INFO: stderr: ""
  Mar 26 06:19:30.235: INFO: stdout: "I0326 06:19:30.220114       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/2gdn 497\n"
  Mar 26 06:19:30.235: INFO: got output "I0326 06:19:30.220114       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/2gdn 497\n"
  STEP: limiting log bytes @ 03/26/24 06:19:30.235
  Mar 26 06:19:30.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-logs-6016 logs logs-generator logs-generator --limit-bytes=1'
  Mar 26 06:19:30.277: INFO: stderr: ""
  Mar 26 06:19:30.277: INFO: stdout: "I"
  Mar 26 06:19:30.277: INFO: got output "I"
  STEP: exposing timestamps @ 03/26/24 06:19:30.277
  Mar 26 06:19:30.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-logs-6016 logs logs-generator logs-generator --tail=1 --timestamps'
  Mar 26 06:19:30.320: INFO: stderr: ""
  Mar 26 06:19:30.320: INFO: stdout: "2024-03-26T06:19:30.220149112Z I0326 06:19:30.220114       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/2gdn 497\n"
  Mar 26 06:19:30.320: INFO: got output "2024-03-26T06:19:30.220149112Z I0326 06:19:30.220114       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/2gdn 497\n"
  STEP: restricting to a time range @ 03/26/24 06:19:30.32
  E0326 06:19:30.499662      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:31.500586      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:32.500818      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:19:32.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-logs-6016 logs logs-generator logs-generator --since=1s'
  Mar 26 06:19:32.870: INFO: stderr: ""
  Mar 26 06:19:32.870: INFO: stdout: "I0326 06:19:32.020783       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/r2x 233\nI0326 06:19:32.220028       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/jtc 287\nI0326 06:19:32.420343       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/7pl 285\nI0326 06:19:32.620642       1 logs_generator.go:76] 20 POST /api/v1/namespaces/default/pods/lrk4 496\nI0326 06:19:32.819888       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/d56q 477\n"
  Mar 26 06:19:32.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-logs-6016 logs logs-generator logs-generator --since=24h'
  Mar 26 06:19:32.915: INFO: stderr: ""
  Mar 26 06:19:32.915: INFO: stdout: "I0326 06:19:28.619844       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/x5hx 546\nI0326 06:19:28.819918       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/6zq 528\nI0326 06:19:29.020451       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/wjjr 230\nI0326 06:19:29.220752       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/k4q 294\nI0326 06:19:29.419936       1 logs_generator.go:76] 4 POST /api/v1/namespaces/default/pods/vrf 477\nI0326 06:19:29.620239       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/88xp 405\nI0326 06:19:29.820536       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/9vs4 539\nI0326 06:19:30.020838       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/nw8t 434\nI0326 06:19:30.220114       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/2gdn 497\nI0326 06:19:30.420420       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/lkf 459\nI0326 06:19:30.620729       1 logs_generator.go:76] 10 POST /api/v1/namespaces/kube-system/pods/9md 237\nI0326 06:19:30.819965       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/kube-system/pods/lrcf 395\nI0326 06:19:31.020263       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/86q 340\nI0326 06:19:31.220558       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/lk6 505\nI0326 06:19:31.420870       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/sjgg 554\nI0326 06:19:31.620204       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/w2n 449\nI0326 06:19:31.820487       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/pzb 414\nI0326 06:19:32.020783       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/r2x 233\nI0326 06:19:32.220028       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/jtc 287\nI0326 06:19:32.420343       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/7pl 285\nI0326 06:19:32.620642       1 logs_generator.go:76] 20 POST /api/v1/namespaces/default/pods/lrk4 496\nI0326 06:19:32.819888       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/d56q 477\n"
  Mar 26 06:19:32.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-logs-6016 delete pod logs-generator'
  E0326 06:19:33.501616      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:19:33.545: INFO: stderr: ""
  Mar 26 06:19:33.545: INFO: stdout: "pod \"logs-generator\" deleted\n"
  Mar 26 06:19:33.545: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-6016" for this suite. @ 03/26/24 06:19:33.547
• [5.458 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance]
test/e2e/apps/rc.go:424
  STEP: Creating a kubernetes client @ 03/26/24 06:19:33.549
  Mar 26 06:19:33.549: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename replication-controller @ 03/26/24 06:19:33.55
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:19:33.555
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:19:33.557
  STEP: Creating ReplicationController "e2e-rc-xgv4f" @ 03/26/24 06:19:33.559
  Mar 26 06:19:33.561: INFO: Get Replication Controller "e2e-rc-xgv4f" to confirm replicas
  E0326 06:19:34.502599      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:19:34.562: INFO: Get Replication Controller "e2e-rc-xgv4f" to confirm replicas
  Mar 26 06:19:34.564: INFO: Found 1 replicas for "e2e-rc-xgv4f" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-xgv4f" @ 03/26/24 06:19:34.564
  STEP: Updating a scale subresource @ 03/26/24 06:19:34.565
  STEP: Verifying replicas where modified for replication controller "e2e-rc-xgv4f" @ 03/26/24 06:19:34.568
  Mar 26 06:19:34.568: INFO: Get Replication Controller "e2e-rc-xgv4f" to confirm replicas
  E0326 06:19:35.503408      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:19:35.570: INFO: Get Replication Controller "e2e-rc-xgv4f" to confirm replicas
  Mar 26 06:19:35.571: INFO: Found 2 replicas for "e2e-rc-xgv4f" replication controller
  Mar 26 06:19:35.572: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-4264" for this suite. @ 03/26/24 06:19:35.573
• [2.026 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]
test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 03/26/24 06:19:35.576
  Mar 26 06:19:35.576: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename daemonsets @ 03/26/24 06:19:35.577
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:19:35.582
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:19:35.583
  Mar 26 06:19:35.593: INFO: Create a RollingUpdate DaemonSet
  Mar 26 06:19:35.595: INFO: Check that daemon pods launch on every node of the cluster
  Mar 26 06:19:35.605: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Mar 26 06:19:35.605: INFO: Node k8s-master01 is running 0 daemon pod, expected 1
  E0326 06:19:36.503500      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:19:36.608: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Mar 26 06:19:36.608: INFO: Node k8s-worker02 is running 0 daemon pod, expected 1
  E0326 06:19:37.503772      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:19:37.608: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Mar 26 06:19:37.608: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  Mar 26 06:19:37.608: INFO: Update the DaemonSet to trigger a rollout
  Mar 26 06:19:37.612: INFO: Updating DaemonSet daemon-set
  E0326 06:19:38.503854      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:19:38.618: INFO: Roll back the DaemonSet before rollout is complete
  Mar 26 06:19:38.622: INFO: Updating DaemonSet daemon-set
  Mar 26 06:19:38.622: INFO: Make sure DaemonSet rollback is complete
  Mar 26 06:19:38.623: INFO: Wrong image for pod: daemon-set-nprln. Expected: hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4, got: foo:non-existent.
  Mar 26 06:19:38.623: INFO: Pod daemon-set-nprln is not available
  E0326 06:19:39.504680      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:40.505745      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:19:40.628: INFO: Pod daemon-set-zwpjg is not available
  STEP: Deleting DaemonSet "daemon-set" @ 03/26/24 06:19:40.636
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9464, will wait for the garbage collector to delete the pods @ 03/26/24 06:19:40.636
  Mar 26 06:19:40.692: INFO: Deleting DaemonSet.extensions daemon-set took: 2.295802ms
  Mar 26 06:19:40.793: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.705649ms
  E0326 06:19:41.505970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:19:42.295: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Mar 26 06:19:42.295: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Mar 26 06:19:42.296: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"86953"},"items":null}

  Mar 26 06:19:42.297: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"86953"},"items":null}

  Mar 26 06:19:42.302: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-9464" for this suite. @ 03/26/24 06:19:42.304
• [6.730 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 03/26/24 06:19:42.307
  Mar 26 06:19:42.307: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename field-validation @ 03/26/24 06:19:42.308
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:19:42.313
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:19:42.314
  Mar 26 06:19:42.316: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  E0326 06:19:42.507011      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:43.507102      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:44.507204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0326 06:19:44.840544      19 warnings.go:70] unknown field "alpha"
  W0326 06:19:44.840561      19 warnings.go:70] unknown field "beta"
  W0326 06:19:44.840563      19 warnings.go:70] unknown field "delta"
  W0326 06:19:44.840566      19 warnings.go:70] unknown field "epsilon"
  W0326 06:19:44.840568      19 warnings.go:70] unknown field "gamma"
  Mar 26 06:19:45.354: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-532" for this suite. @ 03/26/24 06:19:45.359
• [3.054 seconds]
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:309
  STEP: Creating a kubernetes client @ 03/26/24 06:19:45.361
  Mar 26 06:19:45.361: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename crd-publish-openapi @ 03/26/24 06:19:45.362
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:19:45.367
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:19:45.369
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 03/26/24 06:19:45.37
  Mar 26 06:19:45.371: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  E0326 06:19:45.507549      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:46.508270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:47.509194      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:48.509601      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:49.510617      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 03/26/24 06:19:50.359
  Mar 26 06:19:50.360: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  E0326 06:19:50.510703      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:51.511665      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:19:51.587: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  E0326 06:19:52.511705      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:53.511733      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:54.512724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:55.512926      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:19:56.488: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5351" for this suite. @ 03/26/24 06:19:56.493
• [11.134 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]
test/e2e/kubectl/kubectl.go:1316
  STEP: Creating a kubernetes client @ 03/26/24 06:19:56.496
  Mar 26 06:19:56.496: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubectl @ 03/26/24 06:19:56.497
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:19:56.503
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:19:56.506
  STEP: validating cluster-info @ 03/26/24 06:19:56.507
  Mar 26 06:19:56.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-5801 cluster-info'
  E0326 06:19:56.513887      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:19:56.546: INFO: stderr: ""
  Mar 26 06:19:56.546: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  Mar 26 06:19:56.546: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5801" for this suite. @ 03/26/24 06:19:56.548
• [0.054 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:236
  STEP: Creating a kubernetes client @ 03/26/24 06:19:56.55
  Mar 26 06:19:56.550: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 06:19:56.551
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:19:56.556
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:19:56.558
  STEP: Creating a pod to test downward API volume plugin @ 03/26/24 06:19:56.559
  E0326 06:19:57.514256      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:19:58.515256      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:19:58.565
  Mar 26 06:19:58.566: INFO: Trying to get logs from node k8s-worker02 pod downwardapi-volume-d253236b-8064-493d-8c42-b37d239aa433 container client-container: <nil>
  STEP: delete the pod @ 03/26/24 06:19:58.569
  Mar 26 06:19:58.574: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4941" for this suite. @ 03/26/24 06:19:58.575
• [2.027 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:198
  STEP: Creating a kubernetes client @ 03/26/24 06:19:58.577
  Mar 26 06:19:58.577: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename custom-resource-definition @ 03/26/24 06:19:58.578
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:19:58.584
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:19:58.585
  STEP: fetching the /apis discovery document @ 03/26/24 06:19:58.587
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 03/26/24 06:19:58.588
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 03/26/24 06:19:58.588
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 03/26/24 06:19:58.588
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 03/26/24 06:19:58.589
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 03/26/24 06:19:58.589
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 03/26/24 06:19:58.589
  Mar 26 06:19:58.589: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-2606" for this suite. @ 03/26/24 06:19:58.591
• [0.016 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]
test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 03/26/24 06:19:58.594
  Mar 26 06:19:58.594: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename endpointslicemirroring @ 03/26/24 06:19:58.595
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:19:58.6
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:19:58.601
  STEP: mirroring a new custom Endpoint @ 03/26/24 06:19:58.61
  Mar 26 06:19:58.614: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
  E0326 06:19:59.515895      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:00.516328      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 03/26/24 06:20:00.616
  Mar 26 06:20:00.619: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  E0326 06:20:01.516458      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:02.516556      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring deletion of a custom Endpoint @ 03/26/24 06:20:02.622
  Mar 26 06:20:02.626: INFO: Waiting for 0 EndpointSlices to exist, got 1
  E0326 06:20:03.516645      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:04.517508      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:20:04.628: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-3694" for this suite. @ 03/26/24 06:20:04.629
• [6.037 seconds]
------------------------------
S
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:268
  STEP: Creating a kubernetes client @ 03/26/24 06:20:04.632
  Mar 26 06:20:04.632: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename downward-api @ 03/26/24 06:20:04.632
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:20:04.639
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:20:04.641
  STEP: Creating a pod to test downward api env vars @ 03/26/24 06:20:04.642
  E0326 06:20:05.517610      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:06.517715      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:07.518922      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:08.519044      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:20:08.651
  Mar 26 06:20:08.653: INFO: Trying to get logs from node k8s-worker02 pod downward-api-8ea41b55-97e1-4283-ab13-dc585a4d4079 container dapi-container: <nil>
  STEP: delete the pod @ 03/26/24 06:20:08.656
  Mar 26 06:20:08.665: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2711" for this suite. @ 03/26/24 06:20:08.667
• [4.037 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]
test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 03/26/24 06:20:08.669
  Mar 26 06:20:08.669: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename subpath @ 03/26/24 06:20:08.67
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:20:08.675
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:20:08.677
  STEP: Setting up data @ 03/26/24 06:20:08.678
  STEP: Creating pod pod-subpath-test-configmap-qsdf @ 03/26/24 06:20:08.681
  STEP: Creating a pod to test atomic-volume-subpath @ 03/26/24 06:20:08.681
  E0326 06:20:09.519830      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:10.520209      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:11.521125      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:12.521272      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:13.521313      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:14.522050      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:15.523022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:16.523157      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:17.523254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:18.523353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:19.523389      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:20.523469      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:21.523925      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:22.524009      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:23.524108      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:24.524540      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:25.525552      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:26.525680      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:27.525784      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:28.525881      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:29.526010      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:30.526314      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:31.526470      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:32.526641      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:20:32.712
  Mar 26 06:20:32.714: INFO: Trying to get logs from node k8s-worker02 pod pod-subpath-test-configmap-qsdf container test-container-subpath-configmap-qsdf: <nil>
  STEP: delete the pod @ 03/26/24 06:20:32.717
  STEP: Deleting pod pod-subpath-test-configmap-qsdf @ 03/26/24 06:20:32.722
  Mar 26 06:20:32.722: INFO: Deleting pod "pod-subpath-test-configmap-qsdf" in namespace "subpath-7402"
  Mar 26 06:20:32.723: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-7402" for this suite. @ 03/26/24 06:20:32.725
• [24.058 seconds]
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:222
  STEP: Creating a kubernetes client @ 03/26/24 06:20:32.727
  Mar 26 06:20:32.727: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 06:20:32.728
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:20:32.734
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:20:32.736
  STEP: Creating a pod to test downward API volume plugin @ 03/26/24 06:20:32.737
  E0326 06:20:33.527080      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:34.527705      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:35.527770      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:36.527922      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:20:36.746
  Mar 26 06:20:36.748: INFO: Trying to get logs from node k8s-worker02 pod downwardapi-volume-3e8ed497-cc48-47a9-b475-3bebc93d28fb container client-container: <nil>
  STEP: delete the pod @ 03/26/24 06:20:36.75
  Mar 26 06:20:36.755: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2361" for this suite. @ 03/26/24 06:20:36.757
• [4.032 seconds]
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:54
  STEP: Creating a kubernetes client @ 03/26/24 06:20:36.759
  Mar 26 06:20:36.759: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename downward-api @ 03/26/24 06:20:36.76
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:20:36.765
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:20:36.767
  STEP: Creating a pod to test downward API volume plugin @ 03/26/24 06:20:36.768
  E0326 06:20:37.528596      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:38.528750      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:39.529377      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:40.529448      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:20:40.777
  Mar 26 06:20:40.781: INFO: Trying to get logs from node k8s-worker02 pod downwardapi-volume-68012b7b-1089-4731-abea-0915396a0354 container client-container: <nil>
  STEP: delete the pod @ 03/26/24 06:20:40.784
  Mar 26 06:20:40.789: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3090" for this suite. @ 03/26/24 06:20:40.793
• [4.043 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]
test/e2e/common/node/configmap.go:93
  STEP: Creating a kubernetes client @ 03/26/24 06:20:40.802
  Mar 26 06:20:40.802: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename configmap @ 03/26/24 06:20:40.803
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:20:40.835
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:20:40.837
  STEP: Creating configMap configmap-4374/configmap-test-e2653972-b58c-4e10-96cc-b0fc1416b61c @ 03/26/24 06:20:40.838
  STEP: Creating a pod to test consume configMaps @ 03/26/24 06:20:40.841
  E0326 06:20:41.529554      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:42.530009      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:43.530164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:44.530209      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:20:44.851
  Mar 26 06:20:44.852: INFO: Trying to get logs from node k8s-worker02 pod pod-configmaps-a9486d25-b3cf-4ffb-ad86-a77294abd01c container env-test: <nil>
  STEP: delete the pod @ 03/26/24 06:20:44.855
  Mar 26 06:20:44.859: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4374" for this suite. @ 03/26/24 06:20:44.861
• [4.061 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]
test/e2e/kubectl/kubectl.go:396
  STEP: Creating a kubernetes client @ 03/26/24 06:20:44.865
  Mar 26 06:20:44.865: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubectl @ 03/26/24 06:20:44.866
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:20:44.871
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:20:44.874
  STEP: creating all guestbook components @ 03/26/24 06:20:44.875
  Mar 26 06:20:44.875: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  Mar 26 06:20:44.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-1916 create -f -'
  Mar 26 06:20:45.016: INFO: stderr: ""
  Mar 26 06:20:45.016: INFO: stdout: "service/agnhost-replica created\n"
  Mar 26 06:20:45.016: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  Mar 26 06:20:45.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-1916 create -f -'
  Mar 26 06:20:45.158: INFO: stderr: ""
  Mar 26 06:20:45.158: INFO: stdout: "service/agnhost-primary created\n"
  Mar 26 06:20:45.158: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  Mar 26 06:20:45.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-1916 create -f -'
  Mar 26 06:20:45.298: INFO: stderr: ""
  Mar 26 06:20:45.298: INFO: stdout: "service/frontend created\n"
  Mar 26 06:20:45.298: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  Mar 26 06:20:45.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-1916 create -f -'
  Mar 26 06:20:45.418: INFO: stderr: ""
  Mar 26 06:20:45.418: INFO: stdout: "deployment.apps/frontend created\n"
  Mar 26 06:20:45.418: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Mar 26 06:20:45.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-1916 create -f -'
  E0326 06:20:45.530985      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:20:45.542: INFO: stderr: ""
  Mar 26 06:20:45.542: INFO: stdout: "deployment.apps/agnhost-primary created\n"
  Mar 26 06:20:45.542: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Mar 26 06:20:45.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-1916 create -f -'
  Mar 26 06:20:45.657: INFO: stderr: ""
  Mar 26 06:20:45.657: INFO: stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 03/26/24 06:20:45.657
  Mar 26 06:20:45.657: INFO: Waiting for all frontend pods to be Running.
  E0326 06:20:46.531986      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:47.533065      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:48.533221      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:49.533514      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:50.533640      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:20:50.709: INFO: Waiting for frontend to serve content.
  Mar 26 06:20:50.715: INFO: Trying to add a new entry to the guestbook.
  Mar 26 06:20:50.720: INFO: Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 03/26/24 06:20:50.723
  Mar 26 06:20:50.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-1916 delete --grace-period=0 --force -f -'
  Mar 26 06:20:50.774: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Mar 26 06:20:50.774: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 03/26/24 06:20:50.774
  Mar 26 06:20:50.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-1916 delete --grace-period=0 --force -f -'
  Mar 26 06:20:50.821: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Mar 26 06:20:50.821: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 03/26/24 06:20:50.821
  Mar 26 06:20:50.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-1916 delete --grace-period=0 --force -f -'
  Mar 26 06:20:50.870: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Mar 26 06:20:50.870: INFO: stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 03/26/24 06:20:50.87
  Mar 26 06:20:50.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-1916 delete --grace-period=0 --force -f -'
  Mar 26 06:20:50.914: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Mar 26 06:20:50.914: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 03/26/24 06:20:50.914
  Mar 26 06:20:50.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-1916 delete --grace-period=0 --force -f -'
  Mar 26 06:20:50.964: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Mar 26 06:20:50.965: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 03/26/24 06:20:50.965
  Mar 26 06:20:50.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-1916 delete --grace-period=0 --force -f -'
  Mar 26 06:20:51.007: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Mar 26 06:20:51.007: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  Mar 26 06:20:51.008: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1916" for this suite. @ 03/26/24 06:20:51.01
• [6.148 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 03/26/24 06:20:51.013
  Mar 26 06:20:51.013: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename secrets @ 03/26/24 06:20:51.014
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:20:51.024
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:20:51.025
  STEP: Creating secret with name secret-test-89746834-1801-45f0-8170-a3995f7ea394 @ 03/26/24 06:20:51.027
  STEP: Creating a pod to test consume secrets @ 03/26/24 06:20:51.029
  E0326 06:20:51.534671      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:52.534820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:53.535708      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:54.535855      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:20:55.043
  Mar 26 06:20:55.045: INFO: Trying to get logs from node k8s-worker01 pod pod-secrets-9ceced04-06d2-42a7-a99e-b2b881233c97 container secret-volume-test: <nil>
  STEP: delete the pod @ 03/26/24 06:20:55.047
  Mar 26 06:20:55.052: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2811" for this suite. @ 03/26/24 06:20:55.053
• [4.043 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]
test/e2e/network/service.go:1493
  STEP: Creating a kubernetes client @ 03/26/24 06:20:55.056
  Mar 26 06:20:55.056: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename services @ 03/26/24 06:20:55.057
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:20:55.062
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:20:55.067
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-989 @ 03/26/24 06:20:55.068
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 03/26/24 06:20:55.071
  STEP: creating service externalsvc in namespace services-989 @ 03/26/24 06:20:55.071
  STEP: creating replication controller externalsvc in namespace services-989 @ 03/26/24 06:20:55.077
  I0326 06:20:55.079786      19 runners.go:197] Created replication controller with name: externalsvc, namespace: services-989, replica count: 2
  E0326 06:20:55.536342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:56.537132      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:57.537267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0326 06:20:58.130949      19 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 03/26/24 06:20:58.132
  Mar 26 06:20:58.137: INFO: Creating new exec pod
  E0326 06:20:58.537341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:20:59.537619      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:21:00.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-989 exec execpodm6sxq -- /bin/sh -x -c nslookup clusterip-service.services-989.svc.cluster.local'
  Mar 26 06:21:00.251: INFO: stderr: "+ nslookup clusterip-service.services-989.svc.cluster.local\n"
  Mar 26 06:21:00.251: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-989.svc.cluster.local\tcanonical name = externalsvc.services-989.svc.cluster.local.\nName:\texternalsvc.services-989.svc.cluster.local\nAddress: 10.96.161.47\n\n"
  Mar 26 06:21:00.251: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController externalsvc in namespace services-989, will wait for the garbage collector to delete the pods @ 03/26/24 06:21:00.253
  Mar 26 06:21:00.307: INFO: Deleting ReplicationController externalsvc took: 1.832103ms
  Mar 26 06:21:00.407: INFO: Terminating ReplicationController externalsvc pods took: 100.25883ms
  E0326 06:21:00.537768      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:01.538784      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:02.539518      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:21:03.414: INFO: Cleaning up the ClusterIP to ExternalName test service
  STEP: Destroying namespace "services-989" for this suite. @ 03/26/24 06:21:03.42
• [8.367 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]
test/e2e/scheduling/predicates.go:467
  STEP: Creating a kubernetes client @ 03/26/24 06:21:03.424
  Mar 26 06:21:03.424: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename sched-pred @ 03/26/24 06:21:03.425
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:21:03.431
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:21:03.432
  Mar 26 06:21:03.433: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Mar 26 06:21:03.436: INFO: Waiting for terminating namespaces to be deleted...
  Mar 26 06:21:03.437: INFO: 
  Logging pods the apiserver thinks is on node k8s-master01 before test
  Mar 26 06:21:03.440: INFO: calico-kube-controllers-658d97c59c-j8hzg from kube-system started at 2024-03-26 01:40:20 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:03.440: INFO: 	Container calico-kube-controllers ready: true, restart count 1
  Mar 26 06:21:03.440: INFO: calico-node-ld9rp from kube-system started at 2024-03-26 01:40:19 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:03.440: INFO: 	Container calico-node ready: true, restart count 1
  Mar 26 06:21:03.440: INFO: coredns-6554b8b87f-5qtsr from kube-system started at 2024-03-26 01:40:20 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:03.440: INFO: 	Container coredns ready: true, restart count 1
  Mar 26 06:21:03.440: INFO: coredns-6554b8b87f-745fg from kube-system started at 2024-03-26 01:40:20 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:03.440: INFO: 	Container coredns ready: true, restart count 1
  Mar 26 06:21:03.440: INFO: etcd-k8s-master01 from kube-system started at 2024-03-26 03:13:06 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:03.440: INFO: 	Container etcd ready: true, restart count 1
  Mar 26 06:21:03.440: INFO: kube-apiserver-k8s-master01 from kube-system started at 2024-03-26 03:13:06 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:03.440: INFO: 	Container kube-apiserver ready: true, restart count 1
  Mar 26 06:21:03.440: INFO: kube-controller-manager-k8s-master01 from kube-system started at 2024-03-26 03:13:06 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:03.440: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Mar 26 06:21:03.440: INFO: kube-proxy-m9s5h from kube-system started at 2024-03-26 01:40:19 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:03.440: INFO: 	Container kube-proxy ready: true, restart count 1
  Mar 26 06:21:03.440: INFO: kube-scheduler-k8s-master01 from kube-system started at 2024-03-26 03:13:06 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:03.440: INFO: 	Container kube-scheduler ready: true, restart count 1
  Mar 26 06:21:03.440: INFO: sonobuoy-systemd-logs-daemon-set-c080bc1d82d24b52-pmc2w from sonobuoy started at 2024-03-26 05:32:54 +0000 UTC (2 container statuses recorded)
  Mar 26 06:21:03.440: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Mar 26 06:21:03.440: INFO: 	Container systemd-logs ready: true, restart count 0
  Mar 26 06:21:03.440: INFO: 
  Logging pods the apiserver thinks is on node k8s-worker01 before test
  Mar 26 06:21:03.443: INFO: calico-node-rhg5q from kube-system started at 2024-03-26 01:40:25 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:03.443: INFO: 	Container calico-node ready: true, restart count 1
  Mar 26 06:21:03.443: INFO: kube-proxy-6v82d from kube-system started at 2024-03-26 01:40:25 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:03.443: INFO: 	Container kube-proxy ready: true, restart count 1
  Mar 26 06:21:03.443: INFO: sonobuoy-e2e-job-316da3d257e34653 from sonobuoy started at 2024-03-26 05:32:54 +0000 UTC (2 container statuses recorded)
  Mar 26 06:21:03.443: INFO: 	Container e2e ready: true, restart count 0
  Mar 26 06:21:03.443: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Mar 26 06:21:03.443: INFO: sonobuoy-systemd-logs-daemon-set-c080bc1d82d24b52-vv8ws from sonobuoy started at 2024-03-26 05:32:54 +0000 UTC (2 container statuses recorded)
  Mar 26 06:21:03.443: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Mar 26 06:21:03.443: INFO: 	Container systemd-logs ready: true, restart count 0
  Mar 26 06:21:03.443: INFO: 
  Logging pods the apiserver thinks is on node k8s-worker02 before test
  Mar 26 06:21:03.447: INFO: calico-node-wz7cn from kube-system started at 2024-03-26 01:40:26 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:03.447: INFO: 	Container calico-node ready: true, restart count 1
  Mar 26 06:21:03.447: INFO: kube-proxy-6n6f6 from kube-system started at 2024-03-26 01:40:26 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:03.447: INFO: 	Container kube-proxy ready: true, restart count 1
  Mar 26 06:21:03.447: INFO: execpodm6sxq from services-989 started at 2024-03-26 06:20:58 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:03.447: INFO: 	Container agnhost-container ready: true, restart count 0
  Mar 26 06:21:03.447: INFO: sonobuoy from sonobuoy started at 2024-03-26 05:32:53 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:03.447: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Mar 26 06:21:03.447: INFO: sonobuoy-systemd-logs-daemon-set-c080bc1d82d24b52-6w6hx from sonobuoy started at 2024-03-26 05:32:54 +0000 UTC (2 container statuses recorded)
  Mar 26 06:21:03.447: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Mar 26 06:21:03.447: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 03/26/24 06:21:03.447
  E0326 06:21:03.539513      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:04.540699      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 03/26/24 06:21:05.454
  STEP: Trying to apply a random label on the found node. @ 03/26/24 06:21:05.459
  STEP: verifying the node has the label kubernetes.io/e2e-4c2dd314-9004-406e-94f3-b6aa374cb662 42 @ 03/26/24 06:21:05.464
  STEP: Trying to relaunch the pod, now with labels. @ 03/26/24 06:21:05.466
  E0326 06:21:05.540981      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:06.541215      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-4c2dd314-9004-406e-94f3-b6aa374cb662 off the node k8s-worker01 @ 03/26/24 06:21:07.474
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-4c2dd314-9004-406e-94f3-b6aa374cb662 @ 03/26/24 06:21:07.479
  Mar 26 06:21:07.481: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-7022" for this suite. @ 03/26/24 06:21:07.483
• [4.061 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:168
  STEP: Creating a kubernetes client @ 03/26/24 06:21:07.487
  Mar 26 06:21:07.487: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 03/26/24 06:21:07.488
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:21:07.495
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:21:07.497
  STEP: create the container to handle the HTTPGet hook request. @ 03/26/24 06:21:07.5
  E0326 06:21:07.542118      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:08.543104      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 03/26/24 06:21:09.509
  E0326 06:21:09.543448      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:10.544493      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 03/26/24 06:21:11.517
  STEP: delete the pod with lifecycle hook @ 03/26/24 06:21:11.52
  E0326 06:21:11.544672      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:12.544823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:21:13.527: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-6018" for this suite. @ 03/26/24 06:21:13.529
• [6.044 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]
test/e2e/apps/deployment.go:488
  STEP: Creating a kubernetes client @ 03/26/24 06:21:13.531
  Mar 26 06:21:13.531: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename deployment @ 03/26/24 06:21:13.532
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:21:13.536
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:21:13.537
  STEP: creating a Deployment @ 03/26/24 06:21:13.54
  Mar 26 06:21:13.540: INFO: Creating simple deployment test-deployment-x92qw
  Mar 26 06:21:13.544: INFO: deployment "test-deployment-x92qw" doesn't have the required revision set
  E0326 06:21:13.544852      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:14.545910      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:15.546718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Getting /status @ 03/26/24 06:21:15.55
  Mar 26 06:21:15.552: INFO: Deployment test-deployment-x92qw has Conditions: [{Available True 2024-03-26 06:21:14 +0000 UTC 2024-03-26 06:21:14 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2024-03-26 06:21:14 +0000 UTC 2024-03-26 06:21:13 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-x92qw-7986b7f74" has successfully progressed.}]
  STEP: updating Deployment Status @ 03/26/24 06:21:15.552
  Mar 26 06:21:15.555: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 6, 21, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 6, 21, 14, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.March, 26, 6, 21, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.March, 26, 6, 21, 13, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-x92qw-7986b7f74\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 03/26/24 06:21:15.555
  Mar 26 06:21:15.557: INFO: Observed &Deployment event: ADDED
  Mar 26 06:21:15.557: INFO: Observed Deployment test-deployment-x92qw in namespace deployment-8819 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-03-26 06:21:13 +0000 UTC 2024-03-26 06:21:13 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-x92qw-7986b7f74"}
  Mar 26 06:21:15.557: INFO: Observed &Deployment event: MODIFIED
  Mar 26 06:21:15.557: INFO: Observed Deployment test-deployment-x92qw in namespace deployment-8819 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-03-26 06:21:13 +0000 UTC 2024-03-26 06:21:13 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-x92qw-7986b7f74"}
  Mar 26 06:21:15.557: INFO: Observed Deployment test-deployment-x92qw in namespace deployment-8819 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-03-26 06:21:13 +0000 UTC 2024-03-26 06:21:13 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Mar 26 06:21:15.557: INFO: Observed &Deployment event: MODIFIED
  Mar 26 06:21:15.557: INFO: Observed Deployment test-deployment-x92qw in namespace deployment-8819 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-03-26 06:21:13 +0000 UTC 2024-03-26 06:21:13 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Mar 26 06:21:15.557: INFO: Observed Deployment test-deployment-x92qw in namespace deployment-8819 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-03-26 06:21:13 +0000 UTC 2024-03-26 06:21:13 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-x92qw-7986b7f74" is progressing.}
  Mar 26 06:21:15.558: INFO: Observed &Deployment event: MODIFIED
  Mar 26 06:21:15.558: INFO: Observed Deployment test-deployment-x92qw in namespace deployment-8819 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-03-26 06:21:14 +0000 UTC 2024-03-26 06:21:14 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Mar 26 06:21:15.558: INFO: Observed Deployment test-deployment-x92qw in namespace deployment-8819 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-03-26 06:21:14 +0000 UTC 2024-03-26 06:21:13 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-x92qw-7986b7f74" has successfully progressed.}
  Mar 26 06:21:15.558: INFO: Observed &Deployment event: MODIFIED
  Mar 26 06:21:15.558: INFO: Observed Deployment test-deployment-x92qw in namespace deployment-8819 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-03-26 06:21:14 +0000 UTC 2024-03-26 06:21:14 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Mar 26 06:21:15.558: INFO: Observed Deployment test-deployment-x92qw in namespace deployment-8819 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-03-26 06:21:14 +0000 UTC 2024-03-26 06:21:13 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-x92qw-7986b7f74" has successfully progressed.}
  Mar 26 06:21:15.558: INFO: Found Deployment test-deployment-x92qw in namespace deployment-8819 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Mar 26 06:21:15.558: INFO: Deployment test-deployment-x92qw has an updated status
  STEP: patching the Statefulset Status @ 03/26/24 06:21:15.558
  Mar 26 06:21:15.558: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Mar 26 06:21:15.561: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 03/26/24 06:21:15.561
  Mar 26 06:21:15.565: INFO: Observed &Deployment event: ADDED
  Mar 26 06:21:15.565: INFO: Observed deployment test-deployment-x92qw in namespace deployment-8819 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-03-26 06:21:13 +0000 UTC 2024-03-26 06:21:13 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-x92qw-7986b7f74"}
  Mar 26 06:21:15.565: INFO: Observed &Deployment event: MODIFIED
  Mar 26 06:21:15.565: INFO: Observed deployment test-deployment-x92qw in namespace deployment-8819 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-03-26 06:21:13 +0000 UTC 2024-03-26 06:21:13 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-x92qw-7986b7f74"}
  Mar 26 06:21:15.565: INFO: Observed deployment test-deployment-x92qw in namespace deployment-8819 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-03-26 06:21:13 +0000 UTC 2024-03-26 06:21:13 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Mar 26 06:21:15.566: INFO: Observed &Deployment event: MODIFIED
  Mar 26 06:21:15.566: INFO: Observed deployment test-deployment-x92qw in namespace deployment-8819 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-03-26 06:21:13 +0000 UTC 2024-03-26 06:21:13 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Mar 26 06:21:15.566: INFO: Observed deployment test-deployment-x92qw in namespace deployment-8819 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-03-26 06:21:13 +0000 UTC 2024-03-26 06:21:13 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-x92qw-7986b7f74" is progressing.}
  Mar 26 06:21:15.566: INFO: Observed &Deployment event: MODIFIED
  Mar 26 06:21:15.566: INFO: Observed deployment test-deployment-x92qw in namespace deployment-8819 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-03-26 06:21:14 +0000 UTC 2024-03-26 06:21:14 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Mar 26 06:21:15.566: INFO: Observed deployment test-deployment-x92qw in namespace deployment-8819 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-03-26 06:21:14 +0000 UTC 2024-03-26 06:21:13 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-x92qw-7986b7f74" has successfully progressed.}
  Mar 26 06:21:15.566: INFO: Observed &Deployment event: MODIFIED
  Mar 26 06:21:15.566: INFO: Observed deployment test-deployment-x92qw in namespace deployment-8819 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-03-26 06:21:14 +0000 UTC 2024-03-26 06:21:14 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Mar 26 06:21:15.566: INFO: Observed deployment test-deployment-x92qw in namespace deployment-8819 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-03-26 06:21:14 +0000 UTC 2024-03-26 06:21:13 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-x92qw-7986b7f74" has successfully progressed.}
  Mar 26 06:21:15.566: INFO: Observed deployment test-deployment-x92qw in namespace deployment-8819 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Mar 26 06:21:15.566: INFO: Observed &Deployment event: MODIFIED
  Mar 26 06:21:15.566: INFO: Found deployment test-deployment-x92qw in namespace deployment-8819 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  Mar 26 06:21:15.566: INFO: Deployment test-deployment-x92qw has a patched status
  Mar 26 06:21:15.571: INFO: Deployment "test-deployment-x92qw":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-x92qw",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8819",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8a048692-6238-49d1-a114-6d4243254ec7",
      ResourceVersion: (string) (len=5) "87934",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847030873,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030873,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030875,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030875,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=3) "e2e": (string) (len=7) "testing"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030875,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030875,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=55) "Found new replica set \"test-deployment-x92qw-7986b7f74\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Mar 26 06:21:15.575: INFO: New ReplicaSet "test-deployment-x92qw-7986b7f74" of Deployment "test-deployment-x92qw":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "test-deployment-x92qw-7986b7f74",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8819",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1dfc7d44-8995-4c20-b1c9-8d3a53bebfeb",
      ResourceVersion: (string) (len=5) "87928",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847030873,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "7986b7f74"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-x92qw",
          UID: (types.UID) (len=36) "8a048692-6238-49d1-a114-6d4243254ec7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030873,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 38 61 30  |k:{\"uid\":\"8a0|
              00000120  34 38 36 39 32 2d 36 32  33 38 2d 34 39 64 31 2d  |48692-6238-49d1-|
              00000130  61 31 31 34 2d 36 64 34  32 34 33 32 35 34 65 63  |a114-6d4243254ec|
              00000140  37 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |7\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030874,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "7986b7f74",
          (string) (len=3) "e2e": (string) (len=7) "testing"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "7986b7f74"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Mar 26 06:21:15.580: INFO: Pod "test-deployment-x92qw-7986b7f74-q6hnz" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "test-deployment-x92qw-7986b7f74-q6hnz",
      GenerateName: (string) (len=32) "test-deployment-x92qw-7986b7f74-",
      Namespace: (string) (len=15) "deployment-8819",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f8dc95dd-44ab-406f-9388-0ff7e9007e45",
      ResourceVersion: (string) (len=5) "87927",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847030873,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "7986b7f74",
        (string) (len=3) "e2e": (string) (len=7) "testing"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "bc6760f96898b76de94207624a634228f8c3772c1157b45058e28ec4ac5399fe",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "10.244.69.211/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "10.244.69.211/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "test-deployment-x92qw-7986b7f74",
          UID: (types.UID) (len=36) "1dfc7d44-8995-4c20-b1c9-8d3a53bebfeb",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030873,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030873,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 31 64 66 63 37 64 34  34 2d 38 39 39 35 2d 34  |"1dfc7d44-8995-4|
              000000a0  63 32 30 2d 62 31 63 39  2d 38 64 33 61 35 33 62  |c20-b1c9-8d3a53b|
              000000b0  65 62 66 65 62 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |ebfeb\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030874,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 34 34 2e 36  39 2e 32 31 31 5c 22 7d  |10.244.69.211\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7w4ll",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7w4ll",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030873,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030874,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030874,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030873,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.15",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.244.69.211",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.244.69.211"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847030873,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63847030874,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          ImageID: (string) (len=120) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://c6581efd71466b69dbe36ee05c4e4fc71e794cabe5e63444467b7835d63ec251",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:21:15.581: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-8819" for this suite. @ 03/26/24 06:21:15.585
• [2.056 seconds]
------------------------------
SSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance]
test/e2e/network/service.go:3117
  STEP: Creating a kubernetes client @ 03/26/24 06:21:15.589
  Mar 26 06:21:15.589: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename services @ 03/26/24 06:21:15.591
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:21:15.596
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:21:15.597
  STEP: fetching services @ 03/26/24 06:21:15.599
  Mar 26 06:21:15.600: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8719" for this suite. @ 03/26/24 06:21:15.601
• [0.015 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:250
  STEP: Creating a kubernetes client @ 03/26/24 06:21:15.604
  Mar 26 06:21:15.604: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename downward-api @ 03/26/24 06:21:15.604
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:21:15.61
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:21:15.611
  STEP: Creating a pod to test downward API volume plugin @ 03/26/24 06:21:15.613
  E0326 06:21:16.547538      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:17.547719      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:21:17.62
  Mar 26 06:21:17.621: INFO: Trying to get logs from node k8s-worker01 pod downwardapi-volume-b6ed8e65-349d-4b59-a79e-2fc86e8e71ba container client-container: <nil>
  STEP: delete the pod @ 03/26/24 06:21:17.624
  Mar 26 06:21:17.629: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-644" for this suite. @ 03/26/24 06:21:17.63
• [2.029 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance]
test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 03/26/24 06:21:17.633
  Mar 26 06:21:17.633: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename deployment @ 03/26/24 06:21:17.634
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:21:17.639
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:21:17.64
  Mar 26 06:21:17.644: INFO: Pod name cleanup-pod: Found 0 pods out of 1
  E0326 06:21:18.548559      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:19.548886      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:20.549115      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:21.550033      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:22.550152      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:21:22.646: INFO: Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 03/26/24 06:21:22.646
  Mar 26 06:21:22.646: INFO: Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 03/26/24 06:21:22.651
  Mar 26 06:21:22.655: INFO: Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1954",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5a03ec58-848e-4773-bae8-06520089a5b6",
      ResourceVersion: (string) (len=5) "88038",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847030882,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030882,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=55) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 0,
      Replicas: (int32) 0,
      UpdatedReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) <nil>,
      CollisionCount: (*int32)(<nil>)
    }
  }


  Mar 26 06:21:22.657: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
  Mar 26 06:21:22.657: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
  Mar 26 06:21:22.657: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1954",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ea4bd42c-895c-4840-a4cb-f93c78b2eb63",
      ResourceVersion: (string) (len=5) "88039",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847030877,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "5a03ec58-848e-4773-bae8-06520089a5b6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030877,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=483) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000050  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000060  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000070  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000080  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000090  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              000000a0  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000b0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000c0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000d0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000e0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000f0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000100  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000110  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000120  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000130  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000140  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000160  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000170  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000180  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000190  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000001a0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001b0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001c0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001d0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001e0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030878,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030882,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=103) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000020  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              00000030  22 75 69 64 5c 22 3a 5c  22 35 61 30 33 65 63 35  |"uid\":\"5a03ec5|
              00000040  38 2d 38 34 38 65 2d 34  37 37 33 2d 62 61 65 38  |8-848e-4773-bae8|
              00000050  2d 30 36 35 32 30 30 38  39 61 35 62 36 5c 22 7d  |-06520089a5b6\"}|
              00000060  22 3a 7b 7d 7d 7d 7d                              |":{}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "pod": (string) (len=5) "httpd",
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Mar 26 06:21:22.661: INFO: Pod "test-cleanup-controller-g9zt5" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=29) "test-cleanup-controller-g9zt5",
      GenerateName: (string) (len=24) "test-cleanup-controller-",
      Namespace: (string) (len=15) "deployment-1954",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "09a711ed-7707-4051-aa98-b9d5c5b9e0b9",
      ResourceVersion: (string) (len=5) "87984",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847030877,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "10.244.69.235/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "39b00c039b75f80fb70ef79b4fa1a2f95a2cdfc735b342516a153e0441765ea7",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "10.244.69.235/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=23) "test-cleanup-controller",
          UID: (types.UID) (len=36) "ea4bd42c-895c-4840-a4cb-f93c78b2eb63",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030877,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=500) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 2c 22 66  |},"f:pod":{}},"f|
              00000050  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000060  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000070  75 69 64 5c 22 3a 5c 22  65 61 34 62 64 34 32 63  |uid\":\"ea4bd42c|
              00000080  2d 38 39 35 63 2d 34 38  34 30 2d 61 34 63 62 2d  |-895c-4840-a4cb-|
              00000090  66 39 33 63 37 38 62 32  65 62 36 33 5c 22 7d 22  |f93c78b2eb63\"}"|
              000000a0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000b0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000c0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              000000d0  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              000000e0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              000000f0  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000100  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000110  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000120  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000130  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000140  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000150  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000160  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              00000170  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              00000180  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              00000190  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001a0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001b0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001c0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              000001d0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              000001e0  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              000001f0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030878,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030878,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 34 34 2e 36  39 2e 32 33 35 5c 22 7d  |10.244.69.235\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xhv54",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xhv54",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)(<nil>),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030877,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030878,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030878,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847030877,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.15",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.244.69.235",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.244.69.235"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847030877,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63847030878,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          ImageID: (string) (len=120) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://b8688faca6b8b9babff89950cc4199e3dd1c5486f9fb9aeb54a698a1ba666bd0",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:21:22.662: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1954" for this suite. @ 03/26/24 06:21:22.667
• [5.037 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:177
  STEP: Creating a kubernetes client @ 03/26/24 06:21:22.671
  Mar 26 06:21:22.671: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename emptydir @ 03/26/24 06:21:22.671
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:21:22.682
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:21:22.684
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 03/26/24 06:21:22.686
  E0326 06:21:23.550711      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:24.550922      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:21:24.695
  Mar 26 06:21:24.696: INFO: Trying to get logs from node k8s-worker01 pod pod-52e16354-473e-486d-9154-0f85b0075ba5 container test-container: <nil>
  STEP: delete the pod @ 03/26/24 06:21:24.698
  Mar 26 06:21:24.703: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2161" for this suite. @ 03/26/24 06:21:24.705
• [2.037 seconds]
------------------------------
SSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]
test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 03/26/24 06:21:24.707
  Mar 26 06:21:24.708: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename pods @ 03/26/24 06:21:24.708
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:21:24.713
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:21:24.714
  STEP: creating a Pod with a static label @ 03/26/24 06:21:24.717
  STEP: watching for Pod to be ready @ 03/26/24 06:21:24.72
  Mar 26 06:21:24.721: INFO: observed Pod pod-test in namespace pods-7813 in phase Pending with labels: map[test-pod-static:true] & conditions []
  Mar 26 06:21:24.723: INFO: observed Pod pod-test in namespace pods-7813 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-03-26 06:21:24 +0000 UTC  }]
  Mar 26 06:21:24.728: INFO: observed Pod pod-test in namespace pods-7813 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-03-26 06:21:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-03-26 06:21:24 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-03-26 06:21:24 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-03-26 06:21:24 +0000 UTC  }]
  Mar 26 06:21:25.116: INFO: observed Pod pod-test in namespace pods-7813 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-03-26 06:21:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-03-26 06:21:24 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-03-26 06:21:24 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-03-26 06:21:24 +0000 UTC  }]
  Mar 26 06:21:25.414: INFO: Found Pod pod-test in namespace pods-7813 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-03-26 06:21:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2024-03-26 06:21:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2024-03-26 06:21:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-03-26 06:21:24 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 03/26/24 06:21:25.418
  STEP: getting the Pod and ensuring that it's patched @ 03/26/24 06:21:25.422
  STEP: replacing the Pod's status Ready condition to False @ 03/26/24 06:21:25.423
  STEP: check the Pod again to ensure its Ready conditions are False @ 03/26/24 06:21:25.428
  STEP: deleting the Pod via a Collection with a LabelSelector @ 03/26/24 06:21:25.428
  STEP: watching for the Pod to be deleted @ 03/26/24 06:21:25.431
  Mar 26 06:21:25.435: INFO: observed event type MODIFIED
  E0326 06:21:25.551254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:26.551588      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:21:27.418: INFO: observed event type MODIFIED
  E0326 06:21:27.552429      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:21:27.574: INFO: observed event type MODIFIED
  Mar 26 06:21:27.632: INFO: observed event type MODIFIED
  Mar 26 06:21:28.422: INFO: observed event type MODIFIED
  Mar 26 06:21:28.428: INFO: observed event type MODIFIED
  Mar 26 06:21:28.431: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7813" for this suite. @ 03/26/24 06:21:28.433
• [3.728 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]
test/e2e/apps/daemon_set.go:836
  STEP: Creating a kubernetes client @ 03/26/24 06:21:28.44
  Mar 26 06:21:28.440: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename daemonsets @ 03/26/24 06:21:28.441
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:21:28.448
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:21:28.449
  STEP: Creating simple DaemonSet "daemon-set" @ 03/26/24 06:21:28.458
  STEP: Check that daemon pods launch on every node of the cluster. @ 03/26/24 06:21:28.461
  Mar 26 06:21:28.463: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Mar 26 06:21:28.463: INFO: Node k8s-master01 is running 0 daemon pod, expected 1
  E0326 06:21:28.552484      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:21:29.467: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Mar 26 06:21:29.467: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: listing all DaemonSets @ 03/26/24 06:21:29.468
  STEP: DeleteCollection of the DaemonSets @ 03/26/24 06:21:29.469
  STEP: Verify that ReplicaSets have been deleted @ 03/26/24 06:21:29.472
  Mar 26 06:21:29.476: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"88191"},"items":null}

  Mar 26 06:21:29.478: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"88191"},"items":[{"metadata":{"name":"daemon-set-66t4g","generateName":"daemon-set-","namespace":"daemonsets-4104","uid":"2e0cb6ab-f9c5-4bd6-b759-236c97c510ee","resourceVersion":"88190","creationTimestamp":"2024-03-26T06:21:28Z","deletionTimestamp":"2024-03-26T06:21:59Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"9b9bf89d6","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"3a26c5c13d90d9bc4a5b6d99d895149811f57dd962b1a48842ed04549504ba12","cni.projectcalico.org/podIP":"10.244.69.198/32","cni.projectcalico.org/podIPs":"10.244.69.198/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"32f1ef09-fea0-4178-93c0-75e6ea27084f","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2024-03-26T06:21:28Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-03-26T06:21:28Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"32f1ef09-fea0-4178-93c0-75e6ea27084f\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-03-26T06:21:29Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.69.198\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-5pj4q","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-5pj4q","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"k8s-worker02","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["k8s-worker02"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-03-26T06:21:28Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-03-26T06:21:29Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-03-26T06:21:29Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-03-26T06:21:28Z"}],"hostIP":"192.168.132.15","podIP":"10.244.69.198","podIPs":[{"ip":"10.244.69.198"}],"startTime":"2024-03-26T06:21:28Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-03-26T06:21:28Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4","imageID":"hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3","containerID":"cri-o://bce4b930120bcd99bc7a5962bcb7cc44f7fd86e54efcbbbc1862b97c3441f0ef","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-7tfs8","generateName":"daemon-set-","namespace":"daemonsets-4104","uid":"4f519025-9c96-4e26-bdf6-d33d79d1dc72","resourceVersion":"88191","creationTimestamp":"2024-03-26T06:21:28Z","deletionTimestamp":"2024-03-26T06:21:59Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"9b9bf89d6","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"0ff6cf6e3ab5bf52bc6915fb3c615112218d3fa7c8b727a5f6b89f3e8b7c9846","cni.projectcalico.org/podIP":"10.244.32.164/32","cni.projectcalico.org/podIPs":"10.244.32.164/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"32f1ef09-fea0-4178-93c0-75e6ea27084f","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2024-03-26T06:21:28Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-03-26T06:21:28Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"32f1ef09-fea0-4178-93c0-75e6ea27084f\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-03-26T06:21:29Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.32.164\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-gdb7t","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-gdb7t","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"k8s-master01","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["k8s-master01"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-03-26T06:21:28Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-03-26T06:21:29Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-03-26T06:21:29Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-03-26T06:21:28Z"}],"hostIP":"192.168.132.11","podIP":"10.244.32.164","podIPs":[{"ip":"10.244.32.164"}],"startTime":"2024-03-26T06:21:28Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-03-26T06:21:28Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4","imageID":"hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3","containerID":"cri-o://7a227ec6169a357de6a0922a03cc8f05e2b20ef2e8f8d8b04c7f702a388acdf8","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-l6x9s","generateName":"daemon-set-","namespace":"daemonsets-4104","uid":"98c56d00-2f2a-4498-903f-52e5d194c3e8","resourceVersion":"88189","creationTimestamp":"2024-03-26T06:21:28Z","deletionTimestamp":"2024-03-26T06:21:59Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"9b9bf89d6","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"d8dff15f2d890a0d2519093694bbc45fff5c50f63d6ac27d4db737b66481bd3d","cni.projectcalico.org/podIP":"10.244.79.125/32","cni.projectcalico.org/podIPs":"10.244.79.125/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"32f1ef09-fea0-4178-93c0-75e6ea27084f","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2024-03-26T06:21:28Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-03-26T06:21:28Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"32f1ef09-fea0-4178-93c0-75e6ea27084f\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-03-26T06:21:29Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.79.125\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-pcwfn","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-pcwfn","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"k8s-worker01","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["k8s-worker01"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-03-26T06:21:28Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-03-26T06:21:29Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-03-26T06:21:29Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-03-26T06:21:28Z"}],"hostIP":"192.168.132.14","podIP":"10.244.79.125","podIPs":[{"ip":"10.244.79.125"}],"startTime":"2024-03-26T06:21:28Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-03-26T06:21:28Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4","imageID":"hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3","containerID":"cri-o://adcc7e490faa964bb8029e8b62c952d0d63d73659fd95dad2eafa6f2a608b7f1","started":true}],"qosClass":"BestEffort"}}]}

  Mar 26 06:21:29.487: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-4104" for this suite. @ 03/26/24 06:21:29.488
• [1.051 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 03/26/24 06:21:29.492
  Mar 26 06:21:29.492: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename secrets @ 03/26/24 06:21:29.492
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:21:29.497
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:21:29.499
  STEP: Creating secret with name secret-test-4f9c1b15-a89b-44d3-bf07-723342c221a3 @ 03/26/24 06:21:29.5
  STEP: Creating a pod to test consume secrets @ 03/26/24 06:21:29.501
  E0326 06:21:29.552939      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:30.553111      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:21:31.507
  Mar 26 06:21:31.508: INFO: Trying to get logs from node k8s-worker02 pod pod-secrets-6b58abb2-a47d-44b0-890c-1ea59bc2d883 container secret-volume-test: <nil>
  STEP: delete the pod @ 03/26/24 06:21:31.511
  Mar 26 06:21:31.515: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8413" for this suite. @ 03/26/24 06:21:31.517
• [2.029 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 03/26/24 06:21:31.521
  Mar 26 06:21:31.521: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename secrets @ 03/26/24 06:21:31.522
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:21:31.528
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:21:31.531
  STEP: Creating secret with name secret-test-cc6c8d3d-557c-4ea7-859f-82879e9eb0a2 @ 03/26/24 06:21:31.533
  STEP: Creating a pod to test consume secrets @ 03/26/24 06:21:31.542
  E0326 06:21:31.553317      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:32.553438      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:21:33.552
  E0326 06:21:33.553553      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:21:33.554: INFO: Trying to get logs from node k8s-worker02 pod pod-secrets-dad42186-60d4-4ac9-ad20-1730989c5d11 container secret-volume-test: <nil>
  STEP: delete the pod @ 03/26/24 06:21:33.557
  Mar 26 06:21:33.564: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4513" for this suite. @ 03/26/24 06:21:33.566
• [2.047 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]
test/e2e/common/node/expansion.go:115
  STEP: Creating a kubernetes client @ 03/26/24 06:21:33.569
  Mar 26 06:21:33.569: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename var-expansion @ 03/26/24 06:21:33.569
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:21:33.574
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:21:33.575
  STEP: Creating a pod to test substitution in volume subpath @ 03/26/24 06:21:33.577
  E0326 06:21:34.553820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:35.554642      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:21:35.583
  Mar 26 06:21:35.584: INFO: Trying to get logs from node k8s-worker02 pod var-expansion-da1439aa-814f-4866-8c32-428fdbea5063 container dapi-container: <nil>
  STEP: delete the pod @ 03/26/24 06:21:35.587
  Mar 26 06:21:35.593: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1044" for this suite. @ 03/26/24 06:21:35.594
• [2.027 seconds]
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]
test/e2e/kubectl/kubectl.go:830
  STEP: Creating a kubernetes client @ 03/26/24 06:21:35.596
  Mar 26 06:21:35.596: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubectl @ 03/26/24 06:21:35.597
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:21:35.602
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:21:35.603
  STEP: validating api versions @ 03/26/24 06:21:35.605
  Mar 26 06:21:35.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-3970 api-versions'
  Mar 26 06:21:35.643: INFO: stderr: ""
  Mar 26 06:21:35.643: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta2\nflowcontrol.apiserver.k8s.io/v1beta3\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  Mar 26 06:21:35.643: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3970" for this suite. @ 03/26/24 06:21:35.646
• [0.052 seconds]
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]
test/e2e/kubectl/kubectl.go:1707
  STEP: Creating a kubernetes client @ 03/26/24 06:21:35.648
  Mar 26 06:21:35.648: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubectl @ 03/26/24 06:21:35.649
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:21:35.654
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:21:35.656
  STEP: running the image hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4 @ 03/26/24 06:21:35.657
  Mar 26 06:21:35.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-7283 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4'
  Mar 26 06:21:35.700: INFO: stderr: ""
  Mar 26 06:21:35.700: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 03/26/24 06:21:35.7
  Mar 26 06:21:35.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-7283 delete pods e2e-test-httpd-pod'
  E0326 06:21:36.554694      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:21:37.256: INFO: stderr: ""
  Mar 26 06:21:37.256: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Mar 26 06:21:37.256: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7283" for this suite. @ 03/26/24 06:21:37.257
• [1.611 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:47
  STEP: Creating a kubernetes client @ 03/26/24 06:21:37.262
  Mar 26 06:21:37.262: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename var-expansion @ 03/26/24 06:21:37.262
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:21:37.267
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:21:37.269
  STEP: Creating a pod to test env composition @ 03/26/24 06:21:37.27
  E0326 06:21:37.554841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:38.554990      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:39.555501      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:40.556062      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:21:41.278
  Mar 26 06:21:41.279: INFO: Trying to get logs from node k8s-worker02 pod var-expansion-5a5ea79d-c878-481b-9f73-185e7722f1b1 container dapi-container: <nil>
  STEP: delete the pod @ 03/26/24 06:21:41.282
  Mar 26 06:21:41.287: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1983" for this suite. @ 03/26/24 06:21:41.289
• [4.029 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:528
  STEP: Creating a kubernetes client @ 03/26/24 06:21:41.291
  Mar 26 06:21:41.291: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename security-context-test @ 03/26/24 06:21:41.292
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:21:41.298
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:21:41.299
  E0326 06:21:41.557078      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:42.557205      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:43.557297      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:44.557391      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:21:45.311: INFO: Got logs for pod "busybox-privileged-false-a8f8656f-2bc4-4bc9-a56c-ffa7cc2b9629": "ip: RTNETLINK answers: Operation not permitted\n"
  Mar 26 06:21:45.311: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-7612" for this suite. @ 03/26/24 06:21:45.312
• [4.024 seconds]
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:74
  STEP: Creating a kubernetes client @ 03/26/24 06:21:45.315
  Mar 26 06:21:45.315: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 06:21:45.315
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:21:45.321
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:21:45.322
  STEP: Creating configMap with name projected-configmap-test-volume-648161ea-d957-483b-ac19-f823256329c0 @ 03/26/24 06:21:45.323
  STEP: Creating a pod to test consume configMaps @ 03/26/24 06:21:45.325
  E0326 06:21:45.557620      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:46.557770      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:47.558409      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:48.558897      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:21:49.336
  Mar 26 06:21:49.338: INFO: Trying to get logs from node k8s-worker02 pod pod-projected-configmaps-2282a3bf-4b28-4d57-82c6-39311b015d72 container agnhost-container: <nil>
  STEP: delete the pod @ 03/26/24 06:21:49.341
  Mar 26 06:21:49.348: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8502" for this suite. @ 03/26/24 06:21:49.35
• [4.037 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
test/e2e/scheduling/predicates.go:705
  STEP: Creating a kubernetes client @ 03/26/24 06:21:49.352
  Mar 26 06:21:49.352: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename sched-pred @ 03/26/24 06:21:49.353
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:21:49.358
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:21:49.361
  Mar 26 06:21:49.363: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Mar 26 06:21:49.365: INFO: Waiting for terminating namespaces to be deleted...
  Mar 26 06:21:49.366: INFO: 
  Logging pods the apiserver thinks is on node k8s-master01 before test
  Mar 26 06:21:49.369: INFO: calico-kube-controllers-658d97c59c-j8hzg from kube-system started at 2024-03-26 01:40:20 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:49.369: INFO: 	Container calico-kube-controllers ready: true, restart count 1
  Mar 26 06:21:49.369: INFO: calico-node-ld9rp from kube-system started at 2024-03-26 01:40:19 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:49.369: INFO: 	Container calico-node ready: true, restart count 1
  Mar 26 06:21:49.369: INFO: coredns-6554b8b87f-5qtsr from kube-system started at 2024-03-26 01:40:20 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:49.369: INFO: 	Container coredns ready: true, restart count 1
  Mar 26 06:21:49.369: INFO: coredns-6554b8b87f-745fg from kube-system started at 2024-03-26 01:40:20 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:49.369: INFO: 	Container coredns ready: true, restart count 1
  Mar 26 06:21:49.369: INFO: etcd-k8s-master01 from kube-system started at 2024-03-26 03:13:06 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:49.369: INFO: 	Container etcd ready: true, restart count 1
  Mar 26 06:21:49.369: INFO: kube-apiserver-k8s-master01 from kube-system started at 2024-03-26 03:13:06 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:49.369: INFO: 	Container kube-apiserver ready: true, restart count 1
  Mar 26 06:21:49.369: INFO: kube-controller-manager-k8s-master01 from kube-system started at 2024-03-26 03:13:06 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:49.369: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Mar 26 06:21:49.369: INFO: kube-proxy-m9s5h from kube-system started at 2024-03-26 01:40:19 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:49.369: INFO: 	Container kube-proxy ready: true, restart count 1
  Mar 26 06:21:49.369: INFO: kube-scheduler-k8s-master01 from kube-system started at 2024-03-26 03:13:06 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:49.369: INFO: 	Container kube-scheduler ready: true, restart count 1
  Mar 26 06:21:49.369: INFO: sonobuoy-systemd-logs-daemon-set-c080bc1d82d24b52-pmc2w from sonobuoy started at 2024-03-26 05:32:54 +0000 UTC (2 container statuses recorded)
  Mar 26 06:21:49.369: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Mar 26 06:21:49.369: INFO: 	Container systemd-logs ready: true, restart count 0
  Mar 26 06:21:49.369: INFO: 
  Logging pods the apiserver thinks is on node k8s-worker01 before test
  Mar 26 06:21:49.372: INFO: calico-node-rhg5q from kube-system started at 2024-03-26 01:40:25 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:49.372: INFO: 	Container calico-node ready: true, restart count 1
  Mar 26 06:21:49.372: INFO: kube-proxy-6v82d from kube-system started at 2024-03-26 01:40:25 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:49.372: INFO: 	Container kube-proxy ready: true, restart count 1
  Mar 26 06:21:49.372: INFO: sonobuoy-e2e-job-316da3d257e34653 from sonobuoy started at 2024-03-26 05:32:54 +0000 UTC (2 container statuses recorded)
  Mar 26 06:21:49.372: INFO: 	Container e2e ready: true, restart count 0
  Mar 26 06:21:49.372: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Mar 26 06:21:49.372: INFO: sonobuoy-systemd-logs-daemon-set-c080bc1d82d24b52-vv8ws from sonobuoy started at 2024-03-26 05:32:54 +0000 UTC (2 container statuses recorded)
  Mar 26 06:21:49.372: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Mar 26 06:21:49.372: INFO: 	Container systemd-logs ready: true, restart count 0
  Mar 26 06:21:49.372: INFO: 
  Logging pods the apiserver thinks is on node k8s-worker02 before test
  Mar 26 06:21:49.375: INFO: calico-node-wz7cn from kube-system started at 2024-03-26 01:40:26 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:49.375: INFO: 	Container calico-node ready: true, restart count 1
  Mar 26 06:21:49.375: INFO: kube-proxy-6n6f6 from kube-system started at 2024-03-26 01:40:26 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:49.375: INFO: 	Container kube-proxy ready: true, restart count 1
  Mar 26 06:21:49.375: INFO: busybox-privileged-false-a8f8656f-2bc4-4bc9-a56c-ffa7cc2b9629 from security-context-test-7612 started at 2024-03-26 06:21:41 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:49.375: INFO: 	Container busybox-privileged-false-a8f8656f-2bc4-4bc9-a56c-ffa7cc2b9629 ready: false, restart count 0
  Mar 26 06:21:49.375: INFO: sonobuoy from sonobuoy started at 2024-03-26 05:32:53 +0000 UTC (1 container statuses recorded)
  Mar 26 06:21:49.375: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Mar 26 06:21:49.375: INFO: sonobuoy-systemd-logs-daemon-set-c080bc1d82d24b52-6w6hx from sonobuoy started at 2024-03-26 05:32:54 +0000 UTC (2 container statuses recorded)
  Mar 26 06:21:49.375: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Mar 26 06:21:49.375: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 03/26/24 06:21:49.375
  E0326 06:21:49.559888      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:50.560257      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 03/26/24 06:21:51.383
  STEP: Trying to apply a random label on the found node. @ 03/26/24 06:21:51.39
  STEP: verifying the node has the label kubernetes.io/e2e-ca8336df-4848-4e6c-be4c-a84491c1445e 95 @ 03/26/24 06:21:51.394
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 03/26/24 06:21:51.399
  E0326 06:21:51.560937      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:52.561644      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.132.15 on the node which pod4 resides and expect not scheduled @ 03/26/24 06:21:53.406
  E0326 06:21:53.562148      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:54.562823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:55.563685      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:56.564044      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:57.564594      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:58.564694      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:21:59.565065      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:00.565208      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:01.565933      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:02.566005      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:03.566757      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:04.566888      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:05.567919      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:06.567948      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:07.569092      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:08.569044      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:09.569664      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:10.569755      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:11.570009      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:12.570141      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:13.570472      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:14.570572      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:15.570991      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:16.571115      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:17.571669      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:18.571788      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:19.572357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:20.572718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:21.573304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:22.574135      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:23.574302      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:24.574446      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:25.574925      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:26.575050      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:27.576099      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:28.577118      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:29.577416      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:30.577764      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:31.578227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:32.578373      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:33.578838      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:34.578932      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:35.579556      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:36.579683      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:37.579746      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:38.579832      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:39.580679      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:40.581741      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:41.582544      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:42.582938      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:43.583624      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:44.583731      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:45.584311      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:46.584920      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:47.585037      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:48.585343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:49.586339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:50.586876      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:51.586903      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:52.587365      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:53.588160      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:54.588378      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:55.589401      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:56.589691      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:57.590082      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:58.590477      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:22:59.590827      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:00.591234      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:01.591760      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:02.592174      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:03.592662      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:04.592879      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:05.593227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:06.593493      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:07.593984      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:08.594092      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:09.594598      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:10.595286      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:11.595618      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:12.595712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:13.596117      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:14.596258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:15.596475      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:16.596565      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:17.597555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:18.598431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:19.599038      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:20.599779      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:21.600796      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:22.600915      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:23.601760      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:24.601875      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:25.602527      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:26.602898      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:27.603629      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:28.604712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:29.605413      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:30.605709      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:31.606409      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:32.606549      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:33.606959      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:34.607130      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:35.607560      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:36.607743      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:37.607922      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:38.608060      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:39.608848      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:40.608998      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:41.609937      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:42.610087      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:43.610705      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:44.610848      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:45.611751      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:46.611893      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:47.612832      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:48.612966      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:49.614007      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:50.614186      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:51.614796      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:52.615696      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:53.616574      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:54.617467      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:55.618007      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:56.618329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:57.618940      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:58.619087      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:23:59.619627      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:00.619952      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:01.620634      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:02.620756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:03.621634      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:04.621752      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:05.622399      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:06.622516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:07.623442      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:08.623882      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:09.624473      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:10.624566      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:11.625235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:12.625349      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:13.625834      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:14.626248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:15.626999      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:16.627297      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:17.627943      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:18.628048      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:19.628586      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:20.628690      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:21.629206      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:22.629431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:23.629925      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:24.630099      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:25.630832      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:26.630941      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:27.631739      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:28.631904      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:29.632475      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:30.632618      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:31.633396      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:32.633522      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:33.634242      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:34.634375      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:35.635034      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:36.636029      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:37.636058      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:38.636234      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:39.636439      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:40.636695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:41.637475      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:42.637718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:43.638129      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:44.638265      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:45.638667      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:46.638766      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:47.638820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:48.638914      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:49.639643      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:50.639725      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:51.640262      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:52.640390      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:53.641346      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:54.641499      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:55.642076      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:56.642163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:57.642556      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:58.643712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:24:59.644288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:00.644566      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:01.645034      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:02.645841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:03.645972      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:04.647087      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:05.647386      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:06.647556      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:07.648591      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:08.648762      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:09.649663      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:10.649920      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:11.650571      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:12.650754      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:13.651280      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:14.651453      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:15.652366      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:16.652695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:17.652693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:18.653270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:19.653821      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:20.653870      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:21.654428      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:22.654543      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:23.654668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:24.655625      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:25.656384      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:26.656512      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:27.656800      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:28.656954      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:29.657471      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:30.657600      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:31.657607      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:32.657725      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:33.658150      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:34.659655      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:35.659732      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:36.659913      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:37.660527      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:38.660888      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:39.661622      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:40.661893      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:41.662839      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:42.663025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:43.663911      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:44.664433      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:45.665318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:46.666117      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:47.666279      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:48.666394      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:49.667120      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:50.668189      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:51.668338      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:52.668729      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:53.669421      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:54.669647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:55.670111      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:56.670470      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:57.670564      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:58.671030      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:25:59.671154      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:00.671282      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:01.671374      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:02.672262      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:03.672592      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:04.673298      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:05.673632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:06.674319      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:07.675205      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:08.676202      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:09.676386      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:10.677548      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:11.677683      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:12.678417      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:13.678595      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:14.678691      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:15.679591      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:16.679989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:17.680128      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:18.680258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:19.680605      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:20.681603      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:21.681717      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:22.682026      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:23.682110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:24.682178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:25.682604      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:26.683540      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:27.683645      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:28.684169      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:29.684364      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:30.685216      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:31.686277      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:32.686312      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:33.686697      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:34.686922      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:35.687008      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:36.687034      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:37.687331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:38.687441      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:39.687629      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:40.688561      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:41.689529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:42.689541      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:43.689649      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:44.689896      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:45.689960      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:46.690295      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:47.691041      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:48.691117      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:49.691258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:50.691840      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:51.692259      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:52.692704      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-ca8336df-4848-4e6c-be4c-a84491c1445e off the node k8s-worker02 @ 03/26/24 06:26:53.411
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-ca8336df-4848-4e6c-be4c-a84491c1445e @ 03/26/24 06:26:53.417
  Mar 26 06:26:53.419: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-1478" for this suite. @ 03/26/24 06:26:53.421
• [304.071 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 03/26/24 06:26:53.425
  Mar 26 06:26:53.425: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename sched-preemption @ 03/26/24 06:26:53.425
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:26:53.431
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:26:53.432
  Mar 26 06:26:53.438: INFO: Waiting up to 1m0s for all nodes to be ready
  E0326 06:26:53.693686      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:54.694609      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:55.695039      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:56.695150      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:57.695523      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:58.695716      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:26:59.696302      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:00.696686      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:01.697852      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:02.698473      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:03.699279      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:04.700466      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:05.701205      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:06.701391      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:07.702110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:08.702222      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:09.703262      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:10.703528      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:11.704506      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:12.704616      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:13.705517      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:14.705615      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:15.705695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:16.705821      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:17.706296      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:18.707400      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:19.708049      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:20.708140      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:21.708971      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:22.709093      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:23.709182      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:24.709508      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:25.710337      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:26.710431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:27.711161      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:28.711299      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:29.712038      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:30.712262      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:31.712327      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:32.712424      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:33.713315      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:34.713452      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:35.713900      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:36.714039      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:37.714650      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:38.714783      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:39.714834      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:40.715139      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:41.716014      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:42.716114      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:43.716265      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:44.716384      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:45.716749      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:46.716874      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:47.717482      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:48.717611      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:49.717877      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:50.717971      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:51.718559      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:52.719038      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:27:53.454: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 03/26/24 06:27:53.455
  Mar 26 06:27:53.455: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename sched-preemption-path @ 03/26/24 06:27:53.456
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:27:53.514
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:27:53.516
  Mar 26 06:27:53.522: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  Mar 26 06:27:53.523: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  Mar 26 06:27:53.528: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Mar 26 06:27:53.532: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-7700" for this suite. @ 03/26/24 06:27:53.547
  STEP: Destroying namespace "sched-preemption-880" for this suite. @ 03/26/24 06:27:53.549
• [60.126 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:89
  STEP: Creating a kubernetes client @ 03/26/24 06:27:53.551
  Mar 26 06:27:53.551: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 06:27:53.551
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:27:53.556
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:27:53.557
  STEP: Creating configMap with name projected-configmap-test-volume-map-ff4571e7-75e9-4380-9db9-bdf55d5cc68c @ 03/26/24 06:27:53.558
  STEP: Creating a pod to test consume configMaps @ 03/26/24 06:27:53.56
  E0326 06:27:53.719431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:54.719607      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:55.720378      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:56.720673      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:27:57.568
  Mar 26 06:27:57.569: INFO: Trying to get logs from node k8s-worker02 pod pod-projected-configmaps-944cdc3f-0316-4887-bc94-d7ee603d322f container agnhost-container: <nil>
  STEP: delete the pod @ 03/26/24 06:27:57.573
  Mar 26 06:27:57.578: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-164" for this suite. @ 03/26/24 06:27:57.579
• [4.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:131
  STEP: Creating a kubernetes client @ 03/26/24 06:27:57.581
  Mar 26 06:27:57.582: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename downward-api @ 03/26/24 06:27:57.582
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:27:57.587
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:27:57.588
  STEP: Creating the pod @ 03/26/24 06:27:57.589
  E0326 06:27:57.720721      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:58.721038      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:27:59.721673      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:28:00.103: INFO: Successfully updated pod "labelsupdate7f28c25f-8b5f-4965-b669-30ed0247c377"
  E0326 06:28:00.721941      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:01.722178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:28:02.110: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4293" for this suite. @ 03/26/24 06:28:02.114
• [4.543 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]
test/e2e/apimachinery/webhook.go:285
  STEP: Creating a kubernetes client @ 03/26/24 06:28:02.125
  Mar 26 06:28:02.125: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename webhook @ 03/26/24 06:28:02.126
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:28:02.135
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:28:02.137
  STEP: Setting up server cert @ 03/26/24 06:28:02.146
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 03/26/24 06:28:02.452
  STEP: Deploying the webhook pod @ 03/26/24 06:28:02.455
  STEP: Wait for the deployment to be ready @ 03/26/24 06:28:02.459
  Mar 26 06:28:02.461: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0326 06:28:02.723048      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:03.724097      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 03/26/24 06:28:04.466
  STEP: Verifying the service has paired with the endpoint @ 03/26/24 06:28:04.47
  E0326 06:28:04.724298      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:28:05.471: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Mar 26 06:28:05.473: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  E0326 06:28:05.725333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5414-crds.webhook.example.com via the AdmissionRegistration API @ 03/26/24 06:28:05.978
  STEP: Creating a custom resource that should be mutated by the webhook @ 03/26/24 06:28:05.985
  E0326 06:28:06.725959      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:07.726256      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:28:08.001: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6485" for this suite. @ 03/26/24 06:28:08.525
  STEP: Destroying namespace "webhook-markers-6357" for this suite. @ 03/26/24 06:28:08.531
• [6.408 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:69
  STEP: Creating a kubernetes client @ 03/26/24 06:28:08.535
  Mar 26 06:28:08.535: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename downward-api @ 03/26/24 06:28:08.535
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:28:08.541
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:28:08.542
  STEP: Creating a pod to test downward API volume plugin @ 03/26/24 06:28:08.543
  E0326 06:28:08.726704      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:09.726916      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:10.727632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:11.727773      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:28:12.55
  Mar 26 06:28:12.552: INFO: Trying to get logs from node k8s-worker02 pod downwardapi-volume-2a1deab4-298f-4380-9349-902bb05a9a05 container client-container: <nil>
  STEP: delete the pod @ 03/26/24 06:28:12.554
  Mar 26 06:28:12.560: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-439" for this suite. @ 03/26/24 06:28:12.562
• [4.029 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]
test/e2e/apimachinery/garbage_collector.go:321
  STEP: Creating a kubernetes client @ 03/26/24 06:28:12.565
  Mar 26 06:28:12.565: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename gc @ 03/26/24 06:28:12.566
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:28:12.571
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:28:12.572
  STEP: create the rc @ 03/26/24 06:28:12.573
  W0326 06:28:12.575620      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0326 06:28:12.727877      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:13.728000      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:14.728109      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:15.728473      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:16.728547      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 03/26/24 06:28:17.577
  STEP: wait for all pods to be garbage collected @ 03/26/24 06:28:17.58
  E0326 06:28:17.728637      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:18.728795      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:19.728944      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:20.729070      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:21.729213      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 03/26/24 06:28:22.583
  Mar 26 06:28:22.632: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Mar 26 06:28:22.632: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3594" for this suite. @ 03/26/24 06:28:22.634
• [10.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]
test/e2e/network/service.go:2202
  STEP: Creating a kubernetes client @ 03/26/24 06:28:22.638
  Mar 26 06:28:22.638: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename services @ 03/26/24 06:28:22.639
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:28:22.645
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:28:22.646
  STEP: creating service in namespace services-6317 @ 03/26/24 06:28:22.647
  STEP: creating service affinity-nodeport in namespace services-6317 @ 03/26/24 06:28:22.647
  STEP: creating replication controller affinity-nodeport in namespace services-6317 @ 03/26/24 06:28:22.651
  I0326 06:28:22.655924      19 runners.go:197] Created replication controller with name: affinity-nodeport, namespace: services-6317, replica count: 3
  E0326 06:28:22.729629      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:23.729726      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:24.730370      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0326 06:28:25.706713      19 runners.go:197] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Mar 26 06:28:25.711: INFO: Creating new exec pod
  E0326 06:28:25.731005      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:26.731122      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:27.732146      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:28:28.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-6317 exec execpod-affinityf4vgc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  E0326 06:28:28.732890      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:28:28.804: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  Mar 26 06:28:28.804: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Mar 26 06:28:28.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-6317 exec execpod-affinityf4vgc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.90.51 80'
  Mar 26 06:28:28.879: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.90.51 80\nConnection to 10.96.90.51 80 port [tcp/http] succeeded!\n"
  Mar 26 06:28:28.879: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Mar 26 06:28:28.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-6317 exec execpod-affinityf4vgc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.132.11 31379'
  Mar 26 06:28:28.960: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.132.11 31379\nConnection to 192.168.132.11 31379 port [tcp/*] succeeded!\n"
  Mar 26 06:28:28.960: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Mar 26 06:28:28.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-6317 exec execpod-affinityf4vgc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.132.15 31379'
  Mar 26 06:28:29.036: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.132.15 31379\nConnection to 192.168.132.15 31379 port [tcp/*] succeeded!\n"
  Mar 26 06:28:29.036: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Mar 26 06:28:29.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-6317 exec execpod-affinityf4vgc -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.132.11:31379/ ; done'
  Mar 26 06:28:29.146: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31379/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31379/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31379/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31379/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31379/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31379/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31379/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31379/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31379/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31379/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31379/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31379/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31379/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31379/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31379/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31379/\n"
  Mar 26 06:28:29.146: INFO: stdout: "\naffinity-nodeport-wsm88\naffinity-nodeport-wsm88\naffinity-nodeport-wsm88\naffinity-nodeport-wsm88\naffinity-nodeport-wsm88\naffinity-nodeport-wsm88\naffinity-nodeport-wsm88\naffinity-nodeport-wsm88\naffinity-nodeport-wsm88\naffinity-nodeport-wsm88\naffinity-nodeport-wsm88\naffinity-nodeport-wsm88\naffinity-nodeport-wsm88\naffinity-nodeport-wsm88\naffinity-nodeport-wsm88\naffinity-nodeport-wsm88"
  Mar 26 06:28:29.146: INFO: Received response from host: affinity-nodeport-wsm88
  Mar 26 06:28:29.146: INFO: Received response from host: affinity-nodeport-wsm88
  Mar 26 06:28:29.146: INFO: Received response from host: affinity-nodeport-wsm88
  Mar 26 06:28:29.146: INFO: Received response from host: affinity-nodeport-wsm88
  Mar 26 06:28:29.146: INFO: Received response from host: affinity-nodeport-wsm88
  Mar 26 06:28:29.146: INFO: Received response from host: affinity-nodeport-wsm88
  Mar 26 06:28:29.147: INFO: Received response from host: affinity-nodeport-wsm88
  Mar 26 06:28:29.147: INFO: Received response from host: affinity-nodeport-wsm88
  Mar 26 06:28:29.147: INFO: Received response from host: affinity-nodeport-wsm88
  Mar 26 06:28:29.147: INFO: Received response from host: affinity-nodeport-wsm88
  Mar 26 06:28:29.147: INFO: Received response from host: affinity-nodeport-wsm88
  Mar 26 06:28:29.147: INFO: Received response from host: affinity-nodeport-wsm88
  Mar 26 06:28:29.147: INFO: Received response from host: affinity-nodeport-wsm88
  Mar 26 06:28:29.147: INFO: Received response from host: affinity-nodeport-wsm88
  Mar 26 06:28:29.147: INFO: Received response from host: affinity-nodeport-wsm88
  Mar 26 06:28:29.147: INFO: Received response from host: affinity-nodeport-wsm88
  Mar 26 06:28:29.147: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Mar 26 06:28:29.149: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-6317, will wait for the garbage collector to delete the pods @ 03/26/24 06:28:29.154
  Mar 26 06:28:29.207: INFO: Deleting ReplicationController affinity-nodeport took: 2.249626ms
  Mar 26 06:28:29.308: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.932616ms
  E0326 06:28:29.733176      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:30.733427      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:31.740849      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-6317" for this suite. @ 03/26/24 06:28:32.019
• [9.384 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 03/26/24 06:28:32.021
  Mar 26 06:28:32.021: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 06:28:32.022
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:28:32.026
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:28:32.028
  STEP: Creating secret with name s-test-opt-del-7f5d5dd7-9ddf-4a82-8392-05908635abec @ 03/26/24 06:28:32.03
  STEP: Creating secret with name s-test-opt-upd-1813f8de-ae64-45a2-bed5-738072ffbf1e @ 03/26/24 06:28:32.033
  STEP: Creating the pod @ 03/26/24 06:28:32.035
  E0326 06:28:32.740672      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:33.740820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-7f5d5dd7-9ddf-4a82-8392-05908635abec @ 03/26/24 06:28:34.052
  STEP: Updating secret s-test-opt-upd-1813f8de-ae64-45a2-bed5-738072ffbf1e @ 03/26/24 06:28:34.054
  STEP: Creating secret with name s-test-opt-create-e4e92306-e03a-4512-8986-198ac26511ff @ 03/26/24 06:28:34.056
  STEP: waiting to observe update in volume @ 03/26/24 06:28:34.058
  E0326 06:28:34.741091      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:35.741555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:36.742158      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:37.742824      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:38.742969      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:39.743067      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:40.743304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:41.743408      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:42.744178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:43.744447      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:44.744610      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:45.744705      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:46.745576      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:47.746369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:48.747427      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:49.747450      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:50.747649      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:51.747724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:52.748169      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:53.748375      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:54.748622      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:55.749009      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:56.749269      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:57.749805      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:58.749831      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:28:59.750017      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:00.750083      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:01.750176      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:02.750706      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:03.750795      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:04.751567      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:05.751663      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:06.751958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:07.752680      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:08.752847      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:09.753002      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:10.753058      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:11.753157      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:12.753922      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:13.754103      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:14.754971      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:15.755074      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:16.755248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:17.755268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:18.755542      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:19.755689      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:20.756025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:21.756308      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:22.756686      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:23.756835      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:24.756941      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:25.757401      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:26.757766      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:27.758524      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:28.758584      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:29.758676      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:30.758781      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:31.759232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:32.759783      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:33.759972      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:34.760092      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:35.761087      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:36.762011      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:37.762398      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:38.762530      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:39.762633      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:40.762697      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:41.762782      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:42.763238      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:43.763312      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:44.763408      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:45.763792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:29:46.201: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-719" for this suite. @ 03/26/24 06:29:46.202
• [74.184 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]
test/e2e/apimachinery/resource_quota.go:693
  STEP: Creating a kubernetes client @ 03/26/24 06:29:46.206
  Mar 26 06:29:46.206: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename resourcequota @ 03/26/24 06:29:46.207
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:29:46.212
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:29:46.213
  STEP: Creating a ResourceQuota with terminating scope @ 03/26/24 06:29:46.215
  STEP: Ensuring ResourceQuota status is calculated @ 03/26/24 06:29:46.217
  E0326 06:29:46.763955      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:47.764690      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not terminating scope @ 03/26/24 06:29:48.219
  STEP: Ensuring ResourceQuota status is calculated @ 03/26/24 06:29:48.221
  E0326 06:29:48.764970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:49.765113      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a long running pod @ 03/26/24 06:29:50.223
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 03/26/24 06:29:50.229
  E0326 06:29:50.765751      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:51.766798      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 03/26/24 06:29:52.23
  E0326 06:29:52.767030      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:53.767427      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 03/26/24 06:29:54.232
  STEP: Ensuring resource quota status released the pod usage @ 03/26/24 06:29:54.236
  E0326 06:29:54.768142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:55.769150      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a terminating pod @ 03/26/24 06:29:56.239
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 03/26/24 06:29:56.243
  E0326 06:29:56.769251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:57.769353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 03/26/24 06:29:58.245
  E0326 06:29:58.769978      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:29:59.770685      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 03/26/24 06:30:00.247
  STEP: Ensuring resource quota status released the pod usage @ 03/26/24 06:30:00.253
  E0326 06:30:00.771778      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:01.772046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:30:02.255: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2521" for this suite. @ 03/26/24 06:30:02.259
• [16.056 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]
test/e2e/apimachinery/webhook.go:301
  STEP: Creating a kubernetes client @ 03/26/24 06:30:02.262
  Mar 26 06:30:02.262: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename webhook @ 03/26/24 06:30:02.262
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:30:02.268
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:30:02.269
  STEP: Setting up server cert @ 03/26/24 06:30:02.277
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 03/26/24 06:30:02.618
  STEP: Deploying the webhook pod @ 03/26/24 06:30:02.623
  STEP: Wait for the deployment to be ready @ 03/26/24 06:30:02.627
  Mar 26 06:30:02.630: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0326 06:30:02.772497      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:03.772670      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 03/26/24 06:30:04.635
  STEP: Verifying the service has paired with the endpoint @ 03/26/24 06:30:04.639
  E0326 06:30:04.773389      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:30:05.639: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 03/26/24 06:30:05.642
  STEP: Creating a custom resource definition that should be denied by the webhook @ 03/26/24 06:30:05.649
  Mar 26 06:30:05.649: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 06:30:05.655: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4343" for this suite. @ 03/26/24 06:30:05.675
  STEP: Destroying namespace "webhook-markers-9839" for this suite. @ 03/26/24 06:30:05.681
• [3.423 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]
test/e2e/apimachinery/garbage_collector.go:817
  STEP: Creating a kubernetes client @ 03/26/24 06:30:05.685
  Mar 26 06:30:05.685: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename gc @ 03/26/24 06:30:05.686
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:30:05.692
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:30:05.693
  Mar 26 06:30:05.706: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"8d427faa-6449-4a8f-ab26-483c3834b2ed", Controller:(*bool)(0xc0044a6536), BlockOwnerDeletion:(*bool)(0xc0044a6537)}}
  Mar 26 06:30:05.710: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"eb205472-eda8-48ba-add1-549bbc616f6d", Controller:(*bool)(0xc0044a6756), BlockOwnerDeletion:(*bool)(0xc0044a6757)}}
  Mar 26 06:30:05.715: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"9b6ef5c8-cfa8-4c0f-ab90-2fcc19102421", Controller:(*bool)(0xc0044a6986), BlockOwnerDeletion:(*bool)(0xc0044a6987)}}
  E0326 06:30:05.773572      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:06.773694      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:07.773769      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:08.774122      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:09.775199      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:30:10.721: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-6907" for this suite. @ 03/26/24 06:30:10.723
• [5.040 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance]
test/e2e/apps/job.go:642
  STEP: Creating a kubernetes client @ 03/26/24 06:30:10.725
  Mar 26 06:30:10.725: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename job @ 03/26/24 06:30:10.726
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:30:10.731
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:30:10.733
  STEP: Creating a job @ 03/26/24 06:30:10.735
  STEP: Ensure pods equal to parallelism count is attached to the job @ 03/26/24 06:30:10.738
  E0326 06:30:10.775272      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:11.775397      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 03/26/24 06:30:12.741
  STEP: updating /status @ 03/26/24 06:30:12.744
  STEP: get /status @ 03/26/24 06:30:12.747
  Mar 26 06:30:12.748: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-5893" for this suite. @ 03/26/24 06:30:12.75
• [2.027 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:95
  STEP: Creating a kubernetes client @ 03/26/24 06:30:12.759
  Mar 26 06:30:12.759: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename pod-network-test @ 03/26/24 06:30:12.759
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:30:12.765
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:30:12.767
  STEP: Performing setup for networking test in namespace pod-network-test-5701 @ 03/26/24 06:30:12.768
  STEP: creating a selector @ 03/26/24 06:30:12.768
  STEP: Creating the service pods in kubernetes @ 03/26/24 06:30:12.768
  Mar 26 06:30:12.768: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0326 06:30:12.775716      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:13.775911      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:14.776116      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:15.776340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:16.776469      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:17.777232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:18.777367      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:19.777820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:20.778128      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:21.778988      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:22.779657      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:23.779735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:24.779835      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 03/26/24 06:30:24.803
  E0326 06:30:25.780291      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:26.781255      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:30:26.810: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Mar 26 06:30:26.810: INFO: Breadth first check of 10.244.32.176 on host 192.168.132.11...
  Mar 26 06:30:26.811: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.79.93:9080/dial?request=hostname&protocol=udp&host=10.244.32.176&port=8081&tries=1'] Namespace:pod-network-test-5701 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 06:30:26.811: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 06:30:26.811: INFO: ExecWithOptions: Clientset creation
  Mar 26 06:30:26.811: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-5701/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.79.93%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.32.176%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Mar 26 06:30:26.854: INFO: Waiting for responses: map[]
  Mar 26 06:30:26.854: INFO: reached 10.244.32.176 after 0/1 tries
  Mar 26 06:30:26.854: INFO: Breadth first check of 10.244.79.108 on host 192.168.132.14...
  Mar 26 06:30:26.855: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.79.93:9080/dial?request=hostname&protocol=udp&host=10.244.79.108&port=8081&tries=1'] Namespace:pod-network-test-5701 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 06:30:26.855: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 06:30:26.856: INFO: ExecWithOptions: Clientset creation
  Mar 26 06:30:26.856: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-5701/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.79.93%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.79.108%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Mar 26 06:30:26.896: INFO: Waiting for responses: map[]
  Mar 26 06:30:26.896: INFO: reached 10.244.79.108 after 0/1 tries
  Mar 26 06:30:26.896: INFO: Breadth first check of 10.244.69.223 on host 192.168.132.15...
  Mar 26 06:30:26.897: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.79.93:9080/dial?request=hostname&protocol=udp&host=10.244.69.223&port=8081&tries=1'] Namespace:pod-network-test-5701 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 06:30:26.897: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 06:30:26.897: INFO: ExecWithOptions: Clientset creation
  Mar 26 06:30:26.897: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-5701/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.79.93%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.69.223%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Mar 26 06:30:26.936: INFO: Waiting for responses: map[]
  Mar 26 06:30:26.936: INFO: reached 10.244.69.223 after 0/1 tries
  Mar 26 06:30:26.936: INFO: Going to retry 0 out of 3 pods....
  Mar 26 06:30:26.936: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-5701" for this suite. @ 03/26/24 06:30:26.938
• [14.183 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]
test/e2e/apps/statefulset.go:745
  STEP: Creating a kubernetes client @ 03/26/24 06:30:26.943
  Mar 26 06:30:26.943: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename statefulset @ 03/26/24 06:30:26.944
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:30:26.949
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:30:26.95
  STEP: Creating service test in namespace statefulset-332 @ 03/26/24 06:30:26.952
  STEP: Looking for a node to schedule stateful set and pod @ 03/26/24 06:30:26.953
  STEP: Creating pod with conflicting port in namespace statefulset-332 @ 03/26/24 06:30:26.955
  STEP: Waiting until pod test-pod will start running in namespace statefulset-332 @ 03/26/24 06:30:26.959
  E0326 06:30:27.781357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:28.781462      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating statefulset with conflicting port in namespace statefulset-332 @ 03/26/24 06:30:28.964
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-332 @ 03/26/24 06:30:28.966
  Mar 26 06:30:28.972: INFO: Observed stateful pod in namespace: statefulset-332, name: ss-0, uid: f1b7e3b2-07bb-4ef4-bcae-33c49e4d00a6, status phase: Pending. Waiting for statefulset controller to delete.
  Mar 26 06:30:28.978: INFO: Observed stateful pod in namespace: statefulset-332, name: ss-0, uid: f1b7e3b2-07bb-4ef4-bcae-33c49e4d00a6, status phase: Failed. Waiting for statefulset controller to delete.
  Mar 26 06:30:28.984: INFO: Observed stateful pod in namespace: statefulset-332, name: ss-0, uid: f1b7e3b2-07bb-4ef4-bcae-33c49e4d00a6, status phase: Failed. Waiting for statefulset controller to delete.
  Mar 26 06:30:28.985: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-332
  STEP: Removing pod with conflicting port in namespace statefulset-332 @ 03/26/24 06:30:28.986
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-332 and will be in running state @ 03/26/24 06:30:28.994
  E0326 06:30:29.782397      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:30.782474      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:31.782824      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:32.783265      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:30:33.003: INFO: Deleting all statefulset in ns statefulset-332
  Mar 26 06:30:33.004: INFO: Scaling statefulset ss to 0
  E0326 06:30:33.783353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:34.783445      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:35.783524      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:36.783618      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:37.783719      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:38.783796      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:39.783888      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:40.784153      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:41.784239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:42.784322      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:30:43.010: INFO: Waiting for statefulset status.replicas updated to 0
  Mar 26 06:30:43.012: INFO: Deleting statefulset ss
  Mar 26 06:30:43.016: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-332" for this suite. @ 03/26/24 06:30:43.022
• [16.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]
test/e2e/apimachinery/webhook.go:572
  STEP: Creating a kubernetes client @ 03/26/24 06:30:43.03
  Mar 26 06:30:43.030: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename webhook @ 03/26/24 06:30:43.031
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:30:43.037
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:30:43.039
  STEP: Setting up server cert @ 03/26/24 06:30:43.049
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 03/26/24 06:30:43.356
  STEP: Deploying the webhook pod @ 03/26/24 06:30:43.361
  STEP: Wait for the deployment to be ready @ 03/26/24 06:30:43.366
  Mar 26 06:30:43.370: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0326 06:30:43.785755      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:44.785929      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 03/26/24 06:30:45.375
  STEP: Verifying the service has paired with the endpoint @ 03/26/24 06:30:45.38
  E0326 06:30:45.785996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:30:46.381: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 03/26/24 06:30:46.406
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 03/26/24 06:30:46.428
  STEP: Deleting the collection of validation webhooks @ 03/26/24 06:30:46.447
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 03/26/24 06:30:46.46
  Mar 26 06:30:46.463: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7800" for this suite. @ 03/26/24 06:30:46.478
  STEP: Destroying namespace "webhook-markers-9035" for this suite. @ 03/26/24 06:30:46.48
• [3.454 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
test/e2e/apimachinery/resource_quota.go:76
  STEP: Creating a kubernetes client @ 03/26/24 06:30:46.484
  Mar 26 06:30:46.484: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename resourcequota @ 03/26/24 06:30:46.484
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:30:46.49
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:30:46.492
  STEP: Counting existing ResourceQuota @ 03/26/24 06:30:46.494
  E0326 06:30:46.786454      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:47.786559      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:48.786631      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:49.787039      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:50.787280      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 03/26/24 06:30:51.496
  STEP: Ensuring resource quota status is calculated @ 03/26/24 06:30:51.498
  E0326 06:30:51.787348      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:52.787440      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:30:53.500: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1758" for this suite. @ 03/26/24 06:30:53.502
• [7.022 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]
test/e2e/kubectl/kubectl.go:1641
  STEP: Creating a kubernetes client @ 03/26/24 06:30:53.508
  Mar 26 06:30:53.508: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubectl @ 03/26/24 06:30:53.509
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:30:53.515
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:30:53.516
  STEP: creating Agnhost RC @ 03/26/24 06:30:53.518
  Mar 26 06:30:53.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-656 create -f -'
  Mar 26 06:30:53.655: INFO: stderr: ""
  Mar 26 06:30:53.655: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 03/26/24 06:30:53.655
  E0326 06:30:53.788483      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:30:54.657: INFO: Selector matched 1 pods for map[app:agnhost]
  Mar 26 06:30:54.657: INFO: Found 0 / 1
  E0326 06:30:54.788600      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:30:55.657: INFO: Selector matched 1 pods for map[app:agnhost]
  Mar 26 06:30:55.657: INFO: Found 1 / 1
  Mar 26 06:30:55.657: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 03/26/24 06:30:55.657
  Mar 26 06:30:55.658: INFO: Selector matched 1 pods for map[app:agnhost]
  Mar 26 06:30:55.658: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Mar 26 06:30:55.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-656 patch pod agnhost-primary-z54sn -p {"metadata":{"annotations":{"x":"y"}}}'
  Mar 26 06:30:55.705: INFO: stderr: ""
  Mar 26 06:30:55.705: INFO: stdout: "pod/agnhost-primary-z54sn patched\n"
  STEP: checking annotations @ 03/26/24 06:30:55.705
  Mar 26 06:30:55.707: INFO: Selector matched 1 pods for map[app:agnhost]
  Mar 26 06:30:55.707: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Mar 26 06:30:55.707: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-656" for this suite. @ 03/26/24 06:30:55.709
• [2.204 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:95
  STEP: Creating a kubernetes client @ 03/26/24 06:30:55.712
  Mar 26 06:30:55.712: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename var-expansion @ 03/26/24 06:30:55.712
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:30:55.717
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:30:55.72
  STEP: Creating a pod to test substitution in container's args @ 03/26/24 06:30:55.721
  E0326 06:30:55.789305      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:56.790275      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:57.791251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:30:58.791464      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:30:59.731
  Mar 26 06:30:59.732: INFO: Trying to get logs from node k8s-worker02 pod var-expansion-95ead0ec-a431-4d32-b61a-76423e8ad5f8 container dapi-container: <nil>
  STEP: delete the pod @ 03/26/24 06:30:59.735
  Mar 26 06:30:59.740: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6424" for this suite. @ 03/26/24 06:30:59.741
• [4.031 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:250
  STEP: Creating a kubernetes client @ 03/26/24 06:30:59.744
  Mar 26 06:30:59.744: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 06:30:59.744
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:30:59.75
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:30:59.751
  STEP: Creating a pod to test downward API volume plugin @ 03/26/24 06:30:59.753
  E0326 06:30:59.792310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:00.792885      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:01.793405      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:02.793526      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:31:03.762
  Mar 26 06:31:03.763: INFO: Trying to get logs from node k8s-worker02 pod downwardapi-volume-9f67a9fa-824a-4727-904e-5d2e94359360 container client-container: <nil>
  STEP: delete the pod @ 03/26/24 06:31:03.766
  Mar 26 06:31:03.773: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9816" for this suite. @ 03/26/24 06:31:03.775
• [4.034 seconds]
------------------------------
SSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:76
  STEP: Creating a kubernetes client @ 03/26/24 06:31:03.778
  Mar 26 06:31:03.778: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename var-expansion @ 03/26/24 06:31:03.778
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:31:03.786
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:31:03.787
  STEP: Creating a pod to test substitution in container's command @ 03/26/24 06:31:03.789
  E0326 06:31:03.793644      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:04.793843      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:05.794240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:06.794276      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:07.794346      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:31:07.798
  Mar 26 06:31:07.799: INFO: Trying to get logs from node k8s-worker02 pod var-expansion-6b952367-83b3-48cd-a57c-8eb22b2109b2 container dapi-container: <nil>
  STEP: delete the pod @ 03/26/24 06:31:07.801
  Mar 26 06:31:07.807: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-2518" for this suite. @ 03/26/24 06:31:07.809
• [4.034 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
test/e2e/network/service.go:2224
  STEP: Creating a kubernetes client @ 03/26/24 06:31:07.814
  Mar 26 06:31:07.814: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename services @ 03/26/24 06:31:07.815
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:31:07.821
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:31:07.822
  STEP: creating service in namespace services-4656 @ 03/26/24 06:31:07.823
  STEP: creating service affinity-nodeport-transition in namespace services-4656 @ 03/26/24 06:31:07.823
  STEP: creating replication controller affinity-nodeport-transition in namespace services-4656 @ 03/26/24 06:31:07.83
  I0326 06:31:07.832435      19 runners.go:197] Created replication controller with name: affinity-nodeport-transition, namespace: services-4656, replica count: 3
  E0326 06:31:08.794448      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:09.795522      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:10.795641      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0326 06:31:10.883896      19 runners.go:197] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Mar 26 06:31:10.888: INFO: Creating new exec pod
  E0326 06:31:11.795636      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:12.795992      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:13.797070      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:31:13.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-4656 exec execpod-affinitydcxnt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  Mar 26 06:31:13.990: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  Mar 26 06:31:13.990: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Mar 26 06:31:13.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-4656 exec execpod-affinitydcxnt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.7.126 80'
  Mar 26 06:31:14.073: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.7.126 80\nConnection to 10.96.7.126 80 port [tcp/http] succeeded!\n"
  Mar 26 06:31:14.073: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Mar 26 06:31:14.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-4656 exec execpod-affinitydcxnt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.132.14 31076'
  Mar 26 06:31:14.161: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.132.14 31076\nConnection to 192.168.132.14 31076 port [tcp/*] succeeded!\n"
  Mar 26 06:31:14.161: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Mar 26 06:31:14.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-4656 exec execpod-affinitydcxnt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.132.15 31076'
  Mar 26 06:31:14.241: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.132.15 31076\nConnection to 192.168.132.15 31076 port [tcp/*] succeeded!\n"
  Mar 26 06:31:14.241: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Mar 26 06:31:14.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-4656 exec execpod-affinitydcxnt -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.132.11:31076/ ; done'
  Mar 26 06:31:14.371: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n"
  Mar 26 06:31:14.371: INFO: stdout: "\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-t6w6c\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-t6w6c\naffinity-nodeport-transition-t6w6c\naffinity-nodeport-transition-qgfnb\naffinity-nodeport-transition-t6w6c\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-qgfnb\naffinity-nodeport-transition-t6w6c\naffinity-nodeport-transition-t6w6c\naffinity-nodeport-transition-t6w6c"
  Mar 26 06:31:14.371: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.371: INFO: Received response from host: affinity-nodeport-transition-t6w6c
  Mar 26 06:31:14.371: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.371: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.371: INFO: Received response from host: affinity-nodeport-transition-t6w6c
  Mar 26 06:31:14.371: INFO: Received response from host: affinity-nodeport-transition-t6w6c
  Mar 26 06:31:14.371: INFO: Received response from host: affinity-nodeport-transition-qgfnb
  Mar 26 06:31:14.371: INFO: Received response from host: affinity-nodeport-transition-t6w6c
  Mar 26 06:31:14.371: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.371: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.371: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.371: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.371: INFO: Received response from host: affinity-nodeport-transition-qgfnb
  Mar 26 06:31:14.371: INFO: Received response from host: affinity-nodeport-transition-t6w6c
  Mar 26 06:31:14.371: INFO: Received response from host: affinity-nodeport-transition-t6w6c
  Mar 26 06:31:14.371: INFO: Received response from host: affinity-nodeport-transition-t6w6c
  Mar 26 06:31:14.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-4656 exec execpod-affinitydcxnt -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.132.11:31076/ ; done'
  Mar 26 06:31:14.496: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.11:31076/\n"
  Mar 26 06:31:14.496: INFO: stdout: "\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-fltjx\naffinity-nodeport-transition-fltjx"
  Mar 26 06:31:14.496: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.496: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.496: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.496: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.496: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.496: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.496: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.496: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.496: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.496: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.496: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.496: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.496: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.496: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.496: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.496: INFO: Received response from host: affinity-nodeport-transition-fltjx
  Mar 26 06:31:14.496: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Mar 26 06:31:14.498: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-4656, will wait for the garbage collector to delete the pods @ 03/26/24 06:31:14.505
  Mar 26 06:31:14.559: INFO: Deleting ReplicationController affinity-nodeport-transition took: 2.142747ms
  Mar 26 06:31:14.661: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 101.108762ms
  E0326 06:31:14.797546      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:15.797990      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:16.798675      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-4656" for this suite. @ 03/26/24 06:31:17.27
• [9.457 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:194
  STEP: Creating a kubernetes client @ 03/26/24 06:31:17.273
  Mar 26 06:31:17.273: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename crd-publish-openapi @ 03/26/24 06:31:17.274
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:31:17.279
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:31:17.281
  Mar 26 06:31:17.282: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  E0326 06:31:17.799351      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 03/26/24 06:31:18.486
  Mar 26 06:31:18.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-4490 --namespace=crd-publish-openapi-4490 create -f -'
  E0326 06:31:18.799507      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:19.799639      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:20.799724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:31:20.836: INFO: stderr: ""
  Mar 26 06:31:20.836: INFO: stdout: "e2e-test-crd-publish-openapi-470-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Mar 26 06:31:20.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-4490 --namespace=crd-publish-openapi-4490 delete e2e-test-crd-publish-openapi-470-crds test-cr'
  Mar 26 06:31:20.877: INFO: stderr: ""
  Mar 26 06:31:20.877: INFO: stdout: "e2e-test-crd-publish-openapi-470-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  Mar 26 06:31:20.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-4490 --namespace=crd-publish-openapi-4490 apply -f -'
  Mar 26 06:31:20.968: INFO: stderr: ""
  Mar 26 06:31:20.968: INFO: stdout: "e2e-test-crd-publish-openapi-470-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Mar 26 06:31:20.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-4490 --namespace=crd-publish-openapi-4490 delete e2e-test-crd-publish-openapi-470-crds test-cr'
  Mar 26 06:31:21.009: INFO: stderr: ""
  Mar 26 06:31:21.009: INFO: stdout: "e2e-test-crd-publish-openapi-470-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 03/26/24 06:31:21.009
  Mar 26 06:31:21.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-4490 explain e2e-test-crd-publish-openapi-470-crds'
  Mar 26 06:31:21.095: INFO: stderr: ""
  Mar 26 06:31:21.095: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-470-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0326 06:31:21.800028      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:31:22.298: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4490" for this suite. @ 03/26/24 06:31:22.308
• [5.037 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]
test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 03/26/24 06:31:22.311
  Mar 26 06:31:22.311: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename daemonsets @ 03/26/24 06:31:22.311
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:31:22.317
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:31:22.319
  STEP: Creating simple DaemonSet "daemon-set" @ 03/26/24 06:31:22.327
  STEP: Check that daemon pods launch on every node of the cluster. @ 03/26/24 06:31:22.329
  Mar 26 06:31:22.332: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Mar 26 06:31:22.332: INFO: Node k8s-master01 is running 0 daemon pod, expected 1
  E0326 06:31:22.801103      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:31:23.336: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Mar 26 06:31:23.336: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 03/26/24 06:31:23.337
  Mar 26 06:31:23.345: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Mar 26 06:31:23.345: INFO: Node k8s-worker02 is running 0 daemon pod, expected 1
  E0326 06:31:23.801796      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:31:24.349: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Mar 26 06:31:24.349: INFO: Node k8s-worker02 is running 0 daemon pod, expected 1
  E0326 06:31:24.801892      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:31:25.349: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Mar 26 06:31:25.349: INFO: Node k8s-worker02 is running 0 daemon pod, expected 1
  E0326 06:31:25.802510      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:31:26.349: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Mar 26 06:31:26.349: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 03/26/24 06:31:26.35
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1621, will wait for the garbage collector to delete the pods @ 03/26/24 06:31:26.35
  Mar 26 06:31:26.404: INFO: Deleting DaemonSet.extensions daemon-set took: 2.54641ms
  Mar 26 06:31:26.505: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.805074ms
  E0326 06:31:26.803325      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:27.803422      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:28.803780      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:31:29.106: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Mar 26 06:31:29.106: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Mar 26 06:31:29.108: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"90819"},"items":null}

  Mar 26 06:31:29.109: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"90819"},"items":null}

  Mar 26 06:31:29.113: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1621" for this suite. @ 03/26/24 06:31:29.115
• [6.808 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:124
  STEP: Creating a kubernetes client @ 03/26/24 06:31:29.119
  Mar 26 06:31:29.119: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename pod-network-test @ 03/26/24 06:31:29.12
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:31:29.125
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:31:29.126
  STEP: Performing setup for networking test in namespace pod-network-test-1965 @ 03/26/24 06:31:29.127
  STEP: creating a selector @ 03/26/24 06:31:29.127
  STEP: Creating the service pods in kubernetes @ 03/26/24 06:31:29.127
  Mar 26 06:31:29.127: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0326 06:31:29.804797      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:30.804837      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:31.805772      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:32.805931      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:33.805973      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:34.806116      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:35.806171      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:36.806308      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:37.806943      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:38.807090      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:39.808046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:40.808122      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 03/26/24 06:31:41.157
  E0326 06:31:41.808221      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:42.808321      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:31:43.170: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Mar 26 06:31:43.170: INFO: Going to poll 10.244.32.131 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Mar 26 06:31:43.171: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.32.131 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1965 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 06:31:43.171: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 06:31:43.171: INFO: ExecWithOptions: Clientset creation
  Mar 26 06:31:43.171: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-1965/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.32.131+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0326 06:31:43.808619      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:31:44.210: INFO: Found all 1 expected endpoints: [netserver-0]
  Mar 26 06:31:44.210: INFO: Going to poll 10.244.79.66 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Mar 26 06:31:44.212: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.79.66 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1965 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 06:31:44.212: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 06:31:44.212: INFO: ExecWithOptions: Clientset creation
  Mar 26 06:31:44.212: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-1965/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.79.66+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0326 06:31:44.808951      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:31:45.257: INFO: Found all 1 expected endpoints: [netserver-1]
  Mar 26 06:31:45.257: INFO: Going to poll 10.244.69.254 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Mar 26 06:31:45.259: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.69.254 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1965 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 06:31:45.259: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 06:31:45.259: INFO: ExecWithOptions: Clientset creation
  Mar 26 06:31:45.259: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-1965/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.69.254+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0326 06:31:45.808971      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:31:46.296: INFO: Found all 1 expected endpoints: [netserver-2]
  Mar 26 06:31:46.296: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-1965" for this suite. @ 03/26/24 06:31:46.298
• [17.181 seconds]
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 03/26/24 06:31:46.3
  Mar 26 06:31:46.300: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename containers @ 03/26/24 06:31:46.301
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:31:46.308
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:31:46.309
  STEP: Creating a pod to test override command @ 03/26/24 06:31:46.311
  E0326 06:31:46.810015      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:47.811044      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:48.811420      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:49.811499      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:31:50.32
  Mar 26 06:31:50.321: INFO: Trying to get logs from node k8s-worker02 pod client-containers-e90a0940-a941-44d1-afb1-fb065ada49ae container agnhost-container: <nil>
  STEP: delete the pod @ 03/26/24 06:31:50.324
  Mar 26 06:31:50.329: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-9320" for this suite. @ 03/26/24 06:31:50.33
• [4.033 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance]
test/e2e/apps/rc.go:103
  STEP: Creating a kubernetes client @ 03/26/24 06:31:50.333
  Mar 26 06:31:50.333: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename replication-controller @ 03/26/24 06:31:50.334
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:31:50.34
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:31:50.341
  STEP: Given a ReplicationController is created @ 03/26/24 06:31:50.343
  STEP: When the matched label of one of its pods change @ 03/26/24 06:31:50.345
  Mar 26 06:31:50.346: INFO: Pod name pod-release: Found 0 pods out of 1
  E0326 06:31:50.812448      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:51.812468      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:52.812576      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:53.812592      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:54.812741      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:31:55.349: INFO: Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 03/26/24 06:31:55.354
  E0326 06:31:55.813039      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:31:56.359: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-4716" for this suite. @ 03/26/24 06:31:56.361
• [6.030 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:167
  STEP: Creating a kubernetes client @ 03/26/24 06:31:56.364
  Mar 26 06:31:56.364: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename emptydir @ 03/26/24 06:31:56.364
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:31:56.371
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:31:56.372
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 03/26/24 06:31:56.374
  E0326 06:31:56.813802      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:57.813936      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:31:58.38
  Mar 26 06:31:58.382: INFO: Trying to get logs from node k8s-worker01 pod pod-c0ba6bbc-1771-441f-99c8-6fbc8948383a container test-container: <nil>
  STEP: delete the pod @ 03/26/24 06:31:58.384
  Mar 26 06:31:58.389: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3819" for this suite. @ 03/26/24 06:31:58.39
• [2.029 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:208
  STEP: Creating a kubernetes client @ 03/26/24 06:31:58.395
  Mar 26 06:31:58.395: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 06:31:58.396
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:31:58.402
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:31:58.403
  STEP: Creating a pod to test downward API volume plugin @ 03/26/24 06:31:58.404
  E0326 06:31:58.814222      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:31:59.814437      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:32:00.411
  Mar 26 06:32:00.413: INFO: Trying to get logs from node k8s-worker01 pod downwardapi-volume-75bf6605-fe02-4b00-a35d-32aed52a2328 container client-container: <nil>
  STEP: delete the pod @ 03/26/24 06:32:00.415
  Mar 26 06:32:00.420: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3434" for this suite. @ 03/26/24 06:32:00.422
• [2.029 seconds]
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:131
  STEP: Creating a kubernetes client @ 03/26/24 06:32:00.424
  Mar 26 06:32:00.424: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 06:32:00.425
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:32:00.431
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:32:00.432
  STEP: Creating the pod @ 03/26/24 06:32:00.434
  E0326 06:32:00.814559      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:01.814672      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:02.814651      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:32:02.951: INFO: Successfully updated pod "labelsupdate2371e668-ace3-4f7b-bfbf-a5fb86024ef8"
  E0326 06:32:03.815347      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:04.815419      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:32:04.958: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8923" for this suite. @ 03/26/24 06:32:04.96
• [4.538 seconds]
------------------------------
S
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance]
test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 03/26/24 06:32:04.962
  Mar 26 06:32:04.962: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename deployment @ 03/26/24 06:32:04.963
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:32:04.968
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:32:04.97
  Mar 26 06:32:04.971: INFO: Creating deployment "webserver-deployment"
  Mar 26 06:32:04.973: INFO: Waiting for observed generation 1
  E0326 06:32:05.815534      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:06.815672      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:32:06.978: INFO: Waiting for all required pods to come up
  Mar 26 06:32:06.980: INFO: Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 03/26/24 06:32:06.98
  Mar 26 06:32:06.980: INFO: Waiting for deployment "webserver-deployment" to complete
  Mar 26 06:32:06.982: INFO: Updating deployment "webserver-deployment" with a non-existent image
  Mar 26 06:32:06.986: INFO: Updating deployment webserver-deployment
  Mar 26 06:32:06.986: INFO: Waiting for observed generation 2
  E0326 06:32:07.816046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:08.816304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:32:08.990: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  Mar 26 06:32:08.991: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
  Mar 26 06:32:08.992: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Mar 26 06:32:08.995: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  Mar 26 06:32:08.995: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
  Mar 26 06:32:08.996: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Mar 26 06:32:08.998: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  Mar 26 06:32:08.998: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
  Mar 26 06:32:09.003: INFO: Updating deployment webserver-deployment
  Mar 26 06:32:09.003: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  Mar 26 06:32:09.006: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
  Mar 26 06:32:09.007: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
  Mar 26 06:32:09.011: INFO: Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6fdea60b-915d-446b-a1de-ad3743f67c50",
      ResourceVersion: (string) (len=5) "91448",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031524,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031528,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031524,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=59) "ReplicaSet \"webserver-deployment-9b4f5bf69\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Mar 26 06:32:09.025: INFO: New ReplicaSet "webserver-deployment-9b4f5bf69" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6a44c596-1691-43e0-b601-30bb034b7784",
      ResourceVersion: (string) (len=5) "91451",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031526,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "6fdea60b-915d-446b-a1de-ad3743f67c50",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 36 66 64 65 61 36  30 62 2d 39 31 35 64 2d  |\"6fdea60b-915d-|
              00000120  34 34 36 62 2d 61 31 64  65 2d 61 64 33 37 34 33  |446b-a1de-ad3743|
              00000130  66 36 37 63 35 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |f67c50\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Mar 26 06:32:09.025: INFO: All old ReplicaSets of Deployment "webserver-deployment":
  Mar 26 06:32:09.025: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-788fbd4fc4",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5321f99d-b86a-4eff-9357-5b64a81419a7",
      ResourceVersion: (string) (len=5) "91449",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031524,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "6fdea60b-915d-446b-a1de-ad3743f67c50",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 36 66 64 65 61 36  30 62 2d 39 31 35 64 2d  |\"6fdea60b-915d-|
              00000120  34 34 36 62 2d 61 31 64  65 2d 61 64 33 37 34 33  |446b-a1de-ad3743|
              00000130  66 36 37 63 35 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |f67c50\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Mar 26 06:32:09.039: INFO: Pod "webserver-deployment-788fbd4fc4-4ldn2" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-788fbd4fc4-4ldn2",
      GenerateName: (string) (len=32) "webserver-deployment-788fbd4fc4-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ad9a303d-46cd-418a-b28e-ddfac9deca85",
      ResourceVersion: (string) (len=5) "91461",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031529,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-788fbd4fc4",
          UID: (types.UID) (len=36) "5321f99d-b86a-4eff-9357-5b64a81419a7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 33  32 31 66 39 39 64 2d 62  |d\":\"5321f99d-b|
              00000090  38 36 61 2d 34 65 66 66  2d 39 33 35 37 2d 35 62  |86a-4eff-9357-5b|
              000000a0  36 34 61 38 31 34 31 39  61 37 5c 22 7d 22 3a 7b  |64a81419a7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-zlqv6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-zlqv6",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.040: INFO: Pod "webserver-deployment-788fbd4fc4-4nzf5" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-788fbd4fc4-4nzf5",
      GenerateName: (string) (len=32) "webserver-deployment-788fbd4fc4-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a298ebfb-4ad2-43a8-bf05-55d224972088",
      ResourceVersion: (string) (len=5) "91469",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031529,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-788fbd4fc4",
          UID: (types.UID) (len=36) "5321f99d-b86a-4eff-9357-5b64a81419a7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 33  32 31 66 39 39 64 2d 62  |d\":\"5321f99d-b|
              00000090  38 36 61 2d 34 65 66 66  2d 39 33 35 37 2d 35 62  |86a-4eff-9357-5b|
              000000a0  36 34 61 38 31 34 31 39  61 37 5c 22 7d 22 3a 7b  |64a81419a7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jfgxr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jfgxr",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.041: INFO: Pod "webserver-deployment-788fbd4fc4-5bqgs" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-788fbd4fc4-5bqgs",
      GenerateName: (string) (len=32) "webserver-deployment-788fbd4fc4-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2011c309-e3a7-4798-a014-aceabb531d14",
      ResourceVersion: (string) (len=5) "91328",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031524,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "0752ac6de86104494087534b8e105b5ace96405260fe7dea84a82f6fa8b326b0",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "10.244.79.101/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "10.244.79.101/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-788fbd4fc4",
          UID: (types.UID) (len=36) "5321f99d-b86a-4eff-9357-5b64a81419a7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031524,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 33  32 31 66 39 39 64 2d 62  |d\":\"5321f99d-b|
              00000090  38 36 61 2d 34 65 66 66  2d 39 33 35 37 2d 35 62  |86a-4eff-9357-5b|
              000000a0  36 34 61 38 31 34 31 39  61 37 5c 22 7d 22 3a 7b  |64a81419a7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031525,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 34 34 2e 37  39 2e 31 30 31 5c 22 7d  |10.244.79.101\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-grc77",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-grc77",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031524,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031524,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.14",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.244.79.101",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.244.79.101"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031524,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63847031525,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          ImageID: (string) (len=120) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://549218c0f17227200346b18986b4435f139cbdb086873b740e8cf795daa1c8df",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.042: INFO: Pod "webserver-deployment-788fbd4fc4-7hkr2" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-788fbd4fc4-7hkr2",
      GenerateName: (string) (len=32) "webserver-deployment-788fbd4fc4-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "915aff65-bd2d-4467-907e-b7a44fc3afe5",
      ResourceVersion: (string) (len=5) "91337",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031524,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "3cb8bca9e7fab7480960a6f417a4bed51a603c87e92030d911241ab989f5bae3",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "10.244.32.190/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "10.244.32.190/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-788fbd4fc4",
          UID: (types.UID) (len=36) "5321f99d-b86a-4eff-9357-5b64a81419a7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031524,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 33  32 31 66 39 39 64 2d 62  |d\":\"5321f99d-b|
              00000090  38 36 61 2d 34 65 66 66  2d 39 33 35 37 2d 35 62  |86a-4eff-9357-5b|
              000000a0  36 34 61 38 31 34 31 39  61 37 5c 22 7d 22 3a 7b  |64a81419a7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031525,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 34 34 2e 33  32 2e 31 39 30 5c 22 7d  |10.244.32.190\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-gjkv7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-gjkv7",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-master01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031525,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031524,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.11",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.244.32.190",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.244.32.190"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031525,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63847031525,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          ImageID: (string) (len=120) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://ac3600cce9e99132ac2fa9646b029556ec8ab0ce8974628a57a2eafc19ed13e9",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.043: INFO: Pod "webserver-deployment-788fbd4fc4-7mzf2" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-788fbd4fc4-7mzf2",
      GenerateName: (string) (len=32) "webserver-deployment-788fbd4fc4-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a8f9dd72-1245-4a4d-b750-7e4a1b6d5052",
      ResourceVersion: (string) (len=5) "91468",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031529,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-788fbd4fc4",
          UID: (types.UID) (len=36) "5321f99d-b86a-4eff-9357-5b64a81419a7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 33  32 31 66 39 39 64 2d 62  |d\":\"5321f99d-b|
              00000090  38 36 61 2d 34 65 66 66  2d 39 33 35 37 2d 35 62  |86a-4eff-9357-5b|
              000000a0  36 34 61 38 31 34 31 39  61 37 5c 22 7d 22 3a 7b  |64a81419a7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-82j9k",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-82j9k",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.044: INFO: Pod "webserver-deployment-788fbd4fc4-dtmj4" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-788fbd4fc4-dtmj4",
      GenerateName: (string) (len=32) "webserver-deployment-788fbd4fc4-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ffb8b8b5-972c-44f7-9495-5bcd46fcd233",
      ResourceVersion: (string) (len=5) "91338",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031524,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "0e463efe2a2e09a3408b27ce3206cd854b2b8dd213a63dc982c69d13bf5906fb",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "10.244.32.150/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "10.244.32.150/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-788fbd4fc4",
          UID: (types.UID) (len=36) "5321f99d-b86a-4eff-9357-5b64a81419a7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031524,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 33  32 31 66 39 39 64 2d 62  |d\":\"5321f99d-b|
              00000090  38 36 61 2d 34 65 66 66  2d 39 33 35 37 2d 35 62  |86a-4eff-9357-5b|
              000000a0  36 34 61 38 31 34 31 39  61 37 5c 22 7d 22 3a 7b  |64a81419a7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031525,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 34 34 2e 33  32 2e 31 35 30 5c 22 7d  |10.244.32.150\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-msj97",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-msj97",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-master01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031524,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031524,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.11",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.244.32.150",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.244.32.150"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031524,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63847031525,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          ImageID: (string) (len=120) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://effdce6ac9215b17898f7c0ea0f5c34a7260eedb28b88269dd24bf728f5fa44a",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.045: INFO: Pod "webserver-deployment-788fbd4fc4-g449w" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-788fbd4fc4-g449w",
      GenerateName: (string) (len=32) "webserver-deployment-788fbd4fc4-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "817b74d1-5470-4359-ac6d-0adbdc459d9f",
      ResourceVersion: (string) (len=5) "91466",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031529,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-788fbd4fc4",
          UID: (types.UID) (len=36) "5321f99d-b86a-4eff-9357-5b64a81419a7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 33  32 31 66 39 39 64 2d 62  |d\":\"5321f99d-b|
              00000090  38 36 61 2d 34 65 66 66  2d 39 33 35 37 2d 35 62  |86a-4eff-9357-5b|
              000000a0  36 34 61 38 31 34 31 39  61 37 5c 22 7d 22 3a 7b  |64a81419a7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=482) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000001e0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-p4kns",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-p4kns",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.15",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031529,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.047: INFO: Pod "webserver-deployment-788fbd4fc4-hdt9m" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-788fbd4fc4-hdt9m",
      GenerateName: (string) (len=32) "webserver-deployment-788fbd4fc4-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "dc69e4de-f432-4f0e-af4f-4233e5d3b8ba",
      ResourceVersion: (string) (len=5) "91470",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031529,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-788fbd4fc4",
          UID: (types.UID) (len=36) "5321f99d-b86a-4eff-9357-5b64a81419a7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 33  32 31 66 39 39 64 2d 62  |d\":\"5321f99d-b|
              00000090  38 36 61 2d 34 65 66 66  2d 39 33 35 37 2d 35 62  |86a-4eff-9357-5b|
              000000a0  36 34 61 38 31 34 31 39  61 37 5c 22 7d 22 3a 7b  |64a81419a7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-65nlr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-65nlr",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.047: INFO: Pod "webserver-deployment-788fbd4fc4-jmb82" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-788fbd4fc4-jmb82",
      GenerateName: (string) (len=32) "webserver-deployment-788fbd4fc4-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fb7c05ce-4999-485d-b966-ab78098fb30d",
      ResourceVersion: (string) (len=5) "91333",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031524,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "10.244.79.121/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "d0654e86a2b0cc5157f7d98ecb97af9c02896c3f17d291b8cde90c7ddb54578f",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "10.244.79.121/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-788fbd4fc4",
          UID: (types.UID) (len=36) "5321f99d-b86a-4eff-9357-5b64a81419a7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031524,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 33  32 31 66 39 39 64 2d 62  |d\":\"5321f99d-b|
              00000090  38 36 61 2d 34 65 66 66  2d 39 33 35 37 2d 35 62  |86a-4eff-9357-5b|
              000000a0  36 34 61 38 31 34 31 39  61 37 5c 22 7d 22 3a 7b  |64a81419a7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031525,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 34 34 2e 37  39 2e 31 32 31 5c 22 7d  |10.244.79.121\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9khm7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9khm7",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031525,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031524,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.14",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.244.79.121",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.244.79.121"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031525,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63847031525,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          ImageID: (string) (len=120) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://dd9c9c047f7b98e7e9b257b7d999e85f85a5f2514c985e77d3b8d8b02c53e1d4",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.048: INFO: Pod "webserver-deployment-788fbd4fc4-lkvtg" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-788fbd4fc4-lkvtg",
      GenerateName: (string) (len=32) "webserver-deployment-788fbd4fc4-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "907911d3-1df9-4b55-adf7-ba82121e4c00",
      ResourceVersion: (string) (len=5) "91319",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031524,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "86983265d24c5859cec2b339713a0d23c4965ecf8f2a53c3a7a9b5d0c2182d46",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "10.244.69.236/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "10.244.69.236/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-788fbd4fc4",
          UID: (types.UID) (len=36) "5321f99d-b86a-4eff-9357-5b64a81419a7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031524,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 33  32 31 66 39 39 64 2d 62  |d\":\"5321f99d-b|
              00000090  38 36 61 2d 34 65 66 66  2d 39 33 35 37 2d 35 62  |86a-4eff-9357-5b|
              000000a0  36 34 61 38 31 34 31 39  61 37 5c 22 7d 22 3a 7b  |64a81419a7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031525,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 34 34 2e 36  39 2e 32 33 36 5c 22 7d  |10.244.69.236\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4dz6q",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4dz6q",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031525,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031524,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.15",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.244.69.236",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.244.69.236"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031525,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63847031525,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          ImageID: (string) (len=120) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://3fdf198c4fcd0737e25c55a3dd0e44ad75337d78c63d8cefdc24a744351a7963",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.049: INFO: Pod "webserver-deployment-788fbd4fc4-nwsdc" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-788fbd4fc4-nwsdc",
      GenerateName: (string) (len=32) "webserver-deployment-788fbd4fc4-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "48ac3498-d828-45b5-87e9-9d9bcc576241",
      ResourceVersion: (string) (len=5) "91472",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031529,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-788fbd4fc4",
          UID: (types.UID) (len=36) "5321f99d-b86a-4eff-9357-5b64a81419a7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 33  32 31 66 39 39 64 2d 62  |d\":\"5321f99d-b|
              00000090  38 36 61 2d 34 65 66 66  2d 39 33 35 37 2d 35 62  |86a-4eff-9357-5b|
              000000a0  36 34 61 38 31 34 31 39  61 37 5c 22 7d 22 3a 7b  |64a81419a7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-87vwd",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-87vwd",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.049: INFO: Pod "webserver-deployment-788fbd4fc4-p6sjd" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-788fbd4fc4-p6sjd",
      GenerateName: (string) (len=32) "webserver-deployment-788fbd4fc4-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d63a7225-8302-472b-8722-94299f05ced9",
      ResourceVersion: (string) (len=5) "91342",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031524,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "d2b846651ea1d7315278303830eb4eff74c232157c030b590db8aaea9e1a90f1",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "10.244.32.173/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "10.244.32.173/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-788fbd4fc4",
          UID: (types.UID) (len=36) "5321f99d-b86a-4eff-9357-5b64a81419a7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031524,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 33  32 31 66 39 39 64 2d 62  |d\":\"5321f99d-b|
              00000090  38 36 61 2d 34 65 66 66  2d 39 33 35 37 2d 35 62  |86a-4eff-9357-5b|
              000000a0  36 34 61 38 31 34 31 39  61 37 5c 22 7d 22 3a 7b  |64a81419a7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031525,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 34 34 2e 33  32 2e 31 37 33 5c 22 7d  |10.244.32.173\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-pnjg5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-pnjg5",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-master01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031525,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031524,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.11",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.244.32.173",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.244.32.173"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031525,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63847031525,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          ImageID: (string) (len=120) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://f02271fbd208076ba99d9f45fd896c2fa53718fa13e1fbd3006c731680ecbbc2",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.050: INFO: Pod "webserver-deployment-788fbd4fc4-ps8rt" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-788fbd4fc4-ps8rt",
      GenerateName: (string) (len=32) "webserver-deployment-788fbd4fc4-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0f79d8b9-c173-47f9-8e83-b6e05865b2c8",
      ResourceVersion: (string) (len=5) "91321",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031524,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "49543d19b70c973d2f34b72c95080c681fdadd99dff3b6503c32e298f233a4b2",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "10.244.69.240/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "10.244.69.240/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-788fbd4fc4",
          UID: (types.UID) (len=36) "5321f99d-b86a-4eff-9357-5b64a81419a7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031524,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 33  32 31 66 39 39 64 2d 62  |d\":\"5321f99d-b|
              00000090  38 36 61 2d 34 65 66 66  2d 39 33 35 37 2d 35 62  |86a-4eff-9357-5b|
              000000a0  36 34 61 38 31 34 31 39  61 37 5c 22 7d 22 3a 7b  |64a81419a7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031525,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 34 34 2e 36  39 2e 32 34 30 5c 22 7d  |10.244.69.240\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-khv6n",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-khv6n",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031525,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031525,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.15",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.244.69.240",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.244.69.240"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031525,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63847031525,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          ImageID: (string) (len=120) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://6f746e21ce4180f2348f55eb7cd5a5e06f7b8506cc1fd7708894a089df38ed16",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.051: INFO: Pod "webserver-deployment-788fbd4fc4-xtz8x" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-788fbd4fc4-xtz8x",
      GenerateName: (string) (len=32) "webserver-deployment-788fbd4fc4-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e94fceee-7816-41b3-982e-cb9b7948c268",
      ResourceVersion: (string) (len=5) "91471",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031529,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-788fbd4fc4",
          UID: (types.UID) (len=36) "5321f99d-b86a-4eff-9357-5b64a81419a7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 33  32 31 66 39 39 64 2d 62  |d\":\"5321f99d-b|
              00000090  38 36 61 2d 34 65 66 66  2d 39 33 35 37 2d 35 62  |86a-4eff-9357-5b|
              000000a0  36 34 61 38 31 34 31 39  61 37 5c 22 7d 22 3a 7b  |64a81419a7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dnmsb",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dnmsb",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.052: INFO: Pod "webserver-deployment-788fbd4fc4-zs8b6" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-788fbd4fc4-zs8b6",
      GenerateName: (string) (len=32) "webserver-deployment-788fbd4fc4-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "deb5c562-7d18-40ac-a440-402c75b71ced",
      ResourceVersion: (string) (len=5) "91330",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031524,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "f0599b73f9d755f396b7c66f49d5f61c27a206ed226b2397bc49de3e434fa34a",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=15) "10.244.79.82/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=15) "10.244.79.82/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-788fbd4fc4",
          UID: (types.UID) (len=36) "5321f99d-b86a-4eff-9357-5b64a81419a7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031524,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 33  32 31 66 39 39 64 2d 62  |d\":\"5321f99d-b|
              00000090  38 36 61 2d 34 65 66 66  2d 39 33 35 37 2d 35 62  |86a-4eff-9357-5b|
              000000a0  36 34 61 38 31 34 31 39  61 37 5c 22 7d 22 3a 7b  |64a81419a7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031525,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=519) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 34 34 2e 37  39 2e 38 32 5c 22 7d 22  |10.244.79.82\"}"|
              000001e0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              000001f0  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000200  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-h52vb",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-h52vb",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031525,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031524,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.14",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=12) "10.244.79.82",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.79.82"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031525,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63847031525,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          ImageID: (string) (len=120) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://2ccdab70eb9842dabd4f4cf355608fd3d1becbe1289953e68d1e87e6ab8e5939",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.053: INFO: Pod "webserver-deployment-9b4f5bf69-bqtqb" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-bqtqb",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "39be731f-1832-45fe-a27b-64c3ed45c1fe",
      ResourceVersion: (string) (len=5) "91426",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031527,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "74f79bea3bd380155c4f0e50911284ee1f397359f1b7580483b6858fb6370567",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "10.244.69.218/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "10.244.69.218/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "6a44c596-1691-43e0-b601-30bb034b7784",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 61  34 34 63 35 39 36 2d 31  |d\":\"6a44c596-1|
              00000090  36 39 31 2d 34 33 65 30  2d 62 36 30 31 2d 33 30  |691-43e0-b601-30|
              000000a0  62 62 30 33 34 62 37 37  38 34 5c 22 7d 22 3a 7b  |bb034b7784\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031528,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 70 6f 64 49 50  22 3a 7b 7d 2c 22 66 3a  |"f:podIP":{},"f:|
              000001e0  70 6f 64 49 50 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |podIPs":{".":{},|
              000001f0  22 6b 3a 7b 5c 22 69 70  5c 22 3a 5c 22 31 30 2e  |"k:{\"ip\":\"10.|
              00000200  32 34 34 2e 36 39 2e 32  31 38 5c 22 7d 22 3a 7b  |244.69.218\"}":{|
              00000210  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000220  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7tzpp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7tzpp",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.15",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.244.69.218",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.244.69.218"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031527,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ImageInspectError",
              Message: (string) (len=214) "Failed to inspect image \"webserver:404\": rpc error: code = Unknown desc = short-name \"webserver:404\" did not resolve to an alias and no unqualified-search registries are defined in \"/etc/containers/registries.conf\""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.054: INFO: Pod "webserver-deployment-9b4f5bf69-d4t27" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-d4t27",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0c2159dc-c6f0-497d-bd65-dfa1106f6abe",
      ResourceVersion: (string) (len=5) "91473",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031529,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "6a44c596-1691-43e0-b601-30bb034b7784",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 61  34 34 63 35 39 36 2d 31  |d\":\"6a44c596-1|
              00000090  36 39 31 2d 34 33 65 30  2d 62 36 30 31 2d 33 30  |691-43e0-b601-30|
              000000a0  62 62 30 33 34 62 37 37  38 34 5c 22 7d 22 3a 7b  |bb034b7784\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-cnw4r",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-cnw4r",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.054: INFO: Pod "webserver-deployment-9b4f5bf69-dzj4z" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-dzj4z",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "826dd982-08cb-4aa5-8398-ff7fe5a3ad06",
      ResourceVersion: (string) (len=5) "91463",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031529,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "6a44c596-1691-43e0-b601-30bb034b7784",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 61  34 34 63 35 39 36 2d 31  |d\":\"6a44c596-1|
              00000090  36 39 31 2d 34 33 65 30  2d 62 36 30 31 2d 33 30  |691-43e0-b601-30|
              000000a0  62 62 30 33 34 62 37 37  38 34 5c 22 7d 22 3a 7b  |bb034b7784\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mwbkw",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mwbkw",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.055: INFO: Pod "webserver-deployment-9b4f5bf69-j5pbl" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-j5pbl",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fae5bc6b-4fda-4586-9349-9a8826194627",
      ResourceVersion: (string) (len=5) "91434",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031527,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "c0e4c91017643c89d434ec4127e41c0d5d8a5c31a39fe756ec9e7f09712b0af1",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=15) "10.244.79.98/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=15) "10.244.79.98/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "6a44c596-1691-43e0-b601-30bb034b7784",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 61  34 34 63 35 39 36 2d 31  |d\":\"6a44c596-1|
              00000090  36 39 31 2d 34 33 65 30  2d 62 36 30 31 2d 33 30  |691-43e0-b601-30|
              000000a0  62 62 30 33 34 62 37 37  38 34 5c 22 7d 22 3a 7b  |bb034b7784\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031528,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=564) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 70 6f 64 49 50  22 3a 7b 7d 2c 22 66 3a  |"f:podIP":{},"f:|
              000001e0  70 6f 64 49 50 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |podIPs":{".":{},|
              000001f0  22 6b 3a 7b 5c 22 69 70  5c 22 3a 5c 22 31 30 2e  |"k:{\"ip\":\"10.|
              00000200  32 34 34 2e 37 39 2e 39  38 5c 22 7d 22 3a 7b 22  |244.79.98\"}":{"|
              00000210  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000220  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000230  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jcz9x",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jcz9x",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.14",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=12) "10.244.79.98",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.79.98"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031527,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ImageInspectError",
              Message: (string) (len=214) "Failed to inspect image \"webserver:404\": rpc error: code = Unknown desc = short-name \"webserver:404\" did not resolve to an alias and no unqualified-search registries are defined in \"/etc/containers/registries.conf\""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.057: INFO: Pod "webserver-deployment-9b4f5bf69-kljxq" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-kljxq",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "77fc071c-86d0-4c98-a86a-57565d43bdc4",
      ResourceVersion: (string) (len=5) "91464",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031529,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "6a44c596-1691-43e0-b601-30bb034b7784",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 61  34 34 63 35 39 36 2d 31  |d\":\"6a44c596-1|
              00000090  36 39 31 2d 34 33 65 30  2d 62 36 30 31 2d 33 30  |691-43e0-b601-30|
              000000a0  62 62 30 33 34 62 37 37  38 34 5c 22 7d 22 3a 7b  |bb034b7784\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-s9w65",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-s9w65",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.057: INFO: Pod "webserver-deployment-9b4f5bf69-lmhpv" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-lmhpv",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ec83d1e7-3c79-49e5-b3b6-841b386dec47",
      ResourceVersion: (string) (len=5) "91444",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031526,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "10.244.32.169/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "10.244.32.169/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "e63e0fd9f895eca66d91cecba88525626b35c57b97a878324863b0acfeff6996"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "6a44c596-1691-43e0-b601-30bb034b7784",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 61  34 34 63 35 39 36 2d 31  |d\":\"6a44c596-1|
              00000090  36 39 31 2d 34 33 65 30  2d 62 36 30 31 2d 33 30  |691-43e0-b601-30|
              000000a0  62 62 30 33 34 62 37 37  38 34 5c 22 7d 22 3a 7b  |bb034b7784\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031528,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 70 6f 64 49 50  22 3a 7b 7d 2c 22 66 3a  |"f:podIP":{},"f:|
              000001e0  70 6f 64 49 50 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |podIPs":{".":{},|
              000001f0  22 6b 3a 7b 5c 22 69 70  5c 22 3a 5c 22 31 30 2e  |"k:{\"ip\":\"10.|
              00000200  32 34 34 2e 33 32 2e 31  36 39 5c 22 7d 22 3a 7b  |244.32.169\"}":{|
              00000210  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000220  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-97bn5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-97bn5",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-master01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.11",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.244.32.169",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.244.32.169"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031526,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ImageInspectError",
              Message: (string) (len=214) "Failed to inspect image \"webserver:404\": rpc error: code = Unknown desc = short-name \"webserver:404\" did not resolve to an alias and no unqualified-search registries are defined in \"/etc/containers/registries.conf\""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.058: INFO: Pod "webserver-deployment-9b4f5bf69-qlb6t" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-qlb6t",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9a9e1c83-8a21-49e4-b0c4-d52f8d496b56",
      ResourceVersion: (string) (len=5) "91462",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031529,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "6a44c596-1691-43e0-b601-30bb034b7784",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 61  34 34 63 35 39 36 2d 31  |d\":\"6a44c596-1|
              00000090  36 39 31 2d 34 33 65 30  2d 62 36 30 31 2d 33 30  |691-43e0-b601-30|
              000000a0  62 62 30 33 34 62 37 37  38 34 5c 22 7d 22 3a 7b  |bb034b7784\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-z9v2p",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-z9v2p",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-master01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031529,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.060: INFO: Pod "webserver-deployment-9b4f5bf69-sq2jn" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-sq2jn",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5bb7069b-3f91-4786-baa8-8fd9ec27c504",
      ResourceVersion: (string) (len=5) "91424",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031526,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "10.244.69.222/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "10.244.69.222/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "044fc1d1be8b5366f6db216f7ba522a0b8d6d41f8ee07bfbd0174ceea9ead40a"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "6a44c596-1691-43e0-b601-30bb034b7784",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 61  34 34 63 35 39 36 2d 31  |d\":\"6a44c596-1|
              00000090  36 39 31 2d 34 33 65 30  2d 62 36 30 31 2d 33 30  |691-43e0-b601-30|
              000000a0  62 62 30 33 34 62 37 37  38 34 5c 22 7d 22 3a 7b  |bb034b7784\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031528,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 70 6f 64 49 50  22 3a 7b 7d 2c 22 66 3a  |"f:podIP":{},"f:|
              000001e0  70 6f 64 49 50 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |podIPs":{".":{},|
              000001f0  22 6b 3a 7b 5c 22 69 70  5c 22 3a 5c 22 31 30 2e  |"k:{\"ip\":\"10.|
              00000200  32 34 34 2e 36 39 2e 32  32 32 5c 22 7d 22 3a 7b  |244.69.222\"}":{|
              00000210  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000220  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-76b9g",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-76b9g",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.15",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.244.69.222",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.244.69.222"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031526,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ImageInspectError",
              Message: (string) (len=214) "Failed to inspect image \"webserver:404\": rpc error: code = Unknown desc = short-name \"webserver:404\" did not resolve to an alias and no unqualified-search registries are defined in \"/etc/containers/registries.conf\""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.060: INFO: Pod "webserver-deployment-9b4f5bf69-tsr9q" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-tsr9q",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-5711",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7ee91bfa-9d24-433a-91ec-fc65d4aec16d",
      ResourceVersion: (string) (len=5) "91438",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031526,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "cd58d079e8acfb8b46a947d41ddb481d0ea01b8d49fc980812f5e1dc84173d24",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "10.244.79.109/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "10.244.79.109/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "6a44c596-1691-43e0-b601-30bb034b7784",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 61  34 34 63 35 39 36 2d 31  |d\":\"6a44c596-1|
              00000090  36 39 31 2d 34 33 65 30  2d 62 36 30 31 2d 33 30  |691-43e0-b601-30|
              000000a0  62 62 30 33 34 62 37 37  38 34 5c 22 7d 22 3a 7b  |bb034b7784\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031528,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 70 6f 64 49 50  22 3a 7b 7d 2c 22 66 3a  |"f:podIP":{},"f:|
              000001e0  70 6f 64 49 50 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |podIPs":{".":{},|
              000001f0  22 6b 3a 7b 5c 22 69 70  5c 22 3a 5c 22 31 30 2e  |"k:{\"ip\":\"10.|
              00000200  32 34 34 2e 37 39 2e 31  30 39 5c 22 7d 22 3a 7b  |244.79.109\"}":{|
              00000210  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000220  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mggtq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mggtq",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031526,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.14",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.244.79.109",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.244.79.109"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031527,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ImageInspectError",
              Message: (string) (len=214) "Failed to inspect image \"webserver:404\": rpc error: code = Unknown desc = short-name \"webserver:404\" did not resolve to an alias and no unqualified-search registries are defined in \"/etc/containers/registries.conf\""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:32:09.061: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5711" for this suite. @ 03/26/24 06:32:09.073
• [4.122 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]
test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 03/26/24 06:32:09.085
  Mar 26 06:32:09.085: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename init-container @ 03/26/24 06:32:09.086
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:32:09.107
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:32:09.118
  STEP: creating the pod @ 03/26/24 06:32:09.125
  Mar 26 06:32:09.125: INFO: PodSpec: initContainers in spec.initContainers
  E0326 06:32:09.816486      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:10.816611      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:11.816836      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:32:12.074: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-3398" for this suite. @ 03/26/24 06:32:12.076
• [2.993 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:69
  STEP: Creating a kubernetes client @ 03/26/24 06:32:12.079
  Mar 26 06:32:12.079: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 06:32:12.08
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:32:12.086
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:32:12.087
  STEP: Creating a pod to test downward API volume plugin @ 03/26/24 06:32:12.089
  E0326 06:32:12.816943      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:13.817033      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:14.818015      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:15.818196      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:32:16.096
  Mar 26 06:32:16.097: INFO: Trying to get logs from node k8s-worker01 pod downwardapi-volume-68f6a677-b8c5-4088-8120-0f4df04e39e8 container client-container: <nil>
  STEP: delete the pod @ 03/26/24 06:32:16.1
  Mar 26 06:32:16.106: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6369" for this suite. @ 03/26/24 06:32:16.108
• [4.030 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]
test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 03/26/24 06:32:16.11
  Mar 26 06:32:16.110: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename secrets @ 03/26/24 06:32:16.11
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:32:16.116
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:32:16.117
  Mar 26 06:32:16.131: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5157" for this suite. @ 03/26/24 06:32:16.132
• [0.025 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]
test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 03/26/24 06:32:16.14
  Mar 26 06:32:16.140: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename watch @ 03/26/24 06:32:16.141
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:32:16.152
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:32:16.153
  STEP: creating a watch on configmaps @ 03/26/24 06:32:16.155
  STEP: creating a new configmap @ 03/26/24 06:32:16.155
  STEP: modifying the configmap once @ 03/26/24 06:32:16.157
  STEP: closing the watch once it receives two notifications @ 03/26/24 06:32:16.16
  Mar 26 06:32:16.160: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9456  fe41691f-6093-48dc-9f57-8cff0470a343 91907 0 2024-03-26 06:32:16 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-03-26 06:32:16 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Mar 26 06:32:16.160: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9456  fe41691f-6093-48dc-9f57-8cff0470a343 91908 0 2024-03-26 06:32:16 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-03-26 06:32:16 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 03/26/24 06:32:16.16
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 03/26/24 06:32:16.162
  STEP: deleting the configmap @ 03/26/24 06:32:16.163
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 03/26/24 06:32:16.164
  Mar 26 06:32:16.164: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9456  fe41691f-6093-48dc-9f57-8cff0470a343 91909 0 2024-03-26 06:32:16 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-03-26 06:32:16 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Mar 26 06:32:16.164: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9456  fe41691f-6093-48dc-9f57-8cff0470a343 91910 0 2024-03-26 06:32:16 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-03-26 06:32:16 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Mar 26 06:32:16.164: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-9456" for this suite. @ 03/26/24 06:32:16.166
• [0.028 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:163
  STEP: Creating a kubernetes client @ 03/26/24 06:32:16.169
  Mar 26 06:32:16.169: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename downward-api @ 03/26/24 06:32:16.169
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:32:16.175
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:32:16.177
  STEP: Creating the pod @ 03/26/24 06:32:16.178
  E0326 06:32:16.818995      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:17.819024      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:32:18.694: INFO: Successfully updated pod "annotationupdate725be4b8-f9e0-4b87-ba9e-50f228df7b6f"
  E0326 06:32:18.819313      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:19.819415      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:32:20.701: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6571" for this suite. @ 03/26/24 06:32:20.703
• [4.537 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:152
  STEP: Creating a kubernetes client @ 03/26/24 06:32:20.708
  Mar 26 06:32:20.709: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 03/26/24 06:32:20.709
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:32:20.714
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:32:20.715
  STEP: create the container to handle the HTTPGet hook request. @ 03/26/24 06:32:20.718
  E0326 06:32:20.820442      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:21.820661      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 03/26/24 06:32:22.725
  E0326 06:32:22.821260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:23.821441      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 03/26/24 06:32:24.731
  E0326 06:32:24.821617      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:25.821954      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:26.822617      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:27.823025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 03/26/24 06:32:28.739
  Mar 26 06:32:28.742: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-4142" for this suite. @ 03/26/24 06:32:28.744
• [8.038 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:153
  STEP: Creating a kubernetes client @ 03/26/24 06:32:28.748
  Mar 26 06:32:28.748: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename crd-publish-openapi @ 03/26/24 06:32:28.748
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:32:28.759
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:32:28.76
  Mar 26 06:32:28.761: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  E0326 06:32:28.823413      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:29.823832      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 03/26/24 06:32:29.975
  Mar 26 06:32:29.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-364 --namespace=crd-publish-openapi-364 create -f -'
  Mar 26 06:32:30.323: INFO: stderr: ""
  Mar 26 06:32:30.323: INFO: stdout: "e2e-test-crd-publish-openapi-4608-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Mar 26 06:32:30.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-364 --namespace=crd-publish-openapi-364 delete e2e-test-crd-publish-openapi-4608-crds test-cr'
  Mar 26 06:32:30.363: INFO: stderr: ""
  Mar 26 06:32:30.363: INFO: stdout: "e2e-test-crd-publish-openapi-4608-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  Mar 26 06:32:30.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-364 --namespace=crd-publish-openapi-364 apply -f -'
  Mar 26 06:32:30.455: INFO: stderr: ""
  Mar 26 06:32:30.455: INFO: stdout: "e2e-test-crd-publish-openapi-4608-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Mar 26 06:32:30.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-364 --namespace=crd-publish-openapi-364 delete e2e-test-crd-publish-openapi-4608-crds test-cr'
  Mar 26 06:32:30.497: INFO: stderr: ""
  Mar 26 06:32:30.497: INFO: stdout: "e2e-test-crd-publish-openapi-4608-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 03/26/24 06:32:30.497
  Mar 26 06:32:30.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=crd-publish-openapi-364 explain e2e-test-crd-publish-openapi-4608-crds'
  Mar 26 06:32:30.584: INFO: stderr: ""
  Mar 26 06:32:30.584: INFO: stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-4608-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E0326 06:32:30.824261      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:32:31.783: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-364" for this suite. @ 03/26/24 06:32:31.788
• [3.043 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]
test/e2e/apimachinery/resource_quota.go:806
  STEP: Creating a kubernetes client @ 03/26/24 06:32:31.792
  Mar 26 06:32:31.792: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename resourcequota @ 03/26/24 06:32:31.793
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:32:31.798
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:32:31.799
  STEP: Creating a ResourceQuota with best effort scope @ 03/26/24 06:32:31.801
  STEP: Ensuring ResourceQuota status is calculated @ 03/26/24 06:32:31.802
  E0326 06:32:31.824994      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:32.825600      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not best effort scope @ 03/26/24 06:32:33.804
  STEP: Ensuring ResourceQuota status is calculated @ 03/26/24 06:32:33.806
  E0326 06:32:33.826438      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:34.827596      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a best-effort pod @ 03/26/24 06:32:35.808
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 03/26/24 06:32:35.814
  E0326 06:32:35.828361      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:36.828505      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 03/26/24 06:32:37.816
  E0326 06:32:37.829227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:38.829363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 03/26/24 06:32:39.818
  STEP: Ensuring resource quota status released the pod usage @ 03/26/24 06:32:39.824
  E0326 06:32:39.829910      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:40.830184      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a not best-effort pod @ 03/26/24 06:32:41.827
  E0326 06:32:41.830507      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 03/26/24 06:32:41.835
  E0326 06:32:42.831094      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:43.831268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 03/26/24 06:32:43.836
  E0326 06:32:44.831989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:45.832336      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 03/26/24 06:32:45.838
  STEP: Ensuring resource quota status released the pod usage @ 03/26/24 06:32:45.844
  E0326 06:32:46.833117      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:47.833232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:32:47.846: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5564" for this suite. @ 03/26/24 06:32:47.848
• [16.059 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:175
  STEP: Creating a kubernetes client @ 03/26/24 06:32:47.851
  Mar 26 06:32:47.851: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename configmap @ 03/26/24 06:32:47.852
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:32:47.858
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:32:47.859
  STEP: Creating configMap with name configmap-test-upd-e5c8a814-fdf7-4294-801a-30510dab63ee @ 03/26/24 06:32:47.862
  STEP: Creating the pod @ 03/26/24 06:32:47.864
  E0326 06:32:48.833424      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:49.833520      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 03/26/24 06:32:49.871
  STEP: Waiting for pod with binary data @ 03/26/24 06:32:49.874
  Mar 26 06:32:49.876: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9949" for this suite. @ 03/26/24 06:32:49.878
• [2.029 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:54
  STEP: Creating a kubernetes client @ 03/26/24 06:32:49.882
  Mar 26 06:32:49.882: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 06:32:49.882
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:32:49.887
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:32:49.889
  STEP: Creating a pod to test downward API volume plugin @ 03/26/24 06:32:49.89
  E0326 06:32:50.834008      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:51.835284      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:52.835378      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:53.835582      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:32:53.899
  Mar 26 06:32:53.900: INFO: Trying to get logs from node k8s-worker01 pod downwardapi-volume-dd8ef96f-9292-43e6-9f62-3c12cf1e8b32 container client-container: <nil>
  STEP: delete the pod @ 03/26/24 06:32:53.902
  Mar 26 06:32:53.908: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6744" for this suite. @ 03/26/24 06:32:53.909
• [4.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]
test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 03/26/24 06:32:53.912
  Mar 26 06:32:53.912: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename emptydir-wrapper @ 03/26/24 06:32:53.913
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:32:53.918
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:32:53.92
  E0326 06:32:54.836319      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:55.836882      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:32:55.932: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Cleaning up the secret @ 03/26/24 06:32:55.934
  STEP: Cleaning up the configmap @ 03/26/24 06:32:55.936
  STEP: Cleaning up the pod @ 03/26/24 06:32:55.938
  STEP: Destroying namespace "emptydir-wrapper-6916" for this suite. @ 03/26/24 06:32:55.943
• [2.036 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]
test/e2e/apimachinery/resource_quota.go:451
  STEP: Creating a kubernetes client @ 03/26/24 06:32:55.948
  Mar 26 06:32:55.948: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename resourcequota @ 03/26/24 06:32:55.949
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:32:55.954
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:32:55.955
  STEP: Counting existing ResourceQuota @ 03/26/24 06:32:55.957
  E0326 06:32:56.837070      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:57.837334      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:58.838159      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:32:59.838240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:00.839080      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 03/26/24 06:33:00.958
  STEP: Ensuring resource quota status is calculated @ 03/26/24 06:33:00.96
  E0326 06:33:01.840031      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:02.840172      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicaSet @ 03/26/24 06:33:02.965
  STEP: Ensuring resource quota status captures replicaset creation @ 03/26/24 06:33:02.97
  E0326 06:33:03.840287      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:04.840394      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicaSet @ 03/26/24 06:33:04.972
  STEP: Ensuring resource quota status released usage @ 03/26/24 06:33:04.974
  E0326 06:33:05.840640      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:06.840826      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:33:06.976: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6789" for this suite. @ 03/26/24 06:33:06.978
• [11.032 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]
test/e2e/apps/daemon_set.go:875
  STEP: Creating a kubernetes client @ 03/26/24 06:33:06.981
  Mar 26 06:33:06.981: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename daemonsets @ 03/26/24 06:33:06.982
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:33:06.987
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:33:06.988
  STEP: Creating simple DaemonSet "daemon-set" @ 03/26/24 06:33:06.996
  STEP: Check that daemon pods launch on every node of the cluster. @ 03/26/24 06:33:06.998
  Mar 26 06:33:07.002: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Mar 26 06:33:07.002: INFO: Node k8s-master01 is running 0 daemon pod, expected 1
  E0326 06:33:07.841666      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:33:08.006: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Mar 26 06:33:08.006: INFO: Node k8s-master01 is running 0 daemon pod, expected 1
  E0326 06:33:08.842099      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:33:09.007: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Mar 26 06:33:09.007: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Getting /status @ 03/26/24 06:33:09.008
  Mar 26 06:33:09.009: INFO: Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 03/26/24 06:33:09.009
  Mar 26 06:33:09.014: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 03/26/24 06:33:09.014
  Mar 26 06:33:09.015: INFO: Observed &DaemonSet event: ADDED
  Mar 26 06:33:09.016: INFO: Observed &DaemonSet event: MODIFIED
  Mar 26 06:33:09.016: INFO: Observed &DaemonSet event: MODIFIED
  Mar 26 06:33:09.016: INFO: Observed &DaemonSet event: MODIFIED
  Mar 26 06:33:09.016: INFO: Observed &DaemonSet event: MODIFIED
  Mar 26 06:33:09.016: INFO: Observed &DaemonSet event: MODIFIED
  Mar 26 06:33:09.016: INFO: Found daemon set daemon-set in namespace daemonsets-4481 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Mar 26 06:33:09.016: INFO: Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 03/26/24 06:33:09.016
  STEP: watching for the daemon set status to be patched @ 03/26/24 06:33:09.02
  Mar 26 06:33:09.021: INFO: Observed &DaemonSet event: ADDED
  Mar 26 06:33:09.021: INFO: Observed &DaemonSet event: MODIFIED
  Mar 26 06:33:09.021: INFO: Observed &DaemonSet event: MODIFIED
  Mar 26 06:33:09.021: INFO: Observed &DaemonSet event: MODIFIED
  Mar 26 06:33:09.021: INFO: Observed &DaemonSet event: MODIFIED
  Mar 26 06:33:09.022: INFO: Observed &DaemonSet event: MODIFIED
  Mar 26 06:33:09.022: INFO: Observed daemon set daemon-set in namespace daemonsets-4481 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Mar 26 06:33:09.022: INFO: Observed &DaemonSet event: MODIFIED
  Mar 26 06:33:09.022: INFO: Found daemon set daemon-set in namespace daemonsets-4481 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  Mar 26 06:33:09.022: INFO: Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 03/26/24 06:33:09.023
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4481, will wait for the garbage collector to delete the pods @ 03/26/24 06:33:09.023
  Mar 26 06:33:09.077: INFO: Deleting DaemonSet.extensions daemon-set took: 1.984572ms
  Mar 26 06:33:09.177: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.1112ms
  E0326 06:33:09.842533      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:10.843093      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:33:11.479: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Mar 26 06:33:11.479: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Mar 26 06:33:11.480: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"92376"},"items":null}

  Mar 26 06:33:11.481: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"92376"},"items":null}

  Mar 26 06:33:11.486: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-4481" for this suite. @ 03/26/24 06:33:11.487
• [4.508 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 03/26/24 06:33:11.492
  Mar 26 06:33:11.492: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename secrets @ 03/26/24 06:33:11.492
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:33:11.498
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:33:11.499
  STEP: Creating secret with name secret-test-map-4e662108-4e8a-4e7f-8c37-9a71e8b4fd37 @ 03/26/24 06:33:11.5
  STEP: Creating a pod to test consume secrets @ 03/26/24 06:33:11.502
  E0326 06:33:11.843918      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:12.844834      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:33:13.508
  Mar 26 06:33:13.509: INFO: Trying to get logs from node k8s-worker02 pod pod-secrets-aeb4fe70-bef5-4686-ae96-560e75b58245 container secret-volume-test: <nil>
  STEP: delete the pod @ 03/26/24 06:33:13.513
  Mar 26 06:33:13.519: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1848" for this suite. @ 03/26/24 06:33:13.521
• [2.031 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:124
  STEP: Creating a kubernetes client @ 03/26/24 06:33:13.523
  Mar 26 06:33:13.523: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 06:33:13.524
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:33:13.53
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:33:13.531
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-fbca8fd2-c366-4bf3-9643-efcd19b84817 @ 03/26/24 06:33:13.534
  STEP: Creating the pod @ 03/26/24 06:33:13.535
  E0326 06:33:13.844985      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:14.845591      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-fbca8fd2-c366-4bf3-9643-efcd19b84817 @ 03/26/24 06:33:15.546
  STEP: waiting to observe update in volume @ 03/26/24 06:33:15.548
  E0326 06:33:15.846505      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:16.846642      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:17.847387      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:18.847589      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:19.847724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:20.847967      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:21.848482      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:22.848648      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:23.848694      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:24.848799      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:25.849008      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:26.850353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:27.850153      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:28.850304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:29.850357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:30.851434      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:31.852049      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:32.852581      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:33.853055      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:34.853213      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:35.854155      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:36.854283      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:37.855374      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:38.855348      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:39.855733      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:40.855826      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:41.856804      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:42.857011      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:43.857760      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:44.857880      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:45.857952      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:46.858027      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:47.858050      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:48.858139      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:49.859008      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:50.859445      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:51.859527      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:52.860017      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:53.860477      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:54.860576      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:55.861503      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:56.862022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:57.862418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:58.863015      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:33:59.863615      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:00.863724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:01.863923      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:02.864018      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:03.864549      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:04.864649      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:05.864695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:06.865715      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:07.866013      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:08.866151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:09.866579      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:10.866700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:11.867149      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:12.867274      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:13.867764      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:14.867894      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:15.868832      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:16.868980      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:17.870092      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:18.870226      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:19.871229      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:20.871326      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:21.872163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:22.872524      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:23.873526      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:24.873653      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:25.874684      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:26.874741      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:27.875048      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:28.875735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:29.876294      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:30.876576      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:31.876944      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:32.876919      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:33.877376      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:34.877518      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:35.878614      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:36.878707      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:37.879178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:38.879311      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:39.879637      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:40.879881      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:41.880801      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:42.880942      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:43.881780      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:44.881930      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:45.882597      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:46.883019      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:34:47.711: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7049" for this suite. @ 03/26/24 06:34:47.712
• [94.191 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:269
  STEP: Creating a kubernetes client @ 03/26/24 06:34:47.714
  Mar 26 06:34:47.714: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename custom-resource-definition @ 03/26/24 06:34:47.715
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:34:47.72
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:34:47.722
  Mar 26 06:34:47.723: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  E0326 06:34:47.883971      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:48.884110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:49.884426      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:34:50.769: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-3382" for this suite. @ 03/26/24 06:34:50.774
• [3.062 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]
test/e2e/scheduling/predicates.go:332
  STEP: Creating a kubernetes client @ 03/26/24 06:34:50.778
  Mar 26 06:34:50.778: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename sched-pred @ 03/26/24 06:34:50.778
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:34:50.784
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:34:50.786
  Mar 26 06:34:50.787: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Mar 26 06:34:50.790: INFO: Waiting for terminating namespaces to be deleted...
  Mar 26 06:34:50.791: INFO: 
  Logging pods the apiserver thinks is on node k8s-master01 before test
  Mar 26 06:34:50.794: INFO: calico-kube-controllers-658d97c59c-j8hzg from kube-system started at 2024-03-26 01:40:20 +0000 UTC (1 container statuses recorded)
  Mar 26 06:34:50.794: INFO: 	Container calico-kube-controllers ready: true, restart count 1
  Mar 26 06:34:50.794: INFO: calico-node-ld9rp from kube-system started at 2024-03-26 01:40:19 +0000 UTC (1 container statuses recorded)
  Mar 26 06:34:50.794: INFO: 	Container calico-node ready: true, restart count 1
  Mar 26 06:34:50.794: INFO: coredns-6554b8b87f-5qtsr from kube-system started at 2024-03-26 01:40:20 +0000 UTC (1 container statuses recorded)
  Mar 26 06:34:50.794: INFO: 	Container coredns ready: true, restart count 1
  Mar 26 06:34:50.794: INFO: coredns-6554b8b87f-745fg from kube-system started at 2024-03-26 01:40:20 +0000 UTC (1 container statuses recorded)
  Mar 26 06:34:50.794: INFO: 	Container coredns ready: true, restart count 1
  Mar 26 06:34:50.794: INFO: etcd-k8s-master01 from kube-system started at 2024-03-26 03:13:06 +0000 UTC (1 container statuses recorded)
  Mar 26 06:34:50.794: INFO: 	Container etcd ready: true, restart count 1
  Mar 26 06:34:50.794: INFO: kube-apiserver-k8s-master01 from kube-system started at 2024-03-26 03:13:06 +0000 UTC (1 container statuses recorded)
  Mar 26 06:34:50.794: INFO: 	Container kube-apiserver ready: true, restart count 1
  Mar 26 06:34:50.794: INFO: kube-controller-manager-k8s-master01 from kube-system started at 2024-03-26 03:13:06 +0000 UTC (1 container statuses recorded)
  Mar 26 06:34:50.794: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Mar 26 06:34:50.794: INFO: kube-proxy-m9s5h from kube-system started at 2024-03-26 01:40:19 +0000 UTC (1 container statuses recorded)
  Mar 26 06:34:50.794: INFO: 	Container kube-proxy ready: true, restart count 1
  Mar 26 06:34:50.794: INFO: kube-scheduler-k8s-master01 from kube-system started at 2024-03-26 03:13:06 +0000 UTC (1 container statuses recorded)
  Mar 26 06:34:50.794: INFO: 	Container kube-scheduler ready: true, restart count 1
  Mar 26 06:34:50.794: INFO: sonobuoy-systemd-logs-daemon-set-c080bc1d82d24b52-pmc2w from sonobuoy started at 2024-03-26 05:32:54 +0000 UTC (2 container statuses recorded)
  Mar 26 06:34:50.794: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Mar 26 06:34:50.794: INFO: 	Container systemd-logs ready: true, restart count 0
  Mar 26 06:34:50.794: INFO: 
  Logging pods the apiserver thinks is on node k8s-worker01 before test
  Mar 26 06:34:50.796: INFO: calico-node-rhg5q from kube-system started at 2024-03-26 01:40:25 +0000 UTC (1 container statuses recorded)
  Mar 26 06:34:50.796: INFO: 	Container calico-node ready: true, restart count 1
  Mar 26 06:34:50.796: INFO: kube-proxy-6v82d from kube-system started at 2024-03-26 01:40:25 +0000 UTC (1 container statuses recorded)
  Mar 26 06:34:50.796: INFO: 	Container kube-proxy ready: true, restart count 1
  Mar 26 06:34:50.796: INFO: sonobuoy-e2e-job-316da3d257e34653 from sonobuoy started at 2024-03-26 05:32:54 +0000 UTC (2 container statuses recorded)
  Mar 26 06:34:50.796: INFO: 	Container e2e ready: true, restart count 0
  Mar 26 06:34:50.796: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Mar 26 06:34:50.796: INFO: sonobuoy-systemd-logs-daemon-set-c080bc1d82d24b52-vv8ws from sonobuoy started at 2024-03-26 05:32:54 +0000 UTC (2 container statuses recorded)
  Mar 26 06:34:50.797: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Mar 26 06:34:50.797: INFO: 	Container systemd-logs ready: true, restart count 0
  Mar 26 06:34:50.797: INFO: 
  Logging pods the apiserver thinks is on node k8s-worker02 before test
  Mar 26 06:34:50.800: INFO: calico-node-wz7cn from kube-system started at 2024-03-26 01:40:26 +0000 UTC (1 container statuses recorded)
  Mar 26 06:34:50.800: INFO: 	Container calico-node ready: true, restart count 1
  Mar 26 06:34:50.800: INFO: kube-proxy-6n6f6 from kube-system started at 2024-03-26 01:40:26 +0000 UTC (1 container statuses recorded)
  Mar 26 06:34:50.800: INFO: 	Container kube-proxy ready: true, restart count 1
  Mar 26 06:34:50.800: INFO: pod-projected-configmaps-f17cea62-5c17-4109-8abd-c637f6aa4818 from projected-7049 started at 2024-03-26 06:33:13 +0000 UTC (1 container statuses recorded)
  Mar 26 06:34:50.800: INFO: 	Container agnhost-container ready: true, restart count 0
  Mar 26 06:34:50.800: INFO: sonobuoy from sonobuoy started at 2024-03-26 05:32:53 +0000 UTC (1 container statuses recorded)
  Mar 26 06:34:50.800: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Mar 26 06:34:50.800: INFO: sonobuoy-systemd-logs-daemon-set-c080bc1d82d24b52-6w6hx from sonobuoy started at 2024-03-26 05:32:54 +0000 UTC (2 container statuses recorded)
  Mar 26 06:34:50.800: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Mar 26 06:34:50.800: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node k8s-master01 @ 03/26/24 06:34:50.809
  STEP: verifying the node has the label node k8s-worker01 @ 03/26/24 06:34:50.816
  STEP: verifying the node has the label node k8s-worker02 @ 03/26/24 06:34:50.829
  Mar 26 06:34:50.837: INFO: Pod calico-kube-controllers-658d97c59c-j8hzg requesting resource cpu=0m on Node k8s-master01
  Mar 26 06:34:50.837: INFO: Pod calico-node-ld9rp requesting resource cpu=250m on Node k8s-master01
  Mar 26 06:34:50.837: INFO: Pod calico-node-rhg5q requesting resource cpu=250m on Node k8s-worker01
  Mar 26 06:34:50.837: INFO: Pod calico-node-wz7cn requesting resource cpu=250m on Node k8s-worker02
  Mar 26 06:34:50.837: INFO: Pod coredns-6554b8b87f-5qtsr requesting resource cpu=100m on Node k8s-master01
  Mar 26 06:34:50.837: INFO: Pod coredns-6554b8b87f-745fg requesting resource cpu=100m on Node k8s-master01
  Mar 26 06:34:50.837: INFO: Pod etcd-k8s-master01 requesting resource cpu=100m on Node k8s-master01
  Mar 26 06:34:50.837: INFO: Pod kube-apiserver-k8s-master01 requesting resource cpu=250m on Node k8s-master01
  Mar 26 06:34:50.837: INFO: Pod kube-controller-manager-k8s-master01 requesting resource cpu=200m on Node k8s-master01
  Mar 26 06:34:50.837: INFO: Pod kube-proxy-6n6f6 requesting resource cpu=0m on Node k8s-worker02
  Mar 26 06:34:50.837: INFO: Pod kube-proxy-6v82d requesting resource cpu=0m on Node k8s-worker01
  Mar 26 06:34:50.837: INFO: Pod kube-proxy-m9s5h requesting resource cpu=0m on Node k8s-master01
  Mar 26 06:34:50.837: INFO: Pod kube-scheduler-k8s-master01 requesting resource cpu=100m on Node k8s-master01
  Mar 26 06:34:50.837: INFO: Pod pod-projected-configmaps-f17cea62-5c17-4109-8abd-c637f6aa4818 requesting resource cpu=0m on Node k8s-worker02
  Mar 26 06:34:50.837: INFO: Pod sonobuoy requesting resource cpu=0m on Node k8s-worker02
  Mar 26 06:34:50.837: INFO: Pod sonobuoy-e2e-job-316da3d257e34653 requesting resource cpu=0m on Node k8s-worker01
  Mar 26 06:34:50.837: INFO: Pod sonobuoy-systemd-logs-daemon-set-c080bc1d82d24b52-6w6hx requesting resource cpu=0m on Node k8s-worker02
  Mar 26 06:34:50.837: INFO: Pod sonobuoy-systemd-logs-daemon-set-c080bc1d82d24b52-pmc2w requesting resource cpu=0m on Node k8s-master01
  Mar 26 06:34:50.837: INFO: Pod sonobuoy-systemd-logs-daemon-set-c080bc1d82d24b52-vv8ws requesting resource cpu=0m on Node k8s-worker01
  STEP: Starting Pods to consume most of the cluster CPU. @ 03/26/24 06:34:50.837
  Mar 26 06:34:50.837: INFO: Creating a pod which consumes cpu=2030m on Node k8s-master01
  Mar 26 06:34:50.841: INFO: Creating a pod which consumes cpu=2625m on Node k8s-worker01
  Mar 26 06:34:50.844: INFO: Creating a pod which consumes cpu=2625m on Node k8s-worker02
  E0326 06:34:50.884704      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:51.884966      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 03/26/24 06:34:52.86
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-813e5138-b2d7-4901-a51b-72863033b8f9.17c03cf735b7456d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5493/filler-pod-813e5138-b2d7-4901-a51b-72863033b8f9 to k8s-worker02] @ 03/26/24 06:34:52.862
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-813e5138-b2d7-4901-a51b-72863033b8f9.17c03cf74ea11559], Reason = [Pulled], Message = [Container image "hub.oepkgs.net/nestos/nestos-test/sonobuoy/pause:3.9" already present on machine] @ 03/26/24 06:34:52.862
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-813e5138-b2d7-4901-a51b-72863033b8f9.17c03cf7526f7867], Reason = [Created], Message = [Created container filler-pod-813e5138-b2d7-4901-a51b-72863033b8f9] @ 03/26/24 06:34:52.862
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-813e5138-b2d7-4901-a51b-72863033b8f9.17c03cf7531773a0], Reason = [Started], Message = [Started container filler-pod-813e5138-b2d7-4901-a51b-72863033b8f9] @ 03/26/24 06:34:52.862
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-9a8d99ac-f8aa-4cab-90f7-ec71fe80ec6c.17c03cf7354493c4], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5493/filler-pod-9a8d99ac-f8aa-4cab-90f7-ec71fe80ec6c to k8s-worker01] @ 03/26/24 06:34:52.862
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-9a8d99ac-f8aa-4cab-90f7-ec71fe80ec6c.17c03cf74dfe3c16], Reason = [Pulled], Message = [Container image "hub.oepkgs.net/nestos/nestos-test/sonobuoy/pause:3.9" already present on machine] @ 03/26/24 06:34:52.862
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-9a8d99ac-f8aa-4cab-90f7-ec71fe80ec6c.17c03cf752594ca7], Reason = [Created], Message = [Created container filler-pod-9a8d99ac-f8aa-4cab-90f7-ec71fe80ec6c] @ 03/26/24 06:34:52.862
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-9a8d99ac-f8aa-4cab-90f7-ec71fe80ec6c.17c03cf753369fe8], Reason = [Started], Message = [Started container filler-pod-9a8d99ac-f8aa-4cab-90f7-ec71fe80ec6c] @ 03/26/24 06:34:52.862
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-f705eb8e-daa4-4d60-a7db-3407117d6891.17c03cf734f3fc8d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5493/filler-pod-f705eb8e-daa4-4d60-a7db-3407117d6891 to k8s-master01] @ 03/26/24 06:34:52.862
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-f705eb8e-daa4-4d60-a7db-3407117d6891.17c03cf74e4dd170], Reason = [Pulled], Message = [Container image "hub.oepkgs.net/nestos/nestos-test/sonobuoy/pause:3.9" already present on machine] @ 03/26/24 06:34:52.862
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-f705eb8e-daa4-4d60-a7db-3407117d6891.17c03cf7529443e8], Reason = [Created], Message = [Created container filler-pod-f705eb8e-daa4-4d60-a7db-3407117d6891] @ 03/26/24 06:34:52.862
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-f705eb8e-daa4-4d60-a7db-3407117d6891.17c03cf753659ea7], Reason = [Started], Message = [Started container filler-pod-f705eb8e-daa4-4d60-a7db-3407117d6891] @ 03/26/24 06:34:52.862
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.17c03cf7ad60e41e], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod..] @ 03/26/24 06:34:52.867
  E0326 06:34:52.885234      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label node off the node k8s-master01 @ 03/26/24 06:34:53.867
  STEP: verifying the node doesn't have the label node @ 03/26/24 06:34:53.873
  STEP: removing the label node off the node k8s-worker01 @ 03/26/24 06:34:53.875
  STEP: verifying the node doesn't have the label node @ 03/26/24 06:34:53.882
  STEP: removing the label node off the node k8s-worker02 @ 03/26/24 06:34:53.884
  E0326 06:34:53.885810      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the node doesn't have the label node @ 03/26/24 06:34:53.891
  Mar 26 06:34:53.892: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-5493" for this suite. @ 03/26/24 06:34:53.894
• [3.120 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 03/26/24 06:34:53.9
  Mar 26 06:34:53.900: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename container-runtime @ 03/26/24 06:34:53.901
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:34:53.908
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:34:53.909
  STEP: create the container @ 03/26/24 06:34:53.911
  W0326 06:34:53.916494      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 03/26/24 06:34:53.916
  E0326 06:34:54.885925      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:55.885980      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:56.886283      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 03/26/24 06:34:56.925
  STEP: the container should be terminated @ 03/26/24 06:34:56.926
  STEP: the termination message should be set @ 03/26/24 06:34:56.926
  Mar 26 06:34:56.926: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 03/26/24 06:34:56.926
  Mar 26 06:34:56.931: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-9556" for this suite. @ 03/26/24 06:34:56.933
• [3.036 seconds]
------------------------------
SSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
test/e2e/scheduling/limit_range.go:61
  STEP: Creating a kubernetes client @ 03/26/24 06:34:56.936
  Mar 26 06:34:56.936: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename limitrange @ 03/26/24 06:34:56.937
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:34:56.942
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:34:56.944
  STEP: Creating a LimitRange @ 03/26/24 06:34:56.945
  STEP: Setting up watch @ 03/26/24 06:34:56.945
  STEP: Submitting a LimitRange @ 03/26/24 06:34:57.047
  STEP: Verifying LimitRange creation was observed @ 03/26/24 06:34:57.049
  STEP: Fetching the LimitRange to ensure it has proper values @ 03/26/24 06:34:57.049
  Mar 26 06:34:57.050: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Mar 26 06:34:57.050: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 03/26/24 06:34:57.05
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 03/26/24 06:34:57.052
  Mar 26 06:34:57.054: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Mar 26 06:34:57.054: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 03/26/24 06:34:57.054
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 03/26/24 06:34:57.056
  Mar 26 06:34:57.058: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  Mar 26 06:34:57.058: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 03/26/24 06:34:57.058
  STEP: Failing to create a Pod with more than max resources @ 03/26/24 06:34:57.059
  STEP: Updating a LimitRange @ 03/26/24 06:34:57.06
  STEP: Verifying LimitRange updating is effective @ 03/26/24 06:34:57.063
  E0326 06:34:57.886732      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:34:58.886910      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 03/26/24 06:34:59.065
  STEP: Failing to create a Pod with more than max resources @ 03/26/24 06:34:59.068
  STEP: Deleting a LimitRange @ 03/26/24 06:34:59.07
  STEP: Verifying the LimitRange was deleted @ 03/26/24 06:34:59.074
  E0326 06:34:59.886967      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:00.888134      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:01.888282      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:02.888429      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:03.888539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:35:04.076: INFO: limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 03/26/24 06:35:04.076
  Mar 26 06:35:04.080: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-2315" for this suite. @ 03/26/24 06:35:04.083
• [7.150 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:194
  STEP: Creating a kubernetes client @ 03/26/24 06:35:04.086
  Mar 26 06:35:04.086: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename downward-api @ 03/26/24 06:35:04.087
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:35:04.092
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:35:04.093
  STEP: Creating a pod to test downward API volume plugin @ 03/26/24 06:35:04.094
  E0326 06:35:04.889018      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:05.889371      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:06.889464      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:07.889552      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:35:08.103
  Mar 26 06:35:08.104: INFO: Trying to get logs from node k8s-worker02 pod downwardapi-volume-740df81f-50ce-4d93-83c0-eb11ef362df7 container client-container: <nil>
  STEP: delete the pod @ 03/26/24 06:35:08.107
  Mar 26 06:35:08.113: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1506" for this suite. @ 03/26/24 06:35:08.114
• [4.031 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
test/e2e/apimachinery/garbage_collector.go:713
  STEP: Creating a kubernetes client @ 03/26/24 06:35:08.117
  Mar 26 06:35:08.117: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename gc @ 03/26/24 06:35:08.117
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:35:08.122
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:35:08.124
  STEP: create the rc1 @ 03/26/24 06:35:08.127
  STEP: create the rc2 @ 03/26/24 06:35:08.13
  E0326 06:35:08.889693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:09.889760      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:10.890020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:11.890131      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:12.890927      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:13.891095      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 03/26/24 06:35:14.134
  STEP: delete the rc simpletest-rc-to-be-deleted @ 03/26/24 06:35:14.329
  STEP: wait for the rc to be deleted @ 03/26/24 06:35:14.332
  E0326 06:35:14.892118      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:15.892360      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:16.892458      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:17.892541      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:18.892560      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:35:19.340: INFO: 70 pods remaining
  Mar 26 06:35:19.340: INFO: 70 pods has nil DeletionTimestamp
  Mar 26 06:35:19.340: INFO: 
  E0326 06:35:19.892980      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:20.893185      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:21.893271      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:22.893435      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:23.894353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 03/26/24 06:35:24.339
  Mar 26 06:35:24.399: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Mar 26 06:35:24.400: INFO: Deleting pod "simpletest-rc-to-be-deleted-2hfd2" in namespace "gc-3762"
  Mar 26 06:35:24.406: INFO: Deleting pod "simpletest-rc-to-be-deleted-2q2qj" in namespace "gc-3762"
  Mar 26 06:35:24.414: INFO: Deleting pod "simpletest-rc-to-be-deleted-2qgb7" in namespace "gc-3762"
  Mar 26 06:35:24.429: INFO: Deleting pod "simpletest-rc-to-be-deleted-2sqqf" in namespace "gc-3762"
  Mar 26 06:35:24.441: INFO: Deleting pod "simpletest-rc-to-be-deleted-2w6nf" in namespace "gc-3762"
  Mar 26 06:35:24.447: INFO: Deleting pod "simpletest-rc-to-be-deleted-44jf8" in namespace "gc-3762"
  Mar 26 06:35:24.454: INFO: Deleting pod "simpletest-rc-to-be-deleted-46gb2" in namespace "gc-3762"
  Mar 26 06:35:24.462: INFO: Deleting pod "simpletest-rc-to-be-deleted-4jw72" in namespace "gc-3762"
  Mar 26 06:35:24.473: INFO: Deleting pod "simpletest-rc-to-be-deleted-4kztz" in namespace "gc-3762"
  Mar 26 06:35:24.482: INFO: Deleting pod "simpletest-rc-to-be-deleted-4mmtw" in namespace "gc-3762"
  Mar 26 06:35:24.495: INFO: Deleting pod "simpletest-rc-to-be-deleted-4v94m" in namespace "gc-3762"
  Mar 26 06:35:24.501: INFO: Deleting pod "simpletest-rc-to-be-deleted-54m4b" in namespace "gc-3762"
  Mar 26 06:35:24.512: INFO: Deleting pod "simpletest-rc-to-be-deleted-596j6" in namespace "gc-3762"
  Mar 26 06:35:24.524: INFO: Deleting pod "simpletest-rc-to-be-deleted-5dj9f" in namespace "gc-3762"
  Mar 26 06:35:24.540: INFO: Deleting pod "simpletest-rc-to-be-deleted-5k57s" in namespace "gc-3762"
  Mar 26 06:35:24.555: INFO: Deleting pod "simpletest-rc-to-be-deleted-5k74w" in namespace "gc-3762"
  Mar 26 06:35:24.577: INFO: Deleting pod "simpletest-rc-to-be-deleted-5vj8j" in namespace "gc-3762"
  Mar 26 06:35:24.600: INFO: Deleting pod "simpletest-rc-to-be-deleted-5wnlc" in namespace "gc-3762"
  Mar 26 06:35:24.608: INFO: Deleting pod "simpletest-rc-to-be-deleted-5wx5c" in namespace "gc-3762"
  Mar 26 06:35:24.647: INFO: Deleting pod "simpletest-rc-to-be-deleted-644zl" in namespace "gc-3762"
  Mar 26 06:35:24.669: INFO: Deleting pod "simpletest-rc-to-be-deleted-67xft" in namespace "gc-3762"
  Mar 26 06:35:24.708: INFO: Deleting pod "simpletest-rc-to-be-deleted-6bv2h" in namespace "gc-3762"
  Mar 26 06:35:24.744: INFO: Deleting pod "simpletest-rc-to-be-deleted-6gjgf" in namespace "gc-3762"
  Mar 26 06:35:24.821: INFO: Deleting pod "simpletest-rc-to-be-deleted-6r9d6" in namespace "gc-3762"
  Mar 26 06:35:24.857: INFO: Deleting pod "simpletest-rc-to-be-deleted-6s27s" in namespace "gc-3762"
  Mar 26 06:35:24.893: INFO: Deleting pod "simpletest-rc-to-be-deleted-6zfb5" in namespace "gc-3762"
  E0326 06:35:24.895109      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:35:24.911: INFO: Deleting pod "simpletest-rc-to-be-deleted-75zc6" in namespace "gc-3762"
  Mar 26 06:35:24.927: INFO: Deleting pod "simpletest-rc-to-be-deleted-79bhc" in namespace "gc-3762"
  Mar 26 06:35:24.957: INFO: Deleting pod "simpletest-rc-to-be-deleted-7dgln" in namespace "gc-3762"
  Mar 26 06:35:24.974: INFO: Deleting pod "simpletest-rc-to-be-deleted-7tcvw" in namespace "gc-3762"
  Mar 26 06:35:24.991: INFO: Deleting pod "simpletest-rc-to-be-deleted-8kghw" in namespace "gc-3762"
  Mar 26 06:35:25.012: INFO: Deleting pod "simpletest-rc-to-be-deleted-8t8gd" in namespace "gc-3762"
  Mar 26 06:35:25.037: INFO: Deleting pod "simpletest-rc-to-be-deleted-95562" in namespace "gc-3762"
  Mar 26 06:35:25.057: INFO: Deleting pod "simpletest-rc-to-be-deleted-97lrp" in namespace "gc-3762"
  Mar 26 06:35:25.080: INFO: Deleting pod "simpletest-rc-to-be-deleted-98bzv" in namespace "gc-3762"
  Mar 26 06:35:25.109: INFO: Deleting pod "simpletest-rc-to-be-deleted-9f5bk" in namespace "gc-3762"
  Mar 26 06:35:25.127: INFO: Deleting pod "simpletest-rc-to-be-deleted-9wxtt" in namespace "gc-3762"
  Mar 26 06:35:25.142: INFO: Deleting pod "simpletest-rc-to-be-deleted-9zgpz" in namespace "gc-3762"
  Mar 26 06:35:25.164: INFO: Deleting pod "simpletest-rc-to-be-deleted-b4qsc" in namespace "gc-3762"
  Mar 26 06:35:25.179: INFO: Deleting pod "simpletest-rc-to-be-deleted-bp6wh" in namespace "gc-3762"
  Mar 26 06:35:25.202: INFO: Deleting pod "simpletest-rc-to-be-deleted-bq52r" in namespace "gc-3762"
  Mar 26 06:35:25.261: INFO: Deleting pod "simpletest-rc-to-be-deleted-crn5p" in namespace "gc-3762"
  Mar 26 06:35:25.288: INFO: Deleting pod "simpletest-rc-to-be-deleted-ctlc6" in namespace "gc-3762"
  Mar 26 06:35:25.323: INFO: Deleting pod "simpletest-rc-to-be-deleted-f4g7g" in namespace "gc-3762"
  Mar 26 06:35:25.351: INFO: Deleting pod "simpletest-rc-to-be-deleted-fj86j" in namespace "gc-3762"
  Mar 26 06:35:25.385: INFO: Deleting pod "simpletest-rc-to-be-deleted-frzp6" in namespace "gc-3762"
  Mar 26 06:35:25.407: INFO: Deleting pod "simpletest-rc-to-be-deleted-fzq6l" in namespace "gc-3762"
  Mar 26 06:35:25.424: INFO: Deleting pod "simpletest-rc-to-be-deleted-gfdhp" in namespace "gc-3762"
  Mar 26 06:35:25.443: INFO: Deleting pod "simpletest-rc-to-be-deleted-grrj7" in namespace "gc-3762"
  Mar 26 06:35:25.464: INFO: Deleting pod "simpletest-rc-to-be-deleted-gw9zx" in namespace "gc-3762"
  Mar 26 06:35:25.477: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3762" for this suite. @ 03/26/24 06:35:25.483
• [17.390 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]
test/e2e/apimachinery/garbage_collector.go:479
  STEP: Creating a kubernetes client @ 03/26/24 06:35:25.51
  Mar 26 06:35:25.510: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename gc @ 03/26/24 06:35:25.511
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:35:25.551
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:35:25.556
  STEP: create the deployment @ 03/26/24 06:35:25.571
  W0326 06:35:25.598633      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 03/26/24 06:35:25.598
  E0326 06:35:25.896015      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 03/26/24 06:35:26.111
  STEP: wait for all rs to be garbage collected @ 03/26/24 06:35:26.113
  STEP: expected 0 rs, got 1 rs @ 03/26/24 06:35:26.114
  STEP: expected 0 pods, got 2 pods @ 03/26/24 06:35:26.121
  STEP: Gathering metrics @ 03/26/24 06:35:26.63
  Mar 26 06:35:26.681: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Mar 26 06:35:26.681: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-6534" for this suite. @ 03/26/24 06:35:26.683
• [1.176 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance]
test/e2e/apps/job.go:713
  STEP: Creating a kubernetes client @ 03/26/24 06:35:26.687
  Mar 26 06:35:26.687: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename job @ 03/26/24 06:35:26.688
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:35:26.695
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:35:26.696
  STEP: Creating a suspended job @ 03/26/24 06:35:26.699
  STEP: Patching the Job @ 03/26/24 06:35:26.702
  STEP: Watching for Job to be patched @ 03/26/24 06:35:26.707
  Mar 26 06:35:26.707: INFO: Event ADDED observed for Job e2e-xsnwx in namespace job-2598 with labels: map[e2e-job-label:e2e-xsnwx] and annotations: map[]
  Mar 26 06:35:26.708: INFO: Event MODIFIED observed for Job e2e-xsnwx in namespace job-2598 with labels: map[e2e-job-label:e2e-xsnwx] and annotations: map[]
  Mar 26 06:35:26.708: INFO: Event MODIFIED found for Job e2e-xsnwx in namespace job-2598 with labels: map[e2e-job-label:e2e-xsnwx e2e-xsnwx:patched] and annotations: map[]
  STEP: Updating the job @ 03/26/24 06:35:26.708
  STEP: Watching for Job to be updated @ 03/26/24 06:35:26.713
  Mar 26 06:35:26.714: INFO: Event MODIFIED found for Job e2e-xsnwx in namespace job-2598 with labels: map[e2e-job-label:e2e-xsnwx e2e-xsnwx:patched] and annotations: map[updated:true]
  Mar 26 06:35:26.714: INFO: Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 03/26/24 06:35:26.714
  Mar 26 06:35:26.716: INFO: Job: e2e-xsnwx as labels: map[e2e-job-label:e2e-xsnwx e2e-xsnwx:patched]
  STEP: Waiting for job to complete @ 03/26/24 06:35:26.716
  E0326 06:35:26.898916      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:27.898961      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:28.899969      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:29.899745      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:30.899846      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:31.900640      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 03/26/24 06:35:32.718
  STEP: Watching for Job to be deleted @ 03/26/24 06:35:32.721
  Mar 26 06:35:32.722: INFO: Event MODIFIED observed for Job e2e-xsnwx in namespace job-2598 with labels: map[e2e-job-label:e2e-xsnwx e2e-xsnwx:patched] and annotations: map[updated:true]
  Mar 26 06:35:32.722: INFO: Event MODIFIED observed for Job e2e-xsnwx in namespace job-2598 with labels: map[e2e-job-label:e2e-xsnwx e2e-xsnwx:patched] and annotations: map[updated:true]
  Mar 26 06:35:32.722: INFO: Event MODIFIED observed for Job e2e-xsnwx in namespace job-2598 with labels: map[e2e-job-label:e2e-xsnwx e2e-xsnwx:patched] and annotations: map[updated:true]
  Mar 26 06:35:32.722: INFO: Event MODIFIED observed for Job e2e-xsnwx in namespace job-2598 with labels: map[e2e-job-label:e2e-xsnwx e2e-xsnwx:patched] and annotations: map[updated:true]
  Mar 26 06:35:32.722: INFO: Event MODIFIED observed for Job e2e-xsnwx in namespace job-2598 with labels: map[e2e-job-label:e2e-xsnwx e2e-xsnwx:patched] and annotations: map[updated:true]
  Mar 26 06:35:32.723: INFO: Event DELETED found for Job e2e-xsnwx in namespace job-2598 with labels: map[e2e-job-label:e2e-xsnwx e2e-xsnwx:patched] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 03/26/24 06:35:32.723
  Mar 26 06:35:32.724: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2598" for this suite. @ 03/26/24 06:35:32.727
• [6.044 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]
test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 03/26/24 06:35:32.731
  Mar 26 06:35:32.731: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename watch @ 03/26/24 06:35:32.732
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:35:32.74
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:35:32.741
  STEP: getting a starting resourceVersion @ 03/26/24 06:35:32.742
  STEP: starting a background goroutine to produce watch events @ 03/26/24 06:35:32.743
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 03/26/24 06:35:32.743
  E0326 06:35:32.900900      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:33.901257      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:34.901934      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:35:35.534: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3506" for this suite. @ 03/26/24 06:35:35.583
• [2.903 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]
test/e2e/apps/statefulset.go:854
  STEP: Creating a kubernetes client @ 03/26/24 06:35:35.635
  Mar 26 06:35:35.635: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename statefulset @ 03/26/24 06:35:35.636
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:35:35.641
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:35:35.643
  STEP: Creating service test in namespace statefulset-3201 @ 03/26/24 06:35:35.644
  STEP: Creating statefulset ss in namespace statefulset-3201 @ 03/26/24 06:35:35.647
  Mar 26 06:35:35.650: INFO: Found 0 stateful pods, waiting for 1
  E0326 06:35:35.902713      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:36.903398      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:37.903474      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:38.903610      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:39.904345      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:40.904510      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:41.905270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:42.906285      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:43.906822      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:44.907100      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:35:45.652: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 03/26/24 06:35:45.654
  STEP: updating a scale subresource @ 03/26/24 06:35:45.655
  STEP: verifying the statefulset Spec.Replicas was modified @ 03/26/24 06:35:45.658
  STEP: Patch a scale subresource @ 03/26/24 06:35:45.66
  STEP: verifying the statefulset Spec.Replicas was modified @ 03/26/24 06:35:45.662
  Mar 26 06:35:45.664: INFO: Deleting all statefulset in ns statefulset-3201
  Mar 26 06:35:45.665: INFO: Scaling statefulset ss to 0
  E0326 06:35:45.907954      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:46.908740      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:47.909132      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:48.909338      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:49.910100      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:50.910377      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:51.911149      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:52.911320      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:53.911486      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:54.911576      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:35:55.674: INFO: Waiting for statefulset status.replicas updated to 0
  Mar 26 06:35:55.675: INFO: Deleting statefulset ss
  Mar 26 06:35:55.680: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3201" for this suite. @ 03/26/24 06:35:55.681
• [20.048 seconds]
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]
test/e2e/kubectl/kubectl.go:1481
  STEP: Creating a kubernetes client @ 03/26/24 06:35:55.684
  Mar 26 06:35:55.684: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubectl @ 03/26/24 06:35:55.684
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:35:55.691
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:35:55.692
  STEP: creating Agnhost RC @ 03/26/24 06:35:55.694
  Mar 26 06:35:55.694: INFO: namespace kubectl-8487
  Mar 26 06:35:55.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-8487 create -f -'
  E0326 06:35:55.912631      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:35:56.033: INFO: stderr: ""
  Mar 26 06:35:56.033: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 03/26/24 06:35:56.033
  E0326 06:35:56.913389      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:35:57.035: INFO: Selector matched 1 pods for map[app:agnhost]
  Mar 26 06:35:57.035: INFO: Found 0 / 1
  E0326 06:35:57.913551      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:35:58.036: INFO: Selector matched 1 pods for map[app:agnhost]
  Mar 26 06:35:58.036: INFO: Found 1 / 1
  Mar 26 06:35:58.036: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Mar 26 06:35:58.037: INFO: Selector matched 1 pods for map[app:agnhost]
  Mar 26 06:35:58.037: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Mar 26 06:35:58.037: INFO: wait on agnhost-primary startup in kubectl-8487 
  Mar 26 06:35:58.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-8487 logs agnhost-primary-49fxp agnhost-primary'
  Mar 26 06:35:58.079: INFO: stderr: ""
  Mar 26 06:35:58.079: INFO: stdout: "Paused\n"
  STEP: exposing RC @ 03/26/24 06:35:58.079
  Mar 26 06:35:58.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-8487 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  Mar 26 06:35:58.124: INFO: stderr: ""
  Mar 26 06:35:58.124: INFO: stdout: "service/rm2 exposed\n"
  Mar 26 06:35:58.125: INFO: Service rm2 in namespace kubectl-8487 found.
  E0326 06:35:58.913589      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:35:59.913994      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: exposing service @ 03/26/24 06:36:00.128
  Mar 26 06:36:00.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-8487 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  Mar 26 06:36:00.173: INFO: stderr: ""
  Mar 26 06:36:00.173: INFO: stdout: "service/rm3 exposed\n"
  Mar 26 06:36:00.175: INFO: Service rm3 in namespace kubectl-8487 found.
  E0326 06:36:00.914915      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:01.915700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:36:02.178: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8487" for this suite. @ 03/26/24 06:36:02.18
• [6.499 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]
test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 03/26/24 06:36:02.183
  Mar 26 06:36:02.183: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename proxy @ 03/26/24 06:36:02.183
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:36:02.187
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:36:02.189
  Mar 26 06:36:02.191: INFO: Creating pod...
  E0326 06:36:02.915945      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:03.916272      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:36:04.198: INFO: Creating service...
  Mar 26 06:36:04.203: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1872/pods/agnhost/proxy?method=DELETE
  Mar 26 06:36:04.206: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Mar 26 06:36:04.206: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1872/pods/agnhost/proxy?method=OPTIONS
  Mar 26 06:36:04.208: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Mar 26 06:36:04.208: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1872/pods/agnhost/proxy?method=PATCH
  Mar 26 06:36:04.210: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Mar 26 06:36:04.210: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1872/pods/agnhost/proxy?method=POST
  Mar 26 06:36:04.211: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Mar 26 06:36:04.211: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1872/pods/agnhost/proxy?method=PUT
  Mar 26 06:36:04.212: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Mar 26 06:36:04.212: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1872/services/e2e-proxy-test-service/proxy?method=DELETE
  Mar 26 06:36:04.213: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Mar 26 06:36:04.213: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1872/services/e2e-proxy-test-service/proxy?method=OPTIONS
  Mar 26 06:36:04.215: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Mar 26 06:36:04.215: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1872/services/e2e-proxy-test-service/proxy?method=PATCH
  Mar 26 06:36:04.216: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Mar 26 06:36:04.216: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1872/services/e2e-proxy-test-service/proxy?method=POST
  Mar 26 06:36:04.217: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Mar 26 06:36:04.217: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1872/services/e2e-proxy-test-service/proxy?method=PUT
  Mar 26 06:36:04.219: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Mar 26 06:36:04.219: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1872/pods/agnhost/proxy?method=GET
  Mar 26 06:36:04.219: INFO: http.Client request:GET StatusCode:301
  Mar 26 06:36:04.220: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1872/services/e2e-proxy-test-service/proxy?method=GET
  Mar 26 06:36:04.221: INFO: http.Client request:GET StatusCode:301
  Mar 26 06:36:04.222: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1872/pods/agnhost/proxy?method=HEAD
  Mar 26 06:36:04.222: INFO: http.Client request:HEAD StatusCode:301
  Mar 26 06:36:04.222: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1872/services/e2e-proxy-test-service/proxy?method=HEAD
  Mar 26 06:36:04.224: INFO: http.Client request:HEAD StatusCode:301
  Mar 26 06:36:04.224: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-1872" for this suite. @ 03/26/24 06:36:04.225
• [2.045 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
test/e2e/node/security_context.go:129
  STEP: Creating a kubernetes client @ 03/26/24 06:36:04.229
  Mar 26 06:36:04.229: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename security-context @ 03/26/24 06:36:04.23
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:36:04.235
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:36:04.236
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 03/26/24 06:36:04.237
  E0326 06:36:04.916582      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:05.917172      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:06.917899      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:07.917957      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:36:08.248
  Mar 26 06:36:08.250: INFO: Trying to get logs from node k8s-worker01 pod security-context-a32ce56b-1e77-4065-82bc-b72509ce478d container test-container: <nil>
  STEP: delete the pod @ 03/26/24 06:36:08.253
  Mar 26 06:36:08.259: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-7474" for this suite. @ 03/26/24 06:36:08.26
• [4.033 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]
test/e2e/kubectl/kubectl.go:996
  STEP: Creating a kubernetes client @ 03/26/24 06:36:08.263
  Mar 26 06:36:08.263: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubectl @ 03/26/24 06:36:08.264
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:36:08.269
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:36:08.27
  STEP: create deployment with httpd image @ 03/26/24 06:36:08.271
  Mar 26 06:36:08.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-6410 create -f -'
  Mar 26 06:36:08.379: INFO: stderr: ""
  Mar 26 06:36:08.379: INFO: stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 03/26/24 06:36:08.379
  Mar 26 06:36:08.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-6410 diff -f -'
  Mar 26 06:36:08.477: INFO: rc: 1
  Mar 26 06:36:08.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-6410 delete -f -'
  Mar 26 06:36:08.516: INFO: stderr: ""
  Mar 26 06:36:08.516: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  Mar 26 06:36:08.516: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6410" for this suite. @ 03/26/24 06:36:08.518
• [0.258 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:163
  STEP: Creating a kubernetes client @ 03/26/24 06:36:08.523
  Mar 26 06:36:08.523: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 06:36:08.524
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:36:08.529
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:36:08.531
  STEP: Creating the pod @ 03/26/24 06:36:08.532
  E0326 06:36:08.919457      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:09.920421      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:10.920928      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:36:11.050: INFO: Successfully updated pod "annotationupdate749e9044-fbae-431c-b93a-aa1c4b9d06a5"
  E0326 06:36:11.921142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:12.921244      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:36:13.057: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7826" for this suite. @ 03/26/24 06:36:13.059
• [4.538 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance]
test/e2e/network/ingress.go:556
  STEP: Creating a kubernetes client @ 03/26/24 06:36:13.062
  Mar 26 06:36:13.062: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename ingress @ 03/26/24 06:36:13.062
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:36:13.068
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:36:13.069
  STEP: getting /apis @ 03/26/24 06:36:13.071
  STEP: getting /apis/networking.k8s.io @ 03/26/24 06:36:13.073
  STEP: getting /apis/networking.k8s.iov1 @ 03/26/24 06:36:13.073
  STEP: creating @ 03/26/24 06:36:13.074
  STEP: getting @ 03/26/24 06:36:13.079
  STEP: listing @ 03/26/24 06:36:13.079
  STEP: watching @ 03/26/24 06:36:13.081
  Mar 26 06:36:13.081: INFO: starting watch
  STEP: cluster-wide listing @ 03/26/24 06:36:13.081
  STEP: cluster-wide watching @ 03/26/24 06:36:13.082
  Mar 26 06:36:13.082: INFO: starting watch
  STEP: patching @ 03/26/24 06:36:13.083
  STEP: updating @ 03/26/24 06:36:13.085
  Mar 26 06:36:13.087: INFO: waiting for watch events with expected annotations
  Mar 26 06:36:13.087: INFO: saw patched and updated annotations
  STEP: patching /status @ 03/26/24 06:36:13.087
  STEP: updating /status @ 03/26/24 06:36:13.089
  STEP: get /status @ 03/26/24 06:36:13.092
  STEP: deleting @ 03/26/24 06:36:13.093
  STEP: deleting a collection @ 03/26/24 06:36:13.096
  Mar 26 06:36:13.099: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-7061" for this suite. @ 03/26/24 06:36:13.101
• [0.041 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]
test/e2e/apimachinery/webhook.go:199
  STEP: Creating a kubernetes client @ 03/26/24 06:36:13.104
  Mar 26 06:36:13.104: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename webhook @ 03/26/24 06:36:13.104
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:36:13.109
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:36:13.111
  STEP: Setting up server cert @ 03/26/24 06:36:13.119
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 03/26/24 06:36:13.428
  STEP: Deploying the webhook pod @ 03/26/24 06:36:13.431
  STEP: Wait for the deployment to be ready @ 03/26/24 06:36:13.434
  Mar 26 06:36:13.437: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0326 06:36:13.922241      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:14.922959      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 03/26/24 06:36:15.441
  STEP: Verifying the service has paired with the endpoint @ 03/26/24 06:36:15.444
  E0326 06:36:15.923668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:36:16.445: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 03/26/24 06:36:16.448
  STEP: create a pod that should be denied by the webhook @ 03/26/24 06:36:16.456
  STEP: create a pod that causes the webhook to hang @ 03/26/24 06:36:16.461
  E0326 06:36:16.924020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:17.924108      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:18.924203      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:19.924952      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:20.925262      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:21.925826      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:22.926833      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:23.927139      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:24.927635      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:25.928146      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create a configmap that should be denied by the webhook @ 03/26/24 06:36:26.465
  STEP: create a configmap that should be admitted by the webhook @ 03/26/24 06:36:26.47
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 03/26/24 06:36:26.474
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 03/26/24 06:36:26.476
  STEP: create a namespace that bypass the webhook @ 03/26/24 06:36:26.478
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 03/26/24 06:36:26.483
  Mar 26 06:36:26.489: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8469" for this suite. @ 03/26/24 06:36:26.504
  STEP: Destroying namespace "webhook-markers-4418" for this suite. @ 03/26/24 06:36:26.507
  STEP: Destroying namespace "exempted-namespace-9660" for this suite. @ 03/26/24 06:36:26.51
• [13.409 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services should provide secure master service  [Conformance]
test/e2e/network/service.go:775
  STEP: Creating a kubernetes client @ 03/26/24 06:36:26.514
  Mar 26 06:36:26.514: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename services @ 03/26/24 06:36:26.515
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:36:26.52
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:36:26.521
  Mar 26 06:36:26.523: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5723" for this suite. @ 03/26/24 06:36:26.525
• [0.013 seconds]
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:423
  STEP: Creating a kubernetes client @ 03/26/24 06:36:26.527
  Mar 26 06:36:26.527: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename configmap @ 03/26/24 06:36:26.528
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:36:26.532
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:36:26.534
  STEP: Creating configMap with name configmap-test-volume-5a79edee-0d6f-464d-b54c-fb4e99884ccf @ 03/26/24 06:36:26.535
  STEP: Creating a pod to test consume configMaps @ 03/26/24 06:36:26.537
  E0326 06:36:26.929217      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:27.930240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:28.930883      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:29.931707      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:36:30.545
  Mar 26 06:36:30.548: INFO: Trying to get logs from node k8s-worker02 pod pod-configmaps-74599949-f069-478a-b313-e1da39edb9e8 container configmap-volume-test: <nil>
  STEP: delete the pod @ 03/26/24 06:36:30.55
  Mar 26 06:36:30.557: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4551" for this suite. @ 03/26/24 06:36:30.559
• [4.034 seconds]
------------------------------
SSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 03/26/24 06:36:30.561
  Mar 26 06:36:30.561: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename events @ 03/26/24 06:36:30.562
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:36:30.567
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:36:30.568
  STEP: creating a test event @ 03/26/24 06:36:30.569
  STEP: listing events in all namespaces @ 03/26/24 06:36:30.571
  STEP: listing events in test namespace @ 03/26/24 06:36:30.572
  STEP: listing events with field selection filtering on source @ 03/26/24 06:36:30.573
  STEP: listing events with field selection filtering on reportingController @ 03/26/24 06:36:30.574
  STEP: getting the test event @ 03/26/24 06:36:30.575
  STEP: patching the test event @ 03/26/24 06:36:30.575
  STEP: getting the test event @ 03/26/24 06:36:30.578
  STEP: updating the test event @ 03/26/24 06:36:30.579
  STEP: getting the test event @ 03/26/24 06:36:30.58
  STEP: deleting the test event @ 03/26/24 06:36:30.581
  STEP: listing events in all namespaces @ 03/26/24 06:36:30.583
  STEP: listing events in test namespace @ 03/26/24 06:36:30.584
  Mar 26 06:36:30.585: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-6030" for this suite. @ 03/26/24 06:36:30.586
• [0.026 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance]
test/e2e/network/service.go:3142
  STEP: Creating a kubernetes client @ 03/26/24 06:36:30.588
  Mar 26 06:36:30.588: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename services @ 03/26/24 06:36:30.589
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:36:30.594
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:36:30.595
  STEP: creating an Endpoint @ 03/26/24 06:36:30.598
  STEP: waiting for available Endpoint @ 03/26/24 06:36:30.599
  STEP: listing all Endpoints @ 03/26/24 06:36:30.6
  STEP: updating the Endpoint @ 03/26/24 06:36:30.601
  STEP: fetching the Endpoint @ 03/26/24 06:36:30.603
  STEP: patching the Endpoint @ 03/26/24 06:36:30.604
  STEP: fetching the Endpoint @ 03/26/24 06:36:30.606
  STEP: deleting the Endpoint by Collection @ 03/26/24 06:36:30.607
  STEP: waiting for Endpoint deletion @ 03/26/24 06:36:30.609
  STEP: fetching the Endpoint @ 03/26/24 06:36:30.61
  Mar 26 06:36:30.611: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6596" for this suite. @ 03/26/24 06:36:30.613
• [0.027 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod  [Conformance]
test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 03/26/24 06:36:30.615
  Mar 26 06:36:30.615: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename prestop @ 03/26/24 06:36:30.616
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:36:30.623
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:36:30.625
  STEP: Creating server pod server in namespace prestop-4351 @ 03/26/24 06:36:30.626
  STEP: Waiting for pods to come up. @ 03/26/24 06:36:30.629
  E0326 06:36:30.932453      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:31.932557      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating tester pod tester in namespace prestop-4351 @ 03/26/24 06:36:32.634
  E0326 06:36:32.933462      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:33.933660      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting pre-stop pod @ 03/26/24 06:36:34.64
  E0326 06:36:34.934247      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:35.935384      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:36.935607      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:37.936033      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:38.936163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:36:39.645: INFO: Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  Mar 26 06:36:39.646: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Deleting the server pod @ 03/26/24 06:36:39.647
  STEP: Destroying namespace "prestop-4351" for this suite. @ 03/26/24 06:36:39.653
• [9.039 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:157
  STEP: Creating a kubernetes client @ 03/26/24 06:36:39.657
  Mar 26 06:36:39.657: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename emptydir @ 03/26/24 06:36:39.657
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:36:39.663
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:36:39.666
  STEP: Creating a pod to test emptydir volume type on node default medium @ 03/26/24 06:36:39.668
  E0326 06:36:39.936794      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:40.937016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:41.937808      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:42.938813      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:36:43.676
  Mar 26 06:36:43.677: INFO: Trying to get logs from node k8s-worker01 pod pod-8a464773-bf60-4376-9c56-a009e073e3ba container test-container: <nil>
  STEP: delete the pod @ 03/26/24 06:36:43.68
  Mar 26 06:36:43.684: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3347" for this suite. @ 03/26/24 06:36:43.686
• [4.032 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]
test/e2e/apimachinery/namespace.go:303
  STEP: Creating a kubernetes client @ 03/26/24 06:36:43.688
  Mar 26 06:36:43.688: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename namespaces @ 03/26/24 06:36:43.689
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:36:43.694
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:36:43.696
  STEP: Read namespace status @ 03/26/24 06:36:43.698
  Mar 26 06:36:43.699: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 03/26/24 06:36:43.699
  Mar 26 06:36:43.701: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 03/26/24 06:36:43.701
  Mar 26 06:36:43.705: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  Mar 26 06:36:43.705: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-1772" for this suite. @ 03/26/24 06:36:43.707
• [0.021 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 03/26/24 06:36:43.711
  Mar 26 06:36:43.711: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename daemonsets @ 03/26/24 06:36:43.711
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:36:43.717
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:36:43.718
  Mar 26 06:36:43.726: INFO: Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 03/26/24 06:36:43.729
  Mar 26 06:36:43.731: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Mar 26 06:36:43.731: INFO: Node k8s-master01 is running 0 daemon pod, expected 1
  E0326 06:36:43.939198      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:36:44.738: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Mar 26 06:36:44.738: INFO: Node k8s-master01 is running 0 daemon pod, expected 1
  E0326 06:36:44.939921      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:36:45.735: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Mar 26 06:36:45.735: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Update daemon pods image. @ 03/26/24 06:36:45.739
  STEP: Check that daemon pods images are updated. @ 03/26/24 06:36:45.744
  Mar 26 06:36:45.745: INFO: Wrong image for pod: daemon-set-5rdgb. Expected: hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45, got: hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4.
  Mar 26 06:36:45.746: INFO: Wrong image for pod: daemon-set-6hgzx. Expected: hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45, got: hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4.
  Mar 26 06:36:45.746: INFO: Wrong image for pod: daemon-set-smgnk. Expected: hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45, got: hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4.
  E0326 06:36:45.940619      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:36:46.749: INFO: Wrong image for pod: daemon-set-6hgzx. Expected: hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45, got: hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4.
  Mar 26 06:36:46.749: INFO: Pod daemon-set-f6cz6 is not available
  Mar 26 06:36:46.749: INFO: Wrong image for pod: daemon-set-smgnk. Expected: hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45, got: hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4.
  E0326 06:36:46.941543      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:36:47.750: INFO: Wrong image for pod: daemon-set-smgnk. Expected: hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45, got: hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4.
  E0326 06:36:47.941963      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:36:48.749: INFO: Wrong image for pod: daemon-set-smgnk. Expected: hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45, got: hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4.
  Mar 26 06:36:48.749: INFO: Pod daemon-set-sx6lt is not available
  E0326 06:36:48.942240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:36:49.749: INFO: Pod daemon-set-k8p8x is not available
  STEP: Check that daemon pods are still running on every node of the cluster. @ 03/26/24 06:36:49.751
  Mar 26 06:36:49.755: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Mar 26 06:36:49.755: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 03/26/24 06:36:49.761
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5920, will wait for the garbage collector to delete the pods @ 03/26/24 06:36:49.761
  Mar 26 06:36:49.815: INFO: Deleting DaemonSet.extensions daemon-set took: 2.346484ms
  Mar 26 06:36:49.915: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.610745ms
  E0326 06:36:49.943072      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:50.944168      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:51.944214      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:36:52.817: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Mar 26 06:36:52.817: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Mar 26 06:36:52.818: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"96462"},"items":null}

  Mar 26 06:36:52.819: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"96462"},"items":null}

  Mar 26 06:36:52.823: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-5920" for this suite. @ 03/26/24 06:36:52.825
• [9.118 seconds]
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance]
test/e2e/apps/cronjob.go:324
  STEP: Creating a kubernetes client @ 03/26/24 06:36:52.828
  Mar 26 06:36:52.828: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename cronjob @ 03/26/24 06:36:52.829
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:36:52.834
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:36:52.835
  STEP: Creating a cronjob @ 03/26/24 06:36:52.836
  STEP: creating @ 03/26/24 06:36:52.836
  STEP: getting @ 03/26/24 06:36:52.839
  STEP: listing @ 03/26/24 06:36:52.84
  STEP: watching @ 03/26/24 06:36:52.841
  Mar 26 06:36:52.841: INFO: starting watch
  STEP: cluster-wide listing @ 03/26/24 06:36:52.841
  STEP: cluster-wide watching @ 03/26/24 06:36:52.842
  Mar 26 06:36:52.842: INFO: starting watch
  STEP: patching @ 03/26/24 06:36:52.843
  STEP: updating @ 03/26/24 06:36:52.845
  Mar 26 06:36:52.849: INFO: waiting for watch events with expected annotations
  Mar 26 06:36:52.849: INFO: saw patched and updated annotations
  STEP: patching /status @ 03/26/24 06:36:52.849
  STEP: updating /status @ 03/26/24 06:36:52.851
  STEP: get /status @ 03/26/24 06:36:52.853
  STEP: deleting @ 03/26/24 06:36:52.854
  STEP: deleting a collection @ 03/26/24 06:36:52.859
  Mar 26 06:36:52.861: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-617" for this suite. @ 03/26/24 06:36:52.864
• [0.038 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]
test/e2e/apps/disruption.go:349
  STEP: Creating a kubernetes client @ 03/26/24 06:36:52.867
  Mar 26 06:36:52.867: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename disruption @ 03/26/24 06:36:52.868
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:36:52.872
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:36:52.873
  STEP: Creating a pdb that targets all three pods in a test replica set @ 03/26/24 06:36:52.874
  STEP: Waiting for the pdb to be processed @ 03/26/24 06:36:52.877
  E0326 06:36:52.944559      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:53.944754      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: First trying to evict a pod which shouldn't be evictable @ 03/26/24 06:36:54.882
  STEP: Waiting for all pods to be running @ 03/26/24 06:36:54.882
  Mar 26 06:36:54.883: INFO: pods: 0 < 3
  E0326 06:36:54.944918      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:55.945089      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 03/26/24 06:36:56.886
  STEP: Updating the pdb to allow a pod to be evicted @ 03/26/24 06:36:56.889
  STEP: Waiting for the pdb to be processed @ 03/26/24 06:36:56.893
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 03/26/24 06:36:56.895
  STEP: Waiting for all pods to be running @ 03/26/24 06:36:56.895
  STEP: Waiting for the pdb to observed all healthy pods @ 03/26/24 06:36:56.896
  STEP: Patching the pdb to disallow a pod to be evicted @ 03/26/24 06:36:56.905
  STEP: Waiting for the pdb to be processed @ 03/26/24 06:36:56.913
  E0326 06:36:56.945113      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:36:57.946030      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 03/26/24 06:36:58.917
  STEP: locating a running pod @ 03/26/24 06:36:58.918
  STEP: Deleting the pdb to allow a pod to be evicted @ 03/26/24 06:36:58.921
  STEP: Waiting for the pdb to be deleted @ 03/26/24 06:36:58.923
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 03/26/24 06:36:58.924
  STEP: Waiting for all pods to be running @ 03/26/24 06:36:58.924
  Mar 26 06:36:58.930: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-363" for this suite. @ 03/26/24 06:36:58.936
• [6.076 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]
test/e2e/apps/replica_set.go:165
  STEP: Creating a kubernetes client @ 03/26/24 06:36:58.943
  Mar 26 06:36:58.943: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename replicaset @ 03/26/24 06:36:58.944
  E0326 06:36:58.947011      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:36:58.955
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:36:58.958
  STEP: Create a ReplicaSet @ 03/26/24 06:36:58.959
  STEP: Verify that the required pods have come up @ 03/26/24 06:36:58.962
  Mar 26 06:36:58.963: INFO: Pod name sample-pod: Found 0 pods out of 3
  E0326 06:36:59.947916      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:00.948139      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:01.948278      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:02.949112      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:03.949267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:37:03.966: INFO: Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 03/26/24 06:37:03.966
  Mar 26 06:37:03.968: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 03/26/24 06:37:03.968
  STEP: DeleteCollection of the ReplicaSets @ 03/26/24 06:37:03.969
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 03/26/24 06:37:03.977
  Mar 26 06:37:03.979: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-9886" for this suite. @ 03/26/24 06:37:03.981
• [5.042 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:236
  STEP: Creating a kubernetes client @ 03/26/24 06:37:03.993
  Mar 26 06:37:03.993: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename downward-api @ 03/26/24 06:37:03.994
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:37:04.008
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:37:04.01
  STEP: Creating a pod to test downward API volume plugin @ 03/26/24 06:37:04.012
  E0326 06:37:04.950293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:05.950371      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:37:06.023
  Mar 26 06:37:06.024: INFO: Trying to get logs from node k8s-worker01 pod downwardapi-volume-a8bb60c0-bb60-4f65-a637-60364c150ba7 container client-container: <nil>
  STEP: delete the pod @ 03/26/24 06:37:06.026
  Mar 26 06:37:06.036: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6806" for this suite. @ 03/26/24 06:37:06.038
• [2.053 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:218
  STEP: Creating a kubernetes client @ 03/26/24 06:37:06.041
  Mar 26 06:37:06.041: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename downward-api @ 03/26/24 06:37:06.041
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:37:06.047
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:37:06.048
  STEP: Creating a pod to test downward api env vars @ 03/26/24 06:37:06.05
  E0326 06:37:06.950769      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:07.951080      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:37:08.056
  Mar 26 06:37:08.058: INFO: Trying to get logs from node k8s-worker02 pod downward-api-751f8f7c-0d99-4370-96bc-0b3a3bb95125 container dapi-container: <nil>
  STEP: delete the pod @ 03/26/24 06:37:08.06
  Mar 26 06:37:08.067: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8688" for this suite. @ 03/26/24 06:37:08.068
• [2.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]
test/e2e/apimachinery/namespace.go:252
  STEP: Creating a kubernetes client @ 03/26/24 06:37:08.075
  Mar 26 06:37:08.075: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename namespaces @ 03/26/24 06:37:08.075
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:37:08.08
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:37:08.082
  STEP: Creating a test namespace @ 03/26/24 06:37:08.084
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:37:08.093
  STEP: Creating a service in the namespace @ 03/26/24 06:37:08.095
  STEP: Deleting the namespace @ 03/26/24 06:37:08.099
  STEP: Waiting for the namespace to be removed. @ 03/26/24 06:37:08.102
  E0326 06:37:08.951166      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:09.952311      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:10.953002      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:11.953071      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:12.954031      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:13.954523      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 03/26/24 06:37:14.104
  STEP: Verifying there is no service in the namespace @ 03/26/24 06:37:14.11
  Mar 26 06:37:14.111: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-4791" for this suite. @ 03/26/24 06:37:14.113
  STEP: Destroying namespace "nsdeletetest-6127" for this suite. @ 03/26/24 06:37:14.116
  Mar 26 06:37:14.117: INFO: Namespace nsdeletetest-6127 was already deleted
  STEP: Destroying namespace "nsdeletetest-5391" for this suite. @ 03/26/24 06:37:14.117
• [6.044 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]
test/e2e/apimachinery/webhook.go:210
  STEP: Creating a kubernetes client @ 03/26/24 06:37:14.12
  Mar 26 06:37:14.120: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename webhook @ 03/26/24 06:37:14.12
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:37:14.125
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:37:14.127
  STEP: Setting up server cert @ 03/26/24 06:37:14.137
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 03/26/24 06:37:14.301
  STEP: Deploying the webhook pod @ 03/26/24 06:37:14.305
  STEP: Wait for the deployment to be ready @ 03/26/24 06:37:14.31
  Mar 26 06:37:14.312: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0326 06:37:14.954820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:15.954908      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 03/26/24 06:37:16.316
  STEP: Verifying the service has paired with the endpoint @ 03/26/24 06:37:16.32
  E0326 06:37:16.955709      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:37:17.321: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 03/26/24 06:37:17.324
  STEP: create a pod @ 03/26/24 06:37:17.332
  E0326 06:37:17.956369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:18.956608      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 03/26/24 06:37:19.339
  Mar 26 06:37:19.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=webhook-4819 attach --namespace=webhook-4819 to-be-attached-pod -i -c=container1'
  Mar 26 06:37:19.387: INFO: rc: 1
  Mar 26 06:37:19.387: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4819" for this suite. @ 03/26/24 06:37:19.405
  STEP: Destroying namespace "webhook-markers-8569" for this suite. @ 03/26/24 06:37:19.409
• [5.291 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:609
  STEP: Creating a kubernetes client @ 03/26/24 06:37:19.411
  Mar 26 06:37:19.411: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename security-context-test @ 03/26/24 06:37:19.412
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:37:19.468
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:37:19.47
  E0326 06:37:19.957185      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:20.957348      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:21.957635      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:22.957955      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:37:23.482: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-876" for this suite. @ 03/26/24 06:37:23.484
• [4.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:197
  STEP: Creating a kubernetes client @ 03/26/24 06:37:23.502
  Mar 26 06:37:23.503: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename emptydir @ 03/26/24 06:37:23.504
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:37:23.51
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:37:23.512
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 03/26/24 06:37:23.513
  E0326 06:37:23.958739      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:24.959483      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:25.960311      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:26.960414      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:37:27.523
  Mar 26 06:37:27.524: INFO: Trying to get logs from node k8s-worker02 pod pod-3cf7bdc2-c1ce-448b-9364-4179d230bed8 container test-container: <nil>
  STEP: delete the pod @ 03/26/24 06:37:27.527
  Mar 26 06:37:27.532: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8016" for this suite. @ 03/26/24 06:37:27.534
• [4.034 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]
test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 03/26/24 06:37:27.538
  Mar 26 06:37:27.538: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename deployment @ 03/26/24 06:37:27.539
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:37:27.545
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:37:27.546
  Mar 26 06:37:27.548: INFO: Creating simple deployment test-new-deployment
  Mar 26 06:37:27.552: INFO: new replicaset for deployment "test-new-deployment" is yet to be created
  E0326 06:37:27.960510      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:28.961339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 03/26/24 06:37:29.557
  STEP: updating a scale subresource @ 03/26/24 06:37:29.558
  STEP: verifying the deployment Spec.Replicas was modified @ 03/26/24 06:37:29.56
  STEP: Patch a scale subresource @ 03/26/24 06:37:29.561
  Mar 26 06:37:29.568: INFO: Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8590",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ed2d37f0-9a36-4b46-8743-9cee8e537e84",
      ResourceVersion: (string) (len=5) "97096",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031847,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031848,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031848,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031848,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031848,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-788fbd4fc4\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Mar 26 06:37:29.572: INFO: New ReplicaSet "test-new-deployment-788fbd4fc4" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-788fbd4fc4",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8590",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "16e0eddd-464c-4266-85cd-512c6ef46e99",
      ResourceVersion: (string) (len=5) "97095",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031847,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "ed2d37f0-9a36-4b46-8743-9cee8e537e84",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031848,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031849,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 65 64 32 64 33 37  66 30 2d 39 61 33 36 2d  |\"ed2d37f0-9a36-|
              00000120  34 62 34 36 2d 38 37 34  33 2d 39 63 65 65 38 65  |4b46-8743-9cee8e|
              00000130  35 33 37 65 38 34 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |537e84\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Mar 26 06:37:29.576: INFO: Pod "test-new-deployment-788fbd4fc4-6cv69" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-788fbd4fc4-6cv69",
      GenerateName: (string) (len=31) "test-new-deployment-788fbd4fc4-",
      Namespace: (string) (len=15) "deployment-8590",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2a6f5451-31a0-4e9e-afb0-08f14b0c0a86",
      ResourceVersion: (string) (len=5) "97099",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031849,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-788fbd4fc4",
          UID: (types.UID) (len=36) "16e0eddd-464c-4266-85cd-512c6ef46e99",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031849,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 36  65 30 65 64 64 64 2d 34  |d\":\"16e0eddd-4|
              00000090  36 34 63 2d 34 32 36 36  2d 38 35 63 64 2d 35 31  |64c-4266-85cd-51|
              000000a0  32 63 36 65 66 34 36 65  39 39 5c 22 7d 22 3a 7b  |2c6ef46e99\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-z62dm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-z62dm",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031849,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:37:29.577: INFO: Pod "test-new-deployment-788fbd4fc4-ht758" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-788fbd4fc4-ht758",
      GenerateName: (string) (len=31) "test-new-deployment-788fbd4fc4-",
      Namespace: (string) (len=15) "deployment-8590",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c056f6ab-8e41-47ce-89c4-66bdf131c0ab",
      ResourceVersion: (string) (len=5) "97088",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031847,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "788fbd4fc4"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "10.244.69.238/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "10.244.69.238/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "94763e3231bf7ccaae3eb75c56f995f39f19b441eb413385bfb356150521415d"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-788fbd4fc4",
          UID: (types.UID) (len=36) "16e0eddd-464c-4266-85cd-512c6ef46e99",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 36  65 30 65 64 64 64 2d 34  |d\":\"16e0eddd-4|
              00000090  36 34 63 2d 34 32 36 36  2d 38 35 63 64 2d 35 31  |64c-4266-85cd-51|
              000000a0  32 63 36 65 66 34 36 65  39 39 5c 22 7d 22 3a 7b  |2c6ef46e99\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031848,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 34 34 2e 36  39 2e 32 33 38 5c 22 7d  |10.244.69.238\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xs985",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xs985",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031848,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031848,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031847,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.15",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.244.69.238",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.244.69.238"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031847,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63847031848,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          ImageID: (string) (len=120) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://02548e601a1410573a5d6b2e6d214ae6bbc393a27db25b9e6d78194175f8db20",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:37:29.578: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-8590" for this suite. @ 03/26/24 06:37:29.581
• [2.049 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]
test/e2e/common/node/configmap.go:45
  STEP: Creating a kubernetes client @ 03/26/24 06:37:29.587
  Mar 26 06:37:29.587: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename configmap @ 03/26/24 06:37:29.588
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:37:29.594
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:37:29.595
  STEP: Creating configMap configmap-1906/configmap-test-660868ce-3265-456e-bcef-d2ebf9ca5e5f @ 03/26/24 06:37:29.598
  STEP: Creating a pod to test consume configMaps @ 03/26/24 06:37:29.6
  E0326 06:37:29.961530      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:30.961648      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:31.962518      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:32.962658      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:37:33.613
  Mar 26 06:37:33.615: INFO: Trying to get logs from node k8s-worker02 pod pod-configmaps-ad8e30e9-f8f3-424c-a780-df0eeb4f01bf container env-test: <nil>
  STEP: delete the pod @ 03/26/24 06:37:33.617
  Mar 26 06:37:33.623: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1906" for this suite. @ 03/26/24 06:37:33.624
• [4.039 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]
test/e2e/apimachinery/namespace.go:243
  STEP: Creating a kubernetes client @ 03/26/24 06:37:33.627
  Mar 26 06:37:33.627: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename namespaces @ 03/26/24 06:37:33.628
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:37:33.633
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:37:33.635
  STEP: Creating a test namespace @ 03/26/24 06:37:33.637
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:37:33.642
  STEP: Creating a pod in the namespace @ 03/26/24 06:37:33.644
  STEP: Waiting for the pod to have running status @ 03/26/24 06:37:33.647
  E0326 06:37:33.962986      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:34.963077      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the namespace @ 03/26/24 06:37:35.651
  STEP: Waiting for the namespace to be removed. @ 03/26/24 06:37:35.653
  E0326 06:37:35.964010      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:36.964109      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:37.964638      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:38.964943      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:39.965660      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:40.966145      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:41.967119      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:42.967829      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:43.968680      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:44.969704      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:45.970512      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 03/26/24 06:37:46.655
  STEP: Verifying there are no pods in the namespace @ 03/26/24 06:37:46.662
  Mar 26 06:37:46.663: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-4395" for this suite. @ 03/26/24 06:37:46.665
  STEP: Destroying namespace "nsdeletetest-4763" for this suite. @ 03/26/24 06:37:46.668
  Mar 26 06:37:46.669: INFO: Namespace nsdeletetest-4763 was already deleted
  STEP: Destroying namespace "nsdeletetest-1061" for this suite. @ 03/26/24 06:37:46.669
• [13.043 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]
test/e2e/storage/csistoragecapacity.go:49
  STEP: Creating a kubernetes client @ 03/26/24 06:37:46.672
  Mar 26 06:37:46.672: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename csistoragecapacity @ 03/26/24 06:37:46.672
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:37:46.677
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:37:46.679
  STEP: getting /apis @ 03/26/24 06:37:46.68
  STEP: getting /apis/storage.k8s.io @ 03/26/24 06:37:46.682
  STEP: getting /apis/storage.k8s.io/v1 @ 03/26/24 06:37:46.683
  STEP: creating @ 03/26/24 06:37:46.683
  STEP: watching @ 03/26/24 06:37:46.689
  Mar 26 06:37:46.689: INFO: starting watch
  STEP: getting @ 03/26/24 06:37:46.691
  STEP: listing in namespace @ 03/26/24 06:37:46.693
  STEP: listing across namespaces @ 03/26/24 06:37:46.694
  STEP: patching @ 03/26/24 06:37:46.695
  STEP: updating @ 03/26/24 06:37:46.697
  Mar 26 06:37:46.699: INFO: waiting for watch events with expected annotations in namespace
  Mar 26 06:37:46.699: INFO: waiting for watch events with expected annotations across namespace
  STEP: deleting @ 03/26/24 06:37:46.699
  STEP: deleting a collection @ 03/26/24 06:37:46.702
  Mar 26 06:37:46.706: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-9555" for this suite. @ 03/26/24 06:37:46.708
• [0.039 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]
test/e2e/apimachinery/webhook.go:250
  STEP: Creating a kubernetes client @ 03/26/24 06:37:46.711
  Mar 26 06:37:46.711: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename webhook @ 03/26/24 06:37:46.711
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:37:46.716
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:37:46.718
  STEP: Setting up server cert @ 03/26/24 06:37:46.726
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 03/26/24 06:37:46.883
  STEP: Deploying the webhook pod @ 03/26/24 06:37:46.886
  STEP: Wait for the deployment to be ready @ 03/26/24 06:37:46.891
  Mar 26 06:37:46.895: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0326 06:37:46.971329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:47.971744      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 03/26/24 06:37:48.899
  STEP: Verifying the service has paired with the endpoint @ 03/26/24 06:37:48.904
  E0326 06:37:48.972565      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:37:49.904: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 03/26/24 06:37:49.907
  STEP: create a configmap that should be updated by the webhook @ 03/26/24 06:37:49.915
  Mar 26 06:37:49.922: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8645" for this suite. @ 03/26/24 06:37:49.938
  STEP: Destroying namespace "webhook-markers-989" for this suite. @ 03/26/24 06:37:49.942
• [3.236 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
test/e2e/apimachinery/webhook.go:273
  STEP: Creating a kubernetes client @ 03/26/24 06:37:49.948
  Mar 26 06:37:49.948: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename webhook @ 03/26/24 06:37:49.949
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:37:49.963
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:37:49.965
  E0326 06:37:49.972911      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Setting up server cert @ 03/26/24 06:37:49.973
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 03/26/24 06:37:50.369
  STEP: Deploying the webhook pod @ 03/26/24 06:37:50.372
  STEP: Wait for the deployment to be ready @ 03/26/24 06:37:50.377
  Mar 26 06:37:50.380: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0326 06:37:50.973502      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:51.974717      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 03/26/24 06:37:52.384
  STEP: Verifying the service has paired with the endpoint @ 03/26/24 06:37:52.388
  E0326 06:37:52.974637      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:37:53.389: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 03/26/24 06:37:53.392
  E0326 06:37:53.975429      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:54.975958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:55.976613      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:56.976748      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:57.977017      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:58.977169      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:37:59.977504      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:00.977635      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:01.977775      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:02.977913      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:38:03.403: INFO: Waiting for webhook configuration to be ready...
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 03/26/24 06:38:03.509
  STEP: Creating a dummy validating-webhook-configuration object @ 03/26/24 06:38:03.516
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 03/26/24 06:38:03.519
  STEP: Creating a dummy mutating-webhook-configuration object @ 03/26/24 06:38:03.521
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 03/26/24 06:38:03.524
  Mar 26 06:38:03.526: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4475" for this suite. @ 03/26/24 06:38:03.549
  STEP: Destroying namespace "webhook-markers-8836" for this suite. @ 03/26/24 06:38:03.553
• [13.607 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:58
  STEP: Creating a kubernetes client @ 03/26/24 06:38:03.557
  Mar 26 06:38:03.557: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename custom-resource-definition @ 03/26/24 06:38:03.558
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:38:03.564
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:38:03.565
  Mar 26 06:38:03.566: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  E0326 06:38:03.978738      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:38:04.576: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-7412" for this suite. @ 03/26/24 06:38:04.578
• [1.025 seconds]
------------------------------
SS
------------------------------
[sig-node] Secrets should patch a secret [Conformance]
test/e2e/common/node/secrets.go:154
  STEP: Creating a kubernetes client @ 03/26/24 06:38:04.581
  Mar 26 06:38:04.581: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename secrets @ 03/26/24 06:38:04.582
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:38:04.587
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:38:04.588
  STEP: creating a secret @ 03/26/24 06:38:04.59
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 03/26/24 06:38:04.591
  STEP: patching the secret @ 03/26/24 06:38:04.592
  STEP: deleting the secret using a LabelSelector @ 03/26/24 06:38:04.595
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 03/26/24 06:38:04.597
  Mar 26 06:38:04.598: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6193" for this suite. @ 03/26/24 06:38:04.599
• [0.019 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]
test/e2e/network/endpointslice.go:68
  STEP: Creating a kubernetes client @ 03/26/24 06:38:04.601
  Mar 26 06:38:04.601: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename endpointslice @ 03/26/24 06:38:04.601
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:38:04.606
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:38:04.607
  Mar 26 06:38:04.610: INFO: Endpoints addresses: [192.168.132.11] , ports: [6443]
  Mar 26 06:38:04.610: INFO: EndpointSlices addresses: [192.168.132.11] , ports: [6443]
  Mar 26 06:38:04.610: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-7000" for this suite. @ 03/26/24 06:38:04.612
• [0.012 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 03/26/24 06:38:04.613
  Mar 26 06:38:04.613: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename pods @ 03/26/24 06:38:04.614
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:38:04.621
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:38:04.622
  Mar 26 06:38:04.623: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: creating the pod @ 03/26/24 06:38:04.624
  STEP: submitting the pod to kubernetes @ 03/26/24 06:38:04.624
  E0326 06:38:04.979674      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:05.979775      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:38:06.687: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3429" for this suite. @ 03/26/24 06:38:06.689
• [2.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]
test/e2e/apimachinery/webhook.go:403
  STEP: Creating a kubernetes client @ 03/26/24 06:38:06.693
  Mar 26 06:38:06.693: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename webhook @ 03/26/24 06:38:06.693
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:38:06.699
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:38:06.702
  STEP: Setting up server cert @ 03/26/24 06:38:06.711
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 03/26/24 06:38:06.96
  STEP: Deploying the webhook pod @ 03/26/24 06:38:06.962
  STEP: Wait for the deployment to be ready @ 03/26/24 06:38:06.966
  Mar 26 06:38:06.969: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0326 06:38:06.980448      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:07.980584      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 03/26/24 06:38:08.973
  STEP: Verifying the service has paired with the endpoint @ 03/26/24 06:38:08.977
  E0326 06:38:08.981278      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:38:09.977: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 03/26/24 06:38:09.98
  E0326 06:38:09.981292      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 03/26/24 06:38:09.989
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 03/26/24 06:38:09.994
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 03/26/24 06:38:09.997
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 03/26/24 06:38:10.001
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 03/26/24 06:38:10.004
  Mar 26 06:38:10.007: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5878" for this suite. @ 03/26/24 06:38:10.021
  STEP: Destroying namespace "webhook-markers-7615" for this suite. @ 03/26/24 06:38:10.023
• [3.334 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]
test/e2e/common/storage/empty_dir.go:227
  STEP: Creating a kubernetes client @ 03/26/24 06:38:10.031
  Mar 26 06:38:10.031: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename emptydir @ 03/26/24 06:38:10.031
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:38:10.037
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:38:10.039
  STEP: Creating Pod @ 03/26/24 06:38:10.04
  E0326 06:38:10.982177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:11.982822      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 03/26/24 06:38:12.047
  Mar 26 06:38:12.047: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-1969 PodName:pod-sharedvolume-18b2888e-7ebf-4beb-bad7-75b19393e32e ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 06:38:12.047: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 06:38:12.048: INFO: ExecWithOptions: Clientset creation
  Mar 26 06:38:12.048: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/emptydir-1969/pods/pod-sharedvolume-18b2888e-7ebf-4beb-bad7-75b19393e32e/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  Mar 26 06:38:12.084: INFO: Exec stderr: ""
  Mar 26 06:38:12.084: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1969" for this suite. @ 03/26/24 06:38:12.086
• [2.057 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]
test/e2e/kubectl/kubectl.go:1674
  STEP: Creating a kubernetes client @ 03/26/24 06:38:12.089
  Mar 26 06:38:12.089: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubectl @ 03/26/24 06:38:12.089
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:38:12.095
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:38:12.098
  Mar 26 06:38:12.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-8733 version'
  Mar 26 06:38:12.135: INFO: stderr: ""
  Mar 26 06:38:12.135: INFO: stdout: "Client Version: v1.28.0\nKustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\nServer Version: v1.28.0\n"
  Mar 26 06:38:12.135: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8733" for this suite. @ 03/26/24 06:38:12.137
• [0.051 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance]
test/e2e/apps/rc.go:94
  STEP: Creating a kubernetes client @ 03/26/24 06:38:12.14
  Mar 26 06:38:12.140: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename replication-controller @ 03/26/24 06:38:12.141
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:38:12.147
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:38:12.148
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 03/26/24 06:38:12.149
  E0326 06:38:12.982967      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:13.983390      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 03/26/24 06:38:14.156
  STEP: Then the orphan pod is adopted @ 03/26/24 06:38:14.159
  E0326 06:38:14.983701      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:38:15.163: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-3073" for this suite. @ 03/26/24 06:38:15.164
• [3.026 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:57
  STEP: Creating a kubernetes client @ 03/26/24 06:38:15.166
  Mar 26 06:38:15.166: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 06:38:15.167
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:38:15.172
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:38:15.174
  STEP: Creating configMap with name projected-configmap-test-volume-82900f0c-34b7-440d-84c3-1ef7c982f047 @ 03/26/24 06:38:15.175
  STEP: Creating a pod to test consume configMaps @ 03/26/24 06:38:15.176
  E0326 06:38:15.984028      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:16.984493      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:38:17.182
  Mar 26 06:38:17.183: INFO: Trying to get logs from node k8s-worker01 pod pod-projected-configmaps-0cfafb1d-68c8-4144-907a-9396cf5713a6 container agnhost-container: <nil>
  STEP: delete the pod @ 03/26/24 06:38:17.186
  Mar 26 06:38:17.192: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2504" for this suite. @ 03/26/24 06:38:17.193
• [2.029 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:99
  STEP: Creating a kubernetes client @ 03/26/24 06:38:17.196
  Mar 26 06:38:17.196: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 06:38:17.196
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:38:17.204
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:38:17.205
  STEP: Creating configMap with name projected-configmap-test-volume-map-acc3e525-0404-4c53-b30e-180c20e54d54 @ 03/26/24 06:38:17.207
  STEP: Creating a pod to test consume configMaps @ 03/26/24 06:38:17.208
  E0326 06:38:17.985152      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:18.985207      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:19.985776      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:20.986052      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:38:21.217
  Mar 26 06:38:21.219: INFO: Trying to get logs from node k8s-worker02 pod pod-projected-configmaps-f4c7a2f5-2a86-4912-81a8-2e8d9178e750 container agnhost-container: <nil>
  STEP: delete the pod @ 03/26/24 06:38:21.222
  Mar 26 06:38:21.233: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1504" for this suite. @ 03/26/24 06:38:21.235
• [4.041 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 03/26/24 06:38:21.237
  Mar 26 06:38:21.237: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename container-runtime @ 03/26/24 06:38:21.238
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:38:21.243
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:38:21.244
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 03/26/24 06:38:21.249
  E0326 06:38:21.986089      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:22.986641      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:23.987823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:24.987664      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:25.987975      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:26.988465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:27.989301      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:28.990078      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:29.990767      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:30.991493      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:31.992096      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:32.992144      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:33.992841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:34.993059      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:35.994028      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 03/26/24 06:38:36.279
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 03/26/24 06:38:36.28
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 03/26/24 06:38:36.283
  STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] @ 03/26/24 06:38:36.283
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 03/26/24 06:38:36.29
  E0326 06:38:36.994568      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:37.995074      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:38.995647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 03/26/24 06:38:39.296
  E0326 06:38:39.995790      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 03/26/24 06:38:40.299
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 03/26/24 06:38:40.301
  STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] @ 03/26/24 06:38:40.301
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 03/26/24 06:38:40.309
  E0326 06:38:40.996802      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 03/26/24 06:38:41.313
  E0326 06:38:41.997185      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 03/26/24 06:38:42.317
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 03/26/24 06:38:42.32
  STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] @ 03/26/24 06:38:42.32
  Mar 26 06:38:42.325: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-3335" for this suite. @ 03/26/24 06:38:42.329
• [21.095 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]
test/e2e/apimachinery/webhook.go:646
  STEP: Creating a kubernetes client @ 03/26/24 06:38:42.332
  Mar 26 06:38:42.332: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename webhook @ 03/26/24 06:38:42.333
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:38:42.338
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:38:42.34
  STEP: Setting up server cert @ 03/26/24 06:38:42.348
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 03/26/24 06:38:42.498
  STEP: Deploying the webhook pod @ 03/26/24 06:38:42.501
  STEP: Wait for the deployment to be ready @ 03/26/24 06:38:42.506
  Mar 26 06:38:42.511: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0326 06:38:42.997579      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:43.997769      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 03/26/24 06:38:44.516
  STEP: Verifying the service has paired with the endpoint @ 03/26/24 06:38:44.52
  E0326 06:38:44.998320      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:38:45.520: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 03/26/24 06:38:45.544
  STEP: Creating a configMap that should be mutated @ 03/26/24 06:38:45.551
  STEP: Deleting the collection of validation webhooks @ 03/26/24 06:38:45.565
  STEP: Creating a configMap that should not be mutated @ 03/26/24 06:38:45.577
  Mar 26 06:38:45.581: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-679" for this suite. @ 03/26/24 06:38:45.596
  STEP: Destroying namespace "webhook-markers-5556" for this suite. @ 03/26/24 06:38:45.598
• [3.269 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]
test/e2e/network/service.go:1455
  STEP: Creating a kubernetes client @ 03/26/24 06:38:45.602
  Mar 26 06:38:45.602: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename services @ 03/26/24 06:38:45.603
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:38:45.609
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:38:45.611
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-1576 @ 03/26/24 06:38:45.612
  STEP: changing the ExternalName service to type=NodePort @ 03/26/24 06:38:45.614
  STEP: creating replication controller externalname-service in namespace services-1576 @ 03/26/24 06:38:45.62
  I0326 06:38:45.623018      19 runners.go:197] Created replication controller with name: externalname-service, namespace: services-1576, replica count: 2
  E0326 06:38:45.999974      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:47.000902      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:48.001070      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0326 06:38:48.673899      19 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Mar 26 06:38:48.673: INFO: Creating new exec pod
  E0326 06:38:49.001975      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:50.002618      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:51.002736      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:38:51.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-1576 exec execpodbtx8h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Mar 26 06:38:51.764: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Mar 26 06:38:51.764: INFO: stdout: ""
  E0326 06:38:52.003096      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:38:52.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-1576 exec execpodbtx8h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Mar 26 06:38:52.843: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Mar 26 06:38:52.843: INFO: stdout: "externalname-service-hqt7c"
  Mar 26 06:38:52.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-1576 exec execpodbtx8h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.61.18 80'
  Mar 26 06:38:52.918: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.61.18 80\nConnection to 10.96.61.18 80 port [tcp/http] succeeded!\n"
  Mar 26 06:38:52.918: INFO: stdout: "externalname-service-hqt7c"
  Mar 26 06:38:52.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-1576 exec execpodbtx8h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.132.15 31077'
  Mar 26 06:38:53.003: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.132.15 31077\nConnection to 192.168.132.15 31077 port [tcp/*] succeeded!\n"
  Mar 26 06:38:53.003: INFO: stdout: "externalname-service-hqt7c"
  E0326 06:38:53.003313      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:38:53.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-1576 exec execpodbtx8h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.132.11 31077'
  Mar 26 06:38:53.088: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.132.11 31077\nConnection to 192.168.132.11 31077 port [tcp/*] succeeded!\n"
  Mar 26 06:38:53.088: INFO: stdout: "externalname-service-v4tcm"
  Mar 26 06:38:53.088: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Mar 26 06:38:53.090: INFO: Cleaning up the ExternalName to NodePort test service
  STEP: Destroying namespace "services-1576" for this suite. @ 03/26/24 06:38:53.1
• [7.500 seconds]
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
test/e2e/node/security_context.go:164
  STEP: Creating a kubernetes client @ 03/26/24 06:38:53.102
  Mar 26 06:38:53.102: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename security-context @ 03/26/24 06:38:53.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:38:53.109
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:38:53.11
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 03/26/24 06:38:53.111
  E0326 06:38:54.004369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:55.005425      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:38:55.117
  Mar 26 06:38:55.119: INFO: Trying to get logs from node k8s-worker02 pod security-context-ceaf0f33-4f5b-4a39-8f62-1bf3587091bd container test-container: <nil>
  STEP: delete the pod @ 03/26/24 06:38:55.121
  Mar 26 06:38:55.127: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-7005" for this suite. @ 03/26/24 06:38:55.129
• [2.028 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
test/e2e/auth/service_accounts.go:529
  STEP: Creating a kubernetes client @ 03/26/24 06:38:55.131
  Mar 26 06:38:55.131: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename svcaccounts @ 03/26/24 06:38:55.132
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:38:55.137
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:38:55.138
  Mar 26 06:38:55.143: INFO: created pod
  E0326 06:38:56.005513      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:57.005597      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:38:57.148
  E0326 06:38:58.005687      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:38:59.006112      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:00.006470      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:01.006542      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:02.006683      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:03.006894      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:04.007016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:05.007245      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:06.007327      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:07.007412      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:08.007508      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:09.007597      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:10.008349      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:11.008444      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:12.008542      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:13.008620      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:14.008743      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:15.009469      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:16.009566      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:17.009658      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:18.009752      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:19.009905      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:20.010195      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:21.010370      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:22.010752      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:23.010908      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:24.011177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:25.011707      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:26.011848      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:27.011980      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:39:27.149: INFO: polling logs
  Mar 26 06:39:27.152: INFO: Pod logs: 
  I0326 06:38:55.604299       1 log.go:194] OK: Got token
  I0326 06:38:55.604357       1 log.go:194] validating with in-cluster discovery
  I0326 06:38:55.604557       1 log.go:194] OK: got issuer https://kubernetes.default.svc.cluster.local
  I0326 06:38:55.604583       1 log.go:194] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-652:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc000042740), NotBefore:(*jwt.NumericDate)(0xc0000428a8), IssuedAt:(*jwt.NumericDate)(0xc000042750), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-652", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"955d8479-8f9d-40b7-bf89-568b2909d94a"}}}
  I0326 06:38:55.610774       1 log.go:194] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
  I0326 06:38:55.614720       1 log.go:194] OK: Validated signature on JWT
  I0326 06:38:55.614766       1 log.go:194] OK: Got valid claims from token!
  I0326 06:38:55.614788       1 log.go:194] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-652:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0000439f8), NotBefore:(*jwt.NumericDate)(0xc000043a20), IssuedAt:(*jwt.NumericDate)(0xc000043a00), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-652", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"955d8479-8f9d-40b7-bf89-568b2909d94a"}}}

  Mar 26 06:39:27.152: INFO: completed pod
  Mar 26 06:39:27.155: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-652" for this suite. @ 03/26/24 06:39:27.157
• [32.028 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]
test/e2e/auth/service_accounts.go:740
  STEP: Creating a kubernetes client @ 03/26/24 06:39:27.16
  Mar 26 06:39:27.160: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename svcaccounts @ 03/26/24 06:39:27.16
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:39:27.166
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:39:27.167
  Mar 26 06:39:27.170: INFO: Got root ca configmap in namespace "svcaccounts-7362"
  Mar 26 06:39:27.172: INFO: Deleted root ca configmap in namespace "svcaccounts-7362"
  STEP: waiting for a new root ca configmap created @ 03/26/24 06:39:27.672
  Mar 26 06:39:27.674: INFO: Recreated root ca configmap in namespace "svcaccounts-7362"
  Mar 26 06:39:27.677: INFO: Updated root ca configmap in namespace "svcaccounts-7362"
  E0326 06:39:28.012258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for the root ca configmap reconciled @ 03/26/24 06:39:28.178
  Mar 26 06:39:28.180: INFO: Reconciled root ca configmap in namespace "svcaccounts-7362"
  Mar 26 06:39:28.180: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7362" for this suite. @ 03/26/24 06:39:28.182
• [1.025 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 03/26/24 06:39:28.185
  Mar 26 06:39:28.185: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename proxy @ 03/26/24 06:39:28.186
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:39:28.192
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:39:28.194
  Mar 26 06:39:28.195: INFO: Creating pod...
  E0326 06:39:29.012871      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:30.013298      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:39:30.203: INFO: Creating service...
  Mar 26 06:39:30.208: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2724/pods/agnhost/proxy/some/path/with/DELETE
  Mar 26 06:39:30.213: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Mar 26 06:39:30.213: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2724/pods/agnhost/proxy/some/path/with/GET
  Mar 26 06:39:30.214: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Mar 26 06:39:30.214: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2724/pods/agnhost/proxy/some/path/with/HEAD
  Mar 26 06:39:30.216: INFO: http.Client request:HEAD | StatusCode:200
  Mar 26 06:39:30.216: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2724/pods/agnhost/proxy/some/path/with/OPTIONS
  Mar 26 06:39:30.217: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Mar 26 06:39:30.218: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2724/pods/agnhost/proxy/some/path/with/PATCH
  Mar 26 06:39:30.219: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Mar 26 06:39:30.219: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2724/pods/agnhost/proxy/some/path/with/POST
  Mar 26 06:39:30.220: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Mar 26 06:39:30.220: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2724/pods/agnhost/proxy/some/path/with/PUT
  Mar 26 06:39:30.221: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Mar 26 06:39:30.221: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2724/services/test-service/proxy/some/path/with/DELETE
  Mar 26 06:39:30.223: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Mar 26 06:39:30.223: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2724/services/test-service/proxy/some/path/with/GET
  Mar 26 06:39:30.224: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Mar 26 06:39:30.224: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2724/services/test-service/proxy/some/path/with/HEAD
  Mar 26 06:39:30.226: INFO: http.Client request:HEAD | StatusCode:200
  Mar 26 06:39:30.226: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2724/services/test-service/proxy/some/path/with/OPTIONS
  Mar 26 06:39:30.227: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Mar 26 06:39:30.227: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2724/services/test-service/proxy/some/path/with/PATCH
  Mar 26 06:39:30.229: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Mar 26 06:39:30.229: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2724/services/test-service/proxy/some/path/with/POST
  Mar 26 06:39:30.230: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Mar 26 06:39:30.230: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2724/services/test-service/proxy/some/path/with/PUT
  Mar 26 06:39:30.231: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Mar 26 06:39:30.231: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-2724" for this suite. @ 03/26/24 06:39:30.233
• [2.051 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:71
  STEP: Creating a kubernetes client @ 03/26/24 06:39:30.237
  Mar 26 06:39:30.237: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename container-probe @ 03/26/24 06:39:30.238
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:39:30.244
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:39:30.246
  E0326 06:39:31.013892      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:32.014023      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:33.014131      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:34.014268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:35.015273      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:36.015641      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:37.016413      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:38.016605      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:39.016683      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:40.017238      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:41.018174      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:42.018375      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:43.018454      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:44.019221      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:45.020152      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:46.020385      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:47.021024      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:48.021113      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:49.021685      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:50.021763      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:51.022710      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:52.022815      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:39:52.275: INFO: Container started at 2024-03-26 06:39:30 +0000 UTC, pod became ready at 2024-03-26 06:39:50 +0000 UTC
  Mar 26 06:39:52.275: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4769" for this suite. @ 03/26/24 06:39:52.277
• [22.043 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:375
  STEP: Creating a kubernetes client @ 03/26/24 06:39:52.28
  Mar 26 06:39:52.280: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 06:39:52.281
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:39:52.287
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:39:52.288
  STEP: Creating configMap with name projected-configmap-test-volume-488f7f20-4a73-4d93-93c0-d90453ea19f2 @ 03/26/24 06:39:52.29
  STEP: Creating a pod to test consume configMaps @ 03/26/24 06:39:52.292
  E0326 06:39:53.023628      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:54.024362      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:39:54.299
  Mar 26 06:39:54.300: INFO: Trying to get logs from node k8s-worker02 pod pod-projected-configmaps-ba856962-40af-47ea-a08f-5a1118b44939 container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 03/26/24 06:39:54.303
  Mar 26 06:39:54.308: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2767" for this suite. @ 03/26/24 06:39:54.311
• [2.033 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]
test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 03/26/24 06:39:54.313
  Mar 26 06:39:54.313: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename deployment @ 03/26/24 06:39:54.314
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:39:54.319
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:39:54.32
  Mar 26 06:39:54.321: INFO: Creating deployment "test-recreate-deployment"
  Mar 26 06:39:54.323: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
  Mar 26 06:39:54.327: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
  E0326 06:39:55.025118      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:56.026149      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:39:56.330: INFO: Waiting deployment "test-recreate-deployment" to complete
  Mar 26 06:39:56.331: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
  Mar 26 06:39:56.334: INFO: Updating deployment test-recreate-deployment
  Mar 26 06:39:56.334: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  Mar 26 06:39:56.368: INFO: Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2628",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7892fe48-b36d-4cbb-8f27-5ed733d6bd09",
      ResourceVersion: (string) (len=5) "98382",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031994,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031996,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031996,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031996,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031996,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031996,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031994,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=64) "ReplicaSet \"test-recreate-deployment-545c4f5f9d\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Mar 26 06:39:56.372: INFO: New ReplicaSet "test-recreate-deployment-545c4f5f9d" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-545c4f5f9d",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2628",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d55af5cd-bac6-4519-a0a1-0d4db58e1efb",
      ResourceVersion: (string) (len=5) "98381",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031996,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "545c4f5f9d"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "7892fe48-b36d-4cbb-8f27-5ed733d6bd09",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031996,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 37 38 39 32 66 65  34 38 2d 62 33 36 64 2d  |\"7892fe48-b36d-|
              00000120  34 63 62 62 2d 38 66 32  37 2d 35 65 64 37 33 33  |4cbb-8f27-5ed733|
              00000130  64 36 62 64 30 39 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |d6bd09\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031996,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "545c4f5f9d",
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "545c4f5f9d"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Mar 26 06:39:56.372: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
  Mar 26 06:39:56.373: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-67594f86c5",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2628",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a6ef1337-024f-4877-a3ab-fd9b790614a2",
      ResourceVersion: (string) (len=5) "98370",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031994,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67594f86c5"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "7892fe48-b36d-4cbb-8f27-5ed733d6bd09",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031996,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 37 38 39 32 66 65  34 38 2d 62 33 36 64 2d  |\"7892fe48-b36d-|
              00000120  34 63 62 62 2d 38 66 32  37 2d 35 65 64 37 33 33  |4cbb-8f27-5ed733|
              00000130  64 36 62 64 30 39 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |d6bd09\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031996,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "67594f86c5"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "67594f86c5"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=55) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Mar 26 06:39:56.374: INFO: Pod "test-recreate-deployment-545c4f5f9d-ppjtd" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-recreate-deployment-545c4f5f9d-ppjtd",
      GenerateName: (string) (len=36) "test-recreate-deployment-545c4f5f9d-",
      Namespace: (string) (len=15) "deployment-2628",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "50610ea0-86a7-43e4-89cc-20af4dbdf968",
      ResourceVersion: (string) (len=5) "98380",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031996,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "545c4f5f9d"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-recreate-deployment-545c4f5f9d",
          UID: (types.UID) (len=36) "d55af5cd-bac6-4519-a0a1-0d4db58e1efb",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031996,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 35  35 61 66 35 63 64 2d 62  |d\":\"d55af5cd-b|
              00000090  61 63 36 2d 34 35 31 39  2d 61 30 61 31 2d 30 64  |ac6-4519-a0a1-0d|
              000000a0  34 64 62 35 38 65 31 65  66 62 5c 22 7d 22 3a 7b  |4db58e1efb\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031996,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=482) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000001e0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xpnwl",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xpnwl",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031996,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031996,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031996,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63847031996,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.15",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63847031996,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=57) "hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Mar 26 06:39:56.375: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2628" for this suite. @ 03/26/24 06:39:56.377
• [2.067 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:207
  STEP: Creating a kubernetes client @ 03/26/24 06:39:56.38
  Mar 26 06:39:56.380: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename emptydir @ 03/26/24 06:39:56.381
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:39:56.386
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:39:56.387
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 03/26/24 06:39:56.389
  E0326 06:39:57.026931      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:58.027074      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:39:59.028036      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:00.028343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:40:00.397
  Mar 26 06:40:00.398: INFO: Trying to get logs from node k8s-worker02 pod pod-091e10a3-88f5-4ef3-a840-bac5ca15333f container test-container: <nil>
  STEP: delete the pod @ 03/26/24 06:40:00.401
  Mar 26 06:40:00.406: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7002" for this suite. @ 03/26/24 06:40:00.408
• [4.029 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:486
  STEP: Creating a kubernetes client @ 03/26/24 06:40:00.415
  Mar 26 06:40:00.415: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename security-context-test @ 03/26/24 06:40:00.416
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:40:00.423
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:40:00.425
  E0326 06:40:01.028736      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:02.029467      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:40:02.433: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-3254" for this suite. @ 03/26/24 06:40:02.435
• [2.023 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance]
test/e2e/network/service.go:3552
  STEP: Creating a kubernetes client @ 03/26/24 06:40:02.441
  Mar 26 06:40:02.441: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename services @ 03/26/24 06:40:02.442
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:40:02.447
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:40:02.448
  STEP: creating a collection of services @ 03/26/24 06:40:02.449
  Mar 26 06:40:02.450: INFO: Creating e2e-svc-a-mpj8f
  Mar 26 06:40:02.452: INFO: Creating e2e-svc-b-kxsnw
  Mar 26 06:40:02.456: INFO: Creating e2e-svc-c-c9nwx
  STEP: deleting service collection @ 03/26/24 06:40:02.461
  Mar 26 06:40:02.472: INFO: Collection of services has been deleted
  Mar 26 06:40:02.472: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9949" for this suite. @ 03/26/24 06:40:02.474
• [0.036 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]
test/e2e/scheduling/predicates.go:444
  STEP: Creating a kubernetes client @ 03/26/24 06:40:02.478
  Mar 26 06:40:02.478: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename sched-pred @ 03/26/24 06:40:02.478
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:40:02.484
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:40:02.485
  Mar 26 06:40:02.486: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Mar 26 06:40:02.489: INFO: Waiting for terminating namespaces to be deleted...
  Mar 26 06:40:02.490: INFO: 
  Logging pods the apiserver thinks is on node k8s-master01 before test
  Mar 26 06:40:02.493: INFO: calico-kube-controllers-658d97c59c-j8hzg from kube-system started at 2024-03-26 01:40:20 +0000 UTC (1 container statuses recorded)
  Mar 26 06:40:02.493: INFO: 	Container calico-kube-controllers ready: true, restart count 1
  Mar 26 06:40:02.493: INFO: calico-node-ld9rp from kube-system started at 2024-03-26 01:40:19 +0000 UTC (1 container statuses recorded)
  Mar 26 06:40:02.493: INFO: 	Container calico-node ready: true, restart count 1
  Mar 26 06:40:02.493: INFO: coredns-6554b8b87f-5qtsr from kube-system started at 2024-03-26 01:40:20 +0000 UTC (1 container statuses recorded)
  Mar 26 06:40:02.493: INFO: 	Container coredns ready: true, restart count 1
  Mar 26 06:40:02.493: INFO: coredns-6554b8b87f-745fg from kube-system started at 2024-03-26 01:40:20 +0000 UTC (1 container statuses recorded)
  Mar 26 06:40:02.493: INFO: 	Container coredns ready: true, restart count 1
  Mar 26 06:40:02.493: INFO: etcd-k8s-master01 from kube-system started at 2024-03-26 03:13:06 +0000 UTC (1 container statuses recorded)
  Mar 26 06:40:02.493: INFO: 	Container etcd ready: true, restart count 1
  Mar 26 06:40:02.493: INFO: kube-apiserver-k8s-master01 from kube-system started at 2024-03-26 03:13:06 +0000 UTC (1 container statuses recorded)
  Mar 26 06:40:02.493: INFO: 	Container kube-apiserver ready: true, restart count 1
  Mar 26 06:40:02.493: INFO: kube-controller-manager-k8s-master01 from kube-system started at 2024-03-26 03:13:06 +0000 UTC (1 container statuses recorded)
  Mar 26 06:40:02.493: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Mar 26 06:40:02.493: INFO: kube-proxy-m9s5h from kube-system started at 2024-03-26 01:40:19 +0000 UTC (1 container statuses recorded)
  Mar 26 06:40:02.493: INFO: 	Container kube-proxy ready: true, restart count 1
  Mar 26 06:40:02.493: INFO: kube-scheduler-k8s-master01 from kube-system started at 2024-03-26 03:13:06 +0000 UTC (1 container statuses recorded)
  Mar 26 06:40:02.493: INFO: 	Container kube-scheduler ready: true, restart count 1
  Mar 26 06:40:02.493: INFO: sonobuoy-systemd-logs-daemon-set-c080bc1d82d24b52-pmc2w from sonobuoy started at 2024-03-26 05:32:54 +0000 UTC (2 container statuses recorded)
  Mar 26 06:40:02.493: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Mar 26 06:40:02.493: INFO: 	Container systemd-logs ready: true, restart count 0
  Mar 26 06:40:02.493: INFO: 
  Logging pods the apiserver thinks is on node k8s-worker01 before test
  Mar 26 06:40:02.495: INFO: calico-node-rhg5q from kube-system started at 2024-03-26 01:40:25 +0000 UTC (1 container statuses recorded)
  Mar 26 06:40:02.495: INFO: 	Container calico-node ready: true, restart count 1
  Mar 26 06:40:02.495: INFO: kube-proxy-6v82d from kube-system started at 2024-03-26 01:40:25 +0000 UTC (1 container statuses recorded)
  Mar 26 06:40:02.495: INFO: 	Container kube-proxy ready: true, restart count 1
  Mar 26 06:40:02.495: INFO: busybox-readonly-false-de52cbd4-4132-4a7e-a32a-3d73e3cfb599 from security-context-test-3254 started at 2024-03-26 06:40:00 +0000 UTC (1 container statuses recorded)
  Mar 26 06:40:02.495: INFO: 	Container busybox-readonly-false-de52cbd4-4132-4a7e-a32a-3d73e3cfb599 ready: false, restart count 0
  Mar 26 06:40:02.495: INFO: sonobuoy-e2e-job-316da3d257e34653 from sonobuoy started at 2024-03-26 05:32:54 +0000 UTC (2 container statuses recorded)
  Mar 26 06:40:02.495: INFO: 	Container e2e ready: true, restart count 0
  Mar 26 06:40:02.495: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Mar 26 06:40:02.496: INFO: sonobuoy-systemd-logs-daemon-set-c080bc1d82d24b52-vv8ws from sonobuoy started at 2024-03-26 05:32:54 +0000 UTC (2 container statuses recorded)
  Mar 26 06:40:02.496: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Mar 26 06:40:02.496: INFO: 	Container systemd-logs ready: true, restart count 0
  Mar 26 06:40:02.496: INFO: 
  Logging pods the apiserver thinks is on node k8s-worker02 before test
  Mar 26 06:40:02.498: INFO: calico-node-wz7cn from kube-system started at 2024-03-26 01:40:26 +0000 UTC (1 container statuses recorded)
  Mar 26 06:40:02.498: INFO: 	Container calico-node ready: true, restart count 1
  Mar 26 06:40:02.499: INFO: kube-proxy-6n6f6 from kube-system started at 2024-03-26 01:40:26 +0000 UTC (1 container statuses recorded)
  Mar 26 06:40:02.499: INFO: 	Container kube-proxy ready: true, restart count 1
  Mar 26 06:40:02.499: INFO: sonobuoy from sonobuoy started at 2024-03-26 05:32:53 +0000 UTC (1 container statuses recorded)
  Mar 26 06:40:02.499: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Mar 26 06:40:02.499: INFO: sonobuoy-systemd-logs-daemon-set-c080bc1d82d24b52-6w6hx from sonobuoy started at 2024-03-26 05:32:54 +0000 UTC (2 container statuses recorded)
  Mar 26 06:40:02.499: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Mar 26 06:40:02.499: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 03/26/24 06:40:02.499
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.17c03d3fc59c31f9], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling..] @ 03/26/24 06:40:02.511
  E0326 06:40:03.030035      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:40:03.511: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-7943" for this suite. @ 03/26/24 06:40:03.513
• [1.038 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:350
  STEP: Creating a kubernetes client @ 03/26/24 06:40:03.516
  Mar 26 06:40:03.516: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename field-validation @ 03/26/24 06:40:03.517
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:40:03.523
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:40:03.524
  Mar 26 06:40:03.526: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  W0326 06:40:03.527395      19 field_validation.go:423] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc001446af0 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  E0326 06:40:04.031041      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:05.031724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:06.032020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0326 06:40:06.053075      19 warnings.go:70] unknown field "alpha"
  W0326 06:40:06.053303      19 warnings.go:70] unknown field "beta"
  W0326 06:40:06.053524      19 warnings.go:70] unknown field "delta"
  W0326 06:40:06.053696      19 warnings.go:70] unknown field "epsilon"
  W0326 06:40:06.053775      19 warnings.go:70] unknown field "gamma"
  Mar 26 06:40:06.564: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8004" for this suite. @ 03/26/24 06:40:06.57
• [3.057 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance]
test/e2e/common/node/secrets.go:140
  STEP: Creating a kubernetes client @ 03/26/24 06:40:06.574
  Mar 26 06:40:06.574: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename secrets @ 03/26/24 06:40:06.575
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:40:06.58
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:40:06.581
  STEP: Creating projection with secret that has name secret-emptykey-test-61e50adc-414f-45ad-ab86-527c3b9e5cc6 @ 03/26/24 06:40:06.582
  Mar 26 06:40:06.582: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-230" for this suite. @ 03/26/24 06:40:06.584
• [0.013 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]
test/e2e/apimachinery/resource_quota.go:161
  STEP: Creating a kubernetes client @ 03/26/24 06:40:06.59
  Mar 26 06:40:06.590: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename resourcequota @ 03/26/24 06:40:06.591
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:40:06.596
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:40:06.597
  STEP: Discovering how many secrets are in namespace by default @ 03/26/24 06:40:06.598
  E0326 06:40:07.032340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:08.032498      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:09.032553      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:10.032894      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:11.033871      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 03/26/24 06:40:11.6
  E0326 06:40:12.034490      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:13.035171      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:14.035869      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:15.036753      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:16.037799      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 03/26/24 06:40:16.602
  STEP: Ensuring resource quota status is calculated @ 03/26/24 06:40:16.605
  E0326 06:40:17.037908      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:18.038027      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 03/26/24 06:40:18.607
  STEP: Ensuring resource quota status captures secret creation @ 03/26/24 06:40:18.612
  E0326 06:40:19.038645      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:20.038910      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 03/26/24 06:40:20.614
  STEP: Ensuring resource quota status released usage @ 03/26/24 06:40:20.617
  E0326 06:40:21.039137      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:22.039251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:40:22.619: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4546" for this suite. @ 03/26/24 06:40:22.621
• [16.033 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]
test/e2e/apimachinery/webhook.go:261
  STEP: Creating a kubernetes client @ 03/26/24 06:40:22.623
  Mar 26 06:40:22.623: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename webhook @ 03/26/24 06:40:22.624
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:40:22.629
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:40:22.63
  STEP: Setting up server cert @ 03/26/24 06:40:22.639
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 03/26/24 06:40:22.885
  STEP: Deploying the webhook pod @ 03/26/24 06:40:22.888
  STEP: Wait for the deployment to be ready @ 03/26/24 06:40:22.892
  Mar 26 06:40:22.895: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0326 06:40:23.039355      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:24.039571      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 03/26/24 06:40:24.899
  STEP: Verifying the service has paired with the endpoint @ 03/26/24 06:40:24.902
  E0326 06:40:25.040250      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:40:25.903: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 03/26/24 06:40:25.905
  STEP: create a pod that should be updated by the webhook @ 03/26/24 06:40:25.912
  Mar 26 06:40:25.919: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4229" for this suite. @ 03/26/24 06:40:25.937
  STEP: Destroying namespace "webhook-markers-515" for this suite. @ 03/26/24 06:40:25.939
• [3.319 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]
test/e2e/apimachinery/webhook.go:221
  STEP: Creating a kubernetes client @ 03/26/24 06:40:25.942
  Mar 26 06:40:25.942: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename webhook @ 03/26/24 06:40:25.943
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:40:25.947
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:40:25.948
  STEP: Setting up server cert @ 03/26/24 06:40:25.955
  E0326 06:40:26.041115      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 03/26/24 06:40:26.181
  STEP: Deploying the webhook pod @ 03/26/24 06:40:26.184
  STEP: Wait for the deployment to be ready @ 03/26/24 06:40:26.19
  Mar 26 06:40:26.194: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0326 06:40:27.041666      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:28.042021      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 03/26/24 06:40:28.199
  STEP: Verifying the service has paired with the endpoint @ 03/26/24 06:40:28.203
  E0326 06:40:29.042830      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:40:29.204: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Mar 26 06:40:29.206: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 03/26/24 06:40:29.711
  STEP: Creating a custom resource that should be denied by the webhook @ 03/26/24 06:40:29.719
  E0326 06:40:30.044971      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:31.045151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 03/26/24 06:40:31.734
  STEP: Updating the custom resource with disallowed data should be denied @ 03/26/24 06:40:31.737
  STEP: Deleting the custom resource should be denied @ 03/26/24 06:40:31.741
  STEP: Remove the offending key and value from the custom resource data @ 03/26/24 06:40:31.743
  STEP: Deleting the updated custom resource should be successful @ 03/26/24 06:40:31.747
  Mar 26 06:40:31.749: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0326 06:40:32.046157      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-3336" for this suite. @ 03/26/24 06:40:32.273
  STEP: Destroying namespace "webhook-markers-3845" for this suite. @ 03/26/24 06:40:32.277
• [6.337 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]
test/e2e/apimachinery/webhook.go:498
  STEP: Creating a kubernetes client @ 03/26/24 06:40:32.28
  Mar 26 06:40:32.281: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename webhook @ 03/26/24 06:40:32.281
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:40:32.288
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:40:32.29
  STEP: Setting up server cert @ 03/26/24 06:40:32.3
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 03/26/24 06:40:32.574
  STEP: Deploying the webhook pod @ 03/26/24 06:40:32.577
  STEP: Wait for the deployment to be ready @ 03/26/24 06:40:32.581
  Mar 26 06:40:32.585: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0326 06:40:33.047165      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:34.047633      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 03/26/24 06:40:34.59
  STEP: Verifying the service has paired with the endpoint @ 03/26/24 06:40:34.595
  E0326 06:40:35.048535      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:40:35.596: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 03/26/24 06:40:35.598
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 03/26/24 06:40:35.606
  STEP: Creating a configMap that should not be mutated @ 03/26/24 06:40:35.609
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 03/26/24 06:40:35.613
  STEP: Creating a configMap that should be mutated @ 03/26/24 06:40:35.616
  Mar 26 06:40:35.626: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3220" for this suite. @ 03/26/24 06:40:35.641
  STEP: Destroying namespace "webhook-markers-6075" for this suite. @ 03/26/24 06:40:35.645
• [3.367 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance]
test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 03/26/24 06:40:35.648
  Mar 26 06:40:35.648: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename dns @ 03/26/24 06:40:35.649
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:40:35.655
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:40:35.656
  STEP: Creating a test externalName service @ 03/26/24 06:40:35.657
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7299.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7299.svc.cluster.local; sleep 1; done
   @ 03/26/24 06:40:35.659
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7299.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7299.svc.cluster.local; sleep 1; done
   @ 03/26/24 06:40:35.659
  STEP: creating a pod to probe DNS @ 03/26/24 06:40:35.659
  STEP: submitting the pod to kubernetes @ 03/26/24 06:40:35.659
  E0326 06:40:36.049228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:37.050196      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 03/26/24 06:40:37.666
  STEP: looking for the results for each expected name from probers @ 03/26/24 06:40:37.667
  Mar 26 06:40:37.670: INFO: DNS probes using dns-test-c5048d75-1dac-4b19-a6a9-dcf301b373a6 succeeded

  STEP: changing the externalName to bar.example.com @ 03/26/24 06:40:37.67
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7299.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7299.svc.cluster.local; sleep 1; done
   @ 03/26/24 06:40:37.673
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7299.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7299.svc.cluster.local; sleep 1; done
   @ 03/26/24 06:40:37.673
  STEP: creating a second pod to probe DNS @ 03/26/24 06:40:37.673
  STEP: submitting the pod to kubernetes @ 03/26/24 06:40:37.673
  E0326 06:40:38.050436      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:39.052737      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 03/26/24 06:40:39.68
  STEP: looking for the results for each expected name from probers @ 03/26/24 06:40:39.681
  Mar 26 06:40:39.683: INFO: File wheezy_udp@dns-test-service-3.dns-7299.svc.cluster.local from pod  dns-7299/dns-test-995d56b0-72dc-4ee8-ad3c-c7c53ea1beb1 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Mar 26 06:40:39.684: INFO: Lookups using dns-7299/dns-test-995d56b0-72dc-4ee8-ad3c-c7c53ea1beb1 failed for: [wheezy_udp@dns-test-service-3.dns-7299.svc.cluster.local]

  Mar 26 06:40:39.686: INFO: Pod client logs for webserver: 
  Mar 26 06:40:39.688: INFO: Pod client logs for querier: 
  Mar 26 06:40:39.690: INFO: Pod client logs for jessie-querier: 
  E0326 06:40:40.052130      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:41.053049      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:42.053183      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:43.053336      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:44.053345      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:40:44.694: INFO: File jessie_udp@dns-test-service-3.dns-7299.svc.cluster.local from pod  dns-7299/dns-test-995d56b0-72dc-4ee8-ad3c-c7c53ea1beb1 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Mar 26 06:40:44.694: INFO: Lookups using dns-7299/dns-test-995d56b0-72dc-4ee8-ad3c-c7c53ea1beb1 failed for: [jessie_udp@dns-test-service-3.dns-7299.svc.cluster.local]

  Mar 26 06:40:44.696: INFO: Pod client logs for webserver: 
  Mar 26 06:40:44.698: INFO: Pod client logs for querier: 
  Mar 26 06:40:44.700: INFO: Pod client logs for jessie-querier: 
  E0326 06:40:45.054052      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:46.054198      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:47.054590      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:48.055602      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:49.055821      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:40:49.694: INFO: File jessie_udp@dns-test-service-3.dns-7299.svc.cluster.local from pod  dns-7299/dns-test-995d56b0-72dc-4ee8-ad3c-c7c53ea1beb1 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Mar 26 06:40:49.694: INFO: Lookups using dns-7299/dns-test-995d56b0-72dc-4ee8-ad3c-c7c53ea1beb1 failed for: [jessie_udp@dns-test-service-3.dns-7299.svc.cluster.local]

  Mar 26 06:40:49.696: INFO: Pod client logs for webserver: 
  Mar 26 06:40:49.699: INFO: Pod client logs for querier: 
  Mar 26 06:40:49.701: INFO: Pod client logs for jessie-querier: 
  E0326 06:40:50.056813      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:51.056913      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:52.057133      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:53.057290      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:54.057389      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:40:54.692: INFO: File wheezy_udp@dns-test-service-3.dns-7299.svc.cluster.local from pod  dns-7299/dns-test-995d56b0-72dc-4ee8-ad3c-c7c53ea1beb1 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Mar 26 06:40:54.694: INFO: Lookups using dns-7299/dns-test-995d56b0-72dc-4ee8-ad3c-c7c53ea1beb1 failed for: [wheezy_udp@dns-test-service-3.dns-7299.svc.cluster.local]

  Mar 26 06:40:54.697: INFO: Pod client logs for webserver: 
  Mar 26 06:40:54.699: INFO: Pod client logs for querier: 
  Mar 26 06:40:54.700: INFO: Pod client logs for jessie-querier: 
  E0326 06:40:55.057689      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:56.057812      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:57.057988      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:58.058526      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:40:59.059268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:40:59.693: INFO: DNS probes using dns-test-995d56b0-72dc-4ee8-ad3c-c7c53ea1beb1 succeeded

  STEP: changing the service to type=ClusterIP @ 03/26/24 06:40:59.693
  W0326 06:40:59.698768      19 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7299.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7299.svc.cluster.local; sleep 1; done
   @ 03/26/24 06:40:59.698
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7299.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7299.svc.cluster.local; sleep 1; done
   @ 03/26/24 06:40:59.698
  STEP: creating a third pod to probe DNS @ 03/26/24 06:40:59.698
  STEP: submitting the pod to kubernetes @ 03/26/24 06:40:59.7
  E0326 06:41:00.059367      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:01.059452      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 03/26/24 06:41:01.706
  STEP: looking for the results for each expected name from probers @ 03/26/24 06:41:01.707
  Mar 26 06:41:01.710: INFO: DNS probes using dns-test-099a6155-3f87-497c-ba6e-bf5c67c9a71f succeeded

  Mar 26 06:41:01.710: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 03/26/24 06:41:01.712
  STEP: deleting the pod @ 03/26/24 06:41:01.716
  STEP: deleting the pod @ 03/26/24 06:41:01.729
  STEP: deleting the test externalName service @ 03/26/24 06:41:01.739
  STEP: Destroying namespace "dns-7299" for this suite. @ 03/26/24 06:41:01.744
• [26.099 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:89
  STEP: Creating a kubernetes client @ 03/26/24 06:41:01.747
  Mar 26 06:41:01.747: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename configmap @ 03/26/24 06:41:01.748
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:41:01.753
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:41:01.754
  STEP: Creating configMap with name configmap-test-volume-map-41d3d502-15a9-4e5f-b89d-170c2885f2db @ 03/26/24 06:41:01.755
  STEP: Creating a pod to test consume configMaps @ 03/26/24 06:41:01.757
  E0326 06:41:02.060253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:03.060441      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:04.061657      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:05.062044      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:41:05.766
  Mar 26 06:41:05.767: INFO: Trying to get logs from node k8s-worker02 pod pod-configmaps-eaaf224c-1c22-4a5d-af93-f1e2e7d22f39 container agnhost-container: <nil>
  STEP: delete the pod @ 03/26/24 06:41:05.769
  Mar 26 06:41:05.774: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8085" for this suite. @ 03/26/24 06:41:05.776
• [4.031 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 03/26/24 06:41:05.779
  Mar 26 06:41:05.779: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 06:41:05.78
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:41:05.784
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:41:05.785
  STEP: Creating projection with secret that has name projected-secret-test-f177a916-6050-4706-b358-611cd808902d @ 03/26/24 06:41:05.787
  STEP: Creating a pod to test consume secrets @ 03/26/24 06:41:05.789
  E0326 06:41:06.062458      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:07.063378      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:08.064117      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:09.064228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:41:09.797
  Mar 26 06:41:09.798: INFO: Trying to get logs from node k8s-worker02 pod pod-projected-secrets-9d9a5d28-6ca5-4e62-8704-e91a4b81e23f container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 03/26/24 06:41:09.8
  Mar 26 06:41:09.804: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7099" for this suite. @ 03/26/24 06:41:09.806
• [4.029 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]
test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 03/26/24 06:41:09.808
  Mar 26 06:41:09.808: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename emptydir-wrapper @ 03/26/24 06:41:09.809
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:41:09.813
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:41:09.814
  STEP: Creating 50 configmaps @ 03/26/24 06:41:09.816
  STEP: Creating RC which spawns configmap-volume pods @ 03/26/24 06:41:10.061
  E0326 06:41:10.064735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:41:10.163: INFO: Pod name wrapped-volume-race-f45578bb-3b98-46de-9fe5-3654c39dcc95: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 03/26/24 06:41:10.163
  E0326 06:41:11.064871      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:12.064973      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating RC which spawns configmap-volume pods @ 03/26/24 06:41:12.219
  Mar 26 06:41:12.226: INFO: Pod name wrapped-volume-race-c63495b2-de48-43e7-abb6-645ea689ddbc: Found 0 pods out of 5
  E0326 06:41:13.066076      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:14.066339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:15.067123      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:16.067196      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:17.067309      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:41:17.230: INFO: Pod name wrapped-volume-race-c63495b2-de48-43e7-abb6-645ea689ddbc: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 03/26/24 06:41:17.23
  STEP: Creating RC which spawns configmap-volume pods @ 03/26/24 06:41:17.238
  Mar 26 06:41:17.245: INFO: Pod name wrapped-volume-race-597d638f-3cd9-4214-b37f-69c31b1da6b4: Found 0 pods out of 5
  E0326 06:41:18.067793      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:19.067947      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:20.068273      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:21.068476      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:22.068648      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:41:22.250: INFO: Pod name wrapped-volume-race-597d638f-3cd9-4214-b37f-69c31b1da6b4: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 03/26/24 06:41:22.25
  Mar 26 06:41:22.257: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController wrapped-volume-race-597d638f-3cd9-4214-b37f-69c31b1da6b4 in namespace emptydir-wrapper-4539, will wait for the garbage collector to delete the pods @ 03/26/24 06:41:22.258
  Mar 26 06:41:22.312: INFO: Deleting ReplicationController wrapped-volume-race-597d638f-3cd9-4214-b37f-69c31b1da6b4 took: 2.211292ms
  Mar 26 06:41:22.412: INFO: Terminating ReplicationController wrapped-volume-race-597d638f-3cd9-4214-b37f-69c31b1da6b4 pods took: 100.10157ms
  E0326 06:41:23.069573      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-c63495b2-de48-43e7-abb6-645ea689ddbc in namespace emptydir-wrapper-4539, will wait for the garbage collector to delete the pods @ 03/26/24 06:41:23.213
  Mar 26 06:41:23.267: INFO: Deleting ReplicationController wrapped-volume-race-c63495b2-de48-43e7-abb6-645ea689ddbc took: 2.404543ms
  Mar 26 06:41:23.368: INFO: Terminating ReplicationController wrapped-volume-race-c63495b2-de48-43e7-abb6-645ea689ddbc pods took: 100.469137ms
  E0326 06:41:24.070335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-f45578bb-3b98-46de-9fe5-3654c39dcc95 in namespace emptydir-wrapper-4539, will wait for the garbage collector to delete the pods @ 03/26/24 06:41:24.269
  Mar 26 06:41:24.324: INFO: Deleting ReplicationController wrapped-volume-race-f45578bb-3b98-46de-9fe5-3654c39dcc95 took: 2.287165ms
  Mar 26 06:41:24.424: INFO: Terminating ReplicationController wrapped-volume-race-f45578bb-3b98-46de-9fe5-3654c39dcc95 pods took: 100.52642ms
  E0326 06:41:25.071093      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 03/26/24 06:41:25.125
  STEP: Destroying namespace "emptydir-wrapper-4539" for this suite. @ 03/26/24 06:41:25.197
• [15.392 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]
test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 03/26/24 06:41:25.2
  Mar 26 06:41:25.200: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename init-container @ 03/26/24 06:41:25.201
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:41:25.206
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:41:25.208
  STEP: creating the pod @ 03/26/24 06:41:25.21
  Mar 26 06:41:25.210: INFO: PodSpec: initContainers in spec.initContainers
  E0326 06:41:26.071333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:27.072201      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:28.072925      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:41:29.050: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-8620" for this suite. @ 03/26/24 06:41:29.052
• [3.854 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:109
  STEP: Creating a kubernetes client @ 03/26/24 06:41:29.057
  Mar 26 06:41:29.057: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename configmap @ 03/26/24 06:41:29.058
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:41:29.063
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:41:29.065
  STEP: Creating configMap with name configmap-test-volume-map-6ce50da4-a2eb-4a7c-8457-700100500f68 @ 03/26/24 06:41:29.067
  STEP: Creating a pod to test consume configMaps @ 03/26/24 06:41:29.068
  E0326 06:41:29.073674      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:30.073980      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:31.074340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:41:31.075
  Mar 26 06:41:31.076: INFO: Trying to get logs from node k8s-worker02 pod pod-configmaps-815a3241-f5a3-4e1a-a3b2-6ff9883a4746 container agnhost-container: <nil>
  STEP: delete the pod @ 03/26/24 06:41:31.079
  Mar 26 06:41:31.084: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5935" for this suite. @ 03/26/24 06:41:31.086
• [2.032 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods  [Conformance]
test/e2e/network/service.go:846
  STEP: Creating a kubernetes client @ 03/26/24 06:41:31.089
  Mar 26 06:41:31.089: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename services @ 03/26/24 06:41:31.09
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:41:31.095
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:41:31.096
  STEP: creating service multi-endpoint-test in namespace services-9581 @ 03/26/24 06:41:31.098
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9581 to expose endpoints map[] @ 03/26/24 06:41:31.102
  Mar 26 06:41:31.104: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
  E0326 06:41:32.075134      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:41:32.108: INFO: successfully validated that service multi-endpoint-test in namespace services-9581 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-9581 @ 03/26/24 06:41:32.108
  E0326 06:41:33.076108      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:34.076287      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9581 to expose endpoints map[pod1:[100]] @ 03/26/24 06:41:34.117
  Mar 26 06:41:34.120: INFO: successfully validated that service multi-endpoint-test in namespace services-9581 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-9581 @ 03/26/24 06:41:34.12
  E0326 06:41:35.076373      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:36.076499      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9581 to expose endpoints map[pod1:[100] pod2:[101]] @ 03/26/24 06:41:36.128
  Mar 26 06:41:36.133: INFO: successfully validated that service multi-endpoint-test in namespace services-9581 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 03/26/24 06:41:36.133
  Mar 26 06:41:36.133: INFO: Creating new exec pod
  E0326 06:41:37.077413      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:38.077644      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:39.078032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:41:39.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-9581 exec execpod2vj64 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  Mar 26 06:41:39.223: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  Mar 26 06:41:39.223: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Mar 26 06:41:39.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-9581 exec execpod2vj64 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.202.99 80'
  Mar 26 06:41:39.304: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.202.99 80\nConnection to 10.96.202.99 80 port [tcp/http] succeeded!\n"
  Mar 26 06:41:39.304: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Mar 26 06:41:39.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-9581 exec execpod2vj64 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  Mar 26 06:41:39.385: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  Mar 26 06:41:39.385: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Mar 26 06:41:39.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-9581 exec execpod2vj64 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.202.99 81'
  Mar 26 06:41:39.476: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.202.99 81\nConnection to 10.96.202.99 81 port [tcp/*] succeeded!\n"
  Mar 26 06:41:39.476: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-9581 @ 03/26/24 06:41:39.476
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9581 to expose endpoints map[pod2:[101]] @ 03/26/24 06:41:39.482
  Mar 26 06:41:39.489: INFO: successfully validated that service multi-endpoint-test in namespace services-9581 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-9581 @ 03/26/24 06:41:39.489
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9581 to expose endpoints map[] @ 03/26/24 06:41:39.5
  Mar 26 06:41:39.504: INFO: successfully validated that service multi-endpoint-test in namespace services-9581 exposes endpoints map[]
  Mar 26 06:41:39.504: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9581" for this suite. @ 03/26/24 06:41:39.512
• [8.426 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 03/26/24 06:41:39.515
  Mar 26 06:41:39.515: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename hostport @ 03/26/24 06:41:39.515
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:41:39.521
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:41:39.522
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 03/26/24 06:41:39.525
  E0326 06:41:40.079034      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:41.079160      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.132.14 on the node which pod1 resides and expect scheduled @ 03/26/24 06:41:41.531
  E0326 06:41:42.079360      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:43.079479      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.132.14 but use UDP protocol on the node which pod2 resides @ 03/26/24 06:41:43.538
  E0326 06:41:44.079819      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:45.080096      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:46.081001      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:47.081148      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 03/26/24 06:41:47.552
  Mar 26 06:41:47.552: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.132.14 http://127.0.0.1:54323/hostname] Namespace:hostport-3718 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 06:41:47.552: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 06:41:47.553: INFO: ExecWithOptions: Clientset creation
  Mar 26 06:41:47.553: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-3718/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.132.14+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.132.14, port: 54323 @ 03/26/24 06:41:47.601
  Mar 26 06:41:47.601: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.132.14:54323/hostname] Namespace:hostport-3718 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 06:41:47.601: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 06:41:47.601: INFO: ExecWithOptions: Clientset creation
  Mar 26 06:41:47.601: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-3718/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.132.14%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.132.14, port: 54323 UDP @ 03/26/24 06:41:47.642
  Mar 26 06:41:47.642: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.132.14 54323] Namespace:hostport-3718 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 06:41:47.642: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 06:41:47.643: INFO: ExecWithOptions: Clientset creation
  Mar 26 06:41:47.643: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-3718/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.132.14+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E0326 06:41:48.081271      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:49.081339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:50.081434      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:51.081514      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:52.081613      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:41:52.682: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-3718" for this suite. @ 03/26/24 06:41:52.685
• [13.180 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance]
test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 03/26/24 06:41:52.695
  Mar 26 06:41:52.695: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename dns @ 03/26/24 06:41:52.696
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:41:52.715
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:41:52.717
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 03/26/24 06:41:52.719
  Mar 26 06:41:52.728: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-9794  59e906f0-b4fb-447b-b2b4-b3b43e93dcb0 99930 0 2024-03-26 06:41:52 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2024-03-26 06:41:52 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ddrzs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:hub.oepkgs.net/nestos/nestos-test/sonobuoy/agnhost:2.45,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ddrzs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  E0326 06:41:53.081710      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:54.082589      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS suffix list is configured on pod... @ 03/26/24 06:41:54.735
  Mar 26 06:41:54.735: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-9794 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 06:41:54.735: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 06:41:54.736: INFO: ExecWithOptions: Clientset creation
  Mar 26 06:41:54.736: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-9794/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 03/26/24 06:41:54.78
  Mar 26 06:41:54.780: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-9794 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Mar 26 06:41:54.780: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  Mar 26 06:41:54.781: INFO: ExecWithOptions: Clientset creation
  Mar 26 06:41:54.781: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-9794/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Mar 26 06:41:54.828: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Mar 26 06:41:54.830: INFO: Deleting pod test-dns-nameservers...
  STEP: Destroying namespace "dns-9794" for this suite. @ 03/26/24 06:41:54.835
• [2.142 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]
test/e2e/network/service.go:1533
  STEP: Creating a kubernetes client @ 03/26/24 06:41:54.838
  Mar 26 06:41:54.838: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename services @ 03/26/24 06:41:54.839
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:41:54.844
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:41:54.845
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-3898 @ 03/26/24 06:41:54.847
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 03/26/24 06:41:54.851
  STEP: creating service externalsvc in namespace services-3898 @ 03/26/24 06:41:54.851
  STEP: creating replication controller externalsvc in namespace services-3898 @ 03/26/24 06:41:54.862
  I0326 06:41:54.866193      19 runners.go:197] Created replication controller with name: externalsvc, namespace: services-3898, replica count: 2
  E0326 06:41:55.082664      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:56.083599      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:57.083709      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0326 06:41:57.917945      19 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 03/26/24 06:41:57.92
  Mar 26 06:41:57.926: INFO: Creating new exec pod
  E0326 06:41:58.084519      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:41:59.085129      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:41:59.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-3898 exec execpodhjhxc -- /bin/sh -x -c nslookup nodeport-service.services-3898.svc.cluster.local'
  Mar 26 06:42:00.044: INFO: stderr: "+ nslookup nodeport-service.services-3898.svc.cluster.local\n"
  Mar 26 06:42:00.044: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-3898.svc.cluster.local\tcanonical name = externalsvc.services-3898.svc.cluster.local.\nName:\texternalsvc.services-3898.svc.cluster.local\nAddress: 10.96.225.66\n\n"
  Mar 26 06:42:00.045: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController externalsvc in namespace services-3898, will wait for the garbage collector to delete the pods @ 03/26/24 06:42:00.047
  E0326 06:42:00.085964      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:42:00.100: INFO: Deleting ReplicationController externalsvc took: 1.702051ms
  Mar 26 06:42:00.201: INFO: Terminating ReplicationController externalsvc pods took: 100.682329ms
  E0326 06:42:01.086449      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:02.086556      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:03.086774      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:42:03.308: INFO: Cleaning up the NodePort to ExternalName test service
  STEP: Destroying namespace "services-3898" for this suite. @ 03/26/24 06:42:03.313
• [8.478 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods  [Conformance]
test/e2e/network/service.go:785
  STEP: Creating a kubernetes client @ 03/26/24 06:42:03.317
  Mar 26 06:42:03.317: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename services @ 03/26/24 06:42:03.317
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:42:03.323
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:42:03.325
  STEP: creating service endpoint-test2 in namespace services-8153 @ 03/26/24 06:42:03.326
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8153 to expose endpoints map[] @ 03/26/24 06:42:03.329
  Mar 26 06:42:03.331: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
  E0326 06:42:04.087579      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:42:04.335: INFO: successfully validated that service endpoint-test2 in namespace services-8153 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-8153 @ 03/26/24 06:42:04.335
  E0326 06:42:05.088315      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:06.088837      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8153 to expose endpoints map[pod1:[80]] @ 03/26/24 06:42:06.343
  Mar 26 06:42:06.347: INFO: successfully validated that service endpoint-test2 in namespace services-8153 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 03/26/24 06:42:06.347
  Mar 26 06:42:06.347: INFO: Creating new exec pod
  E0326 06:42:07.088892      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:08.089590      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:09.090037      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:42:09.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-8153 exec execpoddf8fb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Mar 26 06:42:09.437: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Mar 26 06:42:09.437: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Mar 26 06:42:09.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-8153 exec execpoddf8fb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.30.72 80'
  Mar 26 06:42:09.515: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.30.72 80\nConnection to 10.96.30.72 80 port [tcp/http] succeeded!\n"
  Mar 26 06:42:09.515: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-8153 @ 03/26/24 06:42:09.515
  E0326 06:42:10.091037      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:11.091235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8153 to expose endpoints map[pod1:[80] pod2:[80]] @ 03/26/24 06:42:11.523
  Mar 26 06:42:11.527: INFO: successfully validated that service endpoint-test2 in namespace services-8153 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 03/26/24 06:42:11.527
  E0326 06:42:12.091267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:42:12.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-8153 exec execpoddf8fb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Mar 26 06:42:12.606: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Mar 26 06:42:12.606: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Mar 26 06:42:12.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-8153 exec execpoddf8fb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.30.72 80'
  Mar 26 06:42:12.681: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.30.72 80\nConnection to 10.96.30.72 80 port [tcp/http] succeeded!\n"
  Mar 26 06:42:12.681: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-8153 @ 03/26/24 06:42:12.681
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8153 to expose endpoints map[pod2:[80]] @ 03/26/24 06:42:12.689
  Mar 26 06:42:12.694: INFO: successfully validated that service endpoint-test2 in namespace services-8153 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 03/26/24 06:42:12.694
  E0326 06:42:13.091285      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:42:13.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-8153 exec execpoddf8fb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Mar 26 06:42:13.779: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Mar 26 06:42:13.779: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Mar 26 06:42:13.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=services-8153 exec execpoddf8fb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.30.72 80'
  Mar 26 06:42:13.862: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.30.72 80\nConnection to 10.96.30.72 80 port [tcp/http] succeeded!\n"
  Mar 26 06:42:13.863: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-8153 @ 03/26/24 06:42:13.863
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8153 to expose endpoints map[] @ 03/26/24 06:42:13.874
  Mar 26 06:42:13.878: INFO: successfully validated that service endpoint-test2 in namespace services-8153 exposes endpoints map[]
  Mar 26 06:42:13.878: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8153" for this suite. @ 03/26/24 06:42:13.886
• [10.572 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:55
  STEP: Creating a kubernetes client @ 03/26/24 06:42:13.89
  Mar 26 06:42:13.890: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename runtimeclass @ 03/26/24 06:42:13.891
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:42:13.897
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:42:13.898
  Mar 26 06:42:13.902: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-5993" for this suite. @ 03/26/24 06:42:13.904
• [0.016 seconds]
------------------------------
SSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster  [Conformance]
test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 03/26/24 06:42:13.906
  Mar 26 06:42:13.906: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename dns @ 03/26/24 06:42:13.907
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:42:13.911
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:42:13.913
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 03/26/24 06:42:13.914
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 03/26/24 06:42:13.914
  STEP: creating a pod to probe DNS @ 03/26/24 06:42:13.914
  STEP: submitting the pod to kubernetes @ 03/26/24 06:42:13.914
  E0326 06:42:14.091868      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:15.092343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 03/26/24 06:42:15.921
  STEP: looking for the results for each expected name from probers @ 03/26/24 06:42:15.922
  Mar 26 06:42:15.926: INFO: DNS probes using dns-8681/dns-test-10e24741-6352-46cf-b1de-8756d11c7838 succeeded

  Mar 26 06:42:15.926: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 03/26/24 06:42:15.927
  STEP: Destroying namespace "dns-8681" for this suite. @ 03/26/24 06:42:15.932
• [2.028 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 03/26/24 06:42:15.934
  Mar 26 06:42:15.934: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename containers @ 03/26/24 06:42:15.935
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:42:15.94
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:42:15.941
  STEP: Creating a pod to test override all @ 03/26/24 06:42:15.942
  E0326 06:42:16.093339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:17.093436      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:18.093944      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:19.094041      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:42:19.953
  Mar 26 06:42:19.954: INFO: Trying to get logs from node k8s-worker02 pod client-containers-a8ba1741-d41d-4d95-a34a-f9d35aeeb337 container agnhost-container: <nil>
  STEP: delete the pod @ 03/26/24 06:42:19.956
  Mar 26 06:42:19.961: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-9170" for this suite. @ 03/26/24 06:42:19.963
• [4.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance]
test/e2e/apps/replica_set.go:154
  STEP: Creating a kubernetes client @ 03/26/24 06:42:19.967
  Mar 26 06:42:19.967: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename replicaset @ 03/26/24 06:42:19.967
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:42:19.972
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:42:19.973
  Mar 26 06:42:19.977: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0326 06:42:20.094122      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:21.094204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:22.094303      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:23.094377      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:24.095389      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:42:24.980: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 03/26/24 06:42:24.98
  STEP: Scaling up "test-rs" replicaset  @ 03/26/24 06:42:24.98
  Mar 26 06:42:24.984: INFO: Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 03/26/24 06:42:24.984
  Mar 26 06:42:24.988: INFO: observed ReplicaSet test-rs in namespace replicaset-2358 with ReadyReplicas 1, AvailableReplicas 1
  Mar 26 06:42:24.994: INFO: observed ReplicaSet test-rs in namespace replicaset-2358 with ReadyReplicas 1, AvailableReplicas 1
  Mar 26 06:42:25.003: INFO: observed ReplicaSet test-rs in namespace replicaset-2358 with ReadyReplicas 1, AvailableReplicas 1
  Mar 26 06:42:25.007: INFO: observed ReplicaSet test-rs in namespace replicaset-2358 with ReadyReplicas 1, AvailableReplicas 1
  E0326 06:42:25.095449      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:26.095508      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:42:26.238: INFO: observed ReplicaSet test-rs in namespace replicaset-2358 with ReadyReplicas 2, AvailableReplicas 2
  Mar 26 06:42:26.362: INFO: observed Replicaset test-rs in namespace replicaset-2358 with ReadyReplicas 3 found true
  Mar 26 06:42:26.362: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-2358" for this suite. @ 03/26/24 06:42:26.365
• [6.400 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:156
  STEP: Creating a kubernetes client @ 03/26/24 06:42:26.369
  Mar 26 06:42:26.369: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename runtimeclass @ 03/26/24 06:42:26.37
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:42:26.376
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:42:26.377
  STEP: Deleting RuntimeClass runtimeclass-1589-delete-me @ 03/26/24 06:42:26.38
  STEP: Waiting for the RuntimeClass to disappear @ 03/26/24 06:42:26.381
  Mar 26 06:42:26.385: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-1589" for this suite. @ 03/26/24 06:42:26.386
• [0.019 seconds]
------------------------------
SS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:91
  STEP: Creating a kubernetes client @ 03/26/24 06:42:26.388
  Mar 26 06:42:26.388: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename downward-api @ 03/26/24 06:42:26.389
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:42:26.393
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:42:26.394
  STEP: Creating a pod to test downward api env vars @ 03/26/24 06:42:26.395
  E0326 06:42:27.096518      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:28.096666      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:42:28.403
  Mar 26 06:42:28.405: INFO: Trying to get logs from node k8s-worker02 pod downward-api-7792c18f-b5e2-4d2e-a733-a27fb80963e9 container dapi-container: <nil>
  STEP: delete the pod @ 03/26/24 06:42:28.409
  Mar 26 06:42:28.418: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4653" for this suite. @ 03/26/24 06:42:28.42
• [2.034 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:222
  STEP: Creating a kubernetes client @ 03/26/24 06:42:28.424
  Mar 26 06:42:28.424: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename downward-api @ 03/26/24 06:42:28.426
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:42:28.434
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:42:28.437
  STEP: Creating a pod to test downward API volume plugin @ 03/26/24 06:42:28.439
  E0326 06:42:29.096982      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:30.097527      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:42:30.448
  Mar 26 06:42:30.449: INFO: Trying to get logs from node k8s-worker02 pod downwardapi-volume-c23773f2-7b1b-4754-bd5a-9f73f90e7d79 container client-container: <nil>
  STEP: delete the pod @ 03/26/24 06:42:30.452
  Mar 26 06:42:30.458: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9434" for this suite. @ 03/26/24 06:42:30.459
• [2.038 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:183
  STEP: Creating a kubernetes client @ 03/26/24 06:42:30.463
  Mar 26 06:42:30.463: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename container-probe @ 03/26/24 06:42:30.463
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:42:30.468
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:42:30.47
  STEP: Creating pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736 @ 03/26/24 06:42:30.471
  E0326 06:42:31.098126      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:32.098423      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 03/26/24 06:42:32.479
  Mar 26 06:42:32.480: INFO: Initial restart count of pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 is 0
  Mar 26 06:42:32.481: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:42:33.099433      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:34.099567      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:42:34.483: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:42:35.100046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:36.100143      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:42:36.485: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:42:37.100759      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:38.100903      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:42:38.486: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:42:39.101367      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:40.101604      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:42:40.488: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:42:41.102237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:42.102331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:42:42.492: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:42:43.102449      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:44.102533      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:42:44.494: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:42:45.103296      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:46.103448      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:42:46.496: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:42:47.104291      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:48.104342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:42:48.498: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:42:49.104595      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:50.105769      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:42:50.500: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:42:51.106084      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:52.106334      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:42:52.502: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:42:53.107090      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:54.107212      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:42:54.504: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:42:55.108013      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:56.108142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:42:56.506: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:42:57.108360      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:42:58.108455      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:42:58.508: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:42:59.109455      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:00.109569      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:00.510: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:01.110632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:02.111490      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:02.514: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:03.111574      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:04.111721      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:04.515: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:05.111855      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:06.112009      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:06.518: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:07.112218      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:08.112365      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:08.520: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:09.112540      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:10.112717      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:10.523: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:11.112809      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:12.112947      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:12.525: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:13.113973      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:14.114096      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:14.527: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:15.115033      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:16.115264      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:16.529: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:17.116132      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:18.116834      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:18.532: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:19.117892      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:20.118081      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:20.534: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:21.119033      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:22.119130      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:22.535: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:23.119248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:24.119317      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:24.537: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:25.120153      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:26.120335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:26.539: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:27.121173      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:28.121263      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:28.541: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:29.121968      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:30.122375      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:30.543: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:31.122525      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:32.122668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:32.545: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:33.123357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:34.123449      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:34.547: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:35.124172      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:36.124313      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:36.549: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:37.125177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:38.125268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:38.551: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:39.125942      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:40.126351      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:40.554: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:41.126486      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:42.126566      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:42.557: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:43.126663      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:44.127027      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:44.559: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:45.127543      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:46.127640      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:46.560: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:47.128393      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:48.129367      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:48.562: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:49.130421      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:50.131464      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:50.564: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:51.132527      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:52.132651      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:52.566: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:53.133108      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:54.133130      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:54.568: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:55.133981      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:56.134071      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:56.570: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:57.134805      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:43:58.135014      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:43:58.572: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:43:59.135903      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:00.136089      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:00.574: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:01.137017      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:02.137167      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:02.576: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:03.137919      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:04.138033      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:04.577: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:05.138823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:06.139057      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:06.580: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:07.139822      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:08.139956      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:08.582: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:09.140826      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:10.141202      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:10.584: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:11.141226      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:12.141426      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:12.586: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:13.141655      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:14.141694      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:14.588: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:15.141980      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:16.142072      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:16.590: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:17.142264      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:18.142426      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:18.592: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:19.143318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:20.143674      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:20.594: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:21.144107      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:22.144263      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:22.596: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:23.144902      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:24.145047      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:24.598: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:25.145961      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:26.146240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:26.600: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:27.147195      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:28.147443      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:28.603: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:29.147781      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:30.148071      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:30.605: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:31.148507      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:32.148677      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:32.608: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:33.148792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:34.149413      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:34.610: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:35.150417      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:36.151290      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:36.612: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:37.152007      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:38.153021      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:38.614: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:39.154035      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:40.154347      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:40.616: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:41.155284      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:42.156218      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:42.619: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:43.156301      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:44.156431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:44.621: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:45.157223      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:46.157350      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:46.623: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:47.157709      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:48.157797      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:48.624: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:49.158596      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:50.158783      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:50.627: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:51.159721      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:52.159770      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:52.628: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:53.160459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:54.160600      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:54.630: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:55.161465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:56.162559      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:56.632: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:57.163374      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:44:58.163465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:44:58.634: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:44:59.163621      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:00.163716      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:00.636: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:01.163813      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:02.164012      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:02.637: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:03.164532      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:04.164662      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:04.639: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:05.165119      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:06.165251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:06.641: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:07.165456      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:08.165592      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:08.643: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:09.166418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:10.166655      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:10.646: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:11.167429      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:12.167529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:12.648: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:13.168018      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:14.168161      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:14.650: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:15.169236      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:16.169369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:16.652: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:17.169743      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:18.170821      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:18.653: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:19.171136      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:20.171557      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:20.655: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:21.172581      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:22.172682      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:22.657: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:23.172881      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:24.173408      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:24.659: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:25.173376      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:26.173503      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:26.661: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:27.173936      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:28.174791      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:28.662: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:29.175517      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:30.176581      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:30.665: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:31.176674      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:32.176810      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:32.666: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:33.177500      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:34.177547      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:34.668: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:35.178484      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:36.178584      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:36.670: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:37.179082      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:38.179220      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:38.672: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:39.179362      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:40.180270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:40.674: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:41.181299      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:42.181431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:42.677: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:43.181520      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:44.181616      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:44.678: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:45.182249      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:46.182343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:46.680: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:47.182433      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:48.182573      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:48.681: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:49.183162      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:50.183250      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:50.683: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:51.183880      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:52.183966      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:52.685: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:53.184056      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:54.184174      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:54.688: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:55.185015      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:56.185175      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:56.690: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:57.185692      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:45:58.185783      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:45:58.691: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:45:59.186041      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:00.186366      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:46:00.693: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:46:01.187022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:02.187189      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:46:02.695: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:46:03.187826      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:04.187981      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:46:04.697: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:46:05.188626      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:06.188787      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:46:06.699: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:46:07.189078      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:08.189208      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:46:08.701: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:46:09.189638      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:10.190716      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:46:10.703: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:46:11.191708      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:12.191838      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:46:12.705: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:46:13.192754      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:14.192845      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:46:14.706: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:46:15.193607      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:16.193741      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:46:16.708: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:46:17.194411      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:18.194796      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:46:18.711: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:46:19.195025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:20.195417      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:46:20.713: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:46:21.196216      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:22.196319      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:46:22.715: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:46:23.196980      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:24.197089      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:46:24.717: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:46:25.197625      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:26.197743      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:46:26.718: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:46:27.198319      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:28.199553      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:46:28.720: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:46:29.199402      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:30.199591      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:46:30.723: INFO: Get pod liveness-d2c90247-a4d6-4e43-aefc-ca0149dc81a0 in namespace container-probe-2736
  E0326 06:46:31.200651      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:32.201302      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:46:32.723: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 03/26/24 06:46:32.726
  STEP: Destroying namespace "container-probe-2736" for this suite. @ 03/26/24 06:46:32.73
• [242.273 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 03/26/24 06:46:32.737
  Mar 26 06:46:32.737: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename pods @ 03/26/24 06:46:32.738
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:46:32.744
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:46:32.745
  STEP: creating the pod @ 03/26/24 06:46:32.747
  STEP: submitting the pod to kubernetes @ 03/26/24 06:46:32.747
  E0326 06:46:33.201422      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:34.201741      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 03/26/24 06:46:34.755
  STEP: updating the pod @ 03/26/24 06:46:34.756
  E0326 06:46:35.201928      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:46:35.263: INFO: Successfully updated pod "pod-update-9f979098-bf00-4960-81cb-9b3a70c62ced"
  STEP: verifying the updated pod is in kubernetes @ 03/26/24 06:46:35.264
  Mar 26 06:46:35.265: INFO: Pod update OK
  Mar 26 06:46:35.265: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5701" for this suite. @ 03/26/24 06:46:35.267
• [2.532 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
test/e2e/network/endpointslice.go:207
  STEP: Creating a kubernetes client @ 03/26/24 06:46:35.269
  Mar 26 06:46:35.269: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename endpointslice @ 03/26/24 06:46:35.27
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:46:35.275
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:46:35.276
  E0326 06:46:36.202647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:37.203908      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:38.204039      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:39.204181      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:40.204527      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 03/26/24 06:46:40.307
  E0326 06:46:41.204594      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:42.204823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:43.204957      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:44.205059      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:45.206032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing matching pods with named port @ 03/26/24 06:46:45.31
  E0326 06:46:46.207031      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:47.207189      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:48.207289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:49.207429      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:50.207653      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 03/26/24 06:46:50.314
  E0326 06:46:51.208683      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:52.209755      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:53.209924      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:54.210086      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:55.210378      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: recreating EndpointSlices after they've been deleted @ 03/26/24 06:46:55.318
  Mar 26 06:46:55.324: INFO: EndpointSlice for Service endpointslice-5700/example-named-port not found
  E0326 06:46:56.210797      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:57.210981      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:58.211172      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:46:59.211246      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:00.211479      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:01.212496      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:02.212585      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:03.212686      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:04.212829      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:05.213040      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:47:05.330: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-5700" for this suite. @ 03/26/24 06:47:05.332
• [30.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 03/26/24 06:47:05.338
  Mar 26 06:47:05.338: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename pods @ 03/26/24 06:47:05.338
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:47:05.346
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:47:05.348
  STEP: creating the pod @ 03/26/24 06:47:05.349
  STEP: setting up watch @ 03/26/24 06:47:05.349
  STEP: submitting the pod to kubernetes @ 03/26/24 06:47:05.45
  STEP: verifying the pod is in kubernetes @ 03/26/24 06:47:05.454
  STEP: verifying pod creation was observed @ 03/26/24 06:47:05.455
  E0326 06:47:06.213124      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:07.214173      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 03/26/24 06:47:07.46
  STEP: verifying pod deletion was observed @ 03/26/24 06:47:07.462
  E0326 06:47:08.214197      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:09.214600      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:47:09.377: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1830" for this suite. @ 03/26/24 06:47:09.379
• [4.044 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]
test/e2e/apimachinery/webhook.go:119
  STEP: Creating a kubernetes client @ 03/26/24 06:47:09.383
  Mar 26 06:47:09.383: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename webhook @ 03/26/24 06:47:09.383
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:47:09.39
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:47:09.391
  STEP: Setting up server cert @ 03/26/24 06:47:09.399
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 03/26/24 06:47:10.128
  STEP: Deploying the webhook pod @ 03/26/24 06:47:10.132
  STEP: Wait for the deployment to be ready @ 03/26/24 06:47:10.136
  Mar 26 06:47:10.140: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0326 06:47:10.215224      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:11.215326      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 03/26/24 06:47:12.143
  STEP: Verifying the service has paired with the endpoint @ 03/26/24 06:47:12.147
  E0326 06:47:12.215633      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:47:13.147: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 03/26/24 06:47:13.15
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 03/26/24 06:47:13.151
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 03/26/24 06:47:13.151
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 03/26/24 06:47:13.151
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 03/26/24 06:47:13.151
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 03/26/24 06:47:13.151
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 03/26/24 06:47:13.152
  Mar 26 06:47:13.152: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6652" for this suite. @ 03/26/24 06:47:13.166
  STEP: Destroying namespace "webhook-markers-9954" for this suite. @ 03/26/24 06:47:13.168
• [3.788 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance]
test/e2e/auth/service_accounts.go:808
  STEP: Creating a kubernetes client @ 03/26/24 06:47:13.171
  Mar 26 06:47:13.172: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename svcaccounts @ 03/26/24 06:47:13.173
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:47:13.177
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:47:13.179
  STEP: Creating ServiceAccount "e2e-sa-8stvv"  @ 03/26/24 06:47:13.181
  Mar 26 06:47:13.182: INFO: AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-8stvv"  @ 03/26/24 06:47:13.182
  Mar 26 06:47:13.186: INFO: AutomountServiceAccountToken: true
  Mar 26 06:47:13.188: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5483" for this suite. @ 03/26/24 06:47:13.19
• [0.021 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]
test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 03/26/24 06:47:13.197
  Mar 26 06:47:13.197: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename dns @ 03/26/24 06:47:13.198
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:47:13.203
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:47:13.204
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6757.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6757.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 03/26/24 06:47:13.206
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6757.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6757.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 03/26/24 06:47:13.206
  STEP: creating a pod to probe /etc/hosts @ 03/26/24 06:47:13.206
  STEP: submitting the pod to kubernetes @ 03/26/24 06:47:13.206
  E0326 06:47:13.215820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:14.216283      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:15.216328      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 03/26/24 06:47:15.216
  STEP: looking for the results for each expected name from probers @ 03/26/24 06:47:15.218
  Mar 26 06:47:15.223: INFO: DNS probes using dns-6757/dns-test-8cfd159d-f5aa-49ac-9f39-7db08996969e succeeded

  Mar 26 06:47:15.223: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 03/26/24 06:47:15.224
  STEP: Destroying namespace "dns-6757" for this suite. @ 03/26/24 06:47:15.229
• [2.035 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]
test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 03/26/24 06:47:15.233
  Mar 26 06:47:15.233: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename sched-preemption @ 03/26/24 06:47:15.233
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:47:15.238
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:47:15.24
  Mar 26 06:47:15.245: INFO: Waiting up to 1m0s for all nodes to be ready
  E0326 06:47:16.216445      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:17.216610      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:18.216679      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:19.216820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:20.217377      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:21.217472      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:22.217624      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:23.217688      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:24.218028      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:25.218669      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:26.219189      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:27.220124      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:28.220207      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:29.220289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:30.220384      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:31.220583      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:32.221021      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:33.221144      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:34.221415      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:35.221783      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:36.222852      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:37.222980      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:38.223993      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:39.224149      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:40.225253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:41.225393      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:42.225659      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:43.225776      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:44.226010      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:45.226263      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:46.226973      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:47.227107      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:48.227194      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:49.227263      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:50.228033      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:51.228172      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:52.228991      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:53.229056      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:54.229333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:55.229625      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:56.229814      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:57.230027      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:58.231031      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:47:59.231172      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:00.231947      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:01.232076      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:02.232570      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:03.232734      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:04.232837      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:05.233926      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:06.233887      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:07.233972      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:08.234069      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:09.234341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:10.234421      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:11.235026      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:12.235083      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:13.235190      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:14.235282      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:15.235431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:48:15.255: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 03/26/24 06:48:15.257
  Mar 26 06:48:15.268: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Mar 26 06:48:15.271: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Mar 26 06:48:15.282: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Mar 26 06:48:15.285: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  Mar 26 06:48:15.296: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Mar 26 06:48:15.298: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 03/26/24 06:48:15.299
  E0326 06:48:16.236010      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:17.236296      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 03/26/24 06:48:17.309
  E0326 06:48:18.236513      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:19.236622      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:20.236895      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:21.237043      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:48:21.324: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-6590" for this suite. @ 03/26/24 06:48:21.341
• [66.111 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]
test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 03/26/24 06:48:21.345
  Mar 26 06:48:21.345: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename sched-preemption @ 03/26/24 06:48:21.345
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:48:21.352
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:48:21.353
  Mar 26 06:48:21.358: INFO: Waiting up to 1m0s for all nodes to be ready
  E0326 06:48:22.237139      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:23.237404      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:24.237582      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:25.238031      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:26.238178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:27.238491      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:28.238951      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:29.239420      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:30.240207      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:31.240290      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:32.240441      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:33.240589      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:34.240950      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:35.240979      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:36.241830      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:37.241976      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:38.242158      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:39.242336      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:40.242993      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:41.243341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:42.243881      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:43.244006      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:44.244100      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:45.245392      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:46.245154      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:47.245258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:48.245352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:49.246043      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:50.246942      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:51.247170      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:52.247974      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:53.248057      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:54.248555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:55.249563      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:56.250608      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:57.251011      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:58.251626      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:48:59.252019      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:00.252899      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:01.252977      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:02.254037      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:03.254267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:04.254547      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:05.255539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:06.256060      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:07.257166      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:08.258260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:09.258491      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:10.259458      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:11.259725      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:12.260555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:13.260885      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:14.261229      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:15.261840      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:16.262341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:17.262549      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:18.263144      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:19.263239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:20.264296      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:21.264684      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:49:21.370: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 03/26/24 06:49:21.371
  Mar 26 06:49:21.379: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Mar 26 06:49:21.383: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Mar 26 06:49:21.394: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Mar 26 06:49:21.397: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  Mar 26 06:49:21.407: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Mar 26 06:49:21.410: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 03/26/24 06:49:21.411
  E0326 06:49:22.265745      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:23.265847      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 03/26/24 06:49:23.421
  E0326 06:49:24.265956      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:25.266067      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:26.266156      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:27.266309      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:49:27.444: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-5571" for this suite. @ 03/26/24 06:49:27.469
• [66.127 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:127
  STEP: Creating a kubernetes client @ 03/26/24 06:49:27.473
  Mar 26 06:49:27.473: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename emptydir @ 03/26/24 06:49:27.473
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:49:27.48
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:49:27.481
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 03/26/24 06:49:27.482
  E0326 06:49:28.266391      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:29.266496      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:30.267178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:31.267305      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:49:31.49
  Mar 26 06:49:31.491: INFO: Trying to get logs from node k8s-worker02 pod pod-cb1ff0e5-48f1-45dc-add9-f32b83bf8f53 container test-container: <nil>
  STEP: delete the pod @ 03/26/24 06:49:31.495
  Mar 26 06:49:31.502: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8511" for this suite. @ 03/26/24 06:49:31.503
• [4.034 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance]
test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 03/26/24 06:49:31.507
  Mar 26 06:49:31.507: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename field-validation @ 03/26/24 06:49:31.508
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:49:31.514
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:49:31.515
  STEP: apply creating a deployment @ 03/26/24 06:49:31.517
  Mar 26 06:49:31.518: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7164" for this suite. @ 03/26/24 06:49:31.523
• [0.018 seconds]
------------------------------
S
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:85
  STEP: Creating a kubernetes client @ 03/26/24 06:49:31.526
  Mar 26 06:49:31.526: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename downward-api @ 03/26/24 06:49:31.526
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:49:31.532
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:49:31.533
  STEP: Creating a pod to test downward API volume plugin @ 03/26/24 06:49:31.534
  E0326 06:49:32.267745      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:33.268824      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:34.269820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:35.269895      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:49:35.543
  Mar 26 06:49:35.544: INFO: Trying to get logs from node k8s-worker02 pod downwardapi-volume-dff320b0-218c-4720-9966-28299490652c container client-container: <nil>
  STEP: delete the pod @ 03/26/24 06:49:35.546
  Mar 26 06:49:35.553: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1615" for this suite. @ 03/26/24 06:49:35.555
• [4.031 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 03/26/24 06:49:35.557
  Mar 26 06:49:35.557: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 06:49:35.558
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:49:35.562
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:49:35.564
  STEP: Creating projection with secret that has name projected-secret-test-b9405ce4-838a-4a26-a9fc-20eee73dd6ff @ 03/26/24 06:49:35.565
  STEP: Creating a pod to test consume secrets @ 03/26/24 06:49:35.566
  E0326 06:49:36.269967      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:37.270226      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:38.271279      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:39.272194      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 06:49:39.581
  Mar 26 06:49:39.584: INFO: Trying to get logs from node k8s-worker02 pod pod-projected-secrets-9fc6c111-8ea2-4ccf-b4b3-b0a1d6d0008d container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 03/26/24 06:49:39.586
  Mar 26 06:49:39.593: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9831" for this suite. @ 03/26/24 06:49:39.595
• [4.039 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:214
  STEP: Creating a kubernetes client @ 03/26/24 06:49:39.597
  Mar 26 06:49:39.597: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename container-probe @ 03/26/24 06:49:39.598
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:49:39.604
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:49:39.605
  STEP: Creating pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371 @ 03/26/24 06:49:39.606
  E0326 06:49:40.272505      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:41.272753      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 03/26/24 06:49:41.612
  Mar 26 06:49:41.614: INFO: Initial restart count of pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 is 0
  Mar 26 06:49:41.615: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:49:42.272903      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:43.273050      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:49:43.617: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:49:44.273796      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:45.274045      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:49:45.619: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:49:46.274176      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:47.274414      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:49:47.621: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:49:48.275078      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:49.276074      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:49:49.622: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:49:50.276744      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:51.276901      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:49:51.625: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:49:52.277831      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:53.277982      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:49:53.627: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:49:54.278816      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:55.278943      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:49:55.629: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:49:56.279996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:57.280119      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:49:57.631: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:49:58.281193      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:49:59.281291      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:49:59.633: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:00.281384      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:01.281606      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:01.636: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:02.281700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:03.282250      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:03.638: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:04.283136      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:05.283334      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:05.640: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:06.283344      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:07.283481      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:07.643: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:08.284066      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:09.284216      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:09.645: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:10.284347      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:11.284545      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:11.647: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:12.284615      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:13.284693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:13.649: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:14.285487      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:15.286092      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:15.652: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:16.286038      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:17.286228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:17.654: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:18.286800      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:19.286997      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:19.656: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:20.287054      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:21.287237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:21.658: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:22.288154      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:23.289084      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:23.660: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:24.289555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:25.290435      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:25.662: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:26.291003      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:27.291161      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:27.665: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:28.292023      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:29.292179      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:29.667: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:30.293084      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:31.293207      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:31.669: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:32.294269      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:33.295078      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:33.671: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:34.296052      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:35.296811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:35.673: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:36.297052      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:37.297163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:37.675: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:38.297747      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:39.297877      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:39.677: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:40.297927      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:41.298015      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:41.679: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:42.298921      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:43.298959      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:43.680: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:44.299651      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:45.300055      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:45.683: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:46.300262      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:47.300999      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:47.685: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:48.301213      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:49.301320      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:49.687: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:50.301387      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:51.301582      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:51.689: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:52.302583      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:53.302680      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:53.691: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:54.303027      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:55.303391      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:55.693: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:56.303496      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:57.303693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:57.695: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:50:58.303792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:50:59.303981      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:50:59.698: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:00.304803      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:01.304956      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:01.700: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:02.305565      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:03.306057      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:03.703: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:04.306955      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:05.307335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:05.705: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:06.308301      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:07.308493      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:07.707: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:08.309520      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:09.310510      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:09.709: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:10.311375      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:11.311559      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:11.711: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:12.312382      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:13.313054      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:13.714: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:14.313879      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:15.314365      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:15.716: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:16.314476      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:17.314586      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:17.718: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:18.315562      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:19.315841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:19.721: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:20.316748      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:21.316922      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:21.724: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:22.317090      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:23.318127      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:23.726: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:24.318923      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:25.319289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:25.728: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:26.319518      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:27.319956      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:27.731: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:28.320783      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:29.321654      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:29.732: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:30.322593      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:31.322721      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:31.734: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:32.323150      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:33.324049      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:33.736: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:34.324212      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:35.324695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:35.739: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:36.325529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:37.325664      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:37.741: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:38.325955      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:39.326072      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:39.742: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:40.326321      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:41.326408      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:41.745: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:42.326441      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:43.327171      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:43.748: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:44.328010      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:45.328320      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:45.750: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:46.329267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:47.329362      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:47.752: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:48.330187      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:49.330281      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:49.753: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:50.330373      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:51.330462      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:51.756: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:52.331244      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:53.331475      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:53.758: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:54.332234      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:55.332329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:55.760: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:56.333270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:57.333366      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:57.761: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:51:58.334415      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:51:59.334506      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:51:59.763: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:00.335116      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:01.335205      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:01.764: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:02.335292      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:03.335402      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:03.767: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:04.336339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:05.337381      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:05.769: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:06.338264      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:07.338353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:07.771: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:08.338447      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:09.338540      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:09.773: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:10.339477      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:11.339563      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:11.775: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:12.340013      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:13.340140      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:13.777: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:14.340957      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:15.341265      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:15.779: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:16.342222      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:17.342346      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:17.781: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:18.342666      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:19.342818      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:19.782: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:20.342909      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:21.343056      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:21.783: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:22.343592      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:23.344016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:23.786: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:24.344798      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:25.344896      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:25.787: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:26.344956      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:27.345045      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:27.790: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:28.345962      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:29.346085      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:29.792: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:30.346943      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:31.347057      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:31.794: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:32.347803      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:33.347955      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:33.796: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:34.348890      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:35.349236      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:35.798: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:36.350025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:37.350160      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:37.801: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:38.350681      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:39.350784      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:39.802: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:40.351438      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:41.351568      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:41.804: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:42.351904      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:43.352032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:43.806: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:44.353064      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:45.353670      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:45.809: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:46.353740      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:47.353983      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:47.810: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:48.354448      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:49.354575      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:49.812: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:50.354967      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:51.355063      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:51.814: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:52.355280      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:53.356144      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:53.816: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:54.356257      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:55.356789      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:55.818: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:56.356803      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:57.357019      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:57.820: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:52:58.357855      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:52:59.357996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:52:59.821: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:53:00.358310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:01.359093      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:53:01.824: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:53:02.358882      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:03.359765      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:53:03.826: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:53:04.360274      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:05.360597      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:53:05.829: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:53:06.360954      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:07.361101      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:53:07.830: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:53:08.361196      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:09.361340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:53:09.832: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:53:10.362009      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:11.362144      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:53:11.834: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:53:12.362600      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:13.362789      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:53:13.835: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:53:14.363417      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:15.363872      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:53:15.838: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:53:16.363989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:17.365204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:53:17.840: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:53:18.365367      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:19.365470      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:53:19.842: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:53:20.366112      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:21.366250      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:53:21.844: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:53:22.367024      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:23.367164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:53:23.846: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:53:24.368173      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:25.368448      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:53:25.848: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:53:26.369074      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:27.369164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:53:27.850: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:53:28.369255      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:29.369355      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:53:29.852: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:53:30.370102      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:31.370546      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:53:31.854: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:53:32.371275      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:33.371415      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:53:33.856: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:53:34.371936      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:35.371969      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:53:35.858: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:53:36.372807      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:37.372918      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:53:37.859: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:53:38.373023      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:39.374021      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:53:39.862: INFO: Get pod test-webserver-4acfd2cc-621b-4551-b541-577ada2af6d5 in namespace container-probe-2371
  E0326 06:53:40.374801      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:41.375524      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:53:41.863: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 03/26/24 06:53:41.865
  STEP: Destroying namespace "container-probe-2371" for this suite. @ 03/26/24 06:53:41.87
• [242.275 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance]
test/e2e/apps/job.go:485
  STEP: Creating a kubernetes client @ 03/26/24 06:53:41.873
  Mar 26 06:53:41.873: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename job @ 03/26/24 06:53:41.873
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:53:41.879
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:53:41.881
  STEP: Creating a job @ 03/26/24 06:53:41.882
  STEP: Ensuring active pods == parallelism @ 03/26/24 06:53:41.885
  E0326 06:53:42.376314      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:43.376440      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete a job @ 03/26/24 06:53:43.887
  STEP: deleting Job.batch foo in namespace job-386, will wait for the garbage collector to delete the pods @ 03/26/24 06:53:43.887
  Mar 26 06:53:43.942: INFO: Deleting Job.batch foo took: 2.646774ms
  Mar 26 06:53:44.043: INFO: Terminating Job.batch foo pods took: 101.023273ms
  E0326 06:53:44.377406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:45.378669      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:46.378811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:47.378852      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:48.379066      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:49.379284      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:50.380267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:51.381290      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:52.382341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:53.383301      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:54.384244      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:55.384317      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:56.385339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:57.386361      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:58.386478      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:53:59.386615      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:00.386654      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:01.386948      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:02.387210      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:03.387387      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:04.387436      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:05.387907      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:06.388214      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:07.388252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:08.388517      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:09.388668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:10.388836      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:11.388941      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:12.389041      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:13.389363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:14.390192      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:15.390883      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 03/26/24 06:54:16.143
  Mar 26 06:54:16.145: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-386" for this suite. @ 03/26/24 06:54:16.147
• [34.276 seconds]
------------------------------
SS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 03/26/24 06:54:16.149
  Mar 26 06:54:16.149: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename taint-multiple-pods @ 03/26/24 06:54:16.15
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:54:16.155
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:54:16.157
  Mar 26 06:54:16.159: INFO: Waiting up to 1m0s for all nodes to be ready
  E0326 06:54:16.391299      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:17.391402      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:18.391430      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:19.391532      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:20.391688      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:21.391788      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:22.392110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:23.393272      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:24.393443      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:25.394269      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:26.395248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:27.395515      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:28.396107      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:29.396679      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:30.397675      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:31.397863      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:32.398784      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:33.399022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:34.399853      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:35.400310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:36.401062      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:37.402027      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:38.402299      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:39.402552      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:40.403495      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:41.404057      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:42.404831      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:43.405823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:44.405933      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:45.406000      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:46.406199      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:47.406311      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:48.406668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:49.406714      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:50.407111      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:51.407317      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:52.408073      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:53.408179      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:54.408548      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:55.409450      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:56.410142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:57.410222      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:58.410268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:54:59.410352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:00.410435      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:01.411026      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:02.411940      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:03.412018      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:04.412746      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:05.413087      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:06.413720      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:07.413879      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:08.413991      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:09.414050      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:10.414786      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:11.414895      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:12.415565      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:13.415671      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:14.416551      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:15.416979      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:55:16.168: INFO: Waiting for terminating namespaces to be deleted...
  Mar 26 06:55:16.169: INFO: Starting informer...
  STEP: Starting pods... @ 03/26/24 06:55:16.169
  Mar 26 06:55:16.377: INFO: Pod1 is running on k8s-worker02. Tainting Node
  E0326 06:55:16.417275      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:17.417430      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:18.417660      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:55:18.586: INFO: Pod2 is running on k8s-worker02. Tainting Node
  STEP: Trying to apply a taint on the Node @ 03/26/24 06:55:18.586
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 03/26/24 06:55:18.592
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 03/26/24 06:55:18.594
  E0326 06:55:19.418344      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:20.418589      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:21.419020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:22.419166      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:23.419340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:55:23.977: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
  E0326 06:55:24.419963      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:25.420210      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:26.420365      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:27.421025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:28.421144      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:29.421254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:30.421439      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:31.421969      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:32.422056      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:33.422204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:34.422415      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:35.422367      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:36.422455      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:37.422539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:38.422632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:39.422724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:40.423776      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:41.423872      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:42.424000      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:43.424103      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:55:43.996: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
  Mar 26 06:55:43.996: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 03/26/24 06:55:44.004
  STEP: Destroying namespace "taint-multiple-pods-4005" for this suite. @ 03/26/24 06:55:44.005
• [87.858 seconds]
------------------------------
SSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
test/e2e/common/node/sysctl.go:77
  STEP: Creating a kubernetes client @ 03/26/24 06:55:44.007
  Mar 26 06:55:44.007: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename sysctl @ 03/26/24 06:55:44.008
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:55:44.014
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:55:44.015
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 03/26/24 06:55:44.016
  STEP: Watching for error events or started pod @ 03/26/24 06:55:44.019
  E0326 06:55:44.424915      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:45.425506      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 03/26/24 06:55:46.021
  E0326 06:55:46.425589      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:47.425700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 03/26/24 06:55:48.025
  STEP: Getting logs from the pod @ 03/26/24 06:55:48.025
  STEP: Checking that the sysctl is actually updated @ 03/26/24 06:55:48.029
  Mar 26 06:55:48.029: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-5160" for this suite. @ 03/26/24 06:55:48.031
• [4.027 seconds]
------------------------------
SS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
test/e2e/common/node/expansion.go:228
  STEP: Creating a kubernetes client @ 03/26/24 06:55:48.034
  Mar 26 06:55:48.034: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename var-expansion @ 03/26/24 06:55:48.035
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:55:48.039
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:55:48.041
  STEP: creating the pod with failed condition @ 03/26/24 06:55:48.042
  E0326 06:55:48.426357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:49.426500      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:50.427253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:51.428018      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:52.428727      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:53.428873      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:54.429619      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:55.429724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:56.430265      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:57.430358      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:58.430472      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:55:59.430676      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:00.430996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:01.431097      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:02.431626      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:03.431747      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:04.432287      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:05.432688      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:06.433431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:07.433566      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:08.434038      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:09.434131      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:10.435101      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:11.435187      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:12.435270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:13.435365      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:14.436004      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:15.436202      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:16.436991      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:17.437165      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:18.437326      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:19.437487      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:20.438337      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:21.440115      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:22.440531      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:23.440768      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:24.441370      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:25.441429      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:26.442464      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:27.442842      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:28.443718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:29.443900      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:30.444719      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:31.445922      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:32.446633      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:33.446746      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:34.446790      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:35.446895      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:36.447391      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:37.447488      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:38.448537      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:39.448756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:40.448814      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:41.448956      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:42.449716      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:43.450605      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:44.450944      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:45.451592      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:46.451780      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:47.451900      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:48.452805      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:49.453478      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:50.454147      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:51.454242      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:52.454764      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:53.455477      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:54.455593      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:55.455721      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:56.455796      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:57.455943      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:58.456812      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:56:59.456911      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:00.457958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:01.458128      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:02.458708      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:03.458904      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:04.458970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:05.459326      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:06.460395      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:07.460498      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:08.460843      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:09.460956      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:10.461770      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:11.461912      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:12.461991      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:13.462080      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:14.462571      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:15.462647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:16.465455      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:17.465503      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:18.465588      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:19.465678      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:20.466526      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:21.466612      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:22.466694      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:23.466784      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:24.467381      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:25.467479      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:26.468071      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:27.469067      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:28.469856      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:29.470008      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:30.470115      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:31.470239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:32.470915      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:33.471049      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:34.471793      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:35.472457      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:36.473078      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:37.473258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:38.473721      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:39.473856      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:40.474595      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:41.474759      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:42.475164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:43.475301      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:44.476323      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:45.476417      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:46.476500      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:47.476596      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pod @ 03/26/24 06:57:48.046
  E0326 06:57:48.476681      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:57:48.552: INFO: Successfully updated pod "var-expansion-fe2ce67d-d164-49b9-9abb-02152df556c2"
  STEP: waiting for pod running @ 03/26/24 06:57:48.552
  E0326 06:57:49.476729      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:50.476764      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 03/26/24 06:57:50.557
  Mar 26 06:57:50.557: INFO: Deleting pod "var-expansion-fe2ce67d-d164-49b9-9abb-02152df556c2" in namespace "var-expansion-1339"
  Mar 26 06:57:50.559: INFO: Wait up to 5m0s for pod "var-expansion-fe2ce67d-d164-49b9-9abb-02152df556c2" to be fully deleted
  E0326 06:57:51.477016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:52.477105      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:53.478143      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:54.478211      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:55.479005      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:56.479397      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:57.479483      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:58.480022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:57:59.480645      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:00.481706      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:01.482766      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:02.482915      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:03.482955      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:04.483043      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:05.484014      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:06.484103      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:07.485055      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:08.486059      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:09.487074      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:10.487302      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:11.487340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:12.487429      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:13.488105      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:14.489014      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:15.489142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:16.489328      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:17.490357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:18.491125      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:19.491224      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:20.491559      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:21.491920      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:22.492149      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:58:22.597: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1339" for this suite. @ 03/26/24 06:58:22.6
• [154.568 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]
test/e2e/apps/statefulset.go:329
  STEP: Creating a kubernetes client @ 03/26/24 06:58:22.608
  Mar 26 06:58:22.608: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename statefulset @ 03/26/24 06:58:22.608
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:58:22.614
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:58:22.616
  STEP: Creating service test in namespace statefulset-9257 @ 03/26/24 06:58:22.617
  STEP: Creating a new StatefulSet @ 03/26/24 06:58:22.619
  Mar 26 06:58:22.624: INFO: Found 0 stateful pods, waiting for 3
  E0326 06:58:23.493025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:24.493328      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:25.493686      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:26.493828      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:27.494823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:28.494976      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:29.495111      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:30.495283      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:31.496284      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:32.496582      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:58:32.627: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Mar 26 06:58:32.627: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Mar 26 06:58:32.627: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.38-4 to hub.oepkgs.net/nestos/nestos-test/sonobuoy/httpd:2.4.39-4 @ 03/26/24 06:58:32.63
  Mar 26 06:58:32.644: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 03/26/24 06:58:32.644
  E0326 06:58:33.497326      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:34.497411      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:35.497488      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:36.497580      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:37.497705      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:38.497834      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:39.497982      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:40.498187      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:41.498321      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:42.498462      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 03/26/24 06:58:42.651
  STEP: Performing a canary update @ 03/26/24 06:58:42.651
  Mar 26 06:58:42.665: INFO: Updating stateful set ss2
  Mar 26 06:58:42.667: INFO: Waiting for Pod statefulset-9257/ss2-2 to have revision ss2-6b66c85569 update revision ss2-6655bf8dfb
  E0326 06:58:43.498553      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:44.498843      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:45.498829      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:46.499108      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:47.499214      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:48.499303      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:49.500310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:50.500781      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:51.502107      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:52.502248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 03/26/24 06:58:52.671
  Mar 26 06:58:52.698: INFO: Found 1 stateful pods, waiting for 3
  E0326 06:58:53.502494      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:54.502618      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:55.502977      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:56.503090      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:57.503257      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:58.503805      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:58:59.503914      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:00.504086      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:01.504679      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:02.505513      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:59:02.700: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Mar 26 06:59:02.701: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Mar 26 06:59:02.701: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 03/26/24 06:59:02.703
  Mar 26 06:59:02.717: INFO: Updating stateful set ss2
  Mar 26 06:59:02.719: INFO: Waiting for Pod statefulset-9257/ss2-1 to have revision ss2-6b66c85569 update revision ss2-6655bf8dfb
  E0326 06:59:03.505806      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:04.506034      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:05.506455      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:06.506672      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:07.506752      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:08.506887      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:09.507082      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:10.507174      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:11.507281      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:12.507383      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:59:12.737: INFO: Updating stateful set ss2
  Mar 26 06:59:12.741: INFO: Waiting for StatefulSet statefulset-9257/ss2 to complete update
  Mar 26 06:59:12.741: INFO: Waiting for Pod statefulset-9257/ss2-0 to have revision ss2-6b66c85569 update revision ss2-6655bf8dfb
  E0326 06:59:13.507474      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:14.507655      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:15.507693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:16.507900      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:17.508121      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:18.508308      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:19.508540      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:20.508787      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:21.509104      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:22.509296      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:59:22.744: INFO: Deleting all statefulset in ns statefulset-9257
  Mar 26 06:59:22.746: INFO: Scaling statefulset ss2 to 0
  E0326 06:59:23.510341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:24.510498      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:25.510986      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:26.511135      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:27.512022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:28.512154      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:29.512249      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:30.512362      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:31.512501      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:32.512601      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:59:32.752: INFO: Waiting for statefulset status.replicas updated to 0
  Mar 26 06:59:32.753: INFO: Deleting statefulset ss2
  Mar 26 06:59:32.758: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-9257" for this suite. @ 03/26/24 06:59:32.76
• [70.155 seconds]
------------------------------
SSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 03/26/24 06:59:32.763
  Mar 26 06:59:32.763: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename init-container @ 03/26/24 06:59:32.764
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:59:32.769
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:59:32.77
  STEP: creating the pod @ 03/26/24 06:59:32.772
  Mar 26 06:59:32.772: INFO: PodSpec: initContainers in spec.initContainers
  E0326 06:59:33.513240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:34.513260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:59:35.362: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-334" for this suite. @ 03/26/24 06:59:35.363
• [2.602 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:527
  STEP: Creating a kubernetes client @ 03/26/24 06:59:35.365
  Mar 26 06:59:35.365: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename container-probe @ 03/26/24 06:59:35.366
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 06:59:35.37
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 06:59:35.371
  STEP: Creating pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338 @ 03/26/24 06:59:35.372
  E0326 06:59:35.513773      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:36.513919      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 03/26/24 06:59:37.378
  Mar 26 06:59:37.379: INFO: Initial restart count of pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 is 0
  Mar 26 06:59:37.380: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 06:59:37.513974      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:38.514991      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:59:39.382: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 06:59:39.515818      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:40.515902      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:59:41.384: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 06:59:41.516783      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:42.516960      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:59:43.387: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 06:59:43.517103      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:44.517214      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:59:45.389: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 06:59:45.517313      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:46.517423      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:59:47.391: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 06:59:47.517961      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:48.518095      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:59:49.393: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 06:59:49.519076      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:50.520125      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:59:51.395: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 06:59:51.521170      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:52.521268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:59:53.398: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 06:59:53.521329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:54.521424      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:59:55.400: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 06:59:55.521422      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:56.521546      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:59:57.402: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 06:59:57.521524      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 06:59:58.521648      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 06:59:59.403: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 06:59:59.521998      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:00.522111      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:01.406: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:01.523148      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:02.523296      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:03.408: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:03.523518      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:04.524562      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:05.410: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:05.524732      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:06.525446      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:07.412: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:07.525536      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:08.525711      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:09.414: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:09.526508      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:10.526655      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:11.416: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:11.527664      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:12.527758      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:13.418: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:13.528676      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:14.528760      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:15.420: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:15.529167      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:16.529359      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:17.423: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:17.530182      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:18.530351      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:19.425: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:19.531323      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:20.531627      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:21.427: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:21.532050      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:22.532520      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:23.430: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:23.532849      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:24.533006      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:25.432: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:25.533495      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:26.533648      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:27.434: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:27.534527      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:28.534663      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:29.436: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:29.535628      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:30.536138      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:31.438: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:31.536660      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:32.536885      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:33.440: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:33.536969      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:34.537055      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:35.442: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:35.537412      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:36.538305      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:37.443: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:37.538915      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:38.539005      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:39.445: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:39.539962      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:40.540311      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:41.448: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:41.540392      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:42.540501      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:43.450: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:43.540849      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:44.541170      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:45.452: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:45.541989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:46.542914      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:47.454: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:47.543100      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:48.543204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:49.457: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:49.544243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:50.544494      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:51.458: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:51.545056      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:52.545190      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:53.461: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:53.545558      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:54.546014      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:55.463: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:55.546646      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:56.546758      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:57.465: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:57.547432      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:00:58.547584      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:00:59.466: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:00:59.547971      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:00.548904      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:01.468: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:01.549778      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:02.550092      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:03.471: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:03.550744      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:04.550984      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:05.473: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:05.551736      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:06.552405      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:07.475: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:07.552798      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:08.553043      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:09.477: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:09.553965      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:10.554119      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:11.479: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:11.554726      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:12.554825      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:13.482: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:13.555101      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:14.555285      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:15.484: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:15.555739      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:16.556193      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:17.487: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:17.556413      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:18.556595      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:19.489: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:19.556919      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:20.557132      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:21.491: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:21.557870      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:22.558004      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:23.494: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:23.558469      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:24.558650      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:25.496: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:25.559385      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:26.559584      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:27.498: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:27.560306      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:28.560473      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:29.500: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:29.561253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:30.561532      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:31.502: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:31.562407      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:32.562578      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:33.504: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:33.562918      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:34.563005      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:35.507: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:35.563393      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:36.563571      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:37.510: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:37.564262      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:38.564422      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:39.512: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:39.564467      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:40.564526      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:41.514: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:41.565391      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:42.566077      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:43.516: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:43.566928      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:44.566964      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:45.518: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:45.567662      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:46.567767      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:47.520: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:47.568670      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:48.568938      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:49.522: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:49.569487      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:50.569590      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:51.524: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:51.569922      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:52.570011      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:53.527: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:53.570264      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:54.570375      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:55.529: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:55.570493      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:56.570717      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:57.531: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:57.571917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:01:58.571962      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:01:59.533: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:01:59.572796      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:00.573023      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:01.535: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:01.573850      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:02.573990      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:03.537: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:03.574031      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:04.574704      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:05.540: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:05.574917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:06.575051      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:07.542: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:07.575747      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:08.575886      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:09.544: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:09.576811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:10.577808      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:11.546: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:11.578550      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:12.578696      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:13.548: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:13.578901      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:14.579004      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:15.550: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:15.579451      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:16.579574      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:17.552: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:17.580415      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:18.580535      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:19.554: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:19.581251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:20.581369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:21.555: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:21.581978      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:22.582108      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:23.558: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:23.582144      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:24.582258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:25.560: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:25.583088      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:26.583209      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:27.562: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:27.583624      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:28.583751      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:29.564: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:29.584181      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:30.584287      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:31.565: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:31.584873      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:32.584968      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:33.567: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:33.585006      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:34.586053      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:35.569: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:35.587072      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:36.587691      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:37.572: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:37.588424      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:38.588551      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:39.574: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:39.589391      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:40.590452      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:41.576: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:41.591191      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:42.591321      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:43.578: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:43.592324      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:44.592451      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:45.580: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:45.592503      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:46.592662      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:47.581: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:47.592925      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:48.593036      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:49.583: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:49.593821      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:50.594132      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:51.585: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:51.594623      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:52.594741      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:53.588: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:53.595377      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:54.595486      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:55.589: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:55.595940      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:56.597033      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:57.591: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:57.597759      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:02:58.597881      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:02:59.593: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:02:59.598827      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:00.598954      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:01.595: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:03:01.599556      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:02.599669      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:03.597: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:03:03.599701      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:04.599818      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:05.599: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:03:05.600582      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:06.601263      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:07.601470      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:07.601: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:03:08.601630      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:09.601772      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:09.604: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:03:10.601828      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:11.601932      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:11.606: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:03:12.602005      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:13.602094      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:13.609: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:03:14.602589      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:15.602674      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:15.611: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:03:16.603056      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:17.604112      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:17.613: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:03:18.604393      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:19.604516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:19.616: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:03:20.604605      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:21.605777      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:21.618: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:03:22.606485      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:23.606625      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:23.620: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:03:24.606725      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:25.607302      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:25.622: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:03:26.608230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:27.608370      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:27.625: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:03:28.608484      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:29.608765      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:29.627: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:03:30.609732      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:31.609877      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:31.629: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:03:32.610010      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:33.610106      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:33.633: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:03:34.611112      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:35.611818      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:35.635: INFO: Get pod test-grpc-607b9a10-b104-4c45-870d-34ecb5d57a24 in namespace container-probe-2338
  E0326 07:03:36.611926      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:37.612023      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:37.636: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 03/26/24 07:03:37.638
  STEP: Destroying namespace "container-probe-2338" for this suite. @ 03/26/24 07:03:37.643
• [242.280 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
test/e2e/apps/statefulset.go:593
  STEP: Creating a kubernetes client @ 03/26/24 07:03:37.647
  Mar 26 07:03:37.647: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename statefulset @ 03/26/24 07:03:37.648
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 07:03:37.654
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 07:03:37.656
  STEP: Creating service test in namespace statefulset-785 @ 03/26/24 07:03:37.657
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 03/26/24 07:03:37.659
  STEP: Creating stateful set ss in namespace statefulset-785 @ 03/26/24 07:03:37.661
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-785 @ 03/26/24 07:03:37.663
  Mar 26 07:03:37.665: INFO: Found 0 stateful pods, waiting for 1
  E0326 07:03:38.612484      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:39.612732      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:40.613108      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:41.613323      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:42.613477      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:43.613632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:44.613781      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:45.614190      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:46.614284      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:47.614363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:47.667: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 03/26/24 07:03:47.667
  Mar 26 07:03:47.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=statefulset-785 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Mar 26 07:03:47.745: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Mar 26 07:03:47.745: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Mar 26 07:03:47.745: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Mar 26 07:03:47.747: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0326 07:03:48.615120      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:49.616177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:50.616446      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:51.616593      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:52.616761      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:53.616908      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:54.616995      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:55.617239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:56.617379      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:03:57.617512      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:57.749: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Mar 26 07:03:57.749: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Mar 26 07:03:57.756: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999736s
  E0326 07:03:58.618312      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:58.757: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.998766592s
  E0326 07:03:59.618410      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:03:59.760: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.996545479s
  E0326 07:04:00.619449      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:04:00.763: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.994504568s
  E0326 07:04:01.619532      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:04:01.766: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.990412747s
  E0326 07:04:02.619603      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:04:02.768: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.988343804s
  E0326 07:04:03.620602      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:04:03.770: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.986403248s
  E0326 07:04:04.620709      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:04:04.772: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.984230038s
  E0326 07:04:05.621684      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:04:05.774: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.982398438s
  E0326 07:04:06.622311      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:04:06.777: INFO: Verifying statefulset ss doesn't scale past 1 for another 979.713487ms
  E0326 07:04:07.623075      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-785 @ 03/26/24 07:04:07.777
  Mar 26 07:04:07.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=statefulset-785 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Mar 26 07:04:07.863: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Mar 26 07:04:07.863: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Mar 26 07:04:07.863: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Mar 26 07:04:07.864: INFO: Found 1 stateful pods, waiting for 3
  E0326 07:04:08.623499      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:09.623898      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:10.624743      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:11.624893      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:12.625393      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:13.625488      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:14.625576      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:15.626735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:16.626920      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:17.626985      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:04:17.867: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Mar 26 07:04:17.867: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Mar 26 07:04:17.867: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 03/26/24 07:04:17.867
  STEP: Scale down will halt with unhealthy stateful pod @ 03/26/24 07:04:17.867
  Mar 26 07:04:17.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=statefulset-785 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Mar 26 07:04:17.950: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Mar 26 07:04:17.950: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Mar 26 07:04:17.950: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Mar 26 07:04:17.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=statefulset-785 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Mar 26 07:04:18.039: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Mar 26 07:04:18.039: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Mar 26 07:04:18.039: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Mar 26 07:04:18.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=statefulset-785 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Mar 26 07:04:18.118: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Mar 26 07:04:18.118: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Mar 26 07:04:18.118: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Mar 26 07:04:18.118: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Mar 26 07:04:18.120: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 2
  E0326 07:04:18.627609      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:19.627762      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:20.627792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:21.627893      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:22.628056      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:23.628226      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:24.628364      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:25.628693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:26.628827      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:27.628930      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:04:28.124: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Mar 26 07:04:28.124: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Mar 26 07:04:28.124: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Mar 26 07:04:28.128: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999822s
  E0326 07:04:28.628973      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:04:29.131: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997929457s
  E0326 07:04:29.629717      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:04:30.132: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.996245172s
  E0326 07:04:30.629809      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:04:31.134: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.994072217s
  E0326 07:04:31.630433      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:04:32.136: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.992502835s
  E0326 07:04:32.631143      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:04:33.138: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.990805402s
  E0326 07:04:33.631907      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:04:34.140: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.989013997s
  E0326 07:04:34.632955      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:04:35.142: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.986689917s
  E0326 07:04:35.633725      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:04:36.154: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.984173259s
  E0326 07:04:36.634403      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:04:37.156: INFO: Verifying statefulset ss doesn't scale past 3 for another 972.457482ms
  E0326 07:04:37.635025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-785 @ 03/26/24 07:04:38.157
  Mar 26 07:04:38.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=statefulset-785 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Mar 26 07:04:38.243: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Mar 26 07:04:38.243: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Mar 26 07:04:38.243: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Mar 26 07:04:38.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=statefulset-785 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Mar 26 07:04:38.329: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Mar 26 07:04:38.329: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Mar 26 07:04:38.329: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Mar 26 07:04:38.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=statefulset-785 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Mar 26 07:04:38.420: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Mar 26 07:04:38.420: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Mar 26 07:04:38.420: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Mar 26 07:04:38.420: INFO: Scaling statefulset ss to 0
  E0326 07:04:38.636052      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:39.636770      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:40.636870      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:41.637756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:42.638317      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:43.638407      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:44.638635      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:45.639032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:46.639186      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:47.639320      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 03/26/24 07:04:48.429
  Mar 26 07:04:48.429: INFO: Deleting all statefulset in ns statefulset-785
  Mar 26 07:04:48.430: INFO: Scaling statefulset ss to 0
  Mar 26 07:04:48.437: INFO: Waiting for statefulset status.replicas updated to 0
  Mar 26 07:04:48.439: INFO: Deleting statefulset ss
  Mar 26 07:04:48.445: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-785" for this suite. @ 03/26/24 07:04:48.447
• [70.803 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance]
test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 03/26/24 07:04:48.451
  Mar 26 07:04:48.451: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename pods @ 03/26/24 07:04:48.452
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 07:04:48.46
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 07:04:48.463
  STEP: Create a pod @ 03/26/24 07:04:48.464
  E0326 07:04:48.639813      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:49.639939      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 03/26/24 07:04:50.471
  Mar 26 07:04:50.475: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
  Mar 26 07:04:50.475: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1551" for this suite. @ 03/26/24 07:04:50.477
• [2.029 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 03/26/24 07:04:50.48
  Mar 26 07:04:50.480: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename projected @ 03/26/24 07:04:50.48
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 07:04:50.485
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 07:04:50.49
  STEP: Creating configMap with name configmap-projected-all-test-volume-72b68b90-6431-45a3-b416-d3ab56177eb4 @ 03/26/24 07:04:50.491
  STEP: Creating secret with name secret-projected-all-test-volume-d05de486-25b5-40e2-93e1-6c391fd7d5ae @ 03/26/24 07:04:50.493
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 03/26/24 07:04:50.494
  E0326 07:04:50.640815      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:51.641016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:52.641339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:53.641483      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 07:04:54.503
  Mar 26 07:04:54.504: INFO: Trying to get logs from node k8s-worker02 pod projected-volume-90adc316-2642-4e43-b865-4eaf8fa15ac9 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 03/26/24 07:04:54.507
  Mar 26 07:04:54.513: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9024" for this suite. @ 03/26/24 07:04:54.515
• [4.037 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:550
  STEP: Creating a kubernetes client @ 03/26/24 07:04:54.517
  Mar 26 07:04:54.517: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename container-probe @ 03/26/24 07:04:54.518
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 07:04:54.523
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 07:04:54.525
  STEP: Creating pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155 @ 03/26/24 07:04:54.527
  E0326 07:04:54.642416      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:55.643155      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 03/26/24 07:04:56.533
  Mar 26 07:04:56.535: INFO: Initial restart count of pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d is 0
  Mar 26 07:04:56.536: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:04:56.643413      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:57.643587      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:04:58.538: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:04:58.643964      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:04:59.644477      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:00.541: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:00.645472      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:01.645634      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:02.543: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:02.646579      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:03.646756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:04.545: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:04.647432      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:05.648700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:06.546: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:06.649015      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:07.649144      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:08.549: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:08.649782      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:09.649916      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:10.551: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:10.650462      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:11.650559      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:12.553: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:12.650678      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:13.650831      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:14.555: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:14.651747      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:15.651783      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:16.557: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:16.652470      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:17.652592      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:18.559: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:18.653051      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:19.653186      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:20.562: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:20.653206      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:21.654341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:22.563: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:22.654889      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:23.655028      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:24.565: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:24.655651      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:25.656137      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:26.567: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:26.656874      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:27.657003      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:28.570: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:28.657399      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:29.657589      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:30.572: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:30.658504      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:31.658684      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:32.574: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:32.659603      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:33.659739      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:34.577: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:34.660407      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:35.660695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:36.578: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:36.661158      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:37.661344      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:38.581: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:38.662101      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:39.662303      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:40.583: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:40.663095      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:41.664005      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:42.586: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:42.664223      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:43.665427      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:44.588: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:44.665627      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:45.666036      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:46.590: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:46.666925      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:47.667024      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:48.593: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:48.667350      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:49.667555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:50.595: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:50.668338      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:51.669352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:52.597: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:52.670224      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:53.670543      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:54.599: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:54.670775      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:55.671119      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:56.601: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:56.672015      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:57.672632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:05:58.604: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:05:58.673007      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:05:59.673179      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:06:00.606: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  E0326 07:06:00.673920      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:01.673960      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:06:02.608: INFO: Get pod test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d in namespace container-probe-8155
  Mar 26 07:06:02.609: INFO: Restart count of pod container-probe-8155/test-grpc-08e9abbd-87dc-40bc-92ff-ad674681075d is now 1 (1m6.074030665s elapsed)
  Mar 26 07:06:02.609: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 03/26/24 07:06:02.611
  STEP: Destroying namespace "container-probe-8155" for this suite. @ 03/26/24 07:06:02.618
• [68.104 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:208
  STEP: Creating a kubernetes client @ 03/26/24 07:06:02.622
  Mar 26 07:06:02.622: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename downward-api @ 03/26/24 07:06:02.623
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 07:06:02.63
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 07:06:02.633
  STEP: Creating a pod to test downward API volume plugin @ 03/26/24 07:06:02.634
  E0326 07:06:02.674895      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:03.675153      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:04.675550      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:05.675665      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 03/26/24 07:06:06.642
  Mar 26 07:06:06.644: INFO: Trying to get logs from node k8s-worker02 pod downwardapi-volume-416f7475-ebc5-4a28-a1a4-7a1fadb83e3e container client-container: <nil>
  STEP: delete the pod @ 03/26/24 07:06:06.646
  Mar 26 07:06:06.651: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5320" for this suite. @ 03/26/24 07:06:06.653
• [4.033 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]
test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 03/26/24 07:06:06.655
  Mar 26 07:06:06.655: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename taint-single-pod @ 03/26/24 07:06:06.656
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 07:06:06.66
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 07:06:06.663
  Mar 26 07:06:06.664: INFO: Waiting up to 1m0s for all nodes to be ready
  E0326 07:06:06.676368      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:07.676511      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:08.677502      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:09.677653      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:10.677912      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:11.678049      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:12.679059      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:13.679292      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:14.680005      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:15.680544      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:16.681174      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:17.681395      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:18.681779      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:19.682228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:20.682834      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:21.683134      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:22.684073      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:23.684202      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:24.684737      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:25.685313      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:26.686136      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:27.686521      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:28.687349      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:29.687553      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:30.687906      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:31.687968      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:32.688015      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:33.688173      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:34.689148      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:35.689489      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:36.689868      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:37.690036      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:38.690944      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:39.691077      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:40.692153      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:41.692317      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:42.693081      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:43.694036      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:44.694112      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:45.694583      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:46.694567      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:47.694675      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:48.695294      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:49.695412      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:50.695538      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:51.696140      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:52.697067      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:53.697174      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:54.697489      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:55.697935      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:56.698683      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:57.698900      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:58.698890      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:06:59.699124      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:00.700000      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:01.701001      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:02.701025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:03.701191      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:04.701685      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:05.701803      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:07:06.673: INFO: Waiting for terminating namespaces to be deleted...
  Mar 26 07:07:06.674: INFO: Starting informer...
  STEP: Starting pod... @ 03/26/24 07:07:06.674
  E0326 07:07:06.702366      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:07:06.880: INFO: Pod is running on k8s-worker02. Tainting Node
  STEP: Trying to apply a taint on the Node @ 03/26/24 07:07:06.88
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 03/26/24 07:07:06.885
  STEP: Waiting short time to make sure Pod is queued for deletion @ 03/26/24 07:07:06.887
  Mar 26 07:07:06.887: INFO: Pod wasn't evicted. Proceeding
  Mar 26 07:07:06.887: INFO: Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 03/26/24 07:07:06.892
  STEP: Waiting some time to make sure that toleration time passed. @ 03/26/24 07:07:06.894
  E0326 07:07:07.702480      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:08.702576      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:09.702675      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:10.703065      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:11.704000      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:12.704014      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:13.704826      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:14.705527      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:15.705869      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:16.706003      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:17.706153      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:18.706284      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:19.707012      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:20.707253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:21.707518      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:22.707609      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:23.708020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:24.708435      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:25.709095      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:26.709314      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:27.709879      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:28.710209      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:29.710419      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:30.710887      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:31.711139      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:32.711465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:33.711622      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:34.714392      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:35.715465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:36.716017      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:37.716160      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:38.716261      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:39.716350      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:40.716426      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:41.716512      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:42.716612      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:43.716698      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:44.716784      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:45.716875      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:46.717020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:47.717164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:48.717272      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:49.717315      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:50.717384      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:51.717485      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:52.717579      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:53.717666      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:54.717743      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:55.717838      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:56.718051      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:57.718148      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:58.718376      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:07:59.719121      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:00.719209      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:01.719683      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:02.719767      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:03.721198      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:04.720954      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:05.721326      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:06.722210      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:07.722959      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:08.723981      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:09.724065      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:10.724458      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:11.724562      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:12.724662      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:13.724763      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:14.724844      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:15.725846      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:16.725945      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:17.726031      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:18.726110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:19.726200      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:20.726288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:21.726431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:08:21.895: INFO: Pod wasn't evicted. Test successful
  Mar 26 07:08:21.896: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-558" for this suite. @ 03/26/24 07:08:21.898
• [135.245 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:129
  STEP: Creating a kubernetes client @ 03/26/24 07:08:21.901
  Mar 26 07:08:21.901: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename runtimeclass @ 03/26/24 07:08:21.902
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 07:08:21.908
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 07:08:21.91
  E0326 07:08:22.726968      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:23.727282      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:08:23.920: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-2084" for this suite. @ 03/26/24 07:08:23.924
• [2.027 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]
test/e2e/kubectl/kubectl.go:341
  STEP: Creating a kubernetes client @ 03/26/24 07:08:23.937
  Mar 26 07:08:23.937: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename kubectl @ 03/26/24 07:08:23.938
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 07:08:23.944
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 07:08:23.945
  STEP: creating a replication controller @ 03/26/24 07:08:23.947
  Mar 26 07:08:23.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-5816 create -f -'
  Mar 26 07:08:24.089: INFO: stderr: ""
  Mar 26 07:08:24.089: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 03/26/24 07:08:24.089
  Mar 26 07:08:24.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-5816 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Mar 26 07:08:24.141: INFO: stderr: ""
  Mar 26 07:08:24.141: INFO: stdout: "update-demo-nautilus-mdng6 update-demo-nautilus-msb6d "
  Mar 26 07:08:24.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-5816 get pods update-demo-nautilus-mdng6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Mar 26 07:08:24.196: INFO: stderr: ""
  Mar 26 07:08:24.196: INFO: stdout: ""
  Mar 26 07:08:24.196: INFO: update-demo-nautilus-mdng6 is created but not running
  E0326 07:08:24.728095      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:25.728200      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:26.728334      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:27.728474      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:28.728560      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:08:29.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-5816 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Mar 26 07:08:29.239: INFO: stderr: ""
  Mar 26 07:08:29.239: INFO: stdout: "update-demo-nautilus-mdng6 update-demo-nautilus-msb6d "
  Mar 26 07:08:29.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-5816 get pods update-demo-nautilus-mdng6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Mar 26 07:08:29.278: INFO: stderr: ""
  Mar 26 07:08:29.278: INFO: stdout: "true"
  Mar 26 07:08:29.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-5816 get pods update-demo-nautilus-mdng6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Mar 26 07:08:29.317: INFO: stderr: ""
  Mar 26 07:08:29.317: INFO: stdout: "hub.oepkgs.net/nestos/nestos-test/sonobuoy/nautilus:1.7"
  Mar 26 07:08:29.317: INFO: validating pod update-demo-nautilus-mdng6
  Mar 26 07:08:29.318: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Mar 26 07:08:29.319: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Mar 26 07:08:29.319: INFO: update-demo-nautilus-mdng6 is verified up and running
  Mar 26 07:08:29.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-5816 get pods update-demo-nautilus-msb6d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Mar 26 07:08:29.359: INFO: stderr: ""
  Mar 26 07:08:29.359: INFO: stdout: "true"
  Mar 26 07:08:29.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-5816 get pods update-demo-nautilus-msb6d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Mar 26 07:08:29.399: INFO: stderr: ""
  Mar 26 07:08:29.399: INFO: stdout: "hub.oepkgs.net/nestos/nestos-test/sonobuoy/nautilus:1.7"
  Mar 26 07:08:29.399: INFO: validating pod update-demo-nautilus-msb6d
  Mar 26 07:08:29.401: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Mar 26 07:08:29.401: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Mar 26 07:08:29.401: INFO: update-demo-nautilus-msb6d is verified up and running
  STEP: using delete to clean up resources @ 03/26/24 07:08:29.401
  Mar 26 07:08:29.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-5816 delete --grace-period=0 --force -f -'
  Mar 26 07:08:29.441: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Mar 26 07:08:29.441: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Mar 26 07:08:29.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-5816 get rc,svc -l name=update-demo --no-headers'
  Mar 26 07:08:29.495: INFO: stderr: "No resources found in kubectl-5816 namespace.\n"
  Mar 26 07:08:29.495: INFO: stdout: ""
  Mar 26 07:08:29.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-385817400 --namespace=kubectl-5816 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Mar 26 07:08:29.536: INFO: stderr: ""
  Mar 26 07:08:29.536: INFO: stdout: ""
  Mar 26 07:08:29.536: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5816" for this suite. @ 03/26/24 07:08:29.539
• [5.604 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]
test/e2e/apps/replica_set.go:111
  STEP: Creating a kubernetes client @ 03/26/24 07:08:29.542
  Mar 26 07:08:29.542: INFO: >>> kubeConfig: /tmp/kubeconfig-385817400
  STEP: Building a namespace api object, basename replicaset @ 03/26/24 07:08:29.542
  STEP: Waiting for a default service account to be provisioned in namespace @ 03/26/24 07:08:29.548
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 03/26/24 07:08:29.549
  Mar 26 07:08:29.550: INFO: Creating ReplicaSet my-hostname-basic-d58d0f9d-c2bc-458d-8b5d-08affc40cae5
  Mar 26 07:08:29.553: INFO: Pod name my-hostname-basic-d58d0f9d-c2bc-458d-8b5d-08affc40cae5: Found 0 pods out of 1
  E0326 07:08:29.729020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:30.729343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:31.729483      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:32.729874      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0326 07:08:33.730001      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Mar 26 07:08:34.555: INFO: Pod name my-hostname-basic-d58d0f9d-c2bc-458d-8b5d-08affc40cae5: Found 1 pods out of 1
  Mar 26 07:08:34.555: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-d58d0f9d-c2bc-458d-8b5d-08affc40cae5" is running
  Mar 26 07:08:34.557: INFO: Pod "my-hostname-basic-d58d0f9d-c2bc-458d-8b5d-08affc40cae5-69gjz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-03-26 07:08:29 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-03-26 07:08:30 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-03-26 07:08:30 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-03-26 07:08:29 +0000 UTC Reason: Message:}])
  Mar 26 07:08:34.557: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 03/26/24 07:08:34.557
  Mar 26 07:08:34.560: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-861" for this suite. @ 03/26/24 07:08:34.562
• [5.023 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:88
  Mar 26 07:08:34.566: INFO: Running AfterSuite actions on node 1
  Mar 26 07:08:34.566: INFO: Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:157
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:585
[ReportAfterSuite] PASSED [0.032 seconds]
------------------------------

Ran 380 of 7387 Specs in 5739.496 seconds
SUCCESS! -- 380 Passed | 0 Failed | 0 Pending | 7007 Skipped
PASS

Ginkgo ran 1 suite in 1h35m39.739073181s
Test Suite Passed
