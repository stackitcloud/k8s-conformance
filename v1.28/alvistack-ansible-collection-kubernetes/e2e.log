  I1219 10:02:10.781559      14 e2e.go:117] Starting e2e run "e1bc3cfb-3863-4649-bff3-a9b53002ab1b" on Ginkgo node 1
  Dec 19 10:02:10.872: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1702980130 - will randomize all specs

Will run 380 of 7389 specs
------------------------------
[ReportBeforeSuite] 
test/e2e/e2e_test.go:153
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:77
  Dec 19 10:02:11.297: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:02:11.302: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
  Dec 19 10:02:11.380: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  Dec 19 10:02:11.392: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
  Dec 19 10:02:11.392: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
  Dec 19 10:02:11.393: INFO: e2e test version: v1.28.4
  Dec 19 10:02:11.395: INFO: kube-apiserver version: v1.28.4
  Dec 19 10:02:11.395: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:02:11.409: INFO: Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.114 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:47
  STEP: Creating a kubernetes client @ 12/19/23 10:02:12
  Dec 19 10:02:12.000: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename var-expansion @ 12/19/23 10:02:12.004
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:02:12.045
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:02:12.05
  STEP: Creating a pod to test env composition @ 12/19/23 10:02:12.055
  STEP: Saw pod success @ 12/19/23 10:02:18.118
  Dec 19 10:02:18.128: INFO: Trying to get logs from node hiengux9ahcu-3 pod var-expansion-c64ca1ba-6338-45dc-9ab7-53e7108ddac7 container dapi-container: <nil>
  STEP: delete the pod @ 12/19/23 10:02:18.181
  Dec 19 10:02:18.213: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7874" for this suite. @ 12/19/23 10:02:18.225
• [6.245 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]
test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 12/19/23 10:02:18.249
  Dec 19 10:02:18.249: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename subpath @ 12/19/23 10:02:18.253
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:02:18.295
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:02:18.302
  STEP: Setting up data @ 12/19/23 10:02:18.307
  STEP: Creating pod pod-subpath-test-projected-2thv @ 12/19/23 10:02:18.331
  STEP: Creating a pod to test atomic-volume-subpath @ 12/19/23 10:02:18.331
  STEP: Saw pod success @ 12/19/23 10:03:16.678
  Dec 19 10:03:16.684: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-subpath-test-projected-2thv container test-container-subpath-projected-2thv: <nil>
  STEP: delete the pod @ 12/19/23 10:03:16.7
  STEP: Deleting pod pod-subpath-test-projected-2thv @ 12/19/23 10:03:16.729
  Dec 19 10:03:16.729: INFO: Deleting pod "pod-subpath-test-projected-2thv" in namespace "subpath-2679"
  Dec 19 10:03:16.737: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-2679" for this suite. @ 12/19/23 10:03:16.746
• [58.512 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:148
  STEP: Creating a kubernetes client @ 12/19/23 10:03:16.767
  Dec 19 10:03:16.767: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubelet-test @ 12/19/23 10:03:16.772
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:03:16.809
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:03:16.814
  STEP: Waiting for pod completion @ 12/19/23 10:03:16.833
  Dec 19 10:03:20.885: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-6462" for this suite. @ 12/19/23 10:03:20.894
• [4.138 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:198
  STEP: Creating a kubernetes client @ 12/19/23 10:03:20.913
  Dec 19 10:03:20.913: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename custom-resource-definition @ 12/19/23 10:03:20.916
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:03:20.946
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:03:20.951
  STEP: fetching the /apis discovery document @ 12/19/23 10:03:20.957
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 12/19/23 10:03:20.959
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 12/19/23 10:03:20.959
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 12/19/23 10:03:20.96
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 12/19/23 10:03:20.962
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 12/19/23 10:03:20.962
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 12/19/23 10:03:20.964
  Dec 19 10:03:20.964: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-3660" for this suite. @ 12/19/23 10:03:20.975
• [0.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:87
  STEP: Creating a kubernetes client @ 12/19/23 10:03:20.992
  Dec 19 10:03:20.993: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 10:03:20.997
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:03:21.027
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:03:21.032
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 12/19/23 10:03:21.038
  STEP: Saw pod success @ 12/19/23 10:03:25.094
  Dec 19 10:03:25.101: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-3d016800-3395-4917-a563-06e823b2d502 container test-container: <nil>
  STEP: delete the pod @ 12/19/23 10:03:25.115
  Dec 19 10:03:25.147: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4894" for this suite. @ 12/19/23 10:03:25.158
• [4.177 seconds]
------------------------------
SSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
test/e2e/network/endpointslice.go:207
  STEP: Creating a kubernetes client @ 12/19/23 10:03:25.172
  Dec 19 10:03:25.172: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename endpointslice @ 12/19/23 10:03:25.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:03:25.211
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:03:25.216
  STEP: referencing a single matching pod @ 12/19/23 10:03:35.397
  STEP: referencing matching pods with named port @ 12/19/23 10:03:40.42
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 12/19/23 10:03:45.452
  STEP: recreating EndpointSlices after they've been deleted @ 12/19/23 10:03:50.504
  Dec 19 10:03:50.572: INFO: EndpointSlice for Service endpointslice-1146/example-named-port not found
  Dec 19 10:04:00.594: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-1146" for this suite. @ 12/19/23 10:04:00.606
• [35.446 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance]
test/e2e/network/service.go:3326
  STEP: Creating a kubernetes client @ 12/19/23 10:04:00.619
  Dec 19 10:04:00.619: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename services @ 12/19/23 10:04:00.627
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:04:00.661
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:04:00.667
  STEP: creating a Service @ 12/19/23 10:04:00.682
  STEP: watching for the Service to be added @ 12/19/23 10:04:00.7
  Dec 19 10:04:00.703: INFO: Found Service test-service-82qxb in namespace services-9519 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
  Dec 19 10:04:00.703: INFO: Service test-service-82qxb created
  STEP: Getting /status @ 12/19/23 10:04:00.703
  Dec 19 10:04:00.712: INFO: Service test-service-82qxb has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 12/19/23 10:04:00.712
  STEP: watching for the Service to be patched @ 12/19/23 10:04:00.725
  Dec 19 10:04:00.727: INFO: observed Service test-service-82qxb in namespace services-9519 with annotations: map[] & LoadBalancer: {[]}
  Dec 19 10:04:00.727: INFO: Found Service test-service-82qxb in namespace services-9519 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
  Dec 19 10:04:00.727: INFO: Service test-service-82qxb has service status patched
  STEP: updating the ServiceStatus @ 12/19/23 10:04:00.727
  Dec 19 10:04:00.746: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 12/19/23 10:04:00.747
  Dec 19 10:04:00.750: INFO: Observed Service test-service-82qxb in namespace services-9519 with annotations: map[] & Conditions: {[]}
  Dec 19 10:04:00.751: INFO: Observed event: &Service{ObjectMeta:{test-service-82qxb  services-9519  4dd51d32-dc91-40d2-ba37-d79e5f9b66cf 2883 0 2023-12-19 10:04:00 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-12-19 10:04:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-12-19 10:04:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.233.32.251,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.233.32.251],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  Dec 19 10:04:00.751: INFO: Found Service test-service-82qxb in namespace services-9519 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Dec 19 10:04:00.751: INFO: Service test-service-82qxb has service status updated
  STEP: patching the service @ 12/19/23 10:04:00.752
  STEP: watching for the Service to be patched @ 12/19/23 10:04:00.768
  Dec 19 10:04:00.772: INFO: observed Service test-service-82qxb in namespace services-9519 with labels: map[test-service-static:true]
  Dec 19 10:04:00.772: INFO: observed Service test-service-82qxb in namespace services-9519 with labels: map[test-service-static:true]
  Dec 19 10:04:00.772: INFO: observed Service test-service-82qxb in namespace services-9519 with labels: map[test-service-static:true]
  Dec 19 10:04:00.772: INFO: Found Service test-service-82qxb in namespace services-9519 with labels: map[test-service:patched test-service-static:true]
  Dec 19 10:04:00.772: INFO: Service test-service-82qxb patched
  STEP: deleting the service @ 12/19/23 10:04:00.772
  STEP: watching for the Service to be deleted @ 12/19/23 10:04:00.794
  Dec 19 10:04:00.801: INFO: Observed event: ADDED
  Dec 19 10:04:00.802: INFO: Observed event: MODIFIED
  Dec 19 10:04:00.802: INFO: Observed event: MODIFIED
  Dec 19 10:04:00.802: INFO: Observed event: MODIFIED
  Dec 19 10:04:00.802: INFO: Found Service test-service-82qxb in namespace services-9519 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  Dec 19 10:04:00.802: INFO: Service test-service-82qxb deleted
  Dec 19 10:04:00.802: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9519" for this suite. @ 12/19/23 10:04:00.812
• [0.212 seconds]
------------------------------
S
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
test/e2e/common/node/expansion.go:189
  STEP: Creating a kubernetes client @ 12/19/23 10:04:00.833
  Dec 19 10:04:00.833: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename var-expansion @ 12/19/23 10:04:00.835
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:04:00.865
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:04:00.87
  Dec 19 10:04:04.912: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec 19 10:04:04.924: INFO: Deleting pod "var-expansion-74b81fc7-7ceb-40ef-9ad3-7e761fada751" in namespace "var-expansion-1458"
  Dec 19 10:04:04.940: INFO: Wait up to 5m0s for pod "var-expansion-74b81fc7-7ceb-40ef-9ad3-7e761fada751" to be fully deleted
  STEP: Destroying namespace "var-expansion-1458" for this suite. @ 12/19/23 10:04:06.964
• [6.145 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:222
  STEP: Creating a kubernetes client @ 12/19/23 10:04:06.981
  Dec 19 10:04:06.981: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 10:04:06.985
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:04:07.029
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:04:07.036
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 10:04:07.045
  STEP: Saw pod success @ 12/19/23 10:04:11.122
  Dec 19 10:04:11.129: INFO: Trying to get logs from node hiengux9ahcu-3 pod downwardapi-volume-711ad26d-8dc9-4396-b27e-c541a80ad967 container client-container: <nil>
  STEP: delete the pod @ 12/19/23 10:04:11.146
  Dec 19 10:04:11.200: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3595" for this suite. @ 12/19/23 10:04:11.21
• [4.239 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]
test/e2e/kubectl/kubectl.go:1316
  STEP: Creating a kubernetes client @ 12/19/23 10:04:11.228
  Dec 19 10:04:11.228: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 10:04:11.23
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:04:11.263
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:04:11.269
  STEP: validating cluster-info @ 12/19/23 10:04:11.276
  Dec 19 10:04:11.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-894 cluster-info'
  Dec 19 10:04:11.627: INFO: stderr: ""
  Dec 19 10:04:11.627: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  Dec 19 10:04:11.627: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-894" for this suite. @ 12/19/23 10:04:11.636
• [0.424 seconds]
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]
test/e2e/apimachinery/resource_quota.go:806
  STEP: Creating a kubernetes client @ 12/19/23 10:04:11.652
  Dec 19 10:04:11.652: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 10:04:11.656
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:04:11.695
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:04:11.701
  STEP: Creating a ResourceQuota with best effort scope @ 12/19/23 10:04:11.705
  STEP: Ensuring ResourceQuota status is calculated @ 12/19/23 10:04:11.714
  STEP: Creating a ResourceQuota with not best effort scope @ 12/19/23 10:04:13.727
  STEP: Ensuring ResourceQuota status is calculated @ 12/19/23 10:04:13.746
  STEP: Creating a best-effort pod @ 12/19/23 10:04:15.754
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 12/19/23 10:04:15.786
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 12/19/23 10:04:17.798
  STEP: Deleting the pod @ 12/19/23 10:04:19.807
  STEP: Ensuring resource quota status released the pod usage @ 12/19/23 10:04:19.845
  STEP: Creating a not best-effort pod @ 12/19/23 10:04:21.858
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 12/19/23 10:04:21.889
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 12/19/23 10:04:23.897
  STEP: Deleting the pod @ 12/19/23 10:04:25.911
  STEP: Ensuring resource quota status released the pod usage @ 12/19/23 10:04:25.939
  Dec 19 10:04:27.948: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3643" for this suite. @ 12/19/23 10:04:27.958
• [16.323 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:194
  STEP: Creating a kubernetes client @ 12/19/23 10:04:27.984
  Dec 19 10:04:27.984: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 10:04:27.988
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:04:28.027
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:04:28.033
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 10:04:28.041
  STEP: Saw pod success @ 12/19/23 10:04:32.103
  Dec 19 10:04:32.112: INFO: Trying to get logs from node hiengux9ahcu-3 pod downwardapi-volume-ac612e43-6286-4163-8a86-12cd53e528ca container client-container: <nil>
  STEP: delete the pod @ 12/19/23 10:04:32.135
  Dec 19 10:04:32.170: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3939" for this suite. @ 12/19/23 10:04:32.183
• [4.215 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance]
test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 12/19/23 10:04:32.212
  Dec 19 10:04:32.212: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename dns @ 12/19/23 10:04:32.215
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:04:32.249
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:04:32.253
  STEP: Creating a test externalName service @ 12/19/23 10:04:32.257
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9523.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9523.svc.cluster.local; sleep 1; done
   @ 12/19/23 10:04:32.265
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9523.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9523.svc.cluster.local; sleep 1; done
   @ 12/19/23 10:04:32.265
  STEP: creating a pod to probe DNS @ 12/19/23 10:04:32.265
  STEP: submitting the pod to kubernetes @ 12/19/23 10:04:32.265
  STEP: retrieving the pod @ 12/19/23 10:05:26.618
  STEP: looking for the results for each expected name from probers @ 12/19/23 10:05:26.625
  Dec 19 10:05:26.657: INFO: DNS probes using dns-test-0e394770-74fc-40da-a147-88024efd5a44 succeeded

  STEP: changing the externalName to bar.example.com @ 12/19/23 10:05:26.657
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9523.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9523.svc.cluster.local; sleep 1; done
   @ 12/19/23 10:05:26.683
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9523.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9523.svc.cluster.local; sleep 1; done
   @ 12/19/23 10:05:26.684
  STEP: creating a second pod to probe DNS @ 12/19/23 10:05:26.684
  STEP: submitting the pod to kubernetes @ 12/19/23 10:05:26.684
  STEP: retrieving the pod @ 12/19/23 10:06:06.972
  STEP: looking for the results for each expected name from probers @ 12/19/23 10:06:06.98
  Dec 19 10:06:07.007: INFO: DNS probes using dns-test-d9a8e0cd-8efe-4ff2-8b81-7760eb91adfd succeeded

  STEP: changing the service to type=ClusterIP @ 12/19/23 10:06:07.008
  W1219 10:06:07.038094      14 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9523.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-9523.svc.cluster.local; sleep 1; done
   @ 12/19/23 10:06:07.038
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9523.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-9523.svc.cluster.local; sleep 1; done
   @ 12/19/23 10:06:07.038
  STEP: creating a third pod to probe DNS @ 12/19/23 10:06:07.038
  STEP: submitting the pod to kubernetes @ 12/19/23 10:06:07.063
  STEP: retrieving the pod @ 12/19/23 10:07:01.395
  STEP: looking for the results for each expected name from probers @ 12/19/23 10:07:01.409
  Dec 19 10:07:01.482: INFO: DNS probes using dns-test-0da0fe3c-9bf1-44d4-b6ed-2f6019dd2e0f succeeded

  Dec 19 10:07:01.483: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/19/23 10:07:01.503
  STEP: deleting the pod @ 12/19/23 10:07:01.541
  STEP: deleting the pod @ 12/19/23 10:07:01.573
  STEP: deleting the test externalName service @ 12/19/23 10:07:01.63
  STEP: Destroying namespace "dns-9523" for this suite. @ 12/19/23 10:07:01.682
• [149.484 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
test/e2e/apps/job.go:430
  STEP: Creating a kubernetes client @ 12/19/23 10:07:01.707
  Dec 19 10:07:01.707: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename job @ 12/19/23 10:07:01.718
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:07:01.756
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:07:01.768
  STEP: Creating a job @ 12/19/23 10:07:01.777
  STEP: Ensuring job reaches completions @ 12/19/23 10:07:01.796
  Dec 19 10:07:13.805: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-5412" for this suite. @ 12/19/23 10:07:13.817
• [12.138 seconds]
------------------------------
[sig-node] Secrets should patch a secret [Conformance]
test/e2e/common/node/secrets.go:154
  STEP: Creating a kubernetes client @ 12/19/23 10:07:13.845
  Dec 19 10:07:13.845: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename secrets @ 12/19/23 10:07:13.848
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:07:13.882
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:07:13.887
  STEP: creating a secret @ 12/19/23 10:07:13.898
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 12/19/23 10:07:13.909
  STEP: patching the secret @ 12/19/23 10:07:13.922
  STEP: deleting the secret using a LabelSelector @ 12/19/23 10:07:13.94
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 12/19/23 10:07:13.956
  Dec 19 10:07:13.967: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9128" for this suite. @ 12/19/23 10:07:13.978
• [0.146 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]
test/e2e/apimachinery/resource_quota.go:946
  STEP: Creating a kubernetes client @ 12/19/23 10:07:13.998
  Dec 19 10:07:13.998: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 10:07:14.005
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:07:14.048
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:07:14.06
  STEP: Creating a ResourceQuota @ 12/19/23 10:07:14.065
  STEP: Getting a ResourceQuota @ 12/19/23 10:07:14.079
  STEP: Listing all ResourceQuotas with LabelSelector @ 12/19/23 10:07:14.091
  STEP: Patching the ResourceQuota @ 12/19/23 10:07:14.099
  STEP: Deleting a Collection of ResourceQuotas @ 12/19/23 10:07:14.115
  STEP: Verifying the deleted ResourceQuota @ 12/19/23 10:07:14.148
  Dec 19 10:07:14.159: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1221" for this suite. @ 12/19/23 10:07:14.168
• [0.184 seconds]
------------------------------
SSSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance]
test/e2e/common/node/podtemplates.go:122
  STEP: Creating a kubernetes client @ 12/19/23 10:07:14.188
  Dec 19 10:07:14.189: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename podtemplate @ 12/19/23 10:07:14.192
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:07:14.221
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:07:14.227
  STEP: Create set of pod templates @ 12/19/23 10:07:14.231
  Dec 19 10:07:14.241: INFO: created test-podtemplate-1
  Dec 19 10:07:14.249: INFO: created test-podtemplate-2
  Dec 19 10:07:14.259: INFO: created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 12/19/23 10:07:14.259
  STEP: delete collection of pod templates @ 12/19/23 10:07:14.266
  Dec 19 10:07:14.266: INFO: requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 12/19/23 10:07:14.292
  Dec 19 10:07:14.293: INFO: requesting list of pod templates to confirm quantity
  Dec 19 10:07:14.298: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-1005" for this suite. @ 12/19/23 10:07:14.307
• [0.131 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]
test/e2e/common/storage/configmap_volume.go:504
  STEP: Creating a kubernetes client @ 12/19/23 10:07:14.322
  Dec 19 10:07:14.322: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename configmap @ 12/19/23 10:07:14.324
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:07:14.353
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:07:14.359
  Dec 19 10:07:14.443: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-145" for this suite. @ 12/19/23 10:07:14.454
• [0.146 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]
test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 12/19/23 10:07:14.469
  Dec 19 10:07:14.469: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename daemonsets @ 12/19/23 10:07:14.472
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:07:14.507
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:07:14.512
  STEP: Creating simple DaemonSet "daemon-set" @ 12/19/23 10:07:14.573
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/19/23 10:07:14.59
  Dec 19 10:07:14.619: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:07:14.619: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  Dec 19 10:07:15.643: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:07:15.644: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  Dec 19 10:07:16.639: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:07:16.639: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  Dec 19 10:07:17.637: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:07:17.637: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  Dec 19 10:07:18.661: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:07:18.661: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  Dec 19 10:07:19.652: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:07:19.652: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  Dec 19 10:07:20.643: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:07:20.643: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  Dec 19 10:07:21.640: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:07:21.640: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  Dec 19 10:07:22.643: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:07:22.643: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  Dec 19 10:07:23.638: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:07:23.638: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  Dec 19 10:07:24.647: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:07:24.647: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  Dec 19 10:07:25.634: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:07:25.634: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  Dec 19 10:07:26.634: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:07:26.634: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  Dec 19 10:07:27.646: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:07:27.646: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  Dec 19 10:07:28.641: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:07:28.642: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  Dec 19 10:07:29.634: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:07:29.634: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  Dec 19 10:07:30.639: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 10:07:30.639: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  Dec 19 10:07:31.639: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec 19 10:07:31.639: INFO: Node hiengux9ahcu-3 is running 0 daemon pod, expected 1
  Dec 19 10:07:32.643: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec 19 10:07:32.644: INFO: Node hiengux9ahcu-3 is running 0 daemon pod, expected 1
  Dec 19 10:07:33.649: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec 19 10:07:33.649: INFO: Node hiengux9ahcu-3 is running 0 daemon pod, expected 1
  Dec 19 10:07:34.642: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec 19 10:07:34.642: INFO: Node hiengux9ahcu-3 is running 0 daemon pod, expected 1
  Dec 19 10:07:35.639: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec 19 10:07:35.639: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 12/19/23 10:07:35.646
  Dec 19 10:07:35.696: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec 19 10:07:35.696: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  Dec 19 10:07:36.725: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec 19 10:07:36.725: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  Dec 19 10:07:37.729: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec 19 10:07:37.730: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 12/19/23 10:07:37.742
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1501, will wait for the garbage collector to delete the pods @ 12/19/23 10:07:37.742
  Dec 19 10:07:37.813: INFO: Deleting DaemonSet.extensions daemon-set took: 12.402831ms
  Dec 19 10:07:37.916: INFO: Terminating DaemonSet.extensions daemon-set pods took: 102.607293ms
  Dec 19 10:07:39.524: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:07:39.525: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec 19 10:07:39.540: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"3822"},"items":null}

  Dec 19 10:07:39.547: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"3822"},"items":null}

  Dec 19 10:07:39.577: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1501" for this suite. @ 12/19/23 10:07:39.59
• [25.140 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:141
  STEP: Creating a kubernetes client @ 12/19/23 10:07:39.611
  Dec 19 10:07:39.611: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename crd-webhook @ 12/19/23 10:07:39.614
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:07:39.655
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:07:39.662
  STEP: Setting up server cert @ 12/19/23 10:07:39.671
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 12/19/23 10:07:40.712
  STEP: Deploying the custom resource conversion webhook pod @ 12/19/23 10:07:40.741
  STEP: Wait for the deployment to be ready @ 12/19/23 10:07:40.767
  Dec 19 10:07:40.786: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 12/19/23 10:07:42.819
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 10:07:42.846
  Dec 19 10:07:43.847: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Dec 19 10:07:43.864: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Creating a v1 custom resource @ 12/19/23 10:07:46.752
  STEP: v2 custom resource should be converted @ 12/19/23 10:07:46.799
  Dec 19 10:07:46.817: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-732" for this suite. @ 12/19/23 10:07:47.496
• [7.910 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]
test/e2e/apimachinery/webhook.go:301
  STEP: Creating a kubernetes client @ 12/19/23 10:07:47.522
  Dec 19 10:07:47.522: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename webhook @ 12/19/23 10:07:47.526
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:07:47.577
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:07:47.589
  STEP: Setting up server cert @ 12/19/23 10:07:47.652
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 10:07:49.198
  STEP: Deploying the webhook pod @ 12/19/23 10:07:49.215
  STEP: Wait for the deployment to be ready @ 12/19/23 10:07:49.236
  Dec 19 10:07:49.251: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 12/19/23 10:07:51.278
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 10:07:51.299
  Dec 19 10:07:52.299: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 12/19/23 10:07:52.314
  STEP: Creating a custom resource definition that should be denied by the webhook @ 12/19/23 10:07:52.368
  Dec 19 10:07:52.368: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:07:52.408: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1983" for this suite. @ 12/19/23 10:07:52.57
  STEP: Destroying namespace "webhook-markers-5246" for this suite. @ 12/19/23 10:07:52.593
• [5.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:55
  STEP: Creating a kubernetes client @ 12/19/23 10:07:52.636
  Dec 19 10:07:52.637: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename runtimeclass @ 12/19/23 10:07:52.653
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:07:52.709
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:07:52.714
  Dec 19 10:07:52.740: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-6593" for this suite. @ 12/19/23 10:07:52.749
• [0.123 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]
test/e2e/kubectl/kubectl.go:996
  STEP: Creating a kubernetes client @ 12/19/23 10:07:52.762
  Dec 19 10:07:52.762: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 10:07:52.766
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:07:52.797
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:07:52.802
  STEP: create deployment with httpd image @ 12/19/23 10:07:52.81
  Dec 19 10:07:52.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-7588 create -f -'
  Dec 19 10:07:53.509: INFO: stderr: ""
  Dec 19 10:07:53.509: INFO: stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 12/19/23 10:07:53.509
  Dec 19 10:07:53.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-7588 diff -f -'
  Dec 19 10:07:53.989: INFO: rc: 1
  Dec 19 10:07:53.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-7588 delete -f -'
  Dec 19 10:07:54.249: INFO: stderr: ""
  Dec 19 10:07:54.250: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  Dec 19 10:07:54.251: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7588" for this suite. @ 12/19/23 10:07:54.264
• [1.549 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance]
test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 12/19/23 10:07:54.313
  Dec 19 10:07:54.313: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename deployment @ 12/19/23 10:07:54.319
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:07:54.35
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:07:54.358
  Dec 19 10:07:54.385: INFO: Pod name cleanup-pod: Found 0 pods out of 1
  Dec 19 10:07:59.415: INFO: Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/19/23 10:07:59.415
  Dec 19 10:07:59.416: INFO: Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 12/19/23 10:07:59.442
  Dec 19 10:07:59.484: INFO: Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4189",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "361e606e-f3c6-4a86-aa7e-4817e221057d",
      ResourceVersion: (string) (len=4) "4062",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838577279,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577279,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 0,
      Replicas: (int32) 0,
      UpdatedReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) <nil>,
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec 19 10:07:59.527: INFO: New ReplicaSet "test-cleanup-deployment-58dcc84f74" of Deployment "test-cleanup-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-cleanup-deployment-58dcc84f74",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4189",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "747c1454-2d15-4c72-80c1-5d69e732c0f3",
      ResourceVersion: (string) (len=4) "4067",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838577279,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "58dcc84f74"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "361e606e-f3c6-4a86-aa7e-4817e221057d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577279,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 33 36 31 65 36 30  36 65 2d 66 33 63 36 2d  |\"361e606e-f3c6-|
              00000120  34 61 38 36 2d 61 61 37  65 2d 34 38 31 37 65 32  |4a86-aa7e-4817e2|
              00000130  32 31 30 35 37 64 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |21057d\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "58dcc84f74"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "58dcc84f74"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 0,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 10:07:59.566: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
  Dec 19 10:07:59.567: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4189",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0c3fe7ef-0662-47b8-8373-8a3fd112f7a2",
      ResourceVersion: (string) (len=4) "4065",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838577274,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "361e606e-f3c6-4a86-aa7e-4817e221057d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577274,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=483) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000050  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000060  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000070  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000080  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000090  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              000000a0  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000b0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000c0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000d0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000e0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000f0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000100  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000110  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000120  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000130  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000140  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000160  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000170  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000180  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000190  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000001a0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001b0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001c0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001d0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001e0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577275,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577279,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=103) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000020  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              00000030  22 75 69 64 5c 22 3a 5c  22 33 36 31 65 36 30 36  |"uid\":\"361e606|
              00000040  65 2d 66 33 63 36 2d 34  61 38 36 2d 61 61 37 65  |e-f3c6-4a86-aa7e|
              00000050  2d 34 38 31 37 65 32 32  31 30 35 37 64 5c 22 7d  |-4817e221057d\"}|
              00000060  22 3a 7b 7d 7d 7d 7d                              |":{}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 10:07:59.612: INFO: Pod "test-cleanup-controller-hvnb2" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=29) "test-cleanup-controller-hvnb2",
      GenerateName: (string) (len=24) "test-cleanup-controller-",
      Namespace: (string) (len=15) "deployment-4189",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b37ca63b-0269-405d-8aea-85c29b2a1166",
      ResourceVersion: (string) (len=4) "4031",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838577274,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=23) "test-cleanup-controller",
          UID: (types.UID) (len=36) "0c3fe7ef-0662-47b8-8373-8a3fd112f7a2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577274,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=500) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 2c 22 66  |},"f:pod":{}},"f|
              00000050  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000060  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000070  75 69 64 5c 22 3a 5c 22  30 63 33 66 65 37 65 66  |uid\":\"0c3fe7ef|
              00000080  2d 30 36 36 32 2d 34 37  62 38 2d 38 33 37 33 2d  |-0662-47b8-8373-|
              00000090  38 61 33 66 64 31 31 32  66 37 61 32 5c 22 7d 22  |8a3fd112f7a2\"}"|
              000000a0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000b0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000c0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              000000d0  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              000000e0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              000000f0  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000100  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000110  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000120  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000130  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000140  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000150  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000160  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              00000170  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              00000180  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              00000190  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001a0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001b0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001c0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              000001d0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              000001e0  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              000001f0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577275,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=519) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  36 2e 32 35 5c 22 7d 22  |10.233.66.25\"}"|
              000001e0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              000001f0  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000200  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jvv6v",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jvv6v",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)(<nil>),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577274,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577275,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577275,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577274,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.172",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=12) "10.233.66.25",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.66.25"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838577274,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838577275,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://4fb9cab0ee5ac9fc7f4141eea05e5bb6ce327abd3101357a7877b9aa1740e8d9",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:07:59.620: INFO: Pod "test-cleanup-deployment-58dcc84f74-kpmjl" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-cleanup-deployment-58dcc84f74-kpmjl",
      GenerateName: (string) (len=35) "test-cleanup-deployment-58dcc84f74-",
      Namespace: (string) (len=15) "deployment-4189",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "12b18ba7-287a-498f-ab23-5b1029bf6dad",
      ResourceVersion: (string) (len=4) "4077",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838577279,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "58dcc84f74"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-cleanup-deployment-58dcc84f74",
          UID: (types.UID) (len=36) "747c1454-2d15-4c72-80c1-5d69e732c0f3",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577279,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 34  37 63 31 34 35 34 2d 32  |d\":\"747c1454-2|
              00000090  64 31 35 2d 34 63 37 32  2d 38 30 63 31 2d 35 64  |d15-4c72-80c1-5d|
              000000a0  36 39 65 37 33 32 63 30  66 33 5c 22 7d 22 3a 7b  |69e732c0f3\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577279,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=482) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000001e0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-kjdj2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-kjdj2",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577279,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577279,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577279,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=41) "containers with unready status: [agnhost]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838577279,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.83",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838577279,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:07:59.628: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4189" for this suite. @ 12/19/23 10:07:59.637
• [5.345 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:69
  STEP: Creating a kubernetes client @ 12/19/23 10:07:59.67
  Dec 19 10:07:59.670: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/19/23 10:07:59.673
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:07:59.702
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:07:59.711
  Dec 19 10:07:59.721: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 12/19/23 10:08:01.995
  Dec 19 10:08:01.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-2712 --namespace=crd-publish-openapi-2712 create -f -'
  Dec 19 10:08:03.499: INFO: stderr: ""
  Dec 19 10:08:03.499: INFO: stdout: "e2e-test-crd-publish-openapi-5245-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Dec 19 10:08:03.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-2712 --namespace=crd-publish-openapi-2712 delete e2e-test-crd-publish-openapi-5245-crds test-foo'
  Dec 19 10:08:03.826: INFO: stderr: ""
  Dec 19 10:08:03.826: INFO: stdout: "e2e-test-crd-publish-openapi-5245-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  Dec 19 10:08:03.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-2712 --namespace=crd-publish-openapi-2712 apply -f -'
  Dec 19 10:08:04.755: INFO: stderr: ""
  Dec 19 10:08:04.755: INFO: stdout: "e2e-test-crd-publish-openapi-5245-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Dec 19 10:08:04.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-2712 --namespace=crd-publish-openapi-2712 delete e2e-test-crd-publish-openapi-5245-crds test-foo'
  Dec 19 10:08:05.016: INFO: stderr: ""
  Dec 19 10:08:05.016: INFO: stdout: "e2e-test-crd-publish-openapi-5245-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 12/19/23 10:08:05.016
  Dec 19 10:08:05.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-2712 --namespace=crd-publish-openapi-2712 create -f -'
  Dec 19 10:08:05.484: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 12/19/23 10:08:05.484
  Dec 19 10:08:05.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-2712 --namespace=crd-publish-openapi-2712 create -f -'
  Dec 19 10:08:05.839: INFO: rc: 1
  Dec 19 10:08:05.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-2712 --namespace=crd-publish-openapi-2712 apply -f -'
  Dec 19 10:08:06.148: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 12/19/23 10:08:06.148
  Dec 19 10:08:06.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-2712 --namespace=crd-publish-openapi-2712 create -f -'
  Dec 19 10:08:06.472: INFO: rc: 1
  Dec 19 10:08:06.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-2712 --namespace=crd-publish-openapi-2712 apply -f -'
  Dec 19 10:08:06.845: INFO: rc: 1
  STEP: kubectl explain works to explain CR properties @ 12/19/23 10:08:06.845
  Dec 19 10:08:06.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-2712 explain e2e-test-crd-publish-openapi-5245-crds'
  Dec 19 10:08:07.145: INFO: stderr: ""
  Dec 19 10:08:07.145: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5245-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 12/19/23 10:08:07.145
  Dec 19 10:08:07.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-2712 explain e2e-test-crd-publish-openapi-5245-crds.metadata'
  Dec 19 10:08:07.480: INFO: stderr: ""
  Dec 19 10:08:07.480: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5245-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  Dec 19 10:08:07.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-2712 explain e2e-test-crd-publish-openapi-5245-crds.spec'
  Dec 19 10:08:07.793: INFO: stderr: ""
  Dec 19 10:08:07.793: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5245-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  Dec 19 10:08:07.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-2712 explain e2e-test-crd-publish-openapi-5245-crds.spec.bars'
  Dec 19 10:08:08.092: INFO: stderr: ""
  Dec 19 10:08:08.092: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5245-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 12/19/23 10:08:08.092
  Dec 19 10:08:08.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-2712 explain e2e-test-crd-publish-openapi-5245-crds.spec.bars2'
  Dec 19 10:08:08.439: INFO: rc: 1
  Dec 19 10:08:10.268: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2712" for this suite. @ 12/19/23 10:08:10.288
• [10.629 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]
test/e2e/apps/rc.go:112
  STEP: Creating a kubernetes client @ 12/19/23 10:08:10.304
  Dec 19 10:08:10.304: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename replication-controller @ 12/19/23 10:08:10.308
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:08:10.343
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:08:10.347
  STEP: creating a ReplicationController @ 12/19/23 10:08:10.367
  STEP: waiting for RC to be added @ 12/19/23 10:08:10.381
  STEP: waiting for available Replicas @ 12/19/23 10:08:10.382
  STEP: patching ReplicationController @ 12/19/23 10:08:12.433
  STEP: waiting for RC to be modified @ 12/19/23 10:08:12.455
  STEP: patching ReplicationController status @ 12/19/23 10:08:12.457
  STEP: waiting for RC to be modified @ 12/19/23 10:08:12.467
  STEP: waiting for available Replicas @ 12/19/23 10:08:12.471
  STEP: fetching ReplicationController status @ 12/19/23 10:08:12.479
  STEP: patching ReplicationController scale @ 12/19/23 10:08:12.49
  STEP: waiting for RC to be modified @ 12/19/23 10:08:12.508
  STEP: waiting for ReplicationController's scale to be the max amount @ 12/19/23 10:08:12.508
  STEP: fetching ReplicationController; ensuring that it's patched @ 12/19/23 10:08:16.556
  STEP: updating ReplicationController status @ 12/19/23 10:08:16.567
  STEP: waiting for RC to be modified @ 12/19/23 10:08:16.603
  STEP: listing all ReplicationControllers @ 12/19/23 10:08:16.603
  STEP: checking that ReplicationController has expected values @ 12/19/23 10:08:16.611
  STEP: deleting ReplicationControllers by collection @ 12/19/23 10:08:16.611
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 12/19/23 10:08:16.638
  E1219 10:08:16.713927      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:08:16.714: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-6811" for this suite. @ 12/19/23 10:08:16.722
• [6.433 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:167
  STEP: Creating a kubernetes client @ 12/19/23 10:08:16.743
  Dec 19 10:08:16.743: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 10:08:16.748
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:08:16.781
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:08:16.788
  STEP: Creating a pod to test downward api env vars @ 12/19/23 10:08:16.798
  E1219 10:08:17.714807      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:18.715239      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:19.715700      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:20.715715      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:08:20.852
  Dec 19 10:08:20.859: INFO: Trying to get logs from node hiengux9ahcu-3 pod downward-api-7531eb0d-d496-4278-b9db-d1912a7e835c container dapi-container: <nil>
  STEP: delete the pod @ 12/19/23 10:08:20.899
  Dec 19 10:08:20.933: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-992" for this suite. @ 12/19/23 10:08:20.949
• [4.220 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]
test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 12/19/23 10:08:20.965
  Dec 19 10:08:20.965: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename taint-single-pod @ 12/19/23 10:08:20.969
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:08:21.006
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:08:21.01
  Dec 19 10:08:21.015: INFO: Waiting up to 1m0s for all nodes to be ready
  E1219 10:08:21.715639      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:22.715823      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:23.716576      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:24.716798      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:25.716976      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:26.718078      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:27.719300      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:28.719365      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:29.719495      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:30.719804      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:31.719916      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:32.720334      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:33.721118      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:34.721649      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:35.721895      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:36.722962      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:37.723523      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:38.724374      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:39.724609      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:40.724813      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:41.725124      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:42.725266      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:43.726117      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:44.726326      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:45.726993      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:46.732170      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:47.729068      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:48.729286      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:49.741399      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:50.732862      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:51.731508      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:52.731740      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:53.732263      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:54.735348      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:55.734574      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:56.734916      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:57.735020      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:58.735333      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:08:59.735642      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:00.735830      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:01.735902      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:02.736095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:03.737561      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:04.738051      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:05.738100      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:06.739026      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:07.739246      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:08.740102      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:09.741844      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:10.741665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:11.741766      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:12.741979      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:13.742200      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:14.743083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:15.743360      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:16.744171      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:17.744932      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:18.745310      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:19.746042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:20.746491      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:09:21.073: INFO: Waiting for terminating namespaces to be deleted...
  Dec 19 10:09:21.085: INFO: Starting informer...
  STEP: Starting pod... @ 12/19/23 10:09:21.086
  Dec 19 10:09:21.333: INFO: Pod is running on hiengux9ahcu-3. Tainting Node
  STEP: Trying to apply a taint on the Node @ 12/19/23 10:09:21.333
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 12/19/23 10:09:21.373
  STEP: Waiting short time to make sure Pod is queued for deletion @ 12/19/23 10:09:21.392
  Dec 19 10:09:21.392: INFO: Pod wasn't evicted. Proceeding
  Dec 19 10:09:21.392: INFO: Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 12/19/23 10:09:21.425
  STEP: Waiting some time to make sure that toleration time passed. @ 12/19/23 10:09:21.449
  E1219 10:09:21.749776      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:22.764955      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:23.754641      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:24.756302      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:25.757922      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:26.767239      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:27.766491      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:28.773479      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:29.767090      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:30.767692      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:31.767969      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:32.768378      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:33.768567      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:34.768946      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:35.769206      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:36.769557      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:37.770164      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:38.770502      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:39.770859      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:40.771921      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:41.774163      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:42.773043      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:43.773470      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:44.773673      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:45.774125      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:46.774683      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:47.775057      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:48.775213      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:49.775646      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:50.775691      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:51.775987      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:52.776193      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:53.776843      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:54.777283      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:55.777610      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:56.777797      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:57.778259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:58.778966      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:09:59.779394      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:00.780395      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:01.782870      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:02.783392      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:03.782916      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:04.783360      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:05.783516      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:06.783801      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:07.783981      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:08.784376      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:09.784949      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:10.785152      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:11.786218      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:12.785879      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:13.786489      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:14.786759      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:15.787406      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:16.787414      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:17.787626      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:18.787820      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:19.788110      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:20.788890      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:21.789375      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:22.789601      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:23.789826      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:24.790142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:25.790156      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:26.790422      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:27.790697      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:28.790906      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:29.791075      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:30.791889      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:31.792831      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:32.793077      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:33.793615      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:34.794500      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:35.795297      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:10:36.450: INFO: Pod wasn't evicted. Test successful
  Dec 19 10:10:36.451: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-3176" for this suite. @ 12/19/23 10:10:36.464
• [135.513 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:177
  STEP: Creating a kubernetes client @ 12/19/23 10:10:36.49
  Dec 19 10:10:36.490: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 10:10:36.494
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:10:36.527
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:10:36.531
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 12/19/23 10:10:36.536
  E1219 10:10:36.796371      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:37.796804      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:38.797019      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:39.797546      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:10:40.577
  Dec 19 10:10:40.583: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-73188958-8ae6-414f-bcec-d756dc407d36 container test-container: <nil>
  STEP: delete the pod @ 12/19/23 10:10:40.617
  Dec 19 10:10:40.643: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9128" for this suite. @ 12/19/23 10:10:40.653
• [4.178 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]
test/e2e/kubectl/kubectl.go:1806
  STEP: Creating a kubernetes client @ 12/19/23 10:10:40.671
  Dec 19 10:10:40.671: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 10:10:40.674
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:10:40.705
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:10:40.711
  STEP: Starting the proxy @ 12/19/23 10:10:40.72
  Dec 19 10:10:40.722: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-7933 proxy --unix-socket=/tmp/kubectl-proxy-unix1505699225/test'
  E1219 10:10:40.798266      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving proxy /api/ output @ 12/19/23 10:10:40.871
  Dec 19 10:10:40.874: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7933" for this suite. @ 12/19/23 10:10:40.883
• [0.234 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:104
  STEP: Creating a kubernetes client @ 12/19/23 10:10:40.906
  Dec 19 10:10:40.906: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename runtimeclass @ 12/19/23 10:10:40.909
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:10:40.941
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:10:40.946
  E1219 10:10:41.799177      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:42.799859      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:10:43.001: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-5152" for this suite. @ 12/19/23 10:10:43.021
• [2.131 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:45
  STEP: Creating a kubernetes client @ 12/19/23 10:10:43.038
  Dec 19 10:10:43.038: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 10:10:43.042
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:10:43.08
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:10:43.085
  STEP: Creating a pod to test downward api env vars @ 12/19/23 10:10:43.089
  E1219 10:10:43.799938      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:44.800666      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:45.802440      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:46.801750      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:10:47.144
  Dec 19 10:10:47.152: INFO: Trying to get logs from node hiengux9ahcu-3 pod downward-api-efe08583-da31-4983-8cb0-d0d3c5e99d0c container dapi-container: <nil>
  STEP: delete the pod @ 12/19/23 10:10:47.173
  Dec 19 10:10:47.211: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1703" for this suite. @ 12/19/23 10:10:47.223
• [4.203 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]
test/e2e/network/service.go:1533
  STEP: Creating a kubernetes client @ 12/19/23 10:10:47.245
  Dec 19 10:10:47.245: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename services @ 12/19/23 10:10:47.249
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:10:47.288
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:10:47.3
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-2608 @ 12/19/23 10:10:47.315
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 12/19/23 10:10:47.356
  STEP: creating service externalsvc in namespace services-2608 @ 12/19/23 10:10:47.356
  STEP: creating replication controller externalsvc in namespace services-2608 @ 12/19/23 10:10:47.411
  I1219 10:10:47.451050      14 runners.go:197] Created replication controller with name: externalsvc, namespace: services-2608, replica count: 2
  E1219 10:10:47.803699      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:48.804453      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:49.804902      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 10:10:50.502804      14 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 12/19/23 10:10:50.513
  Dec 19 10:10:50.547: INFO: Creating new exec pod
  E1219 10:10:50.804917      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:51.805123      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:10:52.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-2608 exec execpod78ckd -- /bin/sh -x -c nslookup nodeport-service.services-2608.svc.cluster.local'
  E1219 10:10:52.806227      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:10:53.086: INFO: stderr: "+ nslookup nodeport-service.services-2608.svc.cluster.local\n"
  Dec 19 10:10:53.086: INFO: stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nnodeport-service.services-2608.svc.cluster.local\tcanonical name = externalsvc.services-2608.svc.cluster.local.\nName:\texternalsvc.services-2608.svc.cluster.local\nAddress: 10.233.38.85\n\n"
  Dec 19 10:10:53.086: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController externalsvc in namespace services-2608, will wait for the garbage collector to delete the pods @ 12/19/23 10:10:53.098
  Dec 19 10:10:53.171: INFO: Deleting ReplicationController externalsvc took: 17.964107ms
  Dec 19 10:10:53.272: INFO: Terminating ReplicationController externalsvc pods took: 100.281331ms
  E1219 10:10:53.806748      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:54.807545      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:55.808577      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:10:56.509: INFO: Cleaning up the NodePort to ExternalName test service
  STEP: Destroying namespace "services-2608" for this suite. @ 12/19/23 10:10:56.54
• [9.318 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:135
  STEP: Creating a kubernetes client @ 12/19/23 10:10:56.569
  Dec 19 10:10:56.569: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 12/19/23 10:10:56.572
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:10:56.609
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:10:56.617
  STEP: create the container to handle the HTTPGet hook request. @ 12/19/23 10:10:56.634
  E1219 10:10:56.809264      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:57.810195      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 12/19/23 10:10:58.677
  E1219 10:10:58.810871      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:10:59.811952      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 12/19/23 10:11:00.714
  STEP: delete the pod with lifecycle hook @ 12/19/23 10:11:00.758
  E1219 10:11:00.812737      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:01.815369      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:11:02.814: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1219 10:11:02.815468      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "container-lifecycle-hook-6700" for this suite. @ 12/19/23 10:11:02.831
• [6.279 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]
test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 12/19/23 10:11:02.853
  Dec 19 10:11:02.854: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename daemonsets @ 12/19/23 10:11:02.861
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:11:02.895
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:11:02.901
  Dec 19 10:11:02.978: INFO: Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 12/19/23 10:11:02.993
  Dec 19 10:11:03.005: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:11:03.006: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 12/19/23 10:11:03.006
  Dec 19 10:11:03.069: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:11:03.069: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  E1219 10:11:03.815765      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:11:04.081: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:11:04.082: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  E1219 10:11:04.815995      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:11:05.078: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:11:05.079: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  E1219 10:11:05.816101      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:11:06.081: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 10:11:06.082: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 12/19/23 10:11:06.116
  Dec 19 10:11:06.153: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 10:11:06.153: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  E1219 10:11:06.816218      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:11:07.165: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:11:07.165: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 12/19/23 10:11:07.165
  Dec 19 10:11:07.202: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:11:07.203: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  E1219 10:11:07.816510      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:11:08.215: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:11:08.215: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  E1219 10:11:08.821303      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:11:09.214: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:11:09.214: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  E1219 10:11:09.818402      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:11:10.211: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 10:11:10.212: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 12/19/23 10:11:10.224
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3898, will wait for the garbage collector to delete the pods @ 12/19/23 10:11:10.225
  Dec 19 10:11:10.297: INFO: Deleting DaemonSet.extensions daemon-set took: 15.564076ms
  Dec 19 10:11:10.398: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.64916ms
  E1219 10:11:10.819261      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:11.819803      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:11:12.607: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:11:12.607: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec 19 10:11:12.616: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4944"},"items":null}

  Dec 19 10:11:12.627: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4944"},"items":null}

  Dec 19 10:11:12.684: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3898" for this suite. @ 12/19/23 10:11:12.698
• [9.860 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:156
  STEP: Creating a kubernetes client @ 12/19/23 10:11:12.722
  Dec 19 10:11:12.722: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename runtimeclass @ 12/19/23 10:11:12.729
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:11:12.77
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:11:12.776
  STEP: Deleting RuntimeClass runtimeclass-6455-delete-me @ 12/19/23 10:11:12.795
  STEP: Waiting for the RuntimeClass to disappear @ 12/19/23 10:11:12.807
  E1219 10:11:12.819896      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:11:12.831: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-6455" for this suite. @ 12/19/23 10:11:12.842
• [0.135 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 12/19/23 10:11:12.871
  Dec 19 10:11:12.871: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename containers @ 12/19/23 10:11:12.876
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:11:12.916
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:11:12.922
  E1219 10:11:13.830673      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:14.829811      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:11:14.981: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-4393" for this suite. @ 12/19/23 10:11:14.996
• [2.139 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]
test/e2e/apimachinery/webhook.go:261
  STEP: Creating a kubernetes client @ 12/19/23 10:11:15.025
  Dec 19 10:11:15.025: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename webhook @ 12/19/23 10:11:15.028
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:11:15.097
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:11:15.111
  STEP: Setting up server cert @ 12/19/23 10:11:15.183
  E1219 10:11:15.833618      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 10:11:16.683
  STEP: Deploying the webhook pod @ 12/19/23 10:11:16.699
  STEP: Wait for the deployment to be ready @ 12/19/23 10:11:16.721
  Dec 19 10:11:16.736: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E1219 10:11:16.831399      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:17.831476      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 10:11:18.797
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 10:11:18.825
  E1219 10:11:18.832612      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:11:19.825: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  E1219 10:11:19.833704      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 12/19/23 10:11:19.843
  Dec 19 10:11:19.876: INFO: Waiting for webhook configuration to be ready...
  STEP: create a pod that should be updated by the webhook @ 12/19/23 10:11:19.999
  Dec 19 10:11:20.035: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7359" for this suite. @ 12/19/23 10:11:20.13
  STEP: Destroying namespace "webhook-markers-6456" for this suite. @ 12/19/23 10:11:20.149
• [5.136 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]
test/e2e/apimachinery/garbage_collector.go:321
  STEP: Creating a kubernetes client @ 12/19/23 10:11:20.162
  Dec 19 10:11:20.162: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename gc @ 12/19/23 10:11:20.167
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:11:20.199
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:11:20.204
  STEP: create the rc @ 12/19/23 10:11:20.21
  W1219 10:11:20.221853      14 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E1219 10:11:20.834023      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:21.834177      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:22.834488      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:23.834678      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:24.835096      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 12/19/23 10:11:25.23
  STEP: wait for all pods to be garbage collected @ 12/19/23 10:11:25.253
  E1219 10:11:25.835287      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:26.835663      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:27.836591      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:28.836905      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:29.837077      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 12/19/23 10:11:30.271
  Dec 19 10:11:30.528: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec 19 10:11:30.529: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-9377" for this suite. @ 12/19/23 10:11:30.538
• [10.394 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]
test/e2e/network/service.go:1455
  STEP: Creating a kubernetes client @ 12/19/23 10:11:30.577
  Dec 19 10:11:30.577: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename services @ 12/19/23 10:11:30.579
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:11:30.622
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:11:30.627
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-1213 @ 12/19/23 10:11:30.634
  STEP: changing the ExternalName service to type=NodePort @ 12/19/23 10:11:30.645
  STEP: creating replication controller externalname-service in namespace services-1213 @ 12/19/23 10:11:30.701
  I1219 10:11:30.729482      14 runners.go:197] Created replication controller with name: externalname-service, namespace: services-1213, replica count: 2
  E1219 10:11:30.837400      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:31.837899      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:32.838687      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 10:11:33.780946      14 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec 19 10:11:33.782: INFO: Creating new exec pod
  E1219 10:11:33.839221      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:34.850841      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:35.840950      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:11:36.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-1213 exec execpodjz6fj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  E1219 10:11:36.841387      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:11:37.180: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Dec 19 10:11:37.180: INFO: stdout: "externalname-service-dfdmm"
  Dec 19 10:11:37.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-1213 exec execpodjz6fj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.56.190 80'
  Dec 19 10:11:37.519: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.56.190 80\nConnection to 10.233.56.190 80 port [tcp/http] succeeded!\n"
  Dec 19 10:11:37.519: INFO: stdout: "externalname-service-dfdmm"
  Dec 19 10:11:37.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-1213 exec execpodjz6fj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.17 31357'
  E1219 10:11:37.841856      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:11:37.869: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.17 31357\nConnection to 192.168.121.17 31357 port [tcp/*] succeeded!\n"
  Dec 19 10:11:37.869: INFO: stdout: ""
  E1219 10:11:38.842127      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:11:38.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-1213 exec execpodjz6fj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.17 31357'
  Dec 19 10:11:39.206: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.17 31357\nConnection to 192.168.121.17 31357 port [tcp/*] succeeded!\n"
  Dec 19 10:11:39.206: INFO: stdout: "externalname-service-dfdmm"
  Dec 19 10:11:39.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-1213 exec execpodjz6fj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.83 31357'
  Dec 19 10:11:39.613: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.83 31357\nConnection to 192.168.121.83 31357 port [tcp/*] succeeded!\n"
  Dec 19 10:11:39.613: INFO: stdout: "externalname-service-dfdmm"
  Dec 19 10:11:39.613: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec 19 10:11:39.628: INFO: Cleaning up the ExternalName to NodePort test service
  STEP: Destroying namespace "services-1213" for this suite. @ 12/19/23 10:11:39.681
• [9.120 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
test/e2e/auth/service_accounts.go:529
  STEP: Creating a kubernetes client @ 12/19/23 10:11:39.701
  Dec 19 10:11:39.701: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename svcaccounts @ 12/19/23 10:11:39.717
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:11:39.763
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:11:39.771
  Dec 19 10:11:39.810: INFO: created pod
  E1219 10:11:39.845357      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:40.845464      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:41.846035      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:42.847038      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:11:43.84
  E1219 10:11:43.847754      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:44.847715      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:45.848401      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:46.849655      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:47.849892      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:48.850967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:49.851305      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:50.852426      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:51.853556      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:52.853837      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:53.854814      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:54.855898      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:55.856705      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:56.856912      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:57.857605      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:58.857609      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:11:59.858021      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:00.858216      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:01.858530      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:02.859293      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:03.860049      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:04.860343      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:05.861125      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:06.861340      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:07.861967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:08.862242      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:09.862373      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:10.863318      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:11.863551      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:12.864220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:12:13.840: INFO: polling logs
  E1219 10:12:13.864714      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:12:13.872: INFO: Pod logs: 
  I1219 10:11:40.554937       1 log.go:194] OK: Got token
  I1219 10:11:40.556074       1 log.go:194] validating with in-cluster discovery
  I1219 10:11:40.556961       1 log.go:194] OK: got issuer https://kubernetes.default.svc.cluster.local
  I1219 10:11:40.557017       1 log.go:194] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-7474:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc000043150), NotBefore:(*jwt.NumericDate)(0xc0000432d8), IssuedAt:(*jwt.NumericDate)(0xc000043160), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7474", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"c2171a84-8ae9-4bac-b059-a6145c0ba411"}}}
  I1219 10:11:40.587970       1 log.go:194] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
  I1219 10:11:40.601809       1 log.go:194] OK: Validated signature on JWT
  I1219 10:11:40.602158       1 log.go:194] OK: Got valid claims from token!
  I1219 10:11:40.602248       1 log.go:194] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-7474:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc000472b68), NotBefore:(*jwt.NumericDate)(0xc000472b90), IssuedAt:(*jwt.NumericDate)(0xc000472b70), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7474", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"c2171a84-8ae9-4bac-b059-a6145c0ba411"}}}

  Dec 19 10:12:13.876: INFO: completed pod
  Dec 19 10:12:13.890: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7474" for this suite. @ 12/19/23 10:12:13.902
• [34.222 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]
test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 12/19/23 10:12:13.93
  Dec 19 10:12:13.930: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename emptydir-wrapper @ 12/19/23 10:12:13.934
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:12:13.98
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:12:13.986
  E1219 10:12:14.865366      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:15.865847      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:12:16.088: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Cleaning up the secret @ 12/19/23 10:12:16.097
  STEP: Cleaning up the configmap @ 12/19/23 10:12:16.112
  STEP: Cleaning up the pod @ 12/19/23 10:12:16.128
  STEP: Destroying namespace "emptydir-wrapper-3068" for this suite. @ 12/19/23 10:12:16.151
• [2.235 seconds]
------------------------------
S
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]
test/e2e/network/endpointslice.go:68
  STEP: Creating a kubernetes client @ 12/19/23 10:12:16.166
  Dec 19 10:12:16.167: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename endpointslice @ 12/19/23 10:12:16.199
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:12:16.24
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:12:16.251
  Dec 19 10:12:16.278: INFO: Endpoints addresses: [192.168.121.17 192.168.121.83] , ports: [6443]
  Dec 19 10:12:16.278: INFO: EndpointSlices addresses: [192.168.121.17 192.168.121.83] , ports: [6443]
  Dec 19 10:12:16.279: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-6759" for this suite. @ 12/19/23 10:12:16.289
• [0.143 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:58
  STEP: Creating a kubernetes client @ 12/19/23 10:12:16.314
  Dec 19 10:12:16.314: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename custom-resource-definition @ 12/19/23 10:12:16.319
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:12:16.357
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:12:16.362
  Dec 19 10:12:16.366: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 10:12:16.867018      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:12:17.420: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-9465" for this suite. @ 12/19/23 10:12:17.432
• [1.154 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]
test/e2e/scheduling/predicates.go:332
  STEP: Creating a kubernetes client @ 12/19/23 10:12:17.469
  Dec 19 10:12:17.469: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename sched-pred @ 12/19/23 10:12:17.474
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:12:17.535
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:12:17.541
  Dec 19 10:12:17.546: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Dec 19 10:12:17.572: INFO: Waiting for terminating namespaces to be deleted...
  Dec 19 10:12:17.588: INFO: 
  Logging pods the apiserver thinks is on node hiengux9ahcu-1 before test
  Dec 19 10:12:17.611: INFO: coredns-5dd5756b68-z5h65 from kube-system started at 2023-12-19 10:09:21 +0000 UTC (1 container statuses recorded)
  Dec 19 10:12:17.611: INFO: 	Container coredns ready: true, restart count 0
  Dec 19 10:12:17.611: INFO: kube-addon-manager-hiengux9ahcu-1 from kube-system started at 2023-12-19 09:57:29 +0000 UTC (1 container statuses recorded)
  Dec 19 10:12:17.611: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Dec 19 10:12:17.611: INFO: kube-apiserver-hiengux9ahcu-1 from kube-system started at 2023-12-19 09:57:29 +0000 UTC (1 container statuses recorded)
  Dec 19 10:12:17.611: INFO: 	Container kube-apiserver ready: true, restart count 1
  Dec 19 10:12:17.611: INFO: kube-controller-manager-hiengux9ahcu-1 from kube-system started at 2023-12-19 09:57:29 +0000 UTC (1 container statuses recorded)
  Dec 19 10:12:17.611: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Dec 19 10:12:17.611: INFO: kube-flannel-ds-8nd22 from kube-system started at 2023-12-19 09:49:46 +0000 UTC (1 container statuses recorded)
  Dec 19 10:12:17.611: INFO: 	Container kube-flannel ready: true, restart count 1
  Dec 19 10:12:17.611: INFO: kube-proxy-lzkkc from kube-system started at 2023-12-19 09:46:48 +0000 UTC (1 container statuses recorded)
  Dec 19 10:12:17.611: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 10:12:17.611: INFO: kube-scheduler-hiengux9ahcu-1 from kube-system started at 2023-12-19 09:57:29 +0000 UTC (1 container statuses recorded)
  Dec 19 10:12:17.611: INFO: 	Container kube-scheduler ready: true, restart count 1
  Dec 19 10:12:17.611: INFO: sonobuoy-systemd-logs-daemon-set-c8f6e06512bd4c62-k4wtt from sonobuoy started at 2023-12-19 10:01:09 +0000 UTC (2 container statuses recorded)
  Dec 19 10:12:17.611: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 10:12:17.611: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec 19 10:12:17.611: INFO: 
  Logging pods the apiserver thinks is on node hiengux9ahcu-2 before test
  Dec 19 10:12:17.650: INFO: coredns-5dd5756b68-d5xhn from kube-system started at 2023-12-19 10:09:21 +0000 UTC (1 container statuses recorded)
  Dec 19 10:12:17.650: INFO: 	Container coredns ready: true, restart count 0
  Dec 19 10:12:17.650: INFO: kube-addon-manager-hiengux9ahcu-2 from kube-system started at 2023-12-19 09:53:01 +0000 UTC (1 container statuses recorded)
  Dec 19 10:12:17.650: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Dec 19 10:12:17.650: INFO: kube-apiserver-hiengux9ahcu-2 from kube-system started at 2023-12-19 09:53:01 +0000 UTC (1 container statuses recorded)
  Dec 19 10:12:17.650: INFO: 	Container kube-apiserver ready: true, restart count 1
  Dec 19 10:12:17.650: INFO: kube-controller-manager-hiengux9ahcu-2 from kube-system started at 2023-12-19 09:53:01 +0000 UTC (1 container statuses recorded)
  Dec 19 10:12:17.650: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Dec 19 10:12:17.650: INFO: kube-flannel-ds-nzb72 from kube-system started at 2023-12-19 09:49:46 +0000 UTC (1 container statuses recorded)
  Dec 19 10:12:17.651: INFO: 	Container kube-flannel ready: true, restart count 1
  Dec 19 10:12:17.651: INFO: kube-proxy-2k68s from kube-system started at 2023-12-19 09:47:35 +0000 UTC (1 container statuses recorded)
  Dec 19 10:12:17.651: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 10:12:17.651: INFO: kube-scheduler-hiengux9ahcu-2 from kube-system started at 2023-12-19 09:53:01 +0000 UTC (1 container statuses recorded)
  Dec 19 10:12:17.651: INFO: 	Container kube-scheduler ready: true, restart count 1
  Dec 19 10:12:17.651: INFO: sonobuoy-systemd-logs-daemon-set-c8f6e06512bd4c62-j8fvw from sonobuoy started at 2023-12-19 10:01:09 +0000 UTC (2 container statuses recorded)
  Dec 19 10:12:17.651: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 10:12:17.651: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec 19 10:12:17.651: INFO: 
  Logging pods the apiserver thinks is on node hiengux9ahcu-3 before test
  Dec 19 10:12:17.664: INFO: kube-flannel-ds-vt8hx from kube-system started at 2023-12-19 10:09:22 +0000 UTC (1 container statuses recorded)
  Dec 19 10:12:17.665: INFO: 	Container kube-flannel ready: true, restart count 0
  Dec 19 10:12:17.666: INFO: kube-proxy-2p94p from kube-system started at 2023-12-19 09:47:58 +0000 UTC (1 container statuses recorded)
  Dec 19 10:12:17.666: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 10:12:17.667: INFO: sonobuoy from sonobuoy started at 2023-12-19 10:00:58 +0000 UTC (1 container statuses recorded)
  Dec 19 10:12:17.668: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Dec 19 10:12:17.670: INFO: sonobuoy-e2e-job-f5f0378b7abe4dc3 from sonobuoy started at 2023-12-19 10:01:09 +0000 UTC (2 container statuses recorded)
  Dec 19 10:12:17.670: INFO: 	Container e2e ready: true, restart count 0
  Dec 19 10:12:17.671: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 10:12:17.671: INFO: sonobuoy-systemd-logs-daemon-set-c8f6e06512bd4c62-fgsng from sonobuoy started at 2023-12-19 10:01:09 +0000 UTC (2 container statuses recorded)
  Dec 19 10:12:17.671: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 10:12:17.672: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec 19 10:12:17.672: INFO: oidc-discovery-validator from svcaccounts-7474 started at 2023-12-19 10:11:39 +0000 UTC (1 container statuses recorded)
  Dec 19 10:12:17.672: INFO: 	Container oidc-discovery-validator ready: false, restart count 0
  STEP: verifying the node has the label node hiengux9ahcu-1 @ 12/19/23 10:12:17.716
  STEP: verifying the node has the label node hiengux9ahcu-2 @ 12/19/23 10:12:17.745
  STEP: verifying the node has the label node hiengux9ahcu-3 @ 12/19/23 10:12:17.792
  Dec 19 10:12:17.851: INFO: Pod coredns-5dd5756b68-d5xhn requesting resource cpu=100m on Node hiengux9ahcu-2
  Dec 19 10:12:17.851: INFO: Pod coredns-5dd5756b68-z5h65 requesting resource cpu=100m on Node hiengux9ahcu-1
  Dec 19 10:12:17.851: INFO: Pod kube-addon-manager-hiengux9ahcu-1 requesting resource cpu=5m on Node hiengux9ahcu-1
  Dec 19 10:12:17.851: INFO: Pod kube-addon-manager-hiengux9ahcu-2 requesting resource cpu=5m on Node hiengux9ahcu-2
  Dec 19 10:12:17.851: INFO: Pod kube-apiserver-hiengux9ahcu-1 requesting resource cpu=250m on Node hiengux9ahcu-1
  Dec 19 10:12:17.851: INFO: Pod kube-apiserver-hiengux9ahcu-2 requesting resource cpu=250m on Node hiengux9ahcu-2
  Dec 19 10:12:17.851: INFO: Pod kube-controller-manager-hiengux9ahcu-1 requesting resource cpu=200m on Node hiengux9ahcu-1
  Dec 19 10:12:17.851: INFO: Pod kube-controller-manager-hiengux9ahcu-2 requesting resource cpu=200m on Node hiengux9ahcu-2
  Dec 19 10:12:17.851: INFO: Pod kube-flannel-ds-8nd22 requesting resource cpu=100m on Node hiengux9ahcu-1
  Dec 19 10:12:17.851: INFO: Pod kube-flannel-ds-nzb72 requesting resource cpu=100m on Node hiengux9ahcu-2
  Dec 19 10:12:17.851: INFO: Pod kube-flannel-ds-vt8hx requesting resource cpu=100m on Node hiengux9ahcu-3
  Dec 19 10:12:17.851: INFO: Pod kube-proxy-2k68s requesting resource cpu=0m on Node hiengux9ahcu-2
  Dec 19 10:12:17.851: INFO: Pod kube-proxy-2p94p requesting resource cpu=0m on Node hiengux9ahcu-3
  Dec 19 10:12:17.851: INFO: Pod kube-proxy-lzkkc requesting resource cpu=0m on Node hiengux9ahcu-1
  Dec 19 10:12:17.851: INFO: Pod kube-scheduler-hiengux9ahcu-1 requesting resource cpu=100m on Node hiengux9ahcu-1
  Dec 19 10:12:17.851: INFO: Pod kube-scheduler-hiengux9ahcu-2 requesting resource cpu=100m on Node hiengux9ahcu-2
  Dec 19 10:12:17.851: INFO: Pod sonobuoy requesting resource cpu=0m on Node hiengux9ahcu-3
  Dec 19 10:12:17.851: INFO: Pod sonobuoy-e2e-job-f5f0378b7abe4dc3 requesting resource cpu=0m on Node hiengux9ahcu-3
  Dec 19 10:12:17.851: INFO: Pod sonobuoy-systemd-logs-daemon-set-c8f6e06512bd4c62-fgsng requesting resource cpu=0m on Node hiengux9ahcu-3
  Dec 19 10:12:17.851: INFO: Pod sonobuoy-systemd-logs-daemon-set-c8f6e06512bd4c62-j8fvw requesting resource cpu=0m on Node hiengux9ahcu-2
  Dec 19 10:12:17.851: INFO: Pod sonobuoy-systemd-logs-daemon-set-c8f6e06512bd4c62-k4wtt requesting resource cpu=0m on Node hiengux9ahcu-1
  STEP: Starting Pods to consume most of the cluster CPU. @ 12/19/23 10:12:17.852
  Dec 19 10:12:17.852: INFO: Creating a pod which consumes cpu=591m on Node hiengux9ahcu-1
  E1219 10:12:17.869475      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:12:17.870: INFO: Creating a pod which consumes cpu=591m on Node hiengux9ahcu-2
  Dec 19 10:12:17.903: INFO: Creating a pod which consumes cpu=1050m on Node hiengux9ahcu-3
  E1219 10:12:18.871102      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:19.870738      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 12/19/23 10:12:20.052
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-3e8477c5-af28-4c5f-82ce-1dd5e6cb1089.17a233f555066aaf], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8150/filler-pod-3e8477c5-af28-4c5f-82ce-1dd5e6cb1089 to hiengux9ahcu-1] @ 12/19/23 10:12:20.066
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-3e8477c5-af28-4c5f-82ce-1dd5e6cb1089.17a233f57946f287], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 12/19/23 10:12:20.066
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-3e8477c5-af28-4c5f-82ce-1dd5e6cb1089.17a233f585728c2f], Reason = [Created], Message = [Created container filler-pod-3e8477c5-af28-4c5f-82ce-1dd5e6cb1089] @ 12/19/23 10:12:20.067
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-3e8477c5-af28-4c5f-82ce-1dd5e6cb1089.17a233f58ad46a9c], Reason = [Started], Message = [Started container filler-pod-3e8477c5-af28-4c5f-82ce-1dd5e6cb1089] @ 12/19/23 10:12:20.067
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-6edfcf0b-0b2d-47cf-b672-b470a23543d2.17a233f5566e1af4], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8150/filler-pod-6edfcf0b-0b2d-47cf-b672-b470a23543d2 to hiengux9ahcu-2] @ 12/19/23 10:12:20.067
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-6edfcf0b-0b2d-47cf-b672-b470a23543d2.17a233f579361671], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 12/19/23 10:12:20.067
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-6edfcf0b-0b2d-47cf-b672-b470a23543d2.17a233f585080152], Reason = [Created], Message = [Created container filler-pod-6edfcf0b-0b2d-47cf-b672-b470a23543d2] @ 12/19/23 10:12:20.067
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-6edfcf0b-0b2d-47cf-b672-b470a23543d2.17a233f5888d1130], Reason = [Started], Message = [Started container filler-pod-6edfcf0b-0b2d-47cf-b672-b470a23543d2] @ 12/19/23 10:12:20.067
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-89e4f87b-1b29-40a2-937d-3070a8810f30.17a233f55a6c0c0f], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8150/filler-pod-89e4f87b-1b29-40a2-937d-3070a8810f30 to hiengux9ahcu-3] @ 12/19/23 10:12:20.067
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-89e4f87b-1b29-40a2-937d-3070a8810f30.17a233f578d0ffde], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 12/19/23 10:12:20.067
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-89e4f87b-1b29-40a2-937d-3070a8810f30.17a233f5844102a1], Reason = [Created], Message = [Created container filler-pod-89e4f87b-1b29-40a2-937d-3070a8810f30] @ 12/19/23 10:12:20.067
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-89e4f87b-1b29-40a2-937d-3070a8810f30.17a233f5866cc991], Reason = [Started], Message = [Started container filler-pod-89e4f87b-1b29-40a2-937d-3070a8810f30] @ 12/19/23 10:12:20.067
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.17a233f5d7e751b3], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod..] @ 12/19/23 10:12:20.096
  E1219 10:12:20.870860      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label node off the node hiengux9ahcu-1 @ 12/19/23 10:12:21.095
  STEP: verifying the node doesn't have the label node @ 12/19/23 10:12:21.138
  STEP: removing the label node off the node hiengux9ahcu-2 @ 12/19/23 10:12:21.148
  STEP: verifying the node doesn't have the label node @ 12/19/23 10:12:21.182
  STEP: removing the label node off the node hiengux9ahcu-3 @ 12/19/23 10:12:21.191
  STEP: verifying the node doesn't have the label node @ 12/19/23 10:12:21.219
  Dec 19 10:12:21.228: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-8150" for this suite. @ 12/19/23 10:12:21.258
• [3.807 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]
test/e2e/apimachinery/namespace.go:303
  STEP: Creating a kubernetes client @ 12/19/23 10:12:21.28
  Dec 19 10:12:21.281: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename namespaces @ 12/19/23 10:12:21.289
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:12:21.337
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:12:21.365
  STEP: Read namespace status @ 12/19/23 10:12:21.376
  Dec 19 10:12:21.388: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 12/19/23 10:12:21.388
  Dec 19 10:12:21.404: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 12/19/23 10:12:21.405
  Dec 19 10:12:21.438: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  Dec 19 10:12:21.440: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-1287" for this suite. @ 12/19/23 10:12:21.469
• [0.226 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]
test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 12/19/23 10:12:21.512
  Dec 19 10:12:21.512: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename dns @ 12/19/23 10:12:21.52
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:12:21.607
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:12:21.614
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7846.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-7846.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 12/19/23 10:12:21.623
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7846.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-7846.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 12/19/23 10:12:21.623
  STEP: creating a pod to probe /etc/hosts @ 12/19/23 10:12:21.623
  STEP: submitting the pod to kubernetes @ 12/19/23 10:12:21.624
  E1219 10:12:21.870944      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:22.874628      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:23.875635      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:24.876459      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/19/23 10:12:25.683
  STEP: looking for the results for each expected name from probers @ 12/19/23 10:12:25.692
  Dec 19 10:12:25.742: INFO: Unable to read jessie_hosts@dns-querier-1 from pod dns-7846/dns-test-d73f2542-2028-4a6a-9734-f646e1639645: the server could not find the requested resource (get pods dns-test-d73f2542-2028-4a6a-9734-f646e1639645)
  Dec 19 10:12:25.742: INFO: Lookups using dns-7846/dns-test-d73f2542-2028-4a6a-9734-f646e1639645 failed for: [jessie_hosts@dns-querier-1]

  Dec 19 10:12:25.759: INFO: Pod client logs for webserver: 
  Dec 19 10:12:25.774: INFO: Pod client logs for querier: 
  Dec 19 10:12:25.792: INFO: Pod client logs for jessie-querier: 
  E1219 10:12:25.877763      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:26.877726      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:27.878415      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:28.879436      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:29.880103      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:12:30.837: INFO: DNS probes using dns-7846/dns-test-d73f2542-2028-4a6a-9734-f646e1639645 succeeded

  Dec 19 10:12:30.838: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/19/23 10:12:30.851
  E1219 10:12:30.881197      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "dns-7846" for this suite. @ 12/19/23 10:12:30.899
• [9.410 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance]
test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 12/19/23 10:12:30.933
  Dec 19 10:12:30.933: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename subjectreview @ 12/19/23 10:12:30.94
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:12:30.979
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:12:30.991
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-5191" @ 12/19/23 10:12:30.997
  Dec 19 10:12:31.007: INFO: saUsername: "system:serviceaccount:subjectreview-5191:e2e"
  Dec 19 10:12:31.007: INFO: saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-5191"}
  Dec 19 10:12:31.007: INFO: saUID: "92b1ea55-c730-4227-8552-ef5b31c922d6"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-5191:e2e" @ 12/19/23 10:12:31.008
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-5191:e2e" @ 12/19/23 10:12:31.009
  Dec 19 10:12:31.014: INFO: sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-5191:e2e" api 'list' configmaps in "subjectreview-5191" namespace @ 12/19/23 10:12:31.015
  Dec 19 10:12:31.019: INFO: SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-5191:e2e" @ 12/19/23 10:12:31.019
  Dec 19 10:12:31.024: INFO: lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  Dec 19 10:12:31.024: INFO: LocalSubjectAccessReview has been verified
  Dec 19 10:12:31.025: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-5191" for this suite. @ 12/19/23 10:12:31.035
• [0.116 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance]
test/e2e/network/service.go:3552
  STEP: Creating a kubernetes client @ 12/19/23 10:12:31.053
  Dec 19 10:12:31.053: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename services @ 12/19/23 10:12:31.055
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:12:31.09
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:12:31.096
  STEP: creating a collection of services @ 12/19/23 10:12:31.103
  Dec 19 10:12:31.103: INFO: Creating e2e-svc-a-wnmlb
  Dec 19 10:12:31.139: INFO: Creating e2e-svc-b-wkd8n
  Dec 19 10:12:31.170: INFO: Creating e2e-svc-c-chh9t
  STEP: deleting service collection @ 12/19/23 10:12:31.209
  Dec 19 10:12:31.291: INFO: Collection of services has been deleted
  Dec 19 10:12:31.292: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1142" for this suite. @ 12/19/23 10:12:31.314
• [0.288 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:442
  STEP: Creating a kubernetes client @ 12/19/23 10:12:31.348
  Dec 19 10:12:31.348: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/19/23 10:12:31.352
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:12:31.447
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:12:31.452
  STEP: set up a multi version CRD @ 12/19/23 10:12:31.458
  Dec 19 10:12:31.460: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 10:12:31.881265      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:32.882329      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:33.883187      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:34.883158      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:35.884357      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mark a version not serverd @ 12/19/23 10:12:36.571
  STEP: check the unserved version gets removed @ 12/19/23 10:12:36.647
  E1219 10:12:36.886418      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:37.885760      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 12/19/23 10:12:37.977
  E1219 10:12:38.886438      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:39.886412      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:40.890198      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:12:41.822: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8060" for this suite. @ 12/19/23 10:12:41.846
• [10.517 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]
test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 12/19/23 10:12:41.874
  Dec 19 10:12:41.874: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename disruption @ 12/19/23 10:12:41.878
  E1219 10:12:41.890484      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:12:41.909
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:12:41.915
  STEP: creating the pdb @ 12/19/23 10:12:41.921
  STEP: Waiting for the pdb to be processed @ 12/19/23 10:12:41.939
  E1219 10:12:42.891305      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:43.892151      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pdb @ 12/19/23 10:12:43.954
  STEP: Waiting for the pdb to be processed @ 12/19/23 10:12:43.97
  E1219 10:12:44.892231      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:45.892145      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching the pdb @ 12/19/23 10:12:45.985
  STEP: Waiting for the pdb to be processed @ 12/19/23 10:12:46.003
  E1219 10:12:46.892495      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:47.895851      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be deleted @ 12/19/23 10:12:48.038
  Dec 19 10:12:48.045: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-8147" for this suite. @ 12/19/23 10:12:48.059
• [6.199 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance]
test/e2e/apimachinery/server_version.go:40
  STEP: Creating a kubernetes client @ 12/19/23 10:12:48.076
  Dec 19 10:12:48.076: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename server-version @ 12/19/23 10:12:48.081
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:12:48.116
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:12:48.125
  STEP: Request ServerVersion @ 12/19/23 10:12:48.13
  STEP: Confirm major version @ 12/19/23 10:12:48.132
  Dec 19 10:12:48.133: INFO: Major version: 1
  STEP: Confirm minor version @ 12/19/23 10:12:48.133
  Dec 19 10:12:48.133: INFO: cleanMinorVersion: 28
  Dec 19 10:12:48.133: INFO: Minor version: 28
  Dec 19 10:12:48.133: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-849" for this suite. @ 12/19/23 10:12:48.146
• [0.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance]
test/e2e/apps/rc.go:424
  STEP: Creating a kubernetes client @ 12/19/23 10:12:48.171
  Dec 19 10:12:48.171: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename replication-controller @ 12/19/23 10:12:48.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:12:48.212
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:12:48.221
  STEP: Creating ReplicationController "e2e-rc-mw7zw" @ 12/19/23 10:12:48.229
  Dec 19 10:12:48.243: INFO: Get Replication Controller "e2e-rc-mw7zw" to confirm replicas
  E1219 10:12:48.895041      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:12:49.254: INFO: Get Replication Controller "e2e-rc-mw7zw" to confirm replicas
  Dec 19 10:12:49.260: INFO: Found 1 replicas for "e2e-rc-mw7zw" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-mw7zw" @ 12/19/23 10:12:49.26
  STEP: Updating a scale subresource @ 12/19/23 10:12:49.27
  STEP: Verifying replicas where modified for replication controller "e2e-rc-mw7zw" @ 12/19/23 10:12:49.282
  Dec 19 10:12:49.282: INFO: Get Replication Controller "e2e-rc-mw7zw" to confirm replicas
  E1219 10:12:49.895304      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:12:50.290: INFO: Get Replication Controller "e2e-rc-mw7zw" to confirm replicas
  Dec 19 10:12:50.298: INFO: Found 2 replicas for "e2e-rc-mw7zw" replication controller
  Dec 19 10:12:50.298: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-4015" for this suite. @ 12/19/23 10:12:50.307
• [2.149 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 12/19/23 10:12:50.321
  Dec 19 10:12:50.321: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename cronjob @ 12/19/23 10:12:50.325
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:12:50.356
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:12:50.362
  STEP: Creating a ForbidConcurrent cronjob @ 12/19/23 10:12:50.37
  STEP: Ensuring a job is scheduled @ 12/19/23 10:12:50.383
  E1219 10:12:50.895476      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:51.895643      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:52.896312      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:53.897152      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:54.897783      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:55.898580      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:56.898826      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:57.899024      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:58.900540      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:12:59.900542      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 12/19/23 10:13:00.4
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 12/19/23 10:13:00.409
  STEP: Ensuring no more jobs are scheduled @ 12/19/23 10:13:00.416
  E1219 10:13:00.900984      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:01.901969      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:02.901941      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:03.902656      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:04.903396      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:05.904393      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:06.905335      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:07.905544      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:08.905754      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:09.906344      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:10.906512      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:11.907126      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:12.907307      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:13.907967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:14.909309      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:15.910240      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:16.911116      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:17.911779      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:18.911977      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:19.912652      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:20.913680      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:21.913981      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:22.914439      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:23.915351      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:24.915596      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:25.916419      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:26.916714      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:27.917001      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:28.917724      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:29.917901      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:30.918343      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:31.920187      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:32.920359      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:33.924917      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:34.925377      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:35.924816      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:36.926612      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:37.927287      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:38.927139      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:39.936869      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:40.931333      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:41.931818      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:42.933902      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:43.934578      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:44.932624      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:45.937106      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:46.935187      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:47.935459      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:48.935576      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:49.935871      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:50.936946      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:51.937075      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:52.937806      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:53.937824      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:54.938185      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:55.938268      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:56.939166      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:57.939299      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:58.939662      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:13:59.940068      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:00.939831      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:01.940174      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:02.941157      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:03.941351      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:04.941621      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:05.942769      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:06.943651      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:07.943915      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:08.944476      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:09.944568      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:10.945542      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:11.946327      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:12.946526      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:13.946749      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:14.947247      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:15.948321      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:16.948747      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:17.949577      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:18.949918      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:19.950531      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:20.951442      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:21.951800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:22.952217      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:23.952531      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:24.953654      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:25.953714      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:26.955130      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:27.955065      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:28.955626      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:29.955827      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:30.956987      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:31.957980      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:32.958234      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:33.959670      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:34.962562      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:35.962110      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:36.962855      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:37.963389      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:38.965231      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:39.965086      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:40.965295      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:41.965284      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:42.966242      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:43.975490      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:44.972458      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:45.973176      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:46.973322      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:47.973460      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:48.974600      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:49.976512      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:50.975516      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:51.976605      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:52.976727      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:53.978062      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:54.978831      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:55.979721      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:56.979783      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:57.980714      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:58.980868      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:14:59.981624      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:00.982257      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:01.982683      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:02.982916      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:03.983326      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:04.984312      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:05.984667      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:06.985514      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:07.985565      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:08.986783      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:09.986601      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:10.986864      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:11.987031      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:12.987108      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:13.988988      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:14.988982      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:15.989379      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:16.990120      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:17.990839      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:18.993787      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:19.994798      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:20.995251      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:21.995602      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:22.999370      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:24.001620      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:25.000368      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:26.001331      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:27.012477      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:28.002691      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:29.006973      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:30.007988      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:31.005000      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:32.005094      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:33.005175      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:34.006091      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:35.006278      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:36.006473      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:37.006910      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:38.006971      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:39.007362      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:40.007811      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:41.008763      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:42.009498      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:43.009681      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:44.010166      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:45.010379      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:46.010649      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:47.010927      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:48.011932      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:49.012758      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:50.013568      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:51.014279      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:52.014622      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:53.015670      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:54.015855      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:55.016863      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:56.018202      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:57.018888      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:58.019232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:15:59.019967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:00.021009      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:01.022107      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:02.022345      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:03.022509      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:04.023312      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:05.024524      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:06.025357      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:07.026491      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:08.026913      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:09.027347      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:10.028973      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:11.029101      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:12.029381      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:13.029682      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:14.029749      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:15.030887      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:16.031922      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:17.031762      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:18.031976      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:19.032365      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:20.033294      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:21.033931      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:22.035124      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:23.035181      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:24.048560      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:25.041564      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:26.042916      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:27.043096      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:28.044058      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:29.044114      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:30.044294      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:31.044958      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:32.045270      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:33.045387      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:34.045866      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:35.046216      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:36.047372      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:37.047669      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:38.047643      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:39.047796      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:40.048705      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:41.051845      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:42.051207      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:43.052304      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:44.053172      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:45.053528      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:46.054545      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:47.054595      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:48.054818      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:49.056073      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:50.056993      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:51.058515      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:52.058356      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:53.059166      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:54.059259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:55.059515      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:56.060521      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:57.060796      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:58.061609      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:16:59.061378      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:00.061675      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:01.062183      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:02.062880      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:03.063109      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:04.063287      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:05.063760      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:06.064517      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:07.066129      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:08.065731      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:09.065967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:10.066747      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:11.067057      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:12.068708      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:13.068085      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:14.068550      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:15.068843      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:16.069567      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:17.070522      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:18.080215      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:19.073113      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:20.073620      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:21.073796      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:22.074408      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:23.074398      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:24.075372      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:25.075455      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:26.085851      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:27.082389      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:28.084525      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:29.083750      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:30.084162      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:31.084529      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:32.084439      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:33.085161      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:34.085523      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:35.085691      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:36.086618      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:37.087127      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:38.087375      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:39.087780      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:40.088649      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:41.089690      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:42.090292      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:43.090839      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:44.091577      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:45.091750      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:46.092628      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:47.092898      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:48.093071      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:49.093361      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:50.094568      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:51.095178      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:52.096407      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:53.096701      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:54.097742      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:55.098339      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:56.098252      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:57.098460      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:58.099306      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:17:59.099418      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:00.099565      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 12/19/23 10:18:00.434
  Dec 19 10:18:00.447: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-6261" for this suite. @ 12/19/23 10:18:00.474
• [310.168 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]
test/e2e/common/node/secrets.go:46
  STEP: Creating a kubernetes client @ 12/19/23 10:18:00.493
  Dec 19 10:18:00.493: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename secrets @ 12/19/23 10:18:00.5
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:18:00.554
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:18:00.562
  STEP: Creating secret with name secret-test-60ba373c-a45e-4fac-851f-013138168b46 @ 12/19/23 10:18:00.57
  STEP: Creating a pod to test consume secrets @ 12/19/23 10:18:00.587
  E1219 10:18:01.100533      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:02.100776      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:03.101297      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:04.101694      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:18:04.633
  Dec 19 10:18:04.639: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-secrets-b12ae1d4-00a5-4656-91d9-e9c8f8dbeb1f container secret-env-test: <nil>
  STEP: delete the pod @ 12/19/23 10:18:04.695
  Dec 19 10:18:04.727: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4716" for this suite. @ 12/19/23 10:18:04.738
• [4.261 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 12/19/23 10:18:04.759
  Dec 19 10:18:04.759: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 10:18:04.763
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:18:04.812
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:18:04.818
  STEP: Creating secret with name s-test-opt-del-04760fa2-db1f-44be-8279-d56ee5cfcfba @ 12/19/23 10:18:04.834
  STEP: Creating secret with name s-test-opt-upd-978492ae-a127-4565-9cbe-7f60e1c8e06b @ 12/19/23 10:18:04.845
  STEP: Creating the pod @ 12/19/23 10:18:04.856
  E1219 10:18:05.102316      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:06.103209      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-04760fa2-db1f-44be-8279-d56ee5cfcfba @ 12/19/23 10:18:06.959
  STEP: Updating secret s-test-opt-upd-978492ae-a127-4565-9cbe-7f60e1c8e06b @ 12/19/23 10:18:06.974
  STEP: Creating secret with name s-test-opt-create-e6d7a41a-99c8-4cba-abd5-94a659ef6948 @ 12/19/23 10:18:06.986
  STEP: waiting to observe update in volume @ 12/19/23 10:18:06.996
  E1219 10:18:07.103381      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:08.103489      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:18:09.065: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3416" for this suite. @ 12/19/23 10:18:09.078
• [4.337 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should serve multiport endpoints from pods  [Conformance]
test/e2e/network/service.go:846
  STEP: Creating a kubernetes client @ 12/19/23 10:18:09.097
  Dec 19 10:18:09.097: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename services @ 12/19/23 10:18:09.103
  E1219 10:18:09.104169      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:18:09.143
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:18:09.152
  STEP: creating service multi-endpoint-test in namespace services-3162 @ 12/19/23 10:18:09.157
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3162 to expose endpoints map[] @ 12/19/23 10:18:09.193
  Dec 19 10:18:09.216: INFO: successfully validated that service multi-endpoint-test in namespace services-3162 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-3162 @ 12/19/23 10:18:09.216
  E1219 10:18:10.105507      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:11.106292      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3162 to expose endpoints map[pod1:[100]] @ 12/19/23 10:18:11.279
  Dec 19 10:18:11.308: INFO: successfully validated that service multi-endpoint-test in namespace services-3162 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-3162 @ 12/19/23 10:18:11.309
  E1219 10:18:12.106705      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:13.106611      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3162 to expose endpoints map[pod1:[100] pod2:[101]] @ 12/19/23 10:18:13.444
  Dec 19 10:18:13.502: INFO: successfully validated that service multi-endpoint-test in namespace services-3162 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 12/19/23 10:18:13.503
  Dec 19 10:18:13.503: INFO: Creating new exec pod
  E1219 10:18:14.110370      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:15.111259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:16.110206      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:18:16.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-3162 exec execpodxdxlj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  Dec 19 10:18:16.913: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  Dec 19 10:18:16.913: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 10:18:16.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-3162 exec execpodxdxlj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.2.24 80'
  E1219 10:18:17.110411      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:18:17.199: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.2.24 80\nConnection to 10.233.2.24 80 port [tcp/http] succeeded!\n"
  Dec 19 10:18:17.199: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 10:18:17.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-3162 exec execpodxdxlj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  Dec 19 10:18:17.490: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  Dec 19 10:18:17.490: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 10:18:17.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-3162 exec execpodxdxlj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.2.24 81'
  Dec 19 10:18:17.821: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.2.24 81\nConnection to 10.233.2.24 81 port [tcp/*] succeeded!\n"
  Dec 19 10:18:17.822: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-3162 @ 12/19/23 10:18:17.822
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3162 to expose endpoints map[pod2:[101]] @ 12/19/23 10:18:17.856
  E1219 10:18:18.111203      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:18:18.934: INFO: successfully validated that service multi-endpoint-test in namespace services-3162 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-3162 @ 12/19/23 10:18:18.935
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3162 to expose endpoints map[] @ 12/19/23 10:18:18.997
  Dec 19 10:18:19.028: INFO: successfully validated that service multi-endpoint-test in namespace services-3162 exposes endpoints map[]
  Dec 19 10:18:19.029: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1219 10:18:19.112236      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-3162" for this suite. @ 12/19/23 10:18:19.133
• [10.064 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]
test/e2e/apimachinery/garbage_collector.go:479
  STEP: Creating a kubernetes client @ 12/19/23 10:18:19.164
  Dec 19 10:18:19.164: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename gc @ 12/19/23 10:18:19.169
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:18:19.209
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:18:19.217
  STEP: create the deployment @ 12/19/23 10:18:19.225
  W1219 10:18:19.245262      14 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 12/19/23 10:18:19.246
  STEP: delete the deployment @ 12/19/23 10:18:19.257
  STEP: wait for all rs to be garbage collected @ 12/19/23 10:18:19.292
  STEP: expected 0 pods, got 1 pods @ 12/19/23 10:18:19.327
  STEP: Gathering metrics @ 12/19/23 10:18:19.976
  E1219 10:18:20.112608      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:18:20.267: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec 19 10:18:20.267: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-7177" for this suite. @ 12/19/23 10:18:20.334
• [1.204 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance]
test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 12/19/23 10:18:20.377
  Dec 19 10:18:20.378: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename field-validation @ 12/19/23 10:18:20.383
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:18:20.435
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:18:20.44
  STEP: apply creating a deployment @ 12/19/23 10:18:20.445
  Dec 19 10:18:20.449: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-5755" for this suite. @ 12/19/23 10:18:20.495
• [0.131 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]
test/e2e/common/node/expansion.go:115
  STEP: Creating a kubernetes client @ 12/19/23 10:18:20.535
  Dec 19 10:18:20.535: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename var-expansion @ 12/19/23 10:18:20.539
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:18:20.577
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:18:20.584
  STEP: Creating a pod to test substitution in volume subpath @ 12/19/23 10:18:20.591
  E1219 10:18:21.116706      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:22.117082      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:23.117961      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:24.118522      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:18:24.635
  Dec 19 10:18:24.643: INFO: Trying to get logs from node hiengux9ahcu-3 pod var-expansion-4d0127f5-a03f-4f45-b15c-d91505e7c209 container dapi-container: <nil>
  STEP: delete the pod @ 12/19/23 10:18:24.662
  Dec 19 10:18:24.704: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5376" for this suite. @ 12/19/23 10:18:24.721
• [4.206 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]
test/e2e/apps/statefulset.go:792
  STEP: Creating a kubernetes client @ 12/19/23 10:18:24.746
  Dec 19 10:18:24.751: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename statefulset @ 12/19/23 10:18:24.755
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:18:24.796
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:18:24.801
  STEP: Creating service test in namespace statefulset-5286 @ 12/19/23 10:18:24.807
  STEP: Looking for a node to schedule stateful set and pod @ 12/19/23 10:18:24.829
  STEP: Creating pod with conflicting port in namespace statefulset-5286 @ 12/19/23 10:18:24.841
  STEP: Waiting until pod test-pod will start running in namespace statefulset-5286 @ 12/19/23 10:18:24.878
  E1219 10:18:25.119581      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:26.119696      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating statefulset with conflicting port in namespace statefulset-5286 @ 12/19/23 10:18:26.898
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-5286 @ 12/19/23 10:18:26.914
  Dec 19 10:18:26.967: INFO: Observed stateful pod in namespace: statefulset-5286, name: ss-0, uid: bfc3a382-33a7-480e-a9bc-f3490a712a1f, status phase: Pending. Waiting for statefulset controller to delete.
  Dec 19 10:18:26.992: INFO: Observed stateful pod in namespace: statefulset-5286, name: ss-0, uid: bfc3a382-33a7-480e-a9bc-f3490a712a1f, status phase: Failed. Waiting for statefulset controller to delete.
  Dec 19 10:18:27.013: INFO: Observed stateful pod in namespace: statefulset-5286, name: ss-0, uid: bfc3a382-33a7-480e-a9bc-f3490a712a1f, status phase: Failed. Waiting for statefulset controller to delete.
  Dec 19 10:18:27.020: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-5286
  STEP: Removing pod with conflicting port in namespace statefulset-5286 @ 12/19/23 10:18:27.021
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-5286 and will be in running state @ 12/19/23 10:18:27.047
  E1219 10:18:27.120492      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:28.120718      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:29.121483      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:30.122588      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:31.122850      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:32.122996      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:33.123778      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:34.124443      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:35.125193      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:36.125304      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:37.125855      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:38.136456      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:39.129672      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:40.130503      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:41.133519      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:18:41.150: INFO: Deleting all statefulset in ns statefulset-5286
  Dec 19 10:18:41.162: INFO: Scaling statefulset ss to 0
  E1219 10:18:42.134029      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:43.131419      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:44.133306      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:45.133942      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:46.134213      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:47.135106      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:48.135328      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:49.135904      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:50.138742      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:51.138581      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:18:51.215: INFO: Waiting for statefulset status.replicas updated to 0
  Dec 19 10:18:51.223: INFO: Deleting statefulset ss
  Dec 19 10:18:51.262: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5286" for this suite. @ 12/19/23 10:18:51.281
• [26.553 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]
test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 12/19/23 10:18:51.303
  Dec 19 10:18:51.303: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename endpointslicemirroring @ 12/19/23 10:18:51.308
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:18:51.374
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:18:51.379
  STEP: mirroring a new custom Endpoint @ 12/19/23 10:18:51.412
  Dec 19 10:18:51.440: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
  E1219 10:18:52.138800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:53.139356      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 12/19/23 10:18:53.456
  STEP: mirroring deletion of a custom Endpoint @ 12/19/23 10:18:53.529
  Dec 19 10:18:53.592: INFO: Waiting for 0 EndpointSlices to exist, got 1
  E1219 10:18:54.140370      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:55.141454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:18:55.604: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-7345" for this suite. @ 12/19/23 10:18:55.62
• [4.332 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:117
  STEP: Creating a kubernetes client @ 12/19/23 10:18:55.647
  Dec 19 10:18:55.647: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 10:18:55.649
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:18:55.684
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:18:55.692
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 12/19/23 10:18:55.699
  E1219 10:18:56.141946      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:57.142626      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:58.143551      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:18:59.143538      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:18:59.753
  Dec 19 10:18:59.763: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-ef822353-92b5-4a23-84f7-0d58d25904fb container test-container: <nil>
  STEP: delete the pod @ 12/19/23 10:18:59.78
  Dec 19 10:18:59.823: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9601" for this suite. @ 12/19/23 10:18:59.839
• [4.214 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:157
  STEP: Creating a kubernetes client @ 12/19/23 10:18:59.87
  Dec 19 10:18:59.870: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 10:18:59.873
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:18:59.913
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:18:59.921
  STEP: Creating a pod to test emptydir volume type on node default medium @ 12/19/23 10:18:59.927
  E1219 10:19:00.143800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:01.144852      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:19:01.968
  Dec 19 10:19:01.975: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-61444c70-b748-4674-b51d-6788622ceacc container test-container: <nil>
  STEP: delete the pod @ 12/19/23 10:19:01.989
  Dec 19 10:19:02.019: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6858" for this suite. @ 12/19/23 10:19:02.032
• [2.178 seconds]
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]
test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 12/19/23 10:19:02.05
  Dec 19 10:19:02.050: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename subpath @ 12/19/23 10:19:02.054
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:19:02.09
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:19:02.097
  STEP: Setting up data @ 12/19/23 10:19:02.104
  STEP: Creating pod pod-subpath-test-configmap-8gtk @ 12/19/23 10:19:02.127
  STEP: Creating a pod to test atomic-volume-subpath @ 12/19/23 10:19:02.128
  E1219 10:19:02.146374      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:03.147309      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:04.147494      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:05.148309      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:06.149121      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:07.149259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:08.149899      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:09.150312      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:10.150946      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:11.151132      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:12.151785      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:13.154381      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:14.155277      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:15.153918      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:16.155059      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:17.155692      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:18.156815      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:19.156135      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:20.156396      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:21.157172      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:22.158859      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:23.157862      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:24.158720      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:25.159823      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:26.159897      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:19:26.298
  Dec 19 10:19:26.310: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-subpath-test-configmap-8gtk container test-container-subpath-configmap-8gtk: <nil>
  STEP: delete the pod @ 12/19/23 10:19:26.327
  STEP: Deleting pod pod-subpath-test-configmap-8gtk @ 12/19/23 10:19:26.359
  Dec 19 10:19:26.359: INFO: Deleting pod "pod-subpath-test-configmap-8gtk" in namespace "subpath-3640"
  Dec 19 10:19:26.367: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3640" for this suite. @ 12/19/23 10:19:26.38
• [24.346 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 12/19/23 10:19:26.403
  Dec 19 10:19:26.403: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename secrets @ 12/19/23 10:19:26.407
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:19:26.451
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:19:26.459
  STEP: Creating secret with name s-test-opt-del-0e4caa67-04aa-45de-b377-c4b5aba087ae @ 12/19/23 10:19:26.481
  STEP: Creating secret with name s-test-opt-upd-27579038-cff2-4c63-ba38-40d6434c6702 @ 12/19/23 10:19:26.494
  STEP: Creating the pod @ 12/19/23 10:19:26.509
  E1219 10:19:27.161658      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:28.161868      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-0e4caa67-04aa-45de-b377-c4b5aba087ae @ 12/19/23 10:19:28.628
  STEP: Updating secret s-test-opt-upd-27579038-cff2-4c63-ba38-40d6434c6702 @ 12/19/23 10:19:28.656
  STEP: Creating secret with name s-test-opt-create-147e21f5-e3b8-4097-b8fe-55e2e1db2277 @ 12/19/23 10:19:28.673
  STEP: waiting to observe update in volume @ 12/19/23 10:19:28.683
  E1219 10:19:29.161982      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:30.162124      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:31.163784      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:32.163638      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:33.163976      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:34.164333      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:35.164939      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:36.165722      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:37.166195      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:38.166767      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:39.167404      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:40.168601      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:41.169223      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:42.169318      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:43.170358      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:44.170884      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:45.171195      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:46.171385      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:47.172141      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:48.172666      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:49.173108      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:50.174226      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:51.175076      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:52.175871      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:53.176379      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:54.176623      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:55.177640      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:56.177599      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:57.178768      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:58.179435      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:19:59.179626      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:00.179917      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:01.180518      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:02.181142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:03.181885      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:04.181909      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:05.182028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:06.182684      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:07.183169      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:08.184026      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:09.185841      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:10.186469      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:11.187567      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:12.187658      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:13.188295      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:14.188504      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:15.194349      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:16.191479      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:17.192003      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:18.192062      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:19.192810      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:20.203040      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:21.195398      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:22.195686      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:23.196119      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:24.197249      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:25.200152      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:26.199281      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:27.200465      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:28.200516      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:29.200642      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:30.201209      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:31.201502      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:32.201963      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:33.202276      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:34.203783      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:35.205789      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:36.205676      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:37.206256      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:38.206628      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:39.207379      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:40.207668      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:41.209860      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:42.209106      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:43.208689      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:44.209633      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:45.210289      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:46.210453      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:47.211178      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:48.211430      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:49.211585      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:50.212640      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:51.213136      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:52.213882      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:53.214770      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:54.215072      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:55.215670      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:56.216713      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:57.217503      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:20:57.823: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6155" for this suite. @ 12/19/23 10:20:57.835
• [91.445 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:153
  STEP: Creating a kubernetes client @ 12/19/23 10:20:57.862
  Dec 19 10:20:57.862: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/19/23 10:20:57.873
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:20:57.925
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:20:57.931
  Dec 19 10:20:57.937: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 10:20:58.217666      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:20:59.218026      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 12/19/23 10:20:59.916
  Dec 19 10:20:59.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-2172 --namespace=crd-publish-openapi-2172 create -f -'
  E1219 10:21:00.218842      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:21:01.152: INFO: stderr: ""
  Dec 19 10:21:01.152: INFO: stdout: "e2e-test-crd-publish-openapi-5156-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Dec 19 10:21:01.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-2172 --namespace=crd-publish-openapi-2172 delete e2e-test-crd-publish-openapi-5156-crds test-cr'
  E1219 10:21:01.219898      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:21:01.405: INFO: stderr: ""
  Dec 19 10:21:01.405: INFO: stdout: "e2e-test-crd-publish-openapi-5156-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  Dec 19 10:21:01.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-2172 --namespace=crd-publish-openapi-2172 apply -f -'
  Dec 19 10:21:01.792: INFO: stderr: ""
  Dec 19 10:21:01.792: INFO: stdout: "e2e-test-crd-publish-openapi-5156-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Dec 19 10:21:01.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-2172 --namespace=crd-publish-openapi-2172 delete e2e-test-crd-publish-openapi-5156-crds test-cr'
  Dec 19 10:21:02.133: INFO: stderr: ""
  Dec 19 10:21:02.133: INFO: stdout: "e2e-test-crd-publish-openapi-5156-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 12/19/23 10:21:02.133
  Dec 19 10:21:02.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-2172 explain e2e-test-crd-publish-openapi-5156-crds'
  E1219 10:21:02.221028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:21:03.090: INFO: stderr: ""
  Dec 19 10:21:03.090: INFO: stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-5156-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E1219 10:21:03.221763      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:04.221873      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:21:05.110: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2172" for this suite. @ 12/19/23 10:21:05.135
• [7.284 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:163
  STEP: Creating a kubernetes client @ 12/19/23 10:21:05.151
  Dec 19 10:21:05.151: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 10:21:05.154
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:21:05.181
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:21:05.187
  STEP: Creating the pod @ 12/19/23 10:21:05.193
  E1219 10:21:05.229853      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:06.223588      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:07.224080      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:21:07.787: INFO: Successfully updated pod "annotationupdate4edc7e9d-cfbc-4498-ae3b-35bc68f6c519"
  E1219 10:21:08.224516      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:09.224728      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:21:09.827: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7281" for this suite. @ 12/19/23 10:21:09.838
• [4.703 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]
test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 12/19/23 10:21:09.87
  Dec 19 10:21:09.871: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename cronjob @ 12/19/23 10:21:09.873
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:21:09.904
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:21:09.912
  STEP: Creating a suspended cronjob @ 12/19/23 10:21:09.921
  STEP: Ensuring no jobs are scheduled @ 12/19/23 10:21:09.932
  E1219 10:21:10.225943      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:11.227310      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:12.227208      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:13.227361      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:14.228029      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:15.228426      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:16.229663      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:17.229924      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:18.230325      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:19.230711      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:20.231252      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:21.232076      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:22.232413      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:23.233110      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:24.233685      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:25.234649      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:26.235458      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:27.236144      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:28.236665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:29.237834      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:30.238383      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:31.239491      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:32.239592      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:33.240205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:34.240365      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:35.240738      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:36.241545      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:37.242269      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:38.243099      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:39.243860      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:40.244413      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:41.244772      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:42.245540      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:43.245680      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:44.245907      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:45.246313      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:46.246576      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:47.246909      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:48.247978      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:49.248157      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:50.249475      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:51.250261      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:52.250854      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:53.251077      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:54.251337      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:55.252083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:56.252486      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:57.252641      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:58.253129      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:21:59.253387      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:00.254123      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:01.254362      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:02.254358      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:03.255265      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:04.256332      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:05.258126      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:06.257269      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:07.257738      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:08.258636      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:09.259053      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:10.259517      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:11.260234      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:12.260614      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:13.260803      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:14.261862      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:15.262484      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:16.263191      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:17.263421      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:18.264194      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:19.265031      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:20.266057      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:21.266602      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:22.267249      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:23.268070      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:24.268236      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:25.268555      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:26.269011      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:27.269192      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:28.270100      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:29.271102      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:30.271685      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:31.272757      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:32.273740      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:33.273931      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:34.274740      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:35.275737      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:36.276524      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:37.277499      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:38.277385      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:39.278281      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:40.278425      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:41.278873      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:42.280019      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:43.280203      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:44.280438      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:45.281125      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:46.281907      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:47.282583      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:48.283674      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:49.283771      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:50.284584      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:51.287695      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:52.286589      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:53.287404      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:54.288158      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:55.288175      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:56.288849      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:57.288853      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:58.288963      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:22:59.289913      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:00.290303      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:01.291326      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:02.292142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:03.292813      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:04.293078      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:05.293844      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:06.293747      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:07.295832      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:08.295471      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:09.295523      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:10.295901      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:11.296154      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:12.296425      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:13.297344      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:14.297778      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:15.298401      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:16.298574      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:17.298789      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:18.299424      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:19.300091      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:20.301025      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:21.302130      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:22.302116      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:23.302441      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:24.303638      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:25.304395      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:26.305185      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:27.306290      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:28.307305      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:29.307653      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:30.307656      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:31.307806      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:32.307976      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:33.308323      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:34.308850      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:35.309101      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:36.309259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:37.309971      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:38.310752      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:39.310941      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:40.312896      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:41.312127      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:42.312831      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:43.313528      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:44.313618      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:45.313797      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:46.315516      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:47.314700      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:48.315759      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:49.316512      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:50.317082      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:51.317829      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:52.318137      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:53.318326      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:54.320109      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:55.319903      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:56.321083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:57.321007      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:58.321660      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:23:59.321565      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:00.322843      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:01.323351      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:02.324523      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:03.324385      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:04.324723      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:05.325346      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:06.326947      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:07.327787      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:08.327877      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:09.328833      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:10.330180      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:11.329338      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:12.330693      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:13.330899      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:14.330991      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:15.331142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:16.331350      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:17.331548      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:18.332689      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:19.332706      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:20.332886      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:21.333284      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:22.333906      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:23.334164      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:24.334932      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:25.335208      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:26.335738      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:27.336186      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:28.336819      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:29.337762      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:30.338546      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:31.338645      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:32.338787      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:33.339715      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:34.340622      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:35.340830      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:36.341670      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:37.341608      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:38.341913      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:39.343842      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:40.344831      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:41.344817      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:42.346453      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:43.346464      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:44.346865      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:45.347259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:46.348004      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:47.348363      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:48.348266      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:49.349213      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:50.349492      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:51.351485      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:52.350564      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:53.351513      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:54.352588      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:55.352811      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:56.353493      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:57.354147      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:58.355440      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:24:59.354885      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:00.355830      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:01.355994      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:02.355981      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:03.357811      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:04.357939      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:05.359947      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:06.358534      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:07.359293      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:08.359836      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:09.360419      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:10.360572      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:11.360750      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:12.361888      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:13.362640      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:14.363752      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:15.364227      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:16.364709      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:17.364963      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:18.365889      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:19.365952      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:20.366259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:21.366911      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:22.367967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:23.368560      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:24.369063      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:25.369469      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:26.369694      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:27.370732      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:28.370703      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:29.371496      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:30.371786      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:31.372256      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:32.372098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:33.372888      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:34.374055      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:35.374706      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:36.375318      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:37.375760      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:38.376676      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:39.376864      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:40.377033      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:41.377193      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:42.378143      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:43.378710      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:44.378882      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:45.378948      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:46.379568      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:47.380306      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:48.380202      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:49.380884      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:50.381498      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:51.381591      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:52.382640      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:53.383071      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:54.383870      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:55.384076      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:56.384280      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:57.384382      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:58.385358      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:25:59.385673      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:00.385840      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:01.386417      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:02.386762      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:03.386942      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:04.387024      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:05.387533      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:06.387791      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:07.388490      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:08.388715      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:09.389010      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 12/19/23 10:26:09.947
  STEP: Removing cronjob @ 12/19/23 10:26:09.955
  Dec 19 10:26:09.971: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-682" for this suite. @ 12/19/23 10:26:09.992
• [300.140 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance]
test/e2e/apimachinery/field_validation.go:474
  STEP: Creating a kubernetes client @ 12/19/23 10:26:10.015
  Dec 19 10:26:10.015: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename field-validation @ 12/19/23 10:26:10.019
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:26:10.066
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:26:10.073
  Dec 19 10:26:10.079: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 10:26:10.389721      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:11.389896      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:12.390369      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  W1219 10:26:12.914238      14 warnings.go:70] unknown field "alpha"
  W1219 10:26:12.914500      14 warnings.go:70] unknown field "beta"
  W1219 10:26:12.914628      14 warnings.go:70] unknown field "delta"
  W1219 10:26:12.914752      14 warnings.go:70] unknown field "epsilon"
  W1219 10:26:12.914892      14 warnings.go:70] unknown field "gamma"
  E1219 10:26:13.391432      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:26:13.494: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-9955" for this suite. @ 12/19/23 10:26:13.554
• [3.567 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]
test/e2e/apps/statefulset.go:320
  STEP: Creating a kubernetes client @ 12/19/23 10:26:13.594
  Dec 19 10:26:13.594: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename statefulset @ 12/19/23 10:26:13.597
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:26:13.638
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:26:13.644
  STEP: Creating service test in namespace statefulset-4982 @ 12/19/23 10:26:13.65
  STEP: Creating a new StatefulSet @ 12/19/23 10:26:13.672
  Dec 19 10:26:13.700: INFO: Found 0 stateful pods, waiting for 3
  E1219 10:26:14.391552      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:15.392088      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:16.392410      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:17.392958      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:18.392889      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:19.393255      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:20.393978      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:21.394125      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:22.394225      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:23.395012      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:26:23.718: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 10:26:23.718: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 10:26:23.718: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 10:26:23.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=statefulset-4982 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec 19 10:26:24.118: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec 19 10:26:24.118: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec 19 10:26:24.118: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E1219 10:26:24.395379      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:25.395720      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:26.396638      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:27.396730      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:28.397009      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:29.398034      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:30.398421      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:31.398529      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:32.398944      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:33.399322      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 12/19/23 10:26:34.16
  Dec 19 10:26:34.194: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 12/19/23 10:26:34.194
  E1219 10:26:34.399586      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:35.399777      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:36.400548      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:37.400698      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:38.400878      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:39.401149      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:40.401327      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:41.402283      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:42.402566      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:43.402664      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 12/19/23 10:26:44.234
  Dec 19 10:26:44.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=statefulset-4982 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E1219 10:26:44.402976      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:26:44.501: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec 19 10:26:44.501: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec 19 10:26:44.501: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E1219 10:26:45.403181      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:46.403477      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:47.403762      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:48.405941      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:49.404827      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:50.405281      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:51.405549      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:52.405984      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:53.406465      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:54.406797      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:26:54.552: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:26:54.552: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:26:54.552: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:26:55.408836      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:56.408443      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:57.407958      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:58.408713      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:26:59.409009      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:00.410671      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:01.411282      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:02.411494      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:03.412157      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:04.412850      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:27:04.586: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:27:04.586: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:27:04.587: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:27:05.414472      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:06.415243      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:07.415280      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:08.415466      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:09.415649      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:10.416339      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:11.416399      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:12.416812      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:13.417052      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:14.417228      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:27:14.578: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:27:14.578: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:27:14.578: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:27:15.417838      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:16.418854      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:17.419618      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:18.419820      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:19.420401      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:20.420580      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:21.421818      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:22.422059      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:23.422281      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:24.423171      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:27:24.570: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:27:24.571: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:27:24.572: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:27:25.423605      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:26.423629      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:27.424132      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:28.424292      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:29.424774      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:30.424769      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:31.425762      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:32.425978      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:33.426255      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:34.426459      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:27:34.582: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:27:34.582: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:27:34.582: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:27:35.426960      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:36.427223      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:37.427519      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:38.427556      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:39.428195      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:40.428475      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:41.429612      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:42.430697      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:43.430883      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:44.431028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:27:44.576: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:27:44.576: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:27:44.576: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:27:45.431718      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:46.432839      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:47.433026      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:48.433467      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:49.433664      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:50.433905      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:51.434139      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:52.434456      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:53.434643      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:54.434989      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:27:54.571: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:27:54.571: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:27:54.571: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:27:55.436520      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:56.436172      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:57.436572      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:58.436808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:27:59.436920      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:00.437652      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:01.437988      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:02.438829      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:03.440435      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:04.440229      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:28:04.575: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:28:04.575: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:28:04.576: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:28:05.440693      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:06.441474      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:07.443241      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:08.442806      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:09.443233      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:10.443398      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:11.444471      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:12.444936      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:13.445066      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:14.445776      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:28:14.570: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:28:14.570: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:28:14.570: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:28:15.446042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:16.446519      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:17.446721      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:18.446711      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:19.446956      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:20.447386      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:21.447304      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:22.448030      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:23.448458      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:24.448873      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:28:24.567: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:28:24.567: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:28:24.567: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:28:25.449713      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:26.449565      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:27.450068      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:28.450234      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:29.450463      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:30.451768      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:31.452526      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:32.452887      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:33.453244      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:34.453649      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:28:34.569: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:28:34.569: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:28:34.569: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:28:35.453715      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:36.454514      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:37.455620      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:38.456116      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:39.456739      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:40.457158      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:41.461577      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:42.461776      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:43.462050      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:44.462199      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:28:44.572: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:28:44.572: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:28:44.572: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:28:45.462629      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:46.462791      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:47.463024      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:48.463317      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:49.463705      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:50.463854      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:51.464363      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:52.464704      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:53.464694      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:54.464974      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:28:54.568: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:28:54.568: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:28:54.568: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:28:55.465553      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:56.466291      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:57.466699      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:58.467168      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:28:59.467252      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:00.467752      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:01.468359      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:02.468496      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:03.468876      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:04.468983      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:29:04.575: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:29:04.575: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:29:04.575: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:29:05.469339      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:06.476969      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:07.471016      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:08.471265      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:09.471913      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:10.472090      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:11.472478      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:12.472682      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:13.473363      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:14.473547      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:29:14.579: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:29:14.579: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:29:14.579: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:29:15.474547      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:16.476147      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:17.474429      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:18.474651      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:19.474894      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:20.475753      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:21.475908      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:22.476748      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:23.476940      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:24.477147      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:29:24.572: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:29:24.573: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:29:24.573: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:29:25.477605      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:26.478388      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:27.479124      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:28.479718      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:29.480124      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:30.480964      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:31.482194      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:32.482608      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:33.483075      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:34.483497      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:29:34.584: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:29:34.584: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:29:34.584: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:29:35.485173      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:36.485610      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:37.485745      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:38.486064      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:39.486787      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:40.486999      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:41.487375      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:42.487827      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:43.487906      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:44.488236      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:29:44.573: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:29:44.574: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:29:44.574: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:29:45.488680      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:46.488863      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:47.489751      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:48.489927      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:49.490949      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:50.491133      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:51.491241      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:52.492056      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:53.492188      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:54.493071      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:29:54.570: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:29:54.570: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:29:54.570: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:29:55.493488      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:56.493709      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:57.494397      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:58.494483      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:29:59.494963      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:00.494768      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:01.495966      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:02.495707      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:03.496824      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:04.496830      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:30:04.571: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:30:04.571: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:30:04.571: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:30:05.497310      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:06.497622      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:07.497822      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:08.498051      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:09.498922      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:10.499174      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:11.499420      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:12.500369      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:13.501724      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:14.502524      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:30:14.572: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:30:14.573: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:30:14.573: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:30:15.502771      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:16.504072      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:17.504133      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:18.504484      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:19.504703      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:20.504953      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:21.505980      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:22.507434      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:23.507710      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:24.507864      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:30:24.571: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:30:24.572: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:30:24.572: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:30:25.508836      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:26.508538      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:27.509310      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:28.510058      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:29.510081      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:30.510434      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:31.511619      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:32.512104      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:33.512541      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:34.512994      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:30:34.574: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:30:34.574: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:30:34.574: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:30:35.513800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:36.514040      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:37.514048      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:38.514209      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:39.514474      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:40.514828      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:41.515271      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:42.515743      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:43.516161      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:44.516073      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:30:44.575: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:30:44.576: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:30:44.577: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:30:45.517099      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:46.517087      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:47.517261      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:48.517906      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:49.518101      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:50.518359      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:51.518665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:52.519442      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:53.519720      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:54.519801      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:30:54.570: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:30:54.570: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:30:54.570: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:30:55.520267      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:56.520729      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:57.521300      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:58.521137      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:30:59.521752      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:00.521683      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:01.527923      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:02.523171      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:03.523710      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:04.523684      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:31:04.576: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:31:04.576: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:31:04.577: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:31:05.524182      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:06.527751      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:07.525015      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:08.524821      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:09.524844      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:10.525015      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:11.525142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:12.525387      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:13.528130      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:14.528205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:31:14.577: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:31:14.577: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:31:14.577: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:31:15.528984      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:16.529011      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:17.529723      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:18.530212      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:19.530885      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:20.531513      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:21.531708      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:22.531949      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:23.532032      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:24.532241      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:31:24.580: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:31:24.580: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:31:24.581: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:31:25.532591      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:26.532553      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:27.533372      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:28.533628      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:29.534191      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:30.534353      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:31.534641      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:32.536055      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:33.536223      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:34.536831      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:31:34.572: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:31:34.572: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:31:34.572: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:31:35.538404      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:36.538967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:37.539751      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:38.539693      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:39.539911      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:40.540071      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:41.540985      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:42.541185      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:43.541375      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:44.541649      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:31:44.568: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:31:44.568: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:31:44.568: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:31:45.541978      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:46.542874      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:47.543210      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:48.544105      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:49.544867      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:50.545231      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:51.546148      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:52.546511      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:53.547042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:54.547429      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:31:54.574: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:31:54.575: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:31:54.575: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:31:55.548544      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:56.548627      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:57.548901      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:58.549232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:31:59.549655      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:00.550199      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:01.550186      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:02.550623      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:03.550844      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:04.551143      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:32:04.574: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:32:04.575: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:32:04.575: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:32:05.551082      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:06.551437      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:07.551456      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:08.551754      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:09.551827      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:10.552005      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:11.552156      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:12.552362      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:13.552524      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:14.553517      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:32:14.576: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:32:14.576: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:32:14.576: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:32:15.553288      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:16.554450      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:17.554581      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:18.554679      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:19.555409      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:20.555612      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:21.556027      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:22.556205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:23.557146      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:24.558059      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:32:24.571: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:32:24.571: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:32:24.571: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:32:25.559220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:26.559346      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:27.559782      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:28.560198      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:29.560614      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:30.561153      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:31.562259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:32.562781      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:33.563219      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:34.563953      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:32:34.569: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:32:34.569: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:32:34.569: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:32:35.564788      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:36.565191      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:37.566080      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:38.566770      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:39.567479      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:40.568283      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:41.568960      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:42.569115      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:43.569346      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:32:44.569: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:32:44.570: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:32:44.570: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:32:44.570375      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:45.571060      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:46.571139      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:47.572005      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:48.572900      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:49.573111      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:50.573998      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:51.574537      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:52.574585      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:53.574799      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:32:54.573: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:32:54.574: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:32:54.574: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:32:54.575027      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:55.575890      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:56.576218      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:57.576401      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:58.577194      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:32:59.577594      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:00.578453      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:01.579355      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:02.579783      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:03.579903      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:33:04.566: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:33:04.566: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:33:04.566: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:33:04.580678      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:05.582660      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:06.582208      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:07.584511      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:08.582638      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:09.582736      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:10.583032      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:11.583317      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:12.583887      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:13.584686      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:33:14.573: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:33:14.574: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:33:14.574: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:33:14.585232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:15.586251      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:16.585928      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:17.586048      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:18.586330      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:19.586747      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:20.587324      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:21.587745      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:22.588045      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:23.588593      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:33:24.578: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:33:24.578: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:33:24.578: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:33:24.589711      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:25.590277      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:26.590861      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:27.591601      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:28.592473      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:29.592926      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:30.593301      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:31.595202      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:32.594791      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:33.595252      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:33:34.576: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:33:34.576: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:33:34.576: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:33:34.596316      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:35.596832      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:36.597768      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:37.598186      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:38.599056      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:39.599334      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:40.600159      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:41.600330      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:42.600599      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:43.601971      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:33:44.577: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:33:44.578: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:33:44.579: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:33:44.602737      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:45.603445      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:46.603537      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:47.603620      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:48.604410      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:49.604800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:50.605220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:51.606323      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:52.606528      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:53.606689      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:33:54.569: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:33:54.569: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:33:54.569: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:33:54.607491      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:55.607496      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:56.607700      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:57.607965      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:58.608713      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:33:59.608948      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:00.609134      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:01.609286      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:02.610178      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:03.610354      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:34:04.569: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:34:04.569: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:34:04.569: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:34:04.611336      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:05.612200      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:06.612412      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:07.613147      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:08.613735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:09.614564      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:10.614973      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:11.616112      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:12.616509      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:13.616858      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:34:14.573: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:34:14.573: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:34:14.574: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:34:14.617885      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:15.618548      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:16.618726      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:17.618791      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:18.619823      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:19.620204      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:20.620450      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:21.621194      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:22.621650      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:23.621931      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:34:24.575: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:34:24.575: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:34:24.576: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:34:24.622543      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:25.623243      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:26.623224      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:27.623278      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:28.624111      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:29.624375      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:30.624642      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:31.624782      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:32.625545      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:33.625681      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:34:34.569: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:34:34.570: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:34:34.570: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:34:34.626444      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:35.626953      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:36.626908      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:37.627220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:38.627182      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:39.627405      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:40.627534      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:41.627878      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:42.628063      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:43.628237      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:34:44.573: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:34:44.574: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:34:44.574: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:34:44.629141      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:45.629938      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:46.630542      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:47.631413      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:48.632410      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:49.633116      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:50.634164      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:51.634220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:52.634652      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:53.634597      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:34:54.572: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:34:54.572: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:34:54.572: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:34:54.635418      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:55.635978      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:56.638377      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:57.637222      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:58.637134      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:34:59.637561      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:00.638972      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:01.638504      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:02.638682      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:03.639734      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:35:04.572: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:35:04.573: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:35:04.573: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:35:04.640679      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:05.640805      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:06.640752      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:07.640989      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:08.641998      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:09.642123      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:10.642527      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:11.642751      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:12.643135      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:13.643456      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:35:14.570: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:35:14.570: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Dec 19 10:35:14.570: INFO: Waiting for Pod statefulset-4982/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:35:14.643680      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:15.644412      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:16.644727      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:17.645308      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:18.646155      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:19.646099      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:20.646663      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:21.647834      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:22.648142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:23.648741      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:35:24.575: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  Dec 19 10:35:24.576: INFO: Waiting for Pod statefulset-4982/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:35:24.649947      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:25.650866      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:26.651020      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:27.651558      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:28.651923      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:29.652004      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:30.652290      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:31.653515      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:32.653798      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:33.654442      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:35:34.571: INFO: Waiting for StatefulSet statefulset-4982/ss2 to complete update
  E1219 10:35:34.654928      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:35.655336      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:36.656157      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:37.656557      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:38.656700      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:39.656838      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:40.656995      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:41.657263      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:42.657393      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:43.657694      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 12/19/23 10:35:44.572
  Dec 19 10:35:44.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=statefulset-4982 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E1219 10:35:44.658775      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:35:44.866: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec 19 10:35:44.866: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec 19 10:35:44.866: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E1219 10:35:45.659540      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:46.659284      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:47.659456      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:48.659941      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:49.660077      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:50.660565      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:51.661375      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:52.661903      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:53.661963      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:54.662764      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:35:54.946: INFO: Updating stateful set ss2
  E1219 10:35:55.662879      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:56.663782      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:57.664157      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:58.664467      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:35:59.665167      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:00.665331      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:01.665448      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:02.665882      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:03.666034      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:04.666064      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 12/19/23 10:36:04.987
  Dec 19 10:36:04.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=statefulset-4982 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec 19 10:36:05.274: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec 19 10:36:05.274: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec 19 10:36:05.274: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E1219 10:36:05.667865      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:06.668202      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:07.668541      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:08.668837      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:09.669519      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:10.669795      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:11.670790      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:12.671091      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:13.671220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:14.671370      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:36:15.337: INFO: Deleting all statefulset in ns statefulset-4982
  Dec 19 10:36:15.342: INFO: Scaling statefulset ss2 to 0
  E1219 10:36:15.671585      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:16.671873      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:17.672159      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:18.672779      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:19.673151      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:20.673196      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:21.673382      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:22.674038      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:23.673966      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:24.674192      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:36:25.405: INFO: Waiting for statefulset status.replicas updated to 0
  Dec 19 10:36:25.410: INFO: Deleting statefulset ss2
  Dec 19 10:36:25.434: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4982" for this suite. @ 12/19/23 10:36:25.446
• [611.871 seconds]
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]
test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 12/19/23 10:36:25.467
  Dec 19 10:36:25.467: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename daemonsets @ 12/19/23 10:36:25.472
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:36:25.515
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:36:25.529
  Dec 19 10:36:25.586: INFO: Create a RollingUpdate DaemonSet
  Dec 19 10:36:25.601: INFO: Check that daemon pods launch on every node of the cluster
  Dec 19 10:36:25.641: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:36:25.642: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  E1219 10:36:25.677828      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:36:26.660: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 10:36:26.660: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  E1219 10:36:26.678570      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:36:27.658: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec 19 10:36:27.658: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  Dec 19 10:36:27.659: INFO: Update the DaemonSet to trigger a rollout
  E1219 10:36:27.679414      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:36:27.681: INFO: Updating DaemonSet daemon-set
  E1219 10:36:28.679800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:36:28.718: INFO: Roll back the DaemonSet before rollout is complete
  Dec 19 10:36:28.736: INFO: Updating DaemonSet daemon-set
  Dec 19 10:36:28.737: INFO: Make sure DaemonSet rollback is complete
  Dec 19 10:36:28.750: INFO: Wrong image for pod: daemon-set-8qvd2. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  Dec 19 10:36:28.750: INFO: Pod daemon-set-8qvd2 is not available
  E1219 10:36:29.680097      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:30.680313      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:36:30.808: INFO: Pod daemon-set-9gvr2 is not available
  STEP: Deleting DaemonSet "daemon-set" @ 12/19/23 10:36:30.866
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8105, will wait for the garbage collector to delete the pods @ 12/19/23 10:36:30.867
  Dec 19 10:36:30.951: INFO: Deleting DaemonSet.extensions daemon-set took: 27.693952ms
  Dec 19 10:36:31.152: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.807953ms
  E1219 10:36:31.680517      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:32.681565      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:33.682166      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:34.682652      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:35.683420      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:36.684159      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:37.684250      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:38.684623      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:39.686288      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:40.686385      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:41.687433      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:42.688215      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:43.689168      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:44.689472      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:45.690101      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:46.690917      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:47.691172      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:48.692110      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:49.692462      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:50.693532      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:51.694341      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:52.694937      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:53.695374      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:54.696214      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:55.697119      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:56.697212      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:57.697594      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:58.698332      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:36:59.699333      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:00.700098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:01.701160      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:37:02.460: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:37:02.461: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec 19 10:37:02.466: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"9218"},"items":null}

  Dec 19 10:37:02.471: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"9218"},"items":null}

  Dec 19 10:37:02.496: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-8105" for this suite. @ 12/19/23 10:37:02.504
• [37.049 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 12/19/23 10:37:02.521
  Dec 19 10:37:02.522: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 10:37:02.525
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:37:02.554
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:37:02.558
  STEP: Creating projection with secret that has name projected-secret-test-map-93f29a1c-44c7-4989-82bf-dd1cf057d1c4 @ 12/19/23 10:37:02.562
  STEP: Creating a pod to test consume secrets @ 12/19/23 10:37:02.569
  E1219 10:37:02.701466      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:03.701931      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:04.702599      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:05.702857      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:37:06.624
  Dec 19 10:37:06.632: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-projected-secrets-32a39033-1dcd-4c73-ad79-2aa2983fdd6a container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 10:37:06.669
  E1219 10:37:06.703376      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:37:06.710: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6795" for this suite. @ 12/19/23 10:37:06.721
• [4.257 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:95
  STEP: Creating a kubernetes client @ 12/19/23 10:37:06.781
  Dec 19 10:37:06.781: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename pod-network-test @ 12/19/23 10:37:06.784
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:37:06.826
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:37:06.833
  STEP: Performing setup for networking test in namespace pod-network-test-2335 @ 12/19/23 10:37:06.839
  STEP: creating a selector @ 12/19/23 10:37:06.84
  STEP: Creating the service pods in kubernetes @ 12/19/23 10:37:06.84
  Dec 19 10:37:06.840: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E1219 10:37:07.705066      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:08.703783      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:09.704688      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:10.704881      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:11.704968      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:12.705176      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:13.706222      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:14.706513      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:15.707031      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:16.707335      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:17.707488      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:18.708273      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 12/19/23 10:37:19.063
  E1219 10:37:19.708992      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:20.709148      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:37:21.101: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Dec 19 10:37:21.102: INFO: Breadth first check of 10.233.64.19 on host 192.168.121.83...
  Dec 19 10:37:21.112: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.64:9080/dial?request=hostname&protocol=udp&host=10.233.64.19&port=8081&tries=1'] Namespace:pod-network-test-2335 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:37:21.112: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:37:21.114: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:37:21.115: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2335/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.64%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.64.19%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec 19 10:37:21.279: INFO: Waiting for responses: map[]
  Dec 19 10:37:21.279: INFO: reached 10.233.64.19 after 0/1 tries
  Dec 19 10:37:21.279: INFO: Breadth first check of 10.233.65.13 on host 192.168.121.17...
  Dec 19 10:37:21.287: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.64:9080/dial?request=hostname&protocol=udp&host=10.233.65.13&port=8081&tries=1'] Namespace:pod-network-test-2335 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:37:21.287: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:37:21.289: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:37:21.289: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2335/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.64%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.65.13%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec 19 10:37:21.419: INFO: Waiting for responses: map[]
  Dec 19 10:37:21.419: INFO: reached 10.233.65.13 after 0/1 tries
  Dec 19 10:37:21.419: INFO: Breadth first check of 10.233.66.63 on host 192.168.121.172...
  Dec 19 10:37:21.427: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.64:9080/dial?request=hostname&protocol=udp&host=10.233.66.63&port=8081&tries=1'] Namespace:pod-network-test-2335 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:37:21.427: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:37:21.429: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:37:21.429: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2335/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.64%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.66.63%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec 19 10:37:21.565: INFO: Waiting for responses: map[]
  Dec 19 10:37:21.565: INFO: reached 10.233.66.63 after 0/1 tries
  Dec 19 10:37:21.565: INFO: Going to retry 0 out of 3 pods....
  Dec 19 10:37:21.565: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-2335" for this suite. @ 12/19/23 10:37:21.579
• [14.828 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]
test/e2e/apps/daemon_set.go:875
  STEP: Creating a kubernetes client @ 12/19/23 10:37:21.61
  Dec 19 10:37:21.610: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename daemonsets @ 12/19/23 10:37:21.613
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:37:21.67
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:37:21.676
  E1219 10:37:21.710269      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating simple DaemonSet "daemon-set" @ 12/19/23 10:37:21.741
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/19/23 10:37:21.753
  Dec 19 10:37:21.785: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:37:21.785: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  E1219 10:37:22.710967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:37:22.873: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:37:22.874: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  E1219 10:37:23.711482      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:37:23.811: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec 19 10:37:23.811: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Getting /status @ 12/19/23 10:37:23.82
  Dec 19 10:37:23.831: INFO: Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 12/19/23 10:37:23.832
  Dec 19 10:37:23.860: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 12/19/23 10:37:23.861
  Dec 19 10:37:23.868: INFO: Observed &DaemonSet event: ADDED
  Dec 19 10:37:23.869: INFO: Observed &DaemonSet event: MODIFIED
  Dec 19 10:37:23.870: INFO: Observed &DaemonSet event: MODIFIED
  Dec 19 10:37:23.870: INFO: Observed &DaemonSet event: MODIFIED
  Dec 19 10:37:23.871: INFO: Observed &DaemonSet event: MODIFIED
  Dec 19 10:37:23.871: INFO: Observed &DaemonSet event: MODIFIED
  Dec 19 10:37:23.872: INFO: Found daemon set daemon-set in namespace daemonsets-4829 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Dec 19 10:37:23.872: INFO: Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 12/19/23 10:37:23.873
  STEP: watching for the daemon set status to be patched @ 12/19/23 10:37:23.894
  Dec 19 10:37:23.898: INFO: Observed &DaemonSet event: ADDED
  Dec 19 10:37:23.898: INFO: Observed &DaemonSet event: MODIFIED
  Dec 19 10:37:23.898: INFO: Observed &DaemonSet event: MODIFIED
  Dec 19 10:37:23.899: INFO: Observed &DaemonSet event: MODIFIED
  Dec 19 10:37:23.899: INFO: Observed &DaemonSet event: MODIFIED
  Dec 19 10:37:23.900: INFO: Observed &DaemonSet event: MODIFIED
  Dec 19 10:37:23.900: INFO: Observed daemon set daemon-set in namespace daemonsets-4829 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Dec 19 10:37:23.900: INFO: Observed &DaemonSet event: MODIFIED
  Dec 19 10:37:23.901: INFO: Found daemon set daemon-set in namespace daemonsets-4829 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  Dec 19 10:37:23.901: INFO: Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 12/19/23 10:37:23.91
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4829, will wait for the garbage collector to delete the pods @ 12/19/23 10:37:23.91
  Dec 19 10:37:23.984: INFO: Deleting DaemonSet.extensions daemon-set took: 14.22171ms
  Dec 19 10:37:24.085: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.370254ms
  E1219 10:37:24.711727      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:37:25.594: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:37:25.594: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec 19 10:37:25.601: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"9415"},"items":null}

  Dec 19 10:37:25.612: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"9415"},"items":null}

  Dec 19 10:37:25.648: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-4829" for this suite. @ 12/19/23 10:37:25.658
• [4.063 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:47
  STEP: Creating a kubernetes client @ 12/19/23 10:37:25.679
  Dec 19 10:37:25.679: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 10:37:25.682
  E1219 10:37:25.712186      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:37:25.715
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:37:25.722
  STEP: Creating configMap with name projected-configmap-test-volume-b393572b-3cca-426a-ba55-668608f54ced @ 12/19/23 10:37:25.728
  STEP: Creating a pod to test consume configMaps @ 12/19/23 10:37:25.738
  E1219 10:37:26.712088      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:27.712676      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:28.712985      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:29.713796      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:37:29.786
  Dec 19 10:37:29.794: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-projected-configmaps-a400571f-21c6-426d-8edb-12dab28b68d4 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 10:37:29.806
  Dec 19 10:37:29.832: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7224" for this suite. @ 12/19/23 10:37:29.844
• [4.178 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:527
  STEP: Creating a kubernetes client @ 12/19/23 10:37:29.86
  Dec 19 10:37:29.860: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename container-probe @ 12/19/23 10:37:29.863
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:37:29.897
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:37:29.902
  STEP: Creating pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369 @ 12/19/23 10:37:29.91
  E1219 10:37:30.714811      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:31.715320      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/19/23 10:37:31.952
  Dec 19 10:37:31.958: INFO: Initial restart count of pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 is 0
  Dec 19 10:37:31.967: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:37:32.714707      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:33.715328      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:37:33.979: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:37:34.715845      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:35.716448      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:37:35.988: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:37:36.717185      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:37.717512      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:37:37.998: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:37:38.717300      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:39.718100      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:37:40.008: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:37:40.718657      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:41.718549      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:37:42.016: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:37:42.719311      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:43.719566      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:37:44.026: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:37:44.719643      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:45.720475      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:37:46.035: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:37:46.721564      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:47.722097      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:37:48.044: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:37:48.722296      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:49.723185      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:37:50.055: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:37:50.723287      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:51.723981      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:37:52.063: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:37:52.724216      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:53.724300      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:37:54.073: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:37:54.724530      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:55.724671      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:37:56.081: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:37:56.724889      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:57.725063      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:37:58.097: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:37:58.725382      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:37:59.725625      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:00.106: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:00.726586      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:01.726753      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:02.114: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:02.727788      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:03.728487      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:04.124: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:04.729005      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:05.729704      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:06.142: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:06.729889      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:07.730503      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:08.152: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:08.731327      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:09.731559      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:10.166: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:10.733719      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:11.733005      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:12.175: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:12.733259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:13.733557      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:14.190: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:14.734678      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:15.734644      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:16.204: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:16.734879      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:17.735879      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:18.214: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:18.736038      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:19.736651      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:20.224: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:20.736791      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:21.736969      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:22.236: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:22.737826      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:23.737994      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:24.247: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:24.738309      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:25.738711      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:26.258: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:26.738828      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:27.739820      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:28.270: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:28.740121      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:29.740181      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:30.278: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:30.740778      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:31.741062      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:32.287: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:32.741953      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:33.742480      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:34.302: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:34.742713      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:35.742648      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:36.312: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:36.743253      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:37.743862      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:38.322: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:38.744281      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:39.745050      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:40.328: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:40.745658      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:41.746680      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:42.338: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:42.747487      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:43.747763      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:44.349: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:44.747936      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:45.748529      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:46.357: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:46.748639      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:47.749279      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:48.368: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:48.750051      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:49.750642      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:50.376: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:50.751466      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:51.752356      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:52.384: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:52.752093      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:53.752249      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:54.393: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:54.752448      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:55.752691      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:56.406: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:56.753607      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:57.753883      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:38:58.416: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:38:58.754535      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:38:59.755340      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:00.426: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:00.755481      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:01.755669      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:02.438: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:02.756720      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:03.757316      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:04.450: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:04.758442      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:05.758559      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:06.460: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:06.758750      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:07.758997      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:08.474: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:08.759381      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:09.759758      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:10.484: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:10.760734      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:11.760878      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:12.494: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:12.761163      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:13.761638      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:14.503: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:14.762244      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:15.762847      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:16.514: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:16.764189      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:17.764028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:18.522: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:18.764254      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:19.764559      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:20.532: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:20.765934      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:21.765984      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:22.538: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:22.766479      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:23.767060      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:24.548: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:24.767709      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:25.768044      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:26.557: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:26.768943      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:27.769196      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:28.566: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:28.770071      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:29.770409      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:30.577: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:30.771138      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:31.772018      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:32.594: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:32.772231      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:33.772868      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:34.604: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:34.773600      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:35.773806      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:36.617: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:36.773972      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:37.774900      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:38.626: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:38.775780      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:39.775865      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:40.634: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:40.776112      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:41.776257      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:42.643: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:42.776813      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:43.776839      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:44.658: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:44.777050      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:45.777695      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:46.666: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:46.778253      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:47.779009      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:48.674: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:48.780200      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:49.780825      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:50.682: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:50.781247      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:51.781503      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:52.690: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:52.782191      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:53.782634      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:54.704: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:54.782967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:55.783122      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:56.714: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:56.783529      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:57.783915      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:39:58.759: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:39:58.783777      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:39:59.784090      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:00.768: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:00.784330      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:01.785695      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:02.781: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:02.786308      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:03.785800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:04.786394      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:04.791: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:05.787222      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:06.788358      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:06.802: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:07.788464      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:08.789698      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:08.809: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:09.789875      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:10.790757      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:10.823: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:11.790996      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:12.791280      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:12.832: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:13.791886      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:14.792023      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:14.847: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:15.792160      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:16.792763      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:16.856: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:17.792769      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:18.793059      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:18.864: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:19.793357      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:20.794177      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:20.877: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:21.794508      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:22.794577      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:22.886: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:23.794463      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:24.794902      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:24.899: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:25.795030      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:26.795331      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:26.906: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:27.795491      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:28.795959      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:28.915: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:29.796165      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:30.796253      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:30.925: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:31.797007      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:32.797124      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:32.931: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:33.797332      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:34.797652      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:34.941: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:35.798384      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:36.798496      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:36.949: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:37.798794      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:38.798959      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:38.957: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:39.799176      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:40.799746      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:40.965: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:41.799991      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:42.800253      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:42.975: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:43.800608      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:44.800994      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:44.986: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:45.801245      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:46.801637      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:46.994: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:47.802145      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:48.802522      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:49.005: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:49.802583      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:50.802698      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:51.013: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:51.802860      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:52.803083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:53.026: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:53.803299      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:54.803589      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:55.036: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:55.804204      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:56.804629      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:57.045: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:57.804528      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:40:58.804669      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:40:59.054: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:40:59.805017      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:00.806221      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:01.065: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:41:01.806082      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:02.806308      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:03.074: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:41:03.806508      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:04.806728      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:05.082: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:41:05.807036      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:06.807735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:07.089: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:41:07.808513      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:08.810164      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:09.096: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:41:09.809301      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:10.810273      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:11.104: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:41:11.810553      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:12.811174      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:13.111: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:41:13.812380      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:14.812628      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:15.121: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:41:15.813194      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:16.813544      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:17.128: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:41:17.813542      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:18.814424      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:19.138: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:41:19.814127      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:20.814452      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:21.150: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:41:21.814663      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:22.815202      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:23.157: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:41:23.816185      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:24.816765      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:25.176: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:41:25.817511      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:26.818134      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:27.188: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:41:27.818444      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:28.818860      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:29.203: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:41:29.820236      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:30.821072      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:31.214: INFO: Get pod test-grpc-0df01926-a034-47a4-a3a3-0afac0d08386 in namespace container-probe-3369
  E1219 10:41:31.822180      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:32.822270      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:41:33.216: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/19/23 10:41:33.231
  STEP: Destroying namespace "container-probe-3369" for this suite. @ 12/19/23 10:41:33.279
• [243.458 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
test/e2e/scheduling/predicates.go:705
  STEP: Creating a kubernetes client @ 12/19/23 10:41:33.331
  Dec 19 10:41:33.331: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename sched-pred @ 12/19/23 10:41:33.335
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:41:33.371
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:41:33.377
  Dec 19 10:41:33.382: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Dec 19 10:41:33.410: INFO: Waiting for terminating namespaces to be deleted...
  Dec 19 10:41:33.423: INFO: 
  Logging pods the apiserver thinks is on node hiengux9ahcu-1 before test
  Dec 19 10:41:33.441: INFO: coredns-5dd5756b68-z5h65 from kube-system started at 2023-12-19 10:09:21 +0000 UTC (1 container statuses recorded)
  Dec 19 10:41:33.441: INFO: 	Container coredns ready: true, restart count 0
  Dec 19 10:41:33.442: INFO: kube-addon-manager-hiengux9ahcu-1 from kube-system started at 2023-12-19 09:57:29 +0000 UTC (1 container statuses recorded)
  Dec 19 10:41:33.442: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Dec 19 10:41:33.442: INFO: kube-apiserver-hiengux9ahcu-1 from kube-system started at 2023-12-19 09:57:29 +0000 UTC (1 container statuses recorded)
  Dec 19 10:41:33.442: INFO: 	Container kube-apiserver ready: true, restart count 1
  Dec 19 10:41:33.443: INFO: kube-controller-manager-hiengux9ahcu-1 from kube-system started at 2023-12-19 09:57:29 +0000 UTC (1 container statuses recorded)
  Dec 19 10:41:33.443: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Dec 19 10:41:33.443: INFO: kube-flannel-ds-8nd22 from kube-system started at 2023-12-19 09:49:46 +0000 UTC (1 container statuses recorded)
  Dec 19 10:41:33.443: INFO: 	Container kube-flannel ready: true, restart count 1
  Dec 19 10:41:33.443: INFO: kube-proxy-lzkkc from kube-system started at 2023-12-19 09:46:48 +0000 UTC (1 container statuses recorded)
  Dec 19 10:41:33.444: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 10:41:33.444: INFO: kube-scheduler-hiengux9ahcu-1 from kube-system started at 2023-12-19 09:57:29 +0000 UTC (1 container statuses recorded)
  Dec 19 10:41:33.444: INFO: 	Container kube-scheduler ready: true, restart count 1
  Dec 19 10:41:33.444: INFO: sonobuoy-systemd-logs-daemon-set-c8f6e06512bd4c62-k4wtt from sonobuoy started at 2023-12-19 10:01:09 +0000 UTC (2 container statuses recorded)
  Dec 19 10:41:33.444: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 10:41:33.445: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec 19 10:41:33.445: INFO: 
  Logging pods the apiserver thinks is on node hiengux9ahcu-2 before test
  Dec 19 10:41:33.467: INFO: coredns-5dd5756b68-d5xhn from kube-system started at 2023-12-19 10:09:21 +0000 UTC (1 container statuses recorded)
  Dec 19 10:41:33.467: INFO: 	Container coredns ready: true, restart count 0
  Dec 19 10:41:33.468: INFO: kube-addon-manager-hiengux9ahcu-2 from kube-system started at 2023-12-19 09:53:01 +0000 UTC (1 container statuses recorded)
  Dec 19 10:41:33.468: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Dec 19 10:41:33.468: INFO: kube-apiserver-hiengux9ahcu-2 from kube-system started at 2023-12-19 09:53:01 +0000 UTC (1 container statuses recorded)
  Dec 19 10:41:33.469: INFO: 	Container kube-apiserver ready: true, restart count 1
  Dec 19 10:41:33.469: INFO: kube-controller-manager-hiengux9ahcu-2 from kube-system started at 2023-12-19 09:53:01 +0000 UTC (1 container statuses recorded)
  Dec 19 10:41:33.469: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Dec 19 10:41:33.470: INFO: kube-flannel-ds-nzb72 from kube-system started at 2023-12-19 09:49:46 +0000 UTC (1 container statuses recorded)
  Dec 19 10:41:33.470: INFO: 	Container kube-flannel ready: true, restart count 1
  Dec 19 10:41:33.470: INFO: kube-proxy-2k68s from kube-system started at 2023-12-19 09:47:35 +0000 UTC (1 container statuses recorded)
  Dec 19 10:41:33.470: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 10:41:33.471: INFO: kube-scheduler-hiengux9ahcu-2 from kube-system started at 2023-12-19 09:53:01 +0000 UTC (1 container statuses recorded)
  Dec 19 10:41:33.471: INFO: 	Container kube-scheduler ready: true, restart count 1
  Dec 19 10:41:33.471: INFO: sonobuoy-systemd-logs-daemon-set-c8f6e06512bd4c62-j8fvw from sonobuoy started at 2023-12-19 10:01:09 +0000 UTC (2 container statuses recorded)
  Dec 19 10:41:33.471: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 10:41:33.472: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec 19 10:41:33.472: INFO: 
  Logging pods the apiserver thinks is on node hiengux9ahcu-3 before test
  Dec 19 10:41:33.488: INFO: kube-flannel-ds-vt8hx from kube-system started at 2023-12-19 10:09:22 +0000 UTC (1 container statuses recorded)
  Dec 19 10:41:33.488: INFO: 	Container kube-flannel ready: true, restart count 0
  Dec 19 10:41:33.488: INFO: kube-proxy-2p94p from kube-system started at 2023-12-19 09:47:58 +0000 UTC (1 container statuses recorded)
  Dec 19 10:41:33.488: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 10:41:33.488: INFO: sonobuoy from sonobuoy started at 2023-12-19 10:00:58 +0000 UTC (1 container statuses recorded)
  Dec 19 10:41:33.488: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Dec 19 10:41:33.488: INFO: sonobuoy-e2e-job-f5f0378b7abe4dc3 from sonobuoy started at 2023-12-19 10:01:09 +0000 UTC (2 container statuses recorded)
  Dec 19 10:41:33.488: INFO: 	Container e2e ready: true, restart count 0
  Dec 19 10:41:33.488: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 10:41:33.488: INFO: sonobuoy-systemd-logs-daemon-set-c8f6e06512bd4c62-fgsng from sonobuoy started at 2023-12-19 10:01:09 +0000 UTC (2 container statuses recorded)
  Dec 19 10:41:33.488: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 10:41:33.488: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 12/19/23 10:41:33.488
  E1219 10:41:33.822237      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:34.822577      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 12/19/23 10:41:35.564
  STEP: Trying to apply a random label on the found node. @ 12/19/23 10:41:35.597
  STEP: verifying the node has the label kubernetes.io/e2e-954929c9-a6ec-4822-a0cb-4c69e036ca23 95 @ 12/19/23 10:41:35.615
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 12/19/23 10:41:35.627
  E1219 10:41:35.823893      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:36.824119      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.121.172 on the node which pod4 resides and expect not scheduled @ 12/19/23 10:41:37.668
  E1219 10:41:37.824903      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:38.825490      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:39.825818      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:40.826274      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:41.831064      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:42.827983      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:43.828693      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:44.828837      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:45.829894      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:46.830294      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:47.830627      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:48.831365      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:49.831853      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:50.832065      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:51.832480      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:52.833085      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:53.833680      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:54.834623      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:55.835121      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:56.835695      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:57.835880      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:58.836389      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:41:59.836496      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:00.837043      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:01.837568      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:02.837763      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:03.837925      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:04.838539      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:05.839009      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:06.840255      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:07.840712      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:08.841088      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:09.841656      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:10.842705      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:11.842872      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:12.843703      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:13.843981      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:14.844169      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:15.845068      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:16.845383      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:17.845971      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:18.846227      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:19.847315      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:20.847976      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:21.848129      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:22.848347      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:23.848562      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:24.848847      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:25.849877      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:26.850625      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:27.850903      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:28.851354      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:29.851516      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:30.852662      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:31.853095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:32.853277      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:33.853992      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:34.854148      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:35.854351      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:36.855070      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:37.855948      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:38.856115      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:39.856229      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:40.856309      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:41.856616      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:42.856802      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:43.857032      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:44.857569      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:45.858484      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:46.859218      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:47.859137      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:48.860240      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:49.860475      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:50.861356      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:51.862604      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:52.862634      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:53.862892      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:54.862994      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:55.864109      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:56.864620      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:57.865905      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:58.865795      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:42:59.865890      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:00.865870      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:01.866322      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:02.866444      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:03.866743      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:04.867001      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:05.867225      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:06.868152      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:07.868318      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:08.870061      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:09.870242      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:10.871242      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:11.872247      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:12.873026      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:13.873380      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:14.874010      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:15.874106      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:16.874442      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:17.874529      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:18.874622      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:19.875416      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:20.875914      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:21.876687      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:22.877210      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:23.877347      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:24.877899      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:25.878679      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:26.879628      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:27.880329      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:28.880753      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:29.880871      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:30.880924      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:31.881660      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:32.881529      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:33.882726      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:34.883664      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:35.884299      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:36.884525      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:37.884707      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:38.884795      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:39.885210      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:40.885996      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:41.888623      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:42.889271      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:43.889714      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:44.890891      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:45.891301      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:46.891822      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:47.892749      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:48.892950      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:49.893608      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:50.894592      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:51.895172      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:52.895400      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:53.895562      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:54.896213      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:55.896008      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:56.896232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:57.896540      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:58.897152      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:43:59.897645      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:00.897782      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:01.898244      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:02.899058      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:03.898547      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:04.899036      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:05.899976      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:06.901233      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:07.900453      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:08.900597      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:09.900906      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:10.901584      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:11.902155      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:12.903545      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:13.903749      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:14.904635      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:15.905522      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:16.905748      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:17.905878      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:18.906606      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:19.906844      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:20.907832      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:21.908793      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:22.909749      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:23.910606      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:24.912047      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:25.912406      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:26.913214      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:27.914033      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:28.915003      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:29.915485      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:30.916033      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:31.916621      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:32.916667      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:33.916934      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:34.918205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:35.919407      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:36.919189      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:37.919264      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:38.919527      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:39.920098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:40.921023      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:41.921214      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:42.921370      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:43.921828      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:44.922438      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:45.923372      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:46.923993      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:47.924172      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:48.924329      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:49.924531      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:50.925444      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:51.926105      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:52.926151      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:53.926613      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:54.927331      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:55.927880      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:56.928721      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:57.929774      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:58.930024      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:44:59.931024      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:00.931272      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:01.931396      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:02.931972      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:03.932230      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:04.933050      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:05.933539      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:06.934003      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:07.934342      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:08.934454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:09.934637      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:10.935026      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:11.935361      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:12.935257      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:13.935585      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:14.936534      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:15.937294      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:16.938168      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:17.938988      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:18.940017      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:19.940921      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:20.941142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:21.941497      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:22.941927      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:23.942799      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:24.943244      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:25.944198      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:26.944941      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:27.945593      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:28.948479      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:29.947286      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:30.947864      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:31.948214      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:32.949037      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:33.949133      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:34.949745      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:35.950289      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:36.952379      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:37.951820      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:38.952126      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:39.952375      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:40.953203      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:41.953864      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:42.954310      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:43.955143      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:44.955141      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:45.955839      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:46.956447      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:47.956864      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:48.957611      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:49.957792      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:50.958242      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:51.958505      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:52.959095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:53.965245      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:54.960888      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:55.961319      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:56.961539      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:57.961881      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:58.962289      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:45:59.962950      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:00.963160      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:01.963585      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:02.963791      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:03.964006      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:04.964247      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:05.964720      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:06.965610      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:07.965661      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:08.966061      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:09.966815      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:10.967579      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:11.968461      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:12.968866      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:13.968925      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:14.969102      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:15.970423      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:16.970532      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:17.970763      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:18.970932      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:19.971935      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:20.972179      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:21.972278      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:22.972570      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:23.972789      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:24.974069      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:25.974546      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:26.975183      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:27.975819      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:28.976568      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:29.977016      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:30.977973      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:31.978235      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:32.979281      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:33.979451      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:34.980108      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:35.980796      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:36.981085      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-954929c9-a6ec-4822-a0cb-4c69e036ca23 off the node hiengux9ahcu-3 @ 12/19/23 10:46:37.686
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-954929c9-a6ec-4822-a0cb-4c69e036ca23 @ 12/19/23 10:46:37.711
  Dec 19 10:46:37.720: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-3776" for this suite. @ 12/19/23 10:46:37.731
• [304.416 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 12/19/23 10:46:37.767
  Dec 19 10:46:37.768: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename pods @ 12/19/23 10:46:37.772
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:46:37.81
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:46:37.816
  E1219 10:46:37.983028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:38.983367      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:39.983005      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:40.983806      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:41.985247      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:42.985299      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:46:43.945
  Dec 19 10:46:43.954: INFO: Trying to get logs from node hiengux9ahcu-3 pod client-envvars-8a093b9e-4e6f-4b1e-8710-3800a0b41218 container env3cont: <nil>
  E1219 10:46:43.985346      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod @ 12/19/23 10:46:43.991
  Dec 19 10:46:44.017: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-986" for this suite. @ 12/19/23 10:46:44.025
• [6.269 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:187
  STEP: Creating a kubernetes client @ 12/19/23 10:46:44.042
  Dec 19 10:46:44.042: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 10:46:44.045
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:46:44.075
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:46:44.081
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 12/19/23 10:46:44.086
  E1219 10:46:44.985880      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:45.986751      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:46:46.119
  Dec 19 10:46:46.126: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-eeb783a9-3093-4c12-971e-8602471df984 container test-container: <nil>
  STEP: delete the pod @ 12/19/23 10:46:46.139
  Dec 19 10:46:46.170: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3458" for this suite. @ 12/19/23 10:46:46.18
• [2.151 seconds]
------------------------------
S
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]
test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 12/19/23 10:46:46.196
  Dec 19 10:46:46.196: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename deployment @ 12/19/23 10:46:46.202
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:46:46.233
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:46:46.239
  STEP: creating a Deployment @ 12/19/23 10:46:46.253
  STEP: waiting for Deployment to be created @ 12/19/23 10:46:46.264
  STEP: waiting for all Replicas to be Ready @ 12/19/23 10:46:46.268
  Dec 19 10:46:46.273: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec 19 10:46:46.275: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec 19 10:46:46.286: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec 19 10:46:46.286: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec 19 10:46:46.323: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec 19 10:46:46.324: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec 19 10:46:46.439: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec 19 10:46:46.439: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E1219 10:46:46.987089      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:47.322: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Dec 19 10:46:47.323: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Dec 19 10:46:47.968: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 12/19/23 10:46:47.969
  E1219 10:46:47.987576      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:47.996: INFO: observed event type ADDED
  STEP: waiting for Replicas to scale @ 12/19/23 10:46:47.996
  Dec 19 10:46:48.002: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 0
  Dec 19 10:46:48.002: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 0
  Dec 19 10:46:48.002: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 0
  Dec 19 10:46:48.003: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 0
  Dec 19 10:46:48.004: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 0
  Dec 19 10:46:48.004: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 0
  Dec 19 10:46:48.004: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 0
  Dec 19 10:46:48.005: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 0
  Dec 19 10:46:48.005: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 1
  Dec 19 10:46:48.005: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 1
  Dec 19 10:46:48.006: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 2
  Dec 19 10:46:48.007: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 2
  Dec 19 10:46:48.007: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 2
  Dec 19 10:46:48.007: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 2
  Dec 19 10:46:48.024: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 2
  Dec 19 10:46:48.024: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 2
  Dec 19 10:46:48.070: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 2
  Dec 19 10:46:48.070: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 2
  Dec 19 10:46:48.115: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 1
  Dec 19 10:46:48.115: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 1
  Dec 19 10:46:48.129: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 1
  Dec 19 10:46:48.129: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 1
  E1219 10:46:48.988558      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:48.989: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 2
  Dec 19 10:46:48.989: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 2
  Dec 19 10:46:49.064: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 1
  STEP: listing Deployments @ 12/19/23 10:46:49.065
  Dec 19 10:46:49.071: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 12/19/23 10:46:49.072
  Dec 19 10:46:49.100: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 12/19/23 10:46:49.102
  Dec 19 10:46:49.124: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Dec 19 10:46:49.136: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Dec 19 10:46:49.219: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Dec 19 10:46:49.295: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Dec 19 10:46:49.337: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E1219 10:46:49.989467      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:50.973: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E1219 10:46:50.989685      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:51.076: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  Dec 19 10:46:51.276: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Dec 19 10:46:51.348: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E1219 10:46:51.990006      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:52.362: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 12/19/23 10:46:52.437
  STEP: fetching the DeploymentStatus @ 12/19/23 10:46:52.453
  Dec 19 10:46:52.465: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 1
  Dec 19 10:46:52.466: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 1
  Dec 19 10:46:52.466: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 1
  Dec 19 10:46:52.467: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 1
  Dec 19 10:46:52.468: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 1
  Dec 19 10:46:52.468: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 2
  Dec 19 10:46:52.469: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 3
  Dec 19 10:46:52.469: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 2
  Dec 19 10:46:52.470: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 2
  Dec 19 10:46:52.470: INFO: observed Deployment test-deployment in namespace deployment-6040 with ReadyReplicas 3
  STEP: deleting the Deployment @ 12/19/23 10:46:52.471
  Dec 19 10:46:52.501: INFO: observed event type MODIFIED
  Dec 19 10:46:52.501: INFO: observed event type MODIFIED
  Dec 19 10:46:52.501: INFO: observed event type MODIFIED
  Dec 19 10:46:52.502: INFO: observed event type MODIFIED
  Dec 19 10:46:52.502: INFO: observed event type MODIFIED
  Dec 19 10:46:52.503: INFO: observed event type MODIFIED
  Dec 19 10:46:52.503: INFO: observed event type MODIFIED
  Dec 19 10:46:52.504: INFO: observed event type MODIFIED
  Dec 19 10:46:52.504: INFO: observed event type MODIFIED
  Dec 19 10:46:52.505: INFO: observed event type MODIFIED
  Dec 19 10:46:52.505: INFO: observed event type MODIFIED
  Dec 19 10:46:52.506: INFO: observed event type MODIFIED
  Dec 19 10:46:52.507: INFO: observed event type MODIFIED
  Dec 19 10:46:52.587: INFO: Log out all the ReplicaSets if there is no deployment created
  Dec 19 10:46:52.601: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6040" for this suite. @ 12/19/23 10:46:52.619
• [6.470 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 12/19/23 10:46:52.667
  Dec 19 10:46:52.667: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename pods @ 12/19/23 10:46:52.67
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:46:52.71
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:46:52.717
  STEP: creating the pod @ 12/19/23 10:46:52.722
  STEP: submitting the pod to kubernetes @ 12/19/23 10:46:52.723
  W1219 10:46:52.744317      14 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E1219 10:46:52.990802      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:53.991247      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 12/19/23 10:46:54.781
  STEP: updating the pod @ 12/19/23 10:46:54.793
  E1219 10:46:54.991902      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:55.331: INFO: Successfully updated pod "pod-update-activedeadlineseconds-9ace9e42-e6fb-49a0-a96d-6f35e70b704f"
  E1219 10:46:55.992269      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:56.993070      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:57.993625      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:46:58.993819      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:46:59.366: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9913" for this suite. @ 12/19/23 10:46:59.376
• [6.738 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 12/19/23 10:46:59.408
  Dec 19 10:46:59.408: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename container-runtime @ 12/19/23 10:46:59.411
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:46:59.456
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:46:59.462
  STEP: create the container @ 12/19/23 10:46:59.467
  W1219 10:46:59.491083      14 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 12/19/23 10:46:59.491
  E1219 10:46:59.994268      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:00.995102      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:01.995682      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 12/19/23 10:47:02.526
  STEP: the container should be terminated @ 12/19/23 10:47:02.533
  STEP: the termination message should be set @ 12/19/23 10:47:02.533
  Dec 19 10:47:02.533: INFO: Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 12/19/23 10:47:02.533
  Dec 19 10:47:02.574: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-5684" for this suite. @ 12/19/23 10:47:02.593
• [3.198 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance]
test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 12/19/23 10:47:02.607
  Dec 19 10:47:02.607: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename csiinlinevolumes @ 12/19/23 10:47:02.611
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:47:02.647
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:47:02.654
  STEP: creating @ 12/19/23 10:47:02.664
  STEP: getting @ 12/19/23 10:47:02.717
  STEP: listing in namespace @ 12/19/23 10:47:02.732
  STEP: patching @ 12/19/23 10:47:02.748
  STEP: deleting @ 12/19/23 10:47:02.829
  Dec 19 10:47:02.874: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-8612" for this suite. @ 12/19/23 10:47:02.889
• [0.296 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:134
  STEP: Creating a kubernetes client @ 12/19/23 10:47:02.907
  Dec 19 10:47:02.907: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename container-probe @ 12/19/23 10:47:02.91
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:47:02.945
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:47:02.952
  STEP: Creating pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887 @ 12/19/23 10:47:02.957
  E1219 10:47:02.996798      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:03.997512      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:04.997771      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/19/23 10:47:05.014
  Dec 19 10:47:05.022: INFO: Initial restart count of pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 is 0
  Dec 19 10:47:05.029: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:05.998984      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:06.998670      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:07.037: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:07.998962      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:08.999958      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:09.054: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:10.000726      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:11.001108      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:11.064: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:12.001256      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:13.001733      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:13.072: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:14.002079      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:15.002286      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:15.082: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:16.002262      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:17.002816      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:17.092: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:18.005106      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:19.004883      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:19.101: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:20.005128      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:21.005306      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:21.112: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:22.005881      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:23.005771      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:23.124: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:24.006913      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:25.007192      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:25.137: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:26.007353      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:27.007776      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:27.148: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:28.008041      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:29.009022      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:29.157: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:30.009775      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:31.010888      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:31.170: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:32.010898      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:33.011182      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:33.180: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:34.011517      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:35.011708      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:35.189: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:36.012584      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:37.013312      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:37.198: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:38.013403      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:39.013836      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:39.207: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:40.014133      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:41.014634      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:41.217: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:42.014942      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:43.015594      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:43.228: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:44.016050      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:45.016489      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:45.239: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:46.017219      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:47.017913      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:47.248: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:48.018882      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:49.019047      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:49.256: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:50.019457      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:51.019353      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:51.265: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:52.019642      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:53.020298      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:53.273: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  E1219 10:47:54.020458      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:55.021167      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:55.282: INFO: Get pod busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 in namespace container-probe-2887
  Dec 19 10:47:55.282: INFO: Restart count of pod container-probe-2887/busybox-c68a57dd-9a52-4616-a5ea-13faf0826f12 is now 1 (50.260584044s elapsed)
  Dec 19 10:47:55.283: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/19/23 10:47:55.294
  STEP: Destroying namespace "container-probe-2887" for this suite. @ 12/19/23 10:47:55.352
• [52.471 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]
test/e2e/kubectl/kubectl.go:354
  STEP: Creating a kubernetes client @ 12/19/23 10:47:55.38
  Dec 19 10:47:55.380: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 10:47:55.384
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:47:55.433
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:47:55.44
  STEP: creating a replication controller @ 12/19/23 10:47:55.447
  Dec 19 10:47:55.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 create -f -'
  E1219 10:47:56.021695      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:56.716: INFO: stderr: ""
  Dec 19 10:47:56.716: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 12/19/23 10:47:56.717
  Dec 19 10:47:56.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec 19 10:47:56.980: INFO: stderr: ""
  Dec 19 10:47:56.980: INFO: stdout: "update-demo-nautilus-bhl7d update-demo-nautilus-h58jk "
  Dec 19 10:47:56.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods update-demo-nautilus-bhl7d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E1219 10:47:57.022749      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:47:57.203: INFO: stderr: ""
  Dec 19 10:47:57.203: INFO: stdout: ""
  Dec 19 10:47:57.203: INFO: update-demo-nautilus-bhl7d is created but not running
  E1219 10:47:58.023016      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:47:59.024573      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:00.023682      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:01.027151      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:02.024728      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:02.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec 19 10:48:02.421: INFO: stderr: ""
  Dec 19 10:48:02.421: INFO: stdout: "update-demo-nautilus-bhl7d update-demo-nautilus-h58jk "
  Dec 19 10:48:02.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods update-demo-nautilus-bhl7d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 10:48:02.619: INFO: stderr: ""
  Dec 19 10:48:02.619: INFO: stdout: ""
  Dec 19 10:48:02.619: INFO: update-demo-nautilus-bhl7d is created but not running
  E1219 10:48:03.025361      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:04.025720      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:05.025845      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:06.026363      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:07.026446      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:07.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec 19 10:48:07.827: INFO: stderr: ""
  Dec 19 10:48:07.829: INFO: stdout: "update-demo-nautilus-bhl7d update-demo-nautilus-h58jk "
  Dec 19 10:48:07.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods update-demo-nautilus-bhl7d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 10:48:08.006: INFO: stderr: ""
  Dec 19 10:48:08.006: INFO: stdout: ""
  Dec 19 10:48:08.006: INFO: update-demo-nautilus-bhl7d is created but not running
  E1219 10:48:08.026658      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:09.027220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:10.027598      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:11.028447      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:12.028657      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:13.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E1219 10:48:13.029127      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:13.239: INFO: stderr: ""
  Dec 19 10:48:13.239: INFO: stdout: "update-demo-nautilus-bhl7d update-demo-nautilus-h58jk "
  Dec 19 10:48:13.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods update-demo-nautilus-bhl7d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 10:48:13.414: INFO: stderr: ""
  Dec 19 10:48:13.414: INFO: stdout: ""
  Dec 19 10:48:13.414: INFO: update-demo-nautilus-bhl7d is created but not running
  E1219 10:48:14.029235      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:15.029382      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:16.030269      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:17.030408      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:18.031086      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:18.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec 19 10:48:18.598: INFO: stderr: ""
  Dec 19 10:48:18.598: INFO: stdout: "update-demo-nautilus-bhl7d update-demo-nautilus-h58jk "
  Dec 19 10:48:18.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods update-demo-nautilus-bhl7d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 10:48:18.787: INFO: stderr: ""
  Dec 19 10:48:18.787: INFO: stdout: ""
  Dec 19 10:48:18.787: INFO: update-demo-nautilus-bhl7d is created but not running
  E1219 10:48:19.031985      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:20.032091      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:21.033816      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:22.033792      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:23.036697      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:23.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec 19 10:48:23.993: INFO: stderr: ""
  Dec 19 10:48:23.993: INFO: stdout: "update-demo-nautilus-bhl7d update-demo-nautilus-h58jk "
  Dec 19 10:48:23.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods update-demo-nautilus-bhl7d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E1219 10:48:24.034461      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:24.160: INFO: stderr: ""
  Dec 19 10:48:24.160: INFO: stdout: "true"
  Dec 19 10:48:24.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods update-demo-nautilus-bhl7d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec 19 10:48:24.376: INFO: stderr: ""
  Dec 19 10:48:24.377: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec 19 10:48:24.377: INFO: validating pod update-demo-nautilus-bhl7d
  Dec 19 10:48:24.407: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec 19 10:48:24.408: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec 19 10:48:24.408: INFO: update-demo-nautilus-bhl7d is verified up and running
  Dec 19 10:48:24.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods update-demo-nautilus-h58jk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 10:48:24.569: INFO: stderr: ""
  Dec 19 10:48:24.569: INFO: stdout: "true"
  Dec 19 10:48:24.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods update-demo-nautilus-h58jk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec 19 10:48:24.741: INFO: stderr: ""
  Dec 19 10:48:24.741: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec 19 10:48:24.741: INFO: validating pod update-demo-nautilus-h58jk
  Dec 19 10:48:24.757: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec 19 10:48:24.757: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec 19 10:48:24.758: INFO: update-demo-nautilus-h58jk is verified up and running
  STEP: scaling down the replication controller @ 12/19/23 10:48:24.758
  Dec 19 10:48:24.778: INFO: scanned /root for discovery docs: <nil>
  Dec 19 10:48:24.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E1219 10:48:25.035629      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:26.006: INFO: stderr: ""
  Dec 19 10:48:26.006: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 12/19/23 10:48:26.006
  Dec 19 10:48:26.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E1219 10:48:26.037258      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:26.164: INFO: stderr: ""
  Dec 19 10:48:26.164: INFO: stdout: "update-demo-nautilus-bhl7d update-demo-nautilus-h58jk "
  STEP: Replicas for name=update-demo: expected=1 actual=2 @ 12/19/23 10:48:26.165
  E1219 10:48:27.036450      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:28.036886      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:29.036968      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:30.037215      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:31.038021      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:31.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec 19 10:48:31.418: INFO: stderr: ""
  Dec 19 10:48:31.418: INFO: stdout: "update-demo-nautilus-bhl7d "
  Dec 19 10:48:31.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods update-demo-nautilus-bhl7d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 10:48:31.584: INFO: stderr: ""
  Dec 19 10:48:31.584: INFO: stdout: "true"
  Dec 19 10:48:31.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods update-demo-nautilus-bhl7d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec 19 10:48:31.748: INFO: stderr: ""
  Dec 19 10:48:31.749: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec 19 10:48:31.749: INFO: validating pod update-demo-nautilus-bhl7d
  Dec 19 10:48:31.759: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec 19 10:48:31.760: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec 19 10:48:31.760: INFO: update-demo-nautilus-bhl7d is verified up and running
  STEP: scaling up the replication controller @ 12/19/23 10:48:31.76
  Dec 19 10:48:31.775: INFO: scanned /root for discovery docs: <nil>
  Dec 19 10:48:31.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E1219 10:48:32.038081      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:32.976: INFO: stderr: ""
  Dec 19 10:48:32.976: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 12/19/23 10:48:32.976
  Dec 19 10:48:32.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E1219 10:48:33.038568      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:33.142: INFO: stderr: ""
  Dec 19 10:48:33.142: INFO: stdout: "update-demo-nautilus-bhl7d update-demo-nautilus-hk9hh "
  Dec 19 10:48:33.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods update-demo-nautilus-bhl7d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 10:48:33.298: INFO: stderr: ""
  Dec 19 10:48:33.298: INFO: stdout: "true"
  Dec 19 10:48:33.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods update-demo-nautilus-bhl7d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec 19 10:48:33.472: INFO: stderr: ""
  Dec 19 10:48:33.472: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec 19 10:48:33.472: INFO: validating pod update-demo-nautilus-bhl7d
  Dec 19 10:48:33.484: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec 19 10:48:33.484: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec 19 10:48:33.484: INFO: update-demo-nautilus-bhl7d is verified up and running
  Dec 19 10:48:33.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods update-demo-nautilus-hk9hh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 10:48:33.684: INFO: stderr: ""
  Dec 19 10:48:33.684: INFO: stdout: "true"
  Dec 19 10:48:33.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods update-demo-nautilus-hk9hh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec 19 10:48:33.860: INFO: stderr: ""
  Dec 19 10:48:33.860: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec 19 10:48:33.860: INFO: validating pod update-demo-nautilus-hk9hh
  Dec 19 10:48:33.879: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec 19 10:48:33.879: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec 19 10:48:33.879: INFO: update-demo-nautilus-hk9hh is verified up and running
  STEP: using delete to clean up resources @ 12/19/23 10:48:33.879
  Dec 19 10:48:33.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 delete --grace-period=0 --force -f -'
  E1219 10:48:34.039604      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:34.050: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec 19 10:48:34.050: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Dec 19 10:48:34.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get rc,svc -l name=update-demo --no-headers'
  Dec 19 10:48:34.328: INFO: stderr: "No resources found in kubectl-8983 namespace.\n"
  Dec 19 10:48:34.328: INFO: stdout: ""
  Dec 19 10:48:34.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8983 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Dec 19 10:48:34.545: INFO: stderr: ""
  Dec 19 10:48:34.545: INFO: stdout: ""
  Dec 19 10:48:34.546: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8983" for this suite. @ 12/19/23 10:48:34.563
• [39.198 seconds]
------------------------------
SS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]
test/e2e/network/endpointslice.go:355
  STEP: Creating a kubernetes client @ 12/19/23 10:48:34.579
  Dec 19 10:48:34.579: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename endpointslice @ 12/19/23 10:48:34.587
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:48:34.63
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:48:34.637
  STEP: getting /apis @ 12/19/23 10:48:34.645
  STEP: getting /apis/discovery.k8s.io @ 12/19/23 10:48:34.659
  STEP: getting /apis/discovery.k8s.iov1 @ 12/19/23 10:48:34.664
  STEP: creating @ 12/19/23 10:48:34.667
  STEP: getting @ 12/19/23 10:48:34.713
  STEP: listing @ 12/19/23 10:48:34.72
  STEP: watching @ 12/19/23 10:48:34.769
  Dec 19 10:48:34.770: INFO: starting watch
  STEP: cluster-wide listing @ 12/19/23 10:48:34.772
  STEP: cluster-wide watching @ 12/19/23 10:48:34.788
  Dec 19 10:48:34.788: INFO: starting watch
  STEP: patching @ 12/19/23 10:48:34.791
  STEP: updating @ 12/19/23 10:48:34.799
  Dec 19 10:48:34.816: INFO: waiting for watch events with expected annotations
  Dec 19 10:48:34.816: INFO: saw patched and updated annotations
  STEP: deleting @ 12/19/23 10:48:34.816
  STEP: deleting a collection @ 12/19/23 10:48:34.838
  Dec 19 10:48:34.873: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-8477" for this suite. @ 12/19/23 10:48:34.882
• [0.318 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 12/19/23 10:48:34.902
  Dec 19 10:48:34.902: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename proxy @ 12/19/23 10:48:34.906
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:48:34.946
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:48:34.951
  Dec 19 10:48:34.956: INFO: Creating pod...
  E1219 10:48:35.040293      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:36.040831      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:36.989: INFO: Creating service...
  Dec 19 10:48:37.014: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5743/pods/agnhost/proxy/some/path/with/DELETE
  Dec 19 10:48:37.027: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Dec 19 10:48:37.028: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5743/pods/agnhost/proxy/some/path/with/GET
  Dec 19 10:48:37.038: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Dec 19 10:48:37.038: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5743/pods/agnhost/proxy/some/path/with/HEAD
  E1219 10:48:37.041724      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:37.048: INFO: http.Client request:HEAD | StatusCode:200
  Dec 19 10:48:37.048: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5743/pods/agnhost/proxy/some/path/with/OPTIONS
  Dec 19 10:48:37.060: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Dec 19 10:48:37.060: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5743/pods/agnhost/proxy/some/path/with/PATCH
  Dec 19 10:48:37.068: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Dec 19 10:48:37.068: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5743/pods/agnhost/proxy/some/path/with/POST
  Dec 19 10:48:37.074: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Dec 19 10:48:37.074: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5743/pods/agnhost/proxy/some/path/with/PUT
  Dec 19 10:48:37.083: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Dec 19 10:48:37.084: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5743/services/test-service/proxy/some/path/with/DELETE
  Dec 19 10:48:37.094: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Dec 19 10:48:37.094: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5743/services/test-service/proxy/some/path/with/GET
  Dec 19 10:48:37.106: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Dec 19 10:48:37.108: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5743/services/test-service/proxy/some/path/with/HEAD
  Dec 19 10:48:37.121: INFO: http.Client request:HEAD | StatusCode:200
  Dec 19 10:48:37.122: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5743/services/test-service/proxy/some/path/with/OPTIONS
  Dec 19 10:48:37.134: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Dec 19 10:48:37.134: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5743/services/test-service/proxy/some/path/with/PATCH
  Dec 19 10:48:37.143: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Dec 19 10:48:37.143: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5743/services/test-service/proxy/some/path/with/POST
  Dec 19 10:48:37.152: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Dec 19 10:48:37.152: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5743/services/test-service/proxy/some/path/with/PUT
  Dec 19 10:48:37.160: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Dec 19 10:48:37.160: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-5743" for this suite. @ 12/19/23 10:48:37.168
• [2.276 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance]
test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 12/19/23 10:48:37.189
  Dec 19 10:48:37.189: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename deployment @ 12/19/23 10:48:37.191
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:48:37.226
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:48:37.231
  Dec 19 10:48:37.236: INFO: Creating deployment "webserver-deployment"
  Dec 19 10:48:37.245: INFO: Waiting for observed generation 1
  E1219 10:48:38.042011      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:39.042232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:39.260: INFO: Waiting for all required pods to come up
  Dec 19 10:48:39.272: INFO: Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 12/19/23 10:48:39.273
  E1219 10:48:40.042333      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:41.043304      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:41.298: INFO: Waiting for deployment "webserver-deployment" to complete
  Dec 19 10:48:41.312: INFO: Updating deployment "webserver-deployment" with a non-existent image
  Dec 19 10:48:41.328: INFO: Updating deployment webserver-deployment
  Dec 19 10:48:41.328: INFO: Waiting for observed generation 2
  E1219 10:48:42.044215      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:43.044691      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:48:43.342: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  Dec 19 10:48:43.348: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
  Dec 19 10:48:43.355: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Dec 19 10:48:43.380: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  Dec 19 10:48:43.380: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
  Dec 19 10:48:43.396: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Dec 19 10:48:43.409: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  Dec 19 10:48:43.409: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
  Dec 19 10:48:43.427: INFO: Updating deployment webserver-deployment
  Dec 19 10:48:43.428: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  Dec 19 10:48:43.448: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
  Dec 19 10:48:43.457: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
  Dec 19 10:48:43.515: INFO: Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7011",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "933e97ec-97dc-439d-9c1e-558aba5d4e6c",
      ResourceVersion: (string) (len=5) "11445",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579717,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 3,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=59) "ReplicaSet \"webserver-deployment-9b4f5bf69\" is progressing."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec 19 10:48:43.526: INFO: New ReplicaSet "webserver-deployment-9b4f5bf69" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7011",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b993a38e-6288-4107-9bd0-3a646df02f91",
      ResourceVersion: (string) (len=5) "11441",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579721,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "933e97ec-97dc-439d-9c1e-558aba5d4e6c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 39 33 33 65 39 37  65 63 2d 39 37 64 63 2d  |\"933e97ec-97dc-|
              00000120  34 33 39 64 2d 39 63 31  65 2d 35 35 38 61 62 61  |439d-9c1e-558aba|
              00000130  35 64 34 65 36 63 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |5d4e6c\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 10:48:43.529: INFO: All old ReplicaSets of Deployment "webserver-deployment":
  Dec 19 10:48:43.529: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7011",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5aa491be-353a-45ca-bbec-c3403d08f832",
      ResourceVersion: (string) (len=5) "11439",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579717,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "933e97ec-97dc-439d-9c1e-558aba5d4e6c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 39 33 33 65 39 37  65 63 2d 39 37 64 63 2d  |\"933e97ec-97dc-|
              00000120  34 33 39 64 2d 39 63 31  65 2d 35 35 38 61 62 61  |439d-9c1e-558aba|
              00000130  35 64 34 65 36 63 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |5d4e6c\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 10:48:43.571: INFO: Pod "webserver-deployment-557759b7c7-6vwf4" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-6vwf4",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-7011",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ea3655ec-843a-43d7-a754-58a230899fc5",
      ResourceVersion: (string) (len=5) "11454",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579723,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5aa491be-353a-45ca-bbec-c3403d08f832",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 61  61 34 39 31 62 65 2d 33  |d\":\"5aa491be-3|
              00000090  35 33 61 2d 34 35 63 61  2d 62 62 65 63 2d 63 33  |53a-45ca-bbec-c3|
              000000a0  34 30 33 64 30 38 66 38  33 32 5c 22 7d 22 3a 7b  |403d08f832\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9bmwn",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9bmwn",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:48:43.576: INFO: Pod "webserver-deployment-557759b7c7-9nvw6" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-9nvw6",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-7011",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7542173b-d572-4d65-a344-830c2d981c3e",
      ResourceVersion: (string) (len=5) "11332",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579717,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5aa491be-353a-45ca-bbec-c3403d08f832",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 61  61 34 39 31 62 65 2d 33  |d\":\"5aa491be-3|
              00000090  35 33 61 2d 34 35 63 61  2d 62 62 65 63 2d 63 33  |53a-45ca-bbec-c3|
              000000a0  34 30 33 64 30 38 66 38  33 32 5c 22 7d 22 3a 7b  |403d08f832\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579719,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=519) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  36 2e 38 33 5c 22 7d 22  |10.233.66.83\"}"|
              000001e0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              000001f0  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000200  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jmqdh",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jmqdh",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579719,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579719,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.172",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=12) "10.233.66.83",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.66.83"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579717,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838579718,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://34417ce157a6a82ff137486bdfc5a227f9f573266bdf1a16af328a72db20c305",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:48:43.586: INFO: Pod "webserver-deployment-557759b7c7-dg4pk" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-dg4pk",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-7011",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8d6b2f03-7fd1-47b8-b7bd-90fcbd991217",
      ResourceVersion: (string) (len=5) "11453",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579723,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5aa491be-353a-45ca-bbec-c3403d08f832",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 61  61 34 39 31 62 65 2d 33  |d\":\"5aa491be-3|
              00000090  35 33 61 2d 34 35 63 61  2d 62 62 65 63 2d 63 33  |53a-45ca-bbec-c3|
              000000a0  34 30 33 64 30 38 66 38  33 32 5c 22 7d 22 3a 7b  |403d08f832\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-j7bwg",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-j7bwg",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:48:43.595: INFO: Pod "webserver-deployment-557759b7c7-g58t4" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-g58t4",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-7011",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "cf8561ef-89cf-4c05-97a1-7c822774011f",
      ResourceVersion: (string) (len=5) "11455",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579723,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5aa491be-353a-45ca-bbec-c3403d08f832",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 61  61 34 39 31 62 65 2d 33  |d\":\"5aa491be-3|
              00000090  35 33 61 2d 34 35 63 61  2d 62 62 65 63 2d 63 33  |53a-45ca-bbec-c3|
              000000a0  34 30 33 64 30 38 66 38  33 32 5c 22 7d 22 3a 7b  |403d08f832\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dzvlm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dzvlm",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:48:43.601: INFO: Pod "webserver-deployment-557759b7c7-gxrjm" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-gxrjm",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-7011",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "77e24f3a-1c9a-4f99-9cfc-1f243123480c",
      ResourceVersion: (string) (len=5) "11308",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579717,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5aa491be-353a-45ca-bbec-c3403d08f832",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 61  61 34 39 31 62 65 2d 33  |d\":\"5aa491be-3|
              00000090  35 33 61 2d 34 35 63 61  2d 62 62 65 63 2d 63 33  |53a-45ca-bbec-c3|
              000000a0  34 30 33 64 30 38 66 38  33 32 5c 22 7d 22 3a 7b  |403d08f832\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579718,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=519) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  34 2e 32 33 5c 22 7d 22  |10.233.64.23\"}"|
              000001e0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              000001f0  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000200  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mzndm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mzndm",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579718,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579718,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.83",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=12) "10.233.64.23",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.64.23"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579717,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838579718,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://de6e6975e2adfeeacffc6bcadccbc34d257c3546b9104a24b24fb95ebd4eac6b",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:48:43.626: INFO: Pod "webserver-deployment-557759b7c7-hqkrb" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-hqkrb",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-7011",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "953d7d7f-2608-421f-a17d-f179f2000e2a",
      ResourceVersion: (string) (len=5) "11321",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579717,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5aa491be-353a-45ca-bbec-c3403d08f832",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 61  61 34 39 31 62 65 2d 33  |d\":\"5aa491be-3|
              00000090  35 33 61 2d 34 35 63 61  2d 62 62 65 63 2d 63 33  |53a-45ca-bbec-c3|
              000000a0  34 30 33 64 30 38 66 38  33 32 5c 22 7d 22 3a 7b  |403d08f832\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579719,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=519) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  35 2e 31 38 5c 22 7d 22  |10.233.65.18\"}"|
              000001e0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              000001f0  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000200  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-tbqlw",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-tbqlw",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579719,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579719,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.17",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=12) "10.233.65.18",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.65.18"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579717,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838579718,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://fea587a9da2df678c8372cc6f03162273a812b8dc817c799ecb605185db6f2c7",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:48:43.669: INFO: Pod "webserver-deployment-557759b7c7-jpt7d" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-jpt7d",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-7011",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "89e82080-c3c2-46b7-96f6-969b94316a13",
      ResourceVersion: (string) (len=5) "11327",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579717,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5aa491be-353a-45ca-bbec-c3403d08f832",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 61  61 34 39 31 62 65 2d 33  |d\":\"5aa491be-3|
              00000090  35 33 61 2d 34 35 63 61  2d 62 62 65 63 2d 63 33  |53a-45ca-bbec-c3|
              000000a0  34 30 33 64 30 38 66 38  33 32 5c 22 7d 22 3a 7b  |403d08f832\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579719,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=519) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  36 2e 38 32 5c 22 7d 22  |10.233.66.82\"}"|
              000001e0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              000001f0  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000200  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-gl4vg",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-gl4vg",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579719,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579719,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.172",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=12) "10.233.66.82",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.66.82"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579717,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838579718,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://27077b3db5ba6fcf505b91e2cef1c0bcd1dc0a9ef881a8ed944246498cbb3b69",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:48:43.696: INFO: Pod "webserver-deployment-557759b7c7-qdtpl" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-qdtpl",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-7011",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4e46f666-282f-46c9-824d-4c9d99cbcc13",
      ResourceVersion: (string) (len=5) "11317",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579717,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5aa491be-353a-45ca-bbec-c3403d08f832",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 61  61 34 39 31 62 65 2d 33  |d\":\"5aa491be-3|
              00000090  35 33 61 2d 34 35 63 61  2d 62 62 65 63 2d 63 33  |53a-45ca-bbec-c3|
              000000a0  34 30 33 64 30 38 66 38  33 32 5c 22 7d 22 3a 7b  |403d08f832\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579719,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=519) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  35 2e 32 30 5c 22 7d 22  |10.233.65.20\"}"|
              000001e0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              000001f0  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000200  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-clrdq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-clrdq",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579719,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579719,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.17",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=12) "10.233.65.20",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.65.20"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579717,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838579718,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://ccb983f562d67072f84a6d8ddcb5e4fafe53044a6966517816089a4475cb2cb7",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:48:43.744: INFO: Pod "webserver-deployment-557759b7c7-vkqsm" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-vkqsm",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-7011",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "496f0c46-91b3-4cac-bbe9-85c3bf5c64c7",
      ResourceVersion: (string) (len=5) "11305",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579717,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5aa491be-353a-45ca-bbec-c3403d08f832",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 61  61 34 39 31 62 65 2d 33  |d\":\"5aa491be-3|
              00000090  35 33 61 2d 34 35 63 61  2d 62 62 65 63 2d 63 33  |53a-45ca-bbec-c3|
              000000a0  34 30 33 64 30 38 66 38  33 32 5c 22 7d 22 3a 7b  |403d08f832\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579718,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=519) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  34 2e 32 35 5c 22 7d 22  |10.233.64.25\"}"|
              000001e0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              000001f0  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000200  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4w5xb",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4w5xb",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579718,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579718,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.83",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=12) "10.233.64.25",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.64.25"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579717,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838579718,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://a3387eec598ea5cbc7c538a874e9e96eab6c95b8455bcfc7364202e1e86220ef",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:48:43.748: INFO: Pod "webserver-deployment-557759b7c7-vt4gb" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-vt4gb",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-7011",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8e1ad380-e97e-4314-9966-50385726fe9a",
      ResourceVersion: (string) (len=5) "11451",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579723,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5aa491be-353a-45ca-bbec-c3403d08f832",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 61  61 34 39 31 62 65 2d 33  |d\":\"5aa491be-3|
              00000090  35 33 61 2d 34 35 63 61  2d 62 62 65 63 2d 63 33  |53a-45ca-bbec-c3|
              000000a0  34 30 33 64 30 38 66 38  33 32 5c 22 7d 22 3a 7b  |403d08f832\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=482) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000001e0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-v2kt9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-v2kt9",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.172",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579723,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:48:43.765: INFO: Pod "webserver-deployment-557759b7c7-xlqk9" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-xlqk9",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-7011",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b1e9c4b9-c6c2-44a4-85db-afb5b9f6ed30",
      ResourceVersion: (string) (len=5) "11312",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579717,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5aa491be-353a-45ca-bbec-c3403d08f832",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 61  61 34 39 31 62 65 2d 33  |d\":\"5aa491be-3|
              00000090  35 33 61 2d 34 35 63 61  2d 62 62 65 63 2d 63 33  |53a-45ca-bbec-c3|
              000000a0  34 30 33 64 30 38 66 38  33 32 5c 22 7d 22 3a 7b  |403d08f832\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579718,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=519) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  34 2e 32 34 5c 22 7d 22  |10.233.64.24\"}"|
              000001e0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              000001f0  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000200  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xvl5h",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xvl5h",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579718,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579718,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.83",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=12) "10.233.64.24",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.64.24"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579717,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838579718,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://1a8aaff448afb469d00c6ebd37c90393bc980cc07387c1f0f081cc21b35fae2a",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:48:43.775: INFO: Pod "webserver-deployment-557759b7c7-z7fwt" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-z7fwt",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-7011",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c1b27033-90b0-4e6c-84b0-7a6a3b83dc6c",
      ResourceVersion: (string) (len=5) "11315",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579717,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "5aa491be-353a-45ca-bbec-c3403d08f832",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 61  61 34 39 31 62 65 2d 33  |d\":\"5aa491be-3|
              00000090  35 33 61 2d 34 35 63 61  2d 62 62 65 63 2d 63 33  |53a-45ca-bbec-c3|
              000000a0  34 30 33 64 30 38 66 38  33 32 5c 22 7d 22 3a 7b  |403d08f832\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579719,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=519) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  35 2e 31 39 5c 22 7d 22  |10.233.65.19\"}"|
              000001e0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              000001f0  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000200  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-cmdld",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-cmdld",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579719,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579719,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579717,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.17",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=12) "10.233.65.19",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.65.19"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579717,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838579718,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://ab6c6e4ece46071493704fb3596e023806ba2d75d2b9bc9aebb2d531e582aa74",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:48:43.779: INFO: Pod "webserver-deployment-9b4f5bf69-g2th7" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-g2th7",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-7011",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "56942809-36ff-4aba-8ae0-98dd96fa8ddf",
      ResourceVersion: (string) (len=5) "11378",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579721,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "b993a38e-6288-4107-9bd0-3a646df02f91",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 39  39 33 61 33 38 65 2d 36  |d\":\"b993a38e-6|
              00000090  32 38 38 2d 34 31 30 37  2d 39 62 64 30 2d 33 61  |288-4107-9bd0-3a|
              000000a0  36 34 36 64 66 30 32 66  39 31 5c 22 7d 22 3a 7b  |646df02f91\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=482) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000001e0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6fhh9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6fhh9",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.172",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579721,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:48:43.789: INFO: Pod "webserver-deployment-9b4f5bf69-ksmgt" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-ksmgt",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-7011",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1a2e06ba-b820-4f89-bbef-763f074cf535",
      ResourceVersion: (string) (len=5) "11387",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579721,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "b993a38e-6288-4107-9bd0-3a646df02f91",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 39  39 33 61 33 38 65 2d 36  |d\":\"b993a38e-6|
              00000090  32 38 38 2d 34 31 30 37  2d 39 62 64 30 2d 33 61  |288-4107-9bd0-3a|
              000000a0  36 34 36 64 66 30 32 66  39 31 5c 22 7d 22 3a 7b  |646df02f91\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=482) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000001e0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bsqvr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bsqvr",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.83",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579721,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:48:43.804: INFO: Pod "webserver-deployment-9b4f5bf69-lfjxx" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-lfjxx",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-7011",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b1a052d3-494f-48a2-9cbb-dc5cef9c9f47",
      ResourceVersion: (string) (len=5) "11419",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579721,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "b993a38e-6288-4107-9bd0-3a646df02f91",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 39  39 33 61 33 38 65 2d 36  |d\":\"b993a38e-6|
              00000090  32 38 38 2d 34 31 30 37  2d 39 62 64 30 2d 33 61  |288-4107-9bd0-3a|
              000000a0  36 34 36 64 66 30 32 66  39 31 5c 22 7d 22 3a 7b  |646df02f91\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=482) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000001e0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-qst6x",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-qst6x",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.17",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579721,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:48:43.812: INFO: Pod "webserver-deployment-9b4f5bf69-ppjhq" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-ppjhq",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-7011",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "450500d8-3fbd-491a-8d78-efae7db06ce2",
      ResourceVersion: (string) (len=5) "11413",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579721,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "b993a38e-6288-4107-9bd0-3a646df02f91",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 39  39 33 61 33 38 65 2d 36  |d\":\"b993a38e-6|
              00000090  32 38 38 2d 34 31 30 37  2d 39 62 64 30 2d 33 61  |288-4107-9bd0-3a|
              000000a0  36 34 36 64 66 30 32 66  39 31 5c 22 7d 22 3a 7b  |646df02f91\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=482) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000001e0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-sbl9b",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-sbl9b",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.172",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579721,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:48:43.820: INFO: Pod "webserver-deployment-9b4f5bf69-ttnk9" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-ttnk9",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-7011",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6eee57df-d72d-456f-9dbd-9f1bda68d0f8",
      ResourceVersion: (string) (len=5) "11452",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579723,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "b993a38e-6288-4107-9bd0-3a646df02f91",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 39  39 33 61 33 38 65 2d 36  |d\":\"b993a38e-6|
              00000090  32 38 38 2d 34 31 30 37  2d 39 62 64 30 2d 33 61  |288-4107-9bd0-3a|
              000000a0  36 34 36 64 66 30 32 66  39 31 5c 22 7d 22 3a 7b  |646df02f91\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-knbds",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-knbds",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:48:43.831: INFO: Pod "webserver-deployment-9b4f5bf69-xpxlb" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-xpxlb",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-7011",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "59191d2e-a34b-4083-9177-a6281dc0fdec",
      ResourceVersion: (string) (len=5) "11391",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579721,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "b993a38e-6288-4107-9bd0-3a646df02f91",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 39  39 33 61 33 38 65 2d 36  |d\":\"b993a38e-6|
              00000090  32 38 38 2d 34 31 30 37  2d 39 62 64 30 2d 33 61  |288-4107-9bd0-3a|
              000000a0  36 34 36 64 66 30 32 66  39 31 5c 22 7d 22 3a 7b  |646df02f91\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=482) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000001e0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6wltx",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6wltx",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838579721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.17",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838579721,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:48:43.835: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7011" for this suite. @ 12/19/23 10:48:43.852
• [6.727 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]
test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 12/19/23 10:48:43.919
  Dec 19 10:48:43.919: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename conformance-tests @ 12/19/23 10:48:43.923
  E1219 10:48:44.045149      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:48:44.144
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:48:44.151
  STEP: Getting node addresses @ 12/19/23 10:48:44.157
  Dec 19 10:48:44.157: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  Dec 19 10:48:44.176: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-8977" for this suite. @ 12/19/23 10:48:44.194
• [0.299 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:124
  STEP: Creating a kubernetes client @ 12/19/23 10:48:44.223
  Dec 19 10:48:44.223: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename pod-network-test @ 12/19/23 10:48:44.232
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:48:44.491
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:48:44.497
  STEP: Performing setup for networking test in namespace pod-network-test-5729 @ 12/19/23 10:48:44.502
  STEP: creating a selector @ 12/19/23 10:48:44.503
  STEP: Creating the service pods in kubernetes @ 12/19/23 10:48:44.503
  Dec 19 10:48:44.503: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E1219 10:48:45.046217      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:46.046368      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:47.049134      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:48.048869      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:49.050475      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:50.054252      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:51.054975      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:52.055456      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:53.056095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:54.056910      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:55.057688      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:56.059593      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:57.059355      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:58.059844      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:48:59.059952      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:00.060263      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:01.061214      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:02.061348      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:03.061591      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:04.061802      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:05.062718      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:06.063483      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 12/19/23 10:49:07.006
  E1219 10:49:07.064505      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:08.065143      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:09.066098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:09.097: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Dec 19 10:49:09.097: INFO: Going to poll 10.233.64.30 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Dec 19 10:49:09.111: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.64.30 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5729 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:49:09.111: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:49:09.124: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:49:09.125: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-5729/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.64.30+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E1219 10:49:10.066571      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:10.301: INFO: Found all 1 expected endpoints: [netserver-0]
  Dec 19 10:49:10.301: INFO: Going to poll 10.233.65.25 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Dec 19 10:49:10.311: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.65.25 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5729 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:49:10.311: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:49:10.313: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:49:10.313: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-5729/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.65.25+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E1219 10:49:11.067362      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:11.426: INFO: Found all 1 expected endpoints: [netserver-1]
  Dec 19 10:49:11.426: INFO: Going to poll 10.233.66.89 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Dec 19 10:49:11.432: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.66.89 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5729 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:49:11.432: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:49:11.435: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:49:11.435: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-5729/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.66.89+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E1219 10:49:12.067587      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:12.564: INFO: Found all 1 expected endpoints: [netserver-2]
  Dec 19 10:49:12.566: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-5729" for this suite. @ 12/19/23 10:49:12.58
• [28.372 seconds]
------------------------------
SS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]
test/e2e/apps/statefulset.go:901
  STEP: Creating a kubernetes client @ 12/19/23 10:49:12.595
  Dec 19 10:49:12.595: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename statefulset @ 12/19/23 10:49:12.599
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:49:12.667
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:49:12.675
  STEP: Creating service test in namespace statefulset-7299 @ 12/19/23 10:49:12.686
  STEP: Creating statefulset ss in namespace statefulset-7299 @ 12/19/23 10:49:12.698
  Dec 19 10:49:12.726: INFO: Found 0 stateful pods, waiting for 1
  E1219 10:49:13.068449      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:14.068894      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:15.068913      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:16.069571      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:17.070337      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:18.071302      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:19.072435      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:20.072775      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:21.073128      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:22.073525      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:22.791: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 12/19/23 10:49:22.811
  STEP: updating a scale subresource @ 12/19/23 10:49:22.825
  STEP: verifying the statefulset Spec.Replicas was modified @ 12/19/23 10:49:22.84
  STEP: Patch a scale subresource @ 12/19/23 10:49:22.847
  STEP: verifying the statefulset Spec.Replicas was modified @ 12/19/23 10:49:22.862
  Dec 19 10:49:22.872: INFO: Deleting all statefulset in ns statefulset-7299
  Dec 19 10:49:22.881: INFO: Scaling statefulset ss to 0
  E1219 10:49:23.074500      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:24.076652      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:25.075801      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:26.079301      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:27.076681      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:28.076840      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:29.078493      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:30.078666      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:31.078837      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:32.079223      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:32.933: INFO: Waiting for statefulset status.replicas updated to 0
  Dec 19 10:49:32.942: INFO: Deleting statefulset ss
  Dec 19 10:49:32.968: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7299" for this suite. @ 12/19/23 10:49:32.984
• [20.401 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance]
test/e2e/common/node/lease.go:72
  STEP: Creating a kubernetes client @ 12/19/23 10:49:32.997
  Dec 19 10:49:32.997: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename lease-test @ 12/19/23 10:49:33.004
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:49:33.034
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:49:33.039
  E1219 10:49:33.079245      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:33.168: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-6063" for this suite. @ 12/19/23 10:49:33.18
• [0.195 seconds]
------------------------------
SS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]
test/e2e/apps/statefulset.go:961
  STEP: Creating a kubernetes client @ 12/19/23 10:49:33.195
  Dec 19 10:49:33.195: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename statefulset @ 12/19/23 10:49:33.199
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:49:33.238
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:49:33.246
  STEP: Creating service test in namespace statefulset-4611 @ 12/19/23 10:49:33.252
  Dec 19 10:49:33.290: INFO: Found 0 stateful pods, waiting for 1
  E1219 10:49:34.080185      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:35.079965      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:36.081182      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:37.080781      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:38.081033      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:39.081264      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:40.081754      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:41.082918      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:42.083889      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:43.084254      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:43.301: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 12/19/23 10:49:43.32
  W1219 10:49:43.349067      14 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  Dec 19 10:49:43.370: INFO: Found 1 stateful pods, waiting for 2
  E1219 10:49:44.084870      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:45.085334      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:46.085205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:47.085698      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:48.085869      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:49.086242      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:50.086501      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:51.087518      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:52.088357      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:53.088065      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:49:53.383: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 10:49:53.384: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 12/19/23 10:49:53.402
  STEP: Delete all of the StatefulSets @ 12/19/23 10:49:53.411
  STEP: Verify that StatefulSets have been deleted @ 12/19/23 10:49:53.433
  Dec 19 10:49:53.444: INFO: Deleting all statefulset in ns statefulset-4611
  Dec 19 10:49:53.486: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4611" for this suite. @ 12/19/23 10:49:53.51
• [20.418 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:107
  STEP: Creating a kubernetes client @ 12/19/23 10:49:53.613
  Dec 19 10:49:53.613: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 10:49:53.621
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:49:53.683
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:49:53.689
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 12/19/23 10:49:53.695
  E1219 10:49:54.089152      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:55.089734      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:56.089869      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:57.090320      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:49:57.733
  Dec 19 10:49:57.741: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-27f96bba-34b7-42a5-bb4d-5fd1882992c6 container test-container: <nil>
  STEP: delete the pod @ 12/19/23 10:49:57.776
  Dec 19 10:49:57.804: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7059" for this suite. @ 12/19/23 10:49:57.814
• [4.215 seconds]
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance]
test/e2e/apps/job.go:642
  STEP: Creating a kubernetes client @ 12/19/23 10:49:57.829
  Dec 19 10:49:57.830: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename job @ 12/19/23 10:49:57.834
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:49:57.865
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:49:57.875
  STEP: Creating a job @ 12/19/23 10:49:57.881
  STEP: Ensure pods equal to parallelism count is attached to the job @ 12/19/23 10:49:57.892
  E1219 10:49:58.091147      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:49:59.091189      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 12/19/23 10:49:59.901
  STEP: updating /status @ 12/19/23 10:49:59.914
  STEP: get /status @ 12/19/23 10:49:59.931
  Dec 19 10:49:59.938: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1620" for this suite. @ 12/19/23 10:49:59.948
• [2.131 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]
test/e2e/network/service.go:2202
  STEP: Creating a kubernetes client @ 12/19/23 10:49:59.962
  Dec 19 10:49:59.962: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename services @ 12/19/23 10:49:59.965
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:49:59.997
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:50:00.004
  STEP: creating service in namespace services-4449 @ 12/19/23 10:50:00.011
  STEP: creating service affinity-nodeport in namespace services-4449 @ 12/19/23 10:50:00.012
  STEP: creating replication controller affinity-nodeport in namespace services-4449 @ 12/19/23 10:50:00.048
  I1219 10:50:00.072292      14 runners.go:197] Created replication controller with name: affinity-nodeport, namespace: services-4449, replica count: 3
  E1219 10:50:00.092522      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:01.092503      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:02.093011      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:03.092969      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 10:50:03.124334      14 runners.go:197] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec 19 10:50:03.157: INFO: Creating new exec pod
  E1219 10:50:04.098520      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:05.094827      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:06.099959      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:50:06.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-4449 exec execpod-affinityfs8kh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  Dec 19 10:50:06.572: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  Dec 19 10:50:06.572: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 10:50:06.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-4449 exec execpod-affinityfs8kh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.45.180 80'
  Dec 19 10:50:06.909: INFO: stderr: "+ + nc -v -techo -w 2 10.233.45.180 hostName 80\n\nConnection to 10.233.45.180 80 port [tcp/http] succeeded!\n"
  Dec 19 10:50:06.910: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 10:50:06.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-4449 exec execpod-affinityfs8kh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.83 30151'
  E1219 10:50:07.109488      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:50:07.210: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.83 30151\nConnection to 192.168.121.83 30151 port [tcp/*] succeeded!\n"
  Dec 19 10:50:07.210: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 10:50:07.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-4449 exec execpod-affinityfs8kh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.17 30151'
  Dec 19 10:50:07.515: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.17 30151\nConnection to 192.168.121.17 30151 port [tcp/*] succeeded!\n"
  Dec 19 10:50:07.515: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 10:50:07.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-4449 exec execpod-affinityfs8kh -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.83:30151/ ; done'
  Dec 19 10:50:08.053: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:30151/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:30151/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:30151/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:30151/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:30151/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:30151/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:30151/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:30151/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:30151/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:30151/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:30151/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:30151/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:30151/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:30151/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:30151/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:30151/\n"
  Dec 19 10:50:08.054: INFO: stdout: "\naffinity-nodeport-2gbsj\naffinity-nodeport-2gbsj\naffinity-nodeport-2gbsj\naffinity-nodeport-2gbsj\naffinity-nodeport-2gbsj\naffinity-nodeport-2gbsj\naffinity-nodeport-2gbsj\naffinity-nodeport-2gbsj\naffinity-nodeport-2gbsj\naffinity-nodeport-2gbsj\naffinity-nodeport-2gbsj\naffinity-nodeport-2gbsj\naffinity-nodeport-2gbsj\naffinity-nodeport-2gbsj\naffinity-nodeport-2gbsj\naffinity-nodeport-2gbsj"
  Dec 19 10:50:08.054: INFO: Received response from host: affinity-nodeport-2gbsj
  Dec 19 10:50:08.054: INFO: Received response from host: affinity-nodeport-2gbsj
  Dec 19 10:50:08.054: INFO: Received response from host: affinity-nodeport-2gbsj
  Dec 19 10:50:08.054: INFO: Received response from host: affinity-nodeport-2gbsj
  Dec 19 10:50:08.054: INFO: Received response from host: affinity-nodeport-2gbsj
  Dec 19 10:50:08.054: INFO: Received response from host: affinity-nodeport-2gbsj
  Dec 19 10:50:08.054: INFO: Received response from host: affinity-nodeport-2gbsj
  Dec 19 10:50:08.054: INFO: Received response from host: affinity-nodeport-2gbsj
  Dec 19 10:50:08.054: INFO: Received response from host: affinity-nodeport-2gbsj
  Dec 19 10:50:08.054: INFO: Received response from host: affinity-nodeport-2gbsj
  Dec 19 10:50:08.054: INFO: Received response from host: affinity-nodeport-2gbsj
  Dec 19 10:50:08.054: INFO: Received response from host: affinity-nodeport-2gbsj
  Dec 19 10:50:08.054: INFO: Received response from host: affinity-nodeport-2gbsj
  Dec 19 10:50:08.054: INFO: Received response from host: affinity-nodeport-2gbsj
  Dec 19 10:50:08.054: INFO: Received response from host: affinity-nodeport-2gbsj
  Dec 19 10:50:08.055: INFO: Received response from host: affinity-nodeport-2gbsj
  Dec 19 10:50:08.057: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec 19 10:50:08.070: INFO: Cleaning up the exec pod
  E1219 10:50:08.097823      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController affinity-nodeport in namespace services-4449, will wait for the garbage collector to delete the pods @ 12/19/23 10:50:08.106
  Dec 19 10:50:08.188: INFO: Deleting ReplicationController affinity-nodeport took: 16.81465ms
  Dec 19 10:50:08.288: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.592672ms
  E1219 10:50:09.098452      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:10.100440      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:11.101140      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-4449" for this suite. @ 12/19/23 10:50:11.663
• [11.714 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 12/19/23 10:50:11.686
  Dec 19 10:50:11.686: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 10:50:11.69
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:50:11.721
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:50:11.726
  STEP: Creating projection with secret that has name projected-secret-test-cf651e16-a7a2-4d8d-abe2-22bdb1943a6d @ 12/19/23 10:50:11.731
  STEP: Creating a pod to test consume secrets @ 12/19/23 10:50:11.74
  E1219 10:50:12.102526      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:13.102910      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:14.103653      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:15.104469      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:50:15.79
  Dec 19 10:50:15.797: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-projected-secrets-cadad8e0-69b7-4007-8df8-500adf553c0e container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 10:50:15.809
  Dec 19 10:50:15.843: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9011" for this suite. @ 12/19/23 10:50:15.854
• [4.183 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs  [Conformance]
test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 12/19/23 10:50:15.87
  Dec 19 10:50:15.870: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubectl-logs @ 12/19/23 10:50:15.872
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:50:15.906
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:50:15.914
  STEP: creating an pod @ 12/19/23 10:50:15.922
  Dec 19 10:50:15.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-logs-6586 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.45 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  E1219 10:50:16.105010      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:50:16.172: INFO: stderr: ""
  Dec 19 10:50:16.172: INFO: stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 12/19/23 10:50:16.173
  Dec 19 10:50:16.174: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E1219 10:50:17.105309      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:18.105533      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:50:18.197: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 12/19/23 10:50:18.197
  Dec 19 10:50:18.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-logs-6586 logs logs-generator logs-generator'
  Dec 19 10:50:18.412: INFO: stderr: ""
  Dec 19 10:50:18.412: INFO: stdout: "I1219 10:50:16.985507       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/f9v 582\nI1219 10:50:17.185801       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/wm9 532\nI1219 10:50:17.385176       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/p77f 319\nI1219 10:50:17.584520       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/h8dj 308\nI1219 10:50:17.784777       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/qhk 284\nI1219 10:50:17.985219       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/bkt 534\nI1219 10:50:18.184464       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/w52 328\nI1219 10:50:18.385993       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/2zww 537\n"
  STEP: limiting log lines @ 12/19/23 10:50:18.412
  Dec 19 10:50:18.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-logs-6586 logs logs-generator logs-generator --tail=1'
  Dec 19 10:50:18.597: INFO: stderr: ""
  Dec 19 10:50:18.598: INFO: stdout: "I1219 10:50:18.584370       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/j75k 314\n"
  Dec 19 10:50:18.599: INFO: got output "I1219 10:50:18.584370       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/j75k 314\n"
  STEP: limiting log bytes @ 12/19/23 10:50:18.599
  Dec 19 10:50:18.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-logs-6586 logs logs-generator logs-generator --limit-bytes=1'
  Dec 19 10:50:18.806: INFO: stderr: ""
  Dec 19 10:50:18.806: INFO: stdout: "I"
  Dec 19 10:50:18.806: INFO: got output "I"
  STEP: exposing timestamps @ 12/19/23 10:50:18.806
  Dec 19 10:50:18.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-logs-6586 logs logs-generator logs-generator --tail=1 --timestamps'
  Dec 19 10:50:19.001: INFO: stderr: ""
  Dec 19 10:50:19.001: INFO: stdout: "2023-12-19T10:50:18.985161615Z I1219 10:50:18.985064       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/44dv 215\n"
  Dec 19 10:50:19.001: INFO: got output "2023-12-19T10:50:18.985161615Z I1219 10:50:18.985064       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/44dv 215\n"
  STEP: restricting to a time range @ 12/19/23 10:50:19.001
  E1219 10:50:19.105993      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:20.106336      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:21.106887      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:50:21.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-logs-6586 logs logs-generator logs-generator --since=1s'
  Dec 19 10:50:21.659: INFO: stderr: ""
  Dec 19 10:50:21.659: INFO: stdout: "I1219 10:50:20.784760       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/88f 213\nI1219 10:50:20.986006       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/74v 579\nI1219 10:50:21.185316       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/6dm 352\nI1219 10:50:21.384696       1 logs_generator.go:76] 22 POST /api/v1/namespaces/default/pods/nkn 430\nI1219 10:50:21.585016       1 logs_generator.go:76] 23 GET /api/v1/namespaces/kube-system/pods/zrnl 546\n"
  Dec 19 10:50:21.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-logs-6586 logs logs-generator logs-generator --since=24h'
  Dec 19 10:50:21.830: INFO: stderr: ""
  Dec 19 10:50:21.830: INFO: stdout: "I1219 10:50:16.985507       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/f9v 582\nI1219 10:50:17.185801       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/wm9 532\nI1219 10:50:17.385176       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/p77f 319\nI1219 10:50:17.584520       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/h8dj 308\nI1219 10:50:17.784777       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/qhk 284\nI1219 10:50:17.985219       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/bkt 534\nI1219 10:50:18.184464       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/w52 328\nI1219 10:50:18.385993       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/2zww 537\nI1219 10:50:18.584370       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/j75k 314\nI1219 10:50:18.785549       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/default/pods/b8d 593\nI1219 10:50:18.985064       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/44dv 215\nI1219 10:50:19.184429       1 logs_generator.go:76] 11 POST /api/v1/namespaces/kube-system/pods/2w7 495\nI1219 10:50:19.384831       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/p56 515\nI1219 10:50:19.585181       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/6x94 494\nI1219 10:50:19.784414       1 logs_generator.go:76] 14 POST /api/v1/namespaces/ns/pods/2s7 324\nI1219 10:50:19.984869       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/nwsj 345\nI1219 10:50:20.184277       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/4lk2 359\nI1219 10:50:20.384984       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/ns/pods/v6bp 458\nI1219 10:50:20.584358       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/default/pods/j4ks 297\nI1219 10:50:20.784760       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/88f 213\nI1219 10:50:20.986006       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/74v 579\nI1219 10:50:21.185316       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/6dm 352\nI1219 10:50:21.384696       1 logs_generator.go:76] 22 POST /api/v1/namespaces/default/pods/nkn 430\nI1219 10:50:21.585016       1 logs_generator.go:76] 23 GET /api/v1/namespaces/kube-system/pods/zrnl 546\nI1219 10:50:21.784874       1 logs_generator.go:76] 24 GET /api/v1/namespaces/ns/pods/hm7m 384\n"
  Dec 19 10:50:21.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-logs-6586 delete pod logs-generator'
  E1219 10:50:22.107028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:50:22.410: INFO: stderr: ""
  Dec 19 10:50:22.410: INFO: stdout: "pod \"logs-generator\" deleted\n"
  Dec 19 10:50:22.411: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-6586" for this suite. @ 12/19/23 10:50:22.422
• [6.565 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]
test/e2e/kubectl/kubectl.go:1481
  STEP: Creating a kubernetes client @ 12/19/23 10:50:22.436
  Dec 19 10:50:22.436: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 10:50:22.441
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:50:22.483
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:50:22.489
  STEP: creating Agnhost RC @ 12/19/23 10:50:22.509
  Dec 19 10:50:22.510: INFO: namespace kubectl-1487
  Dec 19 10:50:22.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-1487 create -f -'
  Dec 19 10:50:23.061: INFO: stderr: ""
  Dec 19 10:50:23.061: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 12/19/23 10:50:23.061
  E1219 10:50:23.107782      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:50:24.071: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec 19 10:50:24.072: INFO: Found 0 / 1
  E1219 10:50:24.108092      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:50:25.071: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec 19 10:50:25.071: INFO: Found 1 / 1
  Dec 19 10:50:25.071: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Dec 19 10:50:25.081: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec 19 10:50:25.081: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Dec 19 10:50:25.081: INFO: wait on agnhost-primary startup in kubectl-1487 
  Dec 19 10:50:25.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-1487 logs agnhost-primary-rxm4f agnhost-primary'
  E1219 10:50:25.108798      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:50:25.297: INFO: stderr: ""
  Dec 19 10:50:25.297: INFO: stdout: "Paused\n"
  STEP: exposing RC @ 12/19/23 10:50:25.297
  Dec 19 10:50:25.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-1487 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  Dec 19 10:50:25.588: INFO: stderr: ""
  Dec 19 10:50:25.588: INFO: stdout: "service/rm2 exposed\n"
  Dec 19 10:50:25.601: INFO: Service rm2 in namespace kubectl-1487 found.
  E1219 10:50:26.108699      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:27.109011      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: exposing service @ 12/19/23 10:50:27.627
  Dec 19 10:50:27.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-1487 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  Dec 19 10:50:27.851: INFO: stderr: ""
  Dec 19 10:50:27.851: INFO: stdout: "service/rm3 exposed\n"
  Dec 19 10:50:27.867: INFO: Service rm3 in namespace kubectl-1487 found.
  E1219 10:50:28.109767      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:29.110931      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:50:29.888: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1487" for this suite. @ 12/19/23 10:50:29.903
• [7.482 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:347
  STEP: Creating a kubernetes client @ 12/19/23 10:50:29.922
  Dec 19 10:50:29.922: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename security-context-test @ 12/19/23 10:50:29.927
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:50:29.959
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:50:29.964
  E1219 10:50:30.111605      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:31.112562      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:32.112432      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:33.113226      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:50:34.040: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-3308" for this suite. @ 12/19/23 10:50:34.053
• [4.150 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 12/19/23 10:50:34.091
  Dec 19 10:50:34.092: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename pods @ 12/19/23 10:50:34.098
  E1219 10:50:34.113944      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:50:34.136
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:50:34.142
  Dec 19 10:50:34.148: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: creating the pod @ 12/19/23 10:50:34.15
  STEP: submitting the pod to kubernetes @ 12/19/23 10:50:34.15
  E1219 10:50:35.128893      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:36.128058      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:50:36.311: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3965" for this suite. @ 12/19/23 10:50:36.325
• [2.250 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance]
test/e2e/instrumentation/core_events.go:175
  STEP: Creating a kubernetes client @ 12/19/23 10:50:36.344
  Dec 19 10:50:36.344: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename events @ 12/19/23 10:50:36.347
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:50:36.41
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:50:36.419
  STEP: Create set of events @ 12/19/23 10:50:36.425
  Dec 19 10:50:36.434: INFO: created test-event-1
  Dec 19 10:50:36.445: INFO: created test-event-2
  Dec 19 10:50:36.453: INFO: created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 12/19/23 10:50:36.454
  STEP: delete collection of events @ 12/19/23 10:50:36.462
  Dec 19 10:50:36.463: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 12/19/23 10:50:36.565
  Dec 19 10:50:36.566: INFO: requesting list of events to confirm quantity
  Dec 19 10:50:36.576: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-76" for this suite. @ 12/19/23 10:50:36.595
• [0.286 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]
test/e2e/auth/service_accounts.go:647
  STEP: Creating a kubernetes client @ 12/19/23 10:50:36.633
  Dec 19 10:50:36.633: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename svcaccounts @ 12/19/23 10:50:36.644
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:50:36.69
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:50:36.695
  STEP: creating a ServiceAccount @ 12/19/23 10:50:36.7
  STEP: watching for the ServiceAccount to be added @ 12/19/23 10:50:36.726
  STEP: patching the ServiceAccount @ 12/19/23 10:50:36.742
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 12/19/23 10:50:36.757
  STEP: deleting the ServiceAccount @ 12/19/23 10:50:36.767
  Dec 19 10:50:36.798: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5037" for this suite. @ 12/19/23 10:50:36.817
• [0.201 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:89
  STEP: Creating a kubernetes client @ 12/19/23 10:50:36.857
  Dec 19 10:50:36.857: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename configmap @ 12/19/23 10:50:36.86
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:50:36.895
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:50:36.9
  STEP: Creating configMap with name configmap-test-volume-map-265f6992-ca25-4ea2-89a5-3e6a2980d3f3 @ 12/19/23 10:50:36.905
  STEP: Creating a pod to test consume configMaps @ 12/19/23 10:50:36.914
  E1219 10:50:37.126419      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:38.127286      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:39.128448      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:40.128970      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:50:40.951
  Dec 19 10:50:40.959: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-configmaps-e11b6f7d-c445-407c-aef8-8f9c1d570346 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 10:50:40.973
  Dec 19 10:50:40.999: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1849" for this suite. @ 12/19/23 10:50:41.011
• [4.168 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 12/19/23 10:50:41.029
  Dec 19 10:50:41.030: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename secrets @ 12/19/23 10:50:41.033
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:50:41.065
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:50:41.071
  STEP: Creating secret with name secret-test-b49bf2e7-483e-44bb-a103-eecd0e3de6dc @ 12/19/23 10:50:41.078
  STEP: Creating a pod to test consume secrets @ 12/19/23 10:50:41.095
  E1219 10:50:41.130357      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:42.129810      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:43.130507      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:44.131491      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:45.132526      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:50:45.141
  Dec 19 10:50:45.148: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-secrets-266a563c-6068-46f3-b70b-a0bd9164b3dc container secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 10:50:45.172
  Dec 19 10:50:45.208: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5462" for this suite. @ 12/19/23 10:50:45.218
• [4.205 seconds]
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance]
test/e2e/auth/service_accounts.go:808
  STEP: Creating a kubernetes client @ 12/19/23 10:50:45.238
  Dec 19 10:50:45.238: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename svcaccounts @ 12/19/23 10:50:45.242
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:50:45.281
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:50:45.289
  STEP: Creating ServiceAccount "e2e-sa-vmqpw"  @ 12/19/23 10:50:45.299
  Dec 19 10:50:45.311: INFO: AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-vmqpw"  @ 12/19/23 10:50:45.312
  Dec 19 10:50:45.331: INFO: AutomountServiceAccountToken: true
  Dec 19 10:50:45.331: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2608" for this suite. @ 12/19/23 10:50:45.341
• [0.116 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance]
test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 12/19/23 10:50:45.361
  Dec 19 10:50:45.361: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename field-validation @ 12/19/23 10:50:45.365
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:50:45.406
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:50:45.413
  STEP: apply creating a deployment @ 12/19/23 10:50:45.421
  Dec 19 10:50:45.424: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-9866" for this suite. @ 12/19/23 10:50:45.46
• [0.116 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]
test/e2e/auth/service_accounts.go:78
  STEP: Creating a kubernetes client @ 12/19/23 10:50:45.486
  Dec 19 10:50:45.486: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename svcaccounts @ 12/19/23 10:50:45.49
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:50:45.552
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:50:45.561
  E1219 10:50:46.133051      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:47.133937      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 12/19/23 10:50:47.625
  Dec 19 10:50:47.625: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6619 pod-service-account-e18f324d-d784-40cf-9843-5bdb028ab558 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 12/19/23 10:50:47.935
  Dec 19 10:50:47.935: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6619 pod-service-account-e18f324d-d784-40cf-9843-5bdb028ab558 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  E1219 10:50:48.134644      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 12/19/23 10:50:48.213
  Dec 19 10:50:48.214: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6619 pod-service-account-e18f324d-d784-40cf-9843-5bdb028ab558 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  Dec 19 10:50:48.503: INFO: Got root ca configmap in namespace "svcaccounts-6619"
  Dec 19 10:50:48.509: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-6619" for this suite. @ 12/19/23 10:50:48.518
• [3.042 seconds]
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]
test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 12/19/23 10:50:48.529
  Dec 19 10:50:48.529: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename sched-preemption @ 12/19/23 10:50:48.533
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:50:48.572
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:50:48.577
  Dec 19 10:50:48.614: INFO: Waiting up to 1m0s for all nodes to be ready
  E1219 10:50:49.134817      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:50.135686      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:51.136098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:52.136371      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:53.137631      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:54.138166      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:55.138481      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:56.139769      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:57.140518      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:58.141021      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:50:59.142473      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:00.142142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:01.142857      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:02.143144      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:03.143703      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:04.143869      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:05.144983      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:06.147207      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:07.146889      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:08.147055      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:09.147383      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:10.149326      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:11.150718      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:12.150927      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:13.151662      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:14.152609      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:15.153561      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:16.153689      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:17.153760      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:18.155001      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:19.155699      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:20.155966      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:21.156047      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:22.156237      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:23.157318      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:24.158253      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:25.159335      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:26.159480      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:27.159670      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:28.160465      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:29.160701      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:30.160901      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:31.161222      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:32.161457      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:33.161662      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:34.162366      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:35.163575      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:36.164468      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:37.165641      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:38.165679      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:39.166089      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:40.167085      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:41.167205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:42.168052      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:43.168965      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:44.170062      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:45.170557      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:46.170598      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:47.170659      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:48.171293      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:51:48.668: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 12/19/23 10:51:48.678
  Dec 19 10:51:48.742: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Dec 19 10:51:48.776: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Dec 19 10:51:48.843: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Dec 19 10:51:48.870: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  Dec 19 10:51:48.917: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Dec 19 10:51:48.949: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 12/19/23 10:51:48.95
  E1219 10:51:49.172255      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:50.172772      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:51.173800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:52.188456      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 12/19/23 10:51:53.023
  E1219 10:51:53.179507      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:54.179856      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:55.180011      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:56.182706      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:51:57.133: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1219 10:51:57.181988      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "sched-preemption-3579" for this suite. @ 12/19/23 10:51:57.241
• [68.726 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:391
  STEP: Creating a kubernetes client @ 12/19/23 10:51:57.261
  Dec 19 10:51:57.262: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/19/23 10:51:57.267
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:51:57.306
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:51:57.33
  STEP: set up a multi version CRD @ 12/19/23 10:51:57.337
  Dec 19 10:51:57.339: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 10:51:58.182158      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:51:59.183227      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:00.183500      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:01.186205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:02.188329      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: rename a version @ 12/19/23 10:52:02.3
  STEP: check the new version name is served @ 12/19/23 10:52:02.345
  E1219 10:52:03.188871      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 12/19/23 10:52:03.892
  E1219 10:52:04.189264      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 12/19/23 10:52:04.856
  E1219 10:52:05.189473      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:06.190547      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:07.191264      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:08.191802      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:52:08.399: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3759" for this suite. @ 12/19/23 10:52:08.417
• [11.168 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:194
  STEP: Creating a kubernetes client @ 12/19/23 10:52:08.431
  Dec 19 10:52:08.431: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 10:52:08.434
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:52:08.474
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:52:08.479
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 10:52:08.486
  E1219 10:52:09.194101      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:10.194729      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:11.194823      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:12.195333      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:52:12.535
  Dec 19 10:52:12.542: INFO: Trying to get logs from node hiengux9ahcu-3 pod downwardapi-volume-a1a94351-cfc0-4405-822c-18138383368f container client-container: <nil>
  STEP: delete the pod @ 12/19/23 10:52:12.584
  Dec 19 10:52:12.618: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4820" for this suite. @ 12/19/23 10:52:12.631
• [4.216 seconds]
------------------------------
S
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance]
test/e2e/apps/replica_set.go:154
  STEP: Creating a kubernetes client @ 12/19/23 10:52:12.647
  Dec 19 10:52:12.647: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename replicaset @ 12/19/23 10:52:12.65
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:52:12.688
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:52:12.694
  Dec 19 10:52:12.731: INFO: Pod name sample-pod: Found 0 pods out of 1
  E1219 10:52:13.195477      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:14.196161      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:15.196381      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:16.197012      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:17.197234      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:52:17.743: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/19/23 10:52:17.743
  STEP: Scaling up "test-rs" replicaset  @ 12/19/23 10:52:17.744
  Dec 19 10:52:17.773: INFO: Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 12/19/23 10:52:17.773
  Dec 19 10:52:17.797: INFO: observed ReplicaSet test-rs in namespace replicaset-8226 with ReadyReplicas 1, AvailableReplicas 1
  Dec 19 10:52:17.893: INFO: observed ReplicaSet test-rs in namespace replicaset-8226 with ReadyReplicas 1, AvailableReplicas 1
  Dec 19 10:52:17.939: INFO: observed ReplicaSet test-rs in namespace replicaset-8226 with ReadyReplicas 1, AvailableReplicas 1
  Dec 19 10:52:17.980: INFO: observed ReplicaSet test-rs in namespace replicaset-8226 with ReadyReplicas 1, AvailableReplicas 1
  E1219 10:52:18.197875      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:52:18.945: INFO: observed ReplicaSet test-rs in namespace replicaset-8226 with ReadyReplicas 2, AvailableReplicas 2
  Dec 19 10:52:19.061: INFO: observed Replicaset test-rs in namespace replicaset-8226 with ReadyReplicas 3 found true
  Dec 19 10:52:19.061: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-8226" for this suite. @ 12/19/23 10:52:19.072
• [6.445 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
test/e2e/apimachinery/garbage_collector.go:638
  STEP: Creating a kubernetes client @ 12/19/23 10:52:19.095
  Dec 19 10:52:19.095: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename gc @ 12/19/23 10:52:19.097
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:52:19.14
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:52:19.145
  STEP: create the rc @ 12/19/23 10:52:19.163
  W1219 10:52:19.173166      14 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E1219 10:52:19.198766      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:20.198928      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:21.199923      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:22.204171      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:23.203484      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:24.203897      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 12/19/23 10:52:25.199
  E1219 10:52:25.204635      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: wait for the rc to be deleted @ 12/19/23 10:52:25.25
  E1219 10:52:26.205173      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:52:26.335: INFO: 80 pods remaining
  Dec 19 10:52:26.335: INFO: 80 pods has nil DeletionTimestamp
  Dec 19 10:52:26.335: INFO: 
  E1219 10:52:27.205737      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:52:27.450: INFO: 72 pods remaining
  Dec 19 10:52:27.450: INFO: 67 pods has nil DeletionTimestamp
  Dec 19 10:52:27.450: INFO: 
  E1219 10:52:28.208102      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:52:28.354: INFO: 60 pods remaining
  Dec 19 10:52:28.354: INFO: 60 pods has nil DeletionTimestamp
  Dec 19 10:52:28.354: INFO: 
  E1219 10:52:29.208549      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:52:29.322: INFO: 40 pods remaining
  Dec 19 10:52:29.322: INFO: 40 pods has nil DeletionTimestamp
  Dec 19 10:52:29.322: INFO: 
  E1219 10:52:30.208715      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:52:30.291: INFO: 32 pods remaining
  Dec 19 10:52:30.291: INFO: 31 pods has nil DeletionTimestamp
  Dec 19 10:52:30.291: INFO: 
  E1219 10:52:31.209849      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:52:31.274: INFO: 19 pods remaining
  Dec 19 10:52:31.274: INFO: 18 pods has nil DeletionTimestamp
  Dec 19 10:52:31.274: INFO: 
  E1219 10:52:32.211475      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 12/19/23 10:52:32.265
  Dec 19 10:52:32.656: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec 19 10:52:32.669: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5158" for this suite. @ 12/19/23 10:52:32.682
• [13.607 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 12/19/23 10:52:32.71
  Dec 19 10:52:32.711: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename init-container @ 12/19/23 10:52:32.734
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:52:32.787
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:52:32.793
  STEP: creating the pod @ 12/19/23 10:52:32.798
  Dec 19 10:52:32.798: INFO: PodSpec: initContainers in spec.initContainers
  E1219 10:52:33.212298      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:34.213125      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:35.215310      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:36.214743      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:37.217317      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:38.216472      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:39.216634      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:40.216761      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:41.216710      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:42.216816      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:43.217186      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:44.218421      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:45.217888      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:46.218727      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:47.219450      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:48.219791      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:49.220075      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:50.220526      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:51.220906      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:52.221022      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:53.221662      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:54.221583      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:55.222102      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:56.222376      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:57.222946      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:58.223126      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:52:59.223826      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:00.224013      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:01.224310      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:02.224520      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:03.225590      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:04.225958      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:05.226231      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:06.226400      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:07.226697      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:08.227198      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:09.227926      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:10.228042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:11.228187      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:12.228585      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:13.229591      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:14.229671      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:15.230418      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:16.230835      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:17.231032      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:18.231392      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:19.231964      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:20.232410      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:21.232219      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:22.232347      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:23.232703      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:24.233009      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:53:24.781: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-89e2c518-46d6-4851-b8ea-c67765930c17", GenerateName:"", Namespace:"init-container-2438", SelfLink:"", UID:"3e1e3207-c9c0-4261-8762-001b8cb8ab9e", ResourceVersion:"14519", Generation:0, CreationTimestamp:time.Date(2023, time.December, 19, 10, 52, 32, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"798489330"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 52, 32, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005f53068), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 19, 10, 53, 24, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005f53098), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-phz72", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0030d7a20), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-phz72", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-phz72", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-phz72", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0040393c0), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"hiengux9ahcu-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0002438f0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004039450)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004039470)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc004039478), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00403947c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc0013ccfc0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.December, 19, 10, 52, 32, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.December, 19, 10, 52, 32, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.December, 19, 10, 52, 32, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.December, 19, 10, 52, 32, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.121.172", HostIPs:[]v1.HostIP(nil), PodIP:"10.233.66.147", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.233.66.147"}}, StartTime:time.Date(2023, time.December, 19, 10, 52, 32, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0002439d0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000243a40)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"d59c675982d8692814ec9e1486d4c645cd86ad825ef33975a5db196cf2801592", ContainerID:"cri-o://13023942419a25cbde862966e4440a4aecf7dc52f42f1a3a112c2ad02cae8700", Started:(*bool)(0xc00403951f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0030d7aa0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"", ContainerID:"", Started:(*bool)(0xc004039525), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0030d7a80), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc0040394f4), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  Dec 19 10:53:24.786: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-2438" for this suite. @ 12/19/23 10:53:24.808
• [52.114 seconds]
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]
test/e2e/apps/statefulset.go:331
  STEP: Creating a kubernetes client @ 12/19/23 10:53:24.826
  Dec 19 10:53:24.826: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename statefulset @ 12/19/23 10:53:24.833
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:53:24.877
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:53:24.884
  STEP: Creating service test in namespace statefulset-6616 @ 12/19/23 10:53:24.895
  STEP: Creating a new StatefulSet @ 12/19/23 10:53:24.914
  Dec 19 10:53:24.957: INFO: Found 0 stateful pods, waiting for 3
  E1219 10:53:25.235668      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:26.234651      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:27.235471      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:28.236091      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:29.236434      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:30.237132      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:31.238196      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:32.237799      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:33.238253      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:34.238694      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:53:34.976: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 10:53:34.976: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 10:53:34.976: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 12/19/23 10:53:35.013
  Dec 19 10:53:35.043: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 12/19/23 10:53:35.044
  E1219 10:53:35.239762      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:36.240696      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:37.240768      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:38.241041      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:39.241415      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:40.242493      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:41.243416      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:42.243578      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:43.243874      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:44.244052      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 12/19/23 10:53:45.086
  STEP: Performing a canary update @ 12/19/23 10:53:45.088
  Dec 19 10:53:45.127: INFO: Updating stateful set ss2
  Dec 19 10:53:45.154: INFO: Waiting for Pod statefulset-6616/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:53:45.245199      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:46.245601      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:47.245803      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:48.245967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:49.246188      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:50.246488      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:51.247344      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:52.248280      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:53.248710      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:54.248904      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 12/19/23 10:53:55.173
  E1219 10:53:55.249516      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:53:55.296: INFO: Found 1 stateful pods, waiting for 3
  E1219 10:53:56.250291      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:57.251273      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:58.252211      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:53:59.253152      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:00.253577      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:01.253758      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:02.253929      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:03.254087      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:04.254351      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:05.254685      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:54:05.310: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 10:54:05.310: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 10:54:05.310: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 12/19/23 10:54:05.326
  Dec 19 10:54:05.359: INFO: Updating stateful set ss2
  Dec 19 10:54:05.388: INFO: Waiting for Pod statefulset-6616/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:54:06.255056      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:07.255342      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:08.255906      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:09.256627      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:10.256874      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:11.256986      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:12.257759      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:13.258187      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:14.258878      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:15.259430      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:54:15.458: INFO: Updating stateful set ss2
  Dec 19 10:54:15.474: INFO: Waiting for StatefulSet statefulset-6616/ss2 to complete update
  Dec 19 10:54:15.475: INFO: Waiting for Pod statefulset-6616/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1219 10:54:16.263461      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:17.259728      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:18.269485      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:19.262149      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:20.262334      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:21.264694      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:22.264142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:23.269701      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:24.266935      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:25.267206      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:54:25.497: INFO: Deleting all statefulset in ns statefulset-6616
  Dec 19 10:54:25.507: INFO: Scaling statefulset ss2 to 0
  E1219 10:54:26.268103      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:27.278757      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:28.274408      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:29.274753      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:30.275328      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:31.277659      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:32.277245      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:33.283059      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:34.283399      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:35.285271      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:54:35.571: INFO: Waiting for statefulset status.replicas updated to 0
  Dec 19 10:54:35.581: INFO: Deleting statefulset ss2
  Dec 19 10:54:35.620: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-6616" for this suite. @ 12/19/23 10:54:35.639
• [70.828 seconds]
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:262
  STEP: Creating a kubernetes client @ 12/19/23 10:54:35.659
  Dec 19 10:54:35.659: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 10:54:35.665
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:54:35.699
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:54:35.704
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 10:54:35.709
  E1219 10:54:36.285588      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:37.285685      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:38.285832      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:39.286555      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:54:39.751
  Dec 19 10:54:39.758: INFO: Trying to get logs from node hiengux9ahcu-3 pod downwardapi-volume-0bedaae9-c2ff-4ead-81a9-95304608aea4 container client-container: <nil>
  STEP: delete the pod @ 12/19/23 10:54:39.794
  Dec 19 10:54:39.823: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3881" for this suite. @ 12/19/23 10:54:39.833
• [4.189 seconds]
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:84
  STEP: Creating a kubernetes client @ 12/19/23 10:54:39.848
  Dec 19 10:54:39.848: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename pod-network-test @ 12/19/23 10:54:39.851
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:54:39.886
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:54:39.892
  STEP: Performing setup for networking test in namespace pod-network-test-4729 @ 12/19/23 10:54:39.901
  STEP: creating a selector @ 12/19/23 10:54:39.902
  STEP: Creating the service pods in kubernetes @ 12/19/23 10:54:39.902
  Dec 19 10:54:39.902: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E1219 10:54:40.287520      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:41.287453      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:42.288615      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:43.288833      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:44.289107      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:45.289207      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:46.289375      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:47.290093      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:48.290718      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:49.290867      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:50.291800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:51.291739      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 12/19/23 10:54:52.091
  E1219 10:54:52.292587      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:53.294192      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:54:54.138: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Dec 19 10:54:54.139: INFO: Breadth first check of 10.233.64.70 on host 192.168.121.83...
  Dec 19 10:54:54.150: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.153:9080/dial?request=hostname&protocol=http&host=10.233.64.70&port=8083&tries=1'] Namespace:pod-network-test-4729 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:54:54.150: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:54:54.151: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:54:54.151: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-4729/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.153%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.64.70%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  E1219 10:54:54.294235      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:54:54.341: INFO: Waiting for responses: map[]
  Dec 19 10:54:54.341: INFO: reached 10.233.64.70 after 0/1 tries
  Dec 19 10:54:54.341: INFO: Breadth first check of 10.233.65.66 on host 192.168.121.17...
  Dec 19 10:54:54.350: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.153:9080/dial?request=hostname&protocol=http&host=10.233.65.66&port=8083&tries=1'] Namespace:pod-network-test-4729 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:54:54.351: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:54:54.352: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:54:54.352: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-4729/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.153%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.65.66%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec 19 10:54:54.482: INFO: Waiting for responses: map[]
  Dec 19 10:54:54.483: INFO: reached 10.233.65.66 after 0/1 tries
  Dec 19 10:54:54.484: INFO: Breadth first check of 10.233.66.152 on host 192.168.121.172...
  Dec 19 10:54:54.492: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.153:9080/dial?request=hostname&protocol=http&host=10.233.66.152&port=8083&tries=1'] Namespace:pod-network-test-4729 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:54:54.493: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:54:54.494: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:54:54.495: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-4729/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.153%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.66.152%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec 19 10:54:54.621: INFO: Waiting for responses: map[]
  Dec 19 10:54:54.621: INFO: reached 10.233.66.152 after 0/1 tries
  Dec 19 10:54:54.621: INFO: Going to retry 0 out of 3 pods....
  Dec 19 10:54:54.622: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-4729" for this suite. @ 12/19/23 10:54:54.636
• [14.802 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:97
  STEP: Creating a kubernetes client @ 12/19/23 10:54:54.653
  Dec 19 10:54:54.653: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 10:54:54.656
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:54:54.693
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:54:54.699
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 12/19/23 10:54:54.705
  E1219 10:54:55.294481      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:56.294541      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:57.294849      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:54:58.295092      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:54:58.768
  Dec 19 10:54:58.776: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-93037220-543b-41c6-8776-d220d7f34069 container test-container: <nil>
  STEP: delete the pod @ 12/19/23 10:54:58.791
  Dec 19 10:54:58.833: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9431" for this suite. @ 12/19/23 10:54:58.846
• [4.215 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]
test/e2e/apps/deployment.go:488
  STEP: Creating a kubernetes client @ 12/19/23 10:54:58.872
  Dec 19 10:54:58.872: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename deployment @ 12/19/23 10:54:58.879
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:54:58.913
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:54:58.922
  STEP: creating a Deployment @ 12/19/23 10:54:58.935
  Dec 19 10:54:58.935: INFO: Creating simple deployment test-deployment-vrhqk
  Dec 19 10:54:58.960: INFO: new replicaset for deployment "test-deployment-vrhqk" is yet to be created
  E1219 10:54:59.295561      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:00.295461      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Getting /status @ 12/19/23 10:55:00.988
  Dec 19 10:55:01.006: INFO: Deployment test-deployment-vrhqk has Conditions: [{Available True 2023-12-19 10:55:00 +0000 UTC 2023-12-19 10:55:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-12-19 10:55:00 +0000 UTC 2023-12-19 10:54:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-vrhqk-5d576bd769" has successfully progressed.}]
  STEP: updating Deployment Status @ 12/19/23 10:55:01.007
  Dec 19 10:55:01.034: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 10, 55, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 55, 0, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 10, 55, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 10, 54, 58, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-vrhqk-5d576bd769\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 12/19/23 10:55:01.035
  Dec 19 10:55:01.040: INFO: Observed &Deployment event: ADDED
  Dec 19 10:55:01.040: INFO: Observed Deployment test-deployment-vrhqk in namespace deployment-1540 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-19 10:54:58 +0000 UTC 2023-12-19 10:54:58 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-vrhqk-5d576bd769"}
  Dec 19 10:55:01.042: INFO: Observed &Deployment event: MODIFIED
  Dec 19 10:55:01.043: INFO: Observed Deployment test-deployment-vrhqk in namespace deployment-1540 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-19 10:54:58 +0000 UTC 2023-12-19 10:54:58 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-vrhqk-5d576bd769"}
  Dec 19 10:55:01.043: INFO: Observed Deployment test-deployment-vrhqk in namespace deployment-1540 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-12-19 10:54:58 +0000 UTC 2023-12-19 10:54:58 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Dec 19 10:55:01.044: INFO: Observed &Deployment event: MODIFIED
  Dec 19 10:55:01.045: INFO: Observed Deployment test-deployment-vrhqk in namespace deployment-1540 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-12-19 10:54:58 +0000 UTC 2023-12-19 10:54:58 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Dec 19 10:55:01.046: INFO: Observed Deployment test-deployment-vrhqk in namespace deployment-1540 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-19 10:54:59 +0000 UTC 2023-12-19 10:54:58 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-vrhqk-5d576bd769" is progressing.}
  Dec 19 10:55:01.047: INFO: Observed &Deployment event: MODIFIED
  Dec 19 10:55:01.048: INFO: Observed Deployment test-deployment-vrhqk in namespace deployment-1540 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-12-19 10:55:00 +0000 UTC 2023-12-19 10:55:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Dec 19 10:55:01.048: INFO: Observed Deployment test-deployment-vrhqk in namespace deployment-1540 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-19 10:55:00 +0000 UTC 2023-12-19 10:54:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-vrhqk-5d576bd769" has successfully progressed.}
  Dec 19 10:55:01.049: INFO: Observed &Deployment event: MODIFIED
  Dec 19 10:55:01.050: INFO: Observed Deployment test-deployment-vrhqk in namespace deployment-1540 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-12-19 10:55:00 +0000 UTC 2023-12-19 10:55:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Dec 19 10:55:01.050: INFO: Observed Deployment test-deployment-vrhqk in namespace deployment-1540 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-19 10:55:00 +0000 UTC 2023-12-19 10:54:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-vrhqk-5d576bd769" has successfully progressed.}
  Dec 19 10:55:01.051: INFO: Found Deployment test-deployment-vrhqk in namespace deployment-1540 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec 19 10:55:01.052: INFO: Deployment test-deployment-vrhqk has an updated status
  STEP: patching the Statefulset Status @ 12/19/23 10:55:01.052
  Dec 19 10:55:01.053: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Dec 19 10:55:01.072: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 12/19/23 10:55:01.072
  Dec 19 10:55:01.076: INFO: Observed &Deployment event: ADDED
  Dec 19 10:55:01.077: INFO: Observed deployment test-deployment-vrhqk in namespace deployment-1540 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-19 10:54:58 +0000 UTC 2023-12-19 10:54:58 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-vrhqk-5d576bd769"}
  Dec 19 10:55:01.078: INFO: Observed &Deployment event: MODIFIED
  Dec 19 10:55:01.079: INFO: Observed deployment test-deployment-vrhqk in namespace deployment-1540 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-19 10:54:58 +0000 UTC 2023-12-19 10:54:58 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-vrhqk-5d576bd769"}
  Dec 19 10:55:01.081: INFO: Observed deployment test-deployment-vrhqk in namespace deployment-1540 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-12-19 10:54:58 +0000 UTC 2023-12-19 10:54:58 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Dec 19 10:55:01.081: INFO: Observed &Deployment event: MODIFIED
  Dec 19 10:55:01.082: INFO: Observed deployment test-deployment-vrhqk in namespace deployment-1540 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-12-19 10:54:58 +0000 UTC 2023-12-19 10:54:58 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Dec 19 10:55:01.082: INFO: Observed deployment test-deployment-vrhqk in namespace deployment-1540 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-19 10:54:59 +0000 UTC 2023-12-19 10:54:58 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-vrhqk-5d576bd769" is progressing.}
  Dec 19 10:55:01.083: INFO: Observed &Deployment event: MODIFIED
  Dec 19 10:55:01.083: INFO: Observed deployment test-deployment-vrhqk in namespace deployment-1540 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-12-19 10:55:00 +0000 UTC 2023-12-19 10:55:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Dec 19 10:55:01.083: INFO: Observed deployment test-deployment-vrhqk in namespace deployment-1540 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-19 10:55:00 +0000 UTC 2023-12-19 10:54:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-vrhqk-5d576bd769" has successfully progressed.}
  Dec 19 10:55:01.083: INFO: Observed &Deployment event: MODIFIED
  Dec 19 10:55:01.083: INFO: Observed deployment test-deployment-vrhqk in namespace deployment-1540 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-12-19 10:55:00 +0000 UTC 2023-12-19 10:55:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Dec 19 10:55:01.083: INFO: Observed deployment test-deployment-vrhqk in namespace deployment-1540 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-19 10:55:00 +0000 UTC 2023-12-19 10:54:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-vrhqk-5d576bd769" has successfully progressed.}
  Dec 19 10:55:01.083: INFO: Observed deployment test-deployment-vrhqk in namespace deployment-1540 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec 19 10:55:01.084: INFO: Observed &Deployment event: MODIFIED
  Dec 19 10:55:01.084: INFO: Found deployment test-deployment-vrhqk in namespace deployment-1540 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  Dec 19 10:55:01.084: INFO: Deployment test-deployment-vrhqk has a patched status
  Dec 19 10:55:01.095: INFO: Deployment "test-deployment-vrhqk":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-vrhqk",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1540",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b690fcab-fe0c-45ce-ae3e-3d96a76d6ec1",
      ResourceVersion: (string) (len=5) "15150",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580098,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580098,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580101,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580101,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580101,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580101,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=56) "Found new replica set \"test-deployment-vrhqk-5d576bd769\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec 19 10:55:01.111: INFO: New ReplicaSet "test-deployment-vrhqk-5d576bd769" of Deployment "test-deployment-vrhqk":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-vrhqk-5d576bd769",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1540",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "511f3810-1f3c-417a-b565-6171c66a6fe6",
      ResourceVersion: (string) (len=5) "15132",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580098,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-vrhqk",
          UID: (types.UID) (len=36) "b690fcab-fe0c-45ce-ae3e-3d96a76d6ec1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580098,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 62 36 39  |k:{\"uid\":\"b69|
              00000120  30 66 63 61 62 2d 66 65  30 63 2d 34 35 63 65 2d  |0fcab-fe0c-45ce-|
              00000130  61 65 33 65 2d 33 64 39  36 61 37 36 64 36 65 63  |ae3e-3d96a76d6ec|
              00000140  31 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |1\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580100,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769",
          (string) (len=3) "e2e": (string) (len=7) "testing"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 10:55:01.138: INFO: Pod "test-deployment-vrhqk-5d576bd769-5wmf7" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=38) "test-deployment-vrhqk-5d576bd769-5wmf7",
      GenerateName: (string) (len=33) "test-deployment-vrhqk-5d576bd769-",
      Namespace: (string) (len=15) "deployment-1540",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a7eb462c-77a2-43c8-82a9-ecec1f22f11b",
      ResourceVersion: (string) (len=5) "15131",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580098,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=32) "test-deployment-vrhqk-5d576bd769",
          UID: (types.UID) (len=36) "511f3810-1f3c-417a-b565-6171c66a6fe6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580098,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 35 31 31 66 33 38 31  30 2d 31 66 33 63 2d 34  |"511f3810-1f3c-4|
              000000a0  31 37 61 2d 62 35 36 35  2d 36 31 37 31 63 36 36  |17a-b565-6171c66|
              000000b0  61 36 66 65 36 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |a6fe6\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580100,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  36 2e 31 35 35 5c 22 7d  |10.233.66.155\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9qchn",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9qchn",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580099,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580100,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580100,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580099,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.172",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.233.66.155",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.155"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580099,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838580099,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://a709b827870b13a1479bb04943351735f470b2100948933f0908a1e0eb0a1266",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 10:55:01.161: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1540" for this suite. @ 12/19/23 10:55:01.173
• [2.315 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:74
  STEP: Creating a kubernetes client @ 12/19/23 10:55:01.188
  Dec 19 10:55:01.188: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename configmap @ 12/19/23 10:55:01.191
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:55:01.217
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:55:01.222
  STEP: Creating configMap with name configmap-test-volume-864ed3eb-a51c-4959-be6e-b23060f18aa8 @ 12/19/23 10:55:01.228
  STEP: Creating a pod to test consume configMaps @ 12/19/23 10:55:01.236
  E1219 10:55:01.296779      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:02.296930      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:03.297757      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:04.298688      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:55:05.276
  Dec 19 10:55:05.285: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-configmaps-8db81f9a-25a3-412f-a423-40102c1862b3 container agnhost-container: <nil>
  E1219 10:55:05.298620      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod @ 12/19/23 10:55:05.304
  Dec 19 10:55:05.333: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7554" for this suite. @ 12/19/23 10:55:05.344
• [4.172 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:486
  STEP: Creating a kubernetes client @ 12/19/23 10:55:05.364
  Dec 19 10:55:05.364: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename security-context-test @ 12/19/23 10:55:05.368
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:55:05.398
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:55:05.404
  E1219 10:55:06.299837      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:07.300692      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:07.444: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-1685" for this suite. @ 12/19/23 10:55:07.455
• [2.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:194
  STEP: Creating a kubernetes client @ 12/19/23 10:55:07.48
  Dec 19 10:55:07.480: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/19/23 10:55:07.484
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:55:07.51
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:55:07.516
  Dec 19 10:55:07.522: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 10:55:08.300450      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:09.301238      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 12/19/23 10:55:09.56
  Dec 19 10:55:09.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-8779 --namespace=crd-publish-openapi-8779 create -f -'
  E1219 10:55:10.301624      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:10.990: INFO: stderr: ""
  Dec 19 10:55:10.990: INFO: stdout: "e2e-test-crd-publish-openapi-1166-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Dec 19 10:55:10.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-8779 --namespace=crd-publish-openapi-8779 delete e2e-test-crd-publish-openapi-1166-crds test-cr'
  Dec 19 10:55:11.181: INFO: stderr: ""
  Dec 19 10:55:11.181: INFO: stdout: "e2e-test-crd-publish-openapi-1166-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  Dec 19 10:55:11.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-8779 --namespace=crd-publish-openapi-8779 apply -f -'
  E1219 10:55:11.302698      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:11.969: INFO: stderr: ""
  Dec 19 10:55:11.969: INFO: stdout: "e2e-test-crd-publish-openapi-1166-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Dec 19 10:55:11.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-8779 --namespace=crd-publish-openapi-8779 delete e2e-test-crd-publish-openapi-1166-crds test-cr'
  Dec 19 10:55:12.145: INFO: stderr: ""
  Dec 19 10:55:12.145: INFO: stdout: "e2e-test-crd-publish-openapi-1166-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 12/19/23 10:55:12.146
  Dec 19 10:55:12.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-8779 explain e2e-test-crd-publish-openapi-1166-crds'
  E1219 10:55:12.303454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:12.485: INFO: stderr: ""
  Dec 19 10:55:12.486: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-1166-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E1219 10:55:13.304293      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:14.304460      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:14.382: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8779" for this suite. @ 12/19/23 10:55:14.402
• [6.936 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance]
test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 12/19/23 10:55:14.425
  Dec 19 10:55:14.426: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename dns @ 12/19/23 10:55:14.429
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:55:14.47
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:55:14.475
  STEP: Creating a test headless service @ 12/19/23 10:55:14.485
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2046.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-2046.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 12/19/23 10:55:14.498
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2046.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-2046.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 12/19/23 10:55:14.498
  STEP: creating a pod to probe DNS @ 12/19/23 10:55:14.498
  STEP: submitting the pod to kubernetes @ 12/19/23 10:55:14.498
  E1219 10:55:15.306232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:16.305386      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/19/23 10:55:16.538
  STEP: looking for the results for each expected name from probers @ 12/19/23 10:55:16.547
  Dec 19 10:55:16.591: INFO: Unable to read jessie_hosts@dns-querier-2 from pod dns-2046/dns-test-a12205ca-4c5a-4e43-812b-28303d534c96: the server could not find the requested resource (get pods dns-test-a12205ca-4c5a-4e43-812b-28303d534c96)
  Dec 19 10:55:16.592: INFO: Lookups using dns-2046/dns-test-a12205ca-4c5a-4e43-812b-28303d534c96 failed for: [jessie_hosts@dns-querier-2]

  Dec 19 10:55:16.631: INFO: Pod client logs for webserver: 
  Dec 19 10:55:16.647: INFO: Pod client logs for querier: 
  Dec 19 10:55:16.660: INFO: Pod client logs for jessie-querier: 
  E1219 10:55:17.306028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:18.306216      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:19.306773      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:20.306643      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:21.306848      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:21.691: INFO: DNS probes using dns-2046/dns-test-a12205ca-4c5a-4e43-812b-28303d534c96 succeeded

  Dec 19 10:55:21.691: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/19/23 10:55:21.7
  STEP: deleting the test headless service @ 12/19/23 10:55:21.723
  STEP: Destroying namespace "dns-2046" for this suite. @ 12/19/23 10:55:21.748
• [7.342 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]
test/e2e/kubectl/kubectl.go:1027
  STEP: Creating a kubernetes client @ 12/19/23 10:55:21.773
  Dec 19 10:55:21.773: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 10:55:21.785
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:55:21.826
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:55:21.832
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 12/19/23 10:55:21.838
  Dec 19 10:55:21.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-3410 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Dec 19 10:55:22.028: INFO: stderr: ""
  Dec 19 10:55:22.029: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 12/19/23 10:55:22.029
  Dec 19 10:55:22.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-3410 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-4"}]}} --dry-run=server'
  Dec 19 10:55:22.222: INFO: stderr: ""
  Dec 19 10:55:22.222: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 12/19/23 10:55:22.222
  Dec 19 10:55:22.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-3410 delete pods e2e-test-httpd-pod'
  E1219 10:55:22.307160      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:23.307572      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:24.308570      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:24.423: INFO: stderr: ""
  Dec 19 10:55:24.423: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Dec 19 10:55:24.423: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3410" for this suite. @ 12/19/23 10:55:24.432
• [2.673 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 12/19/23 10:55:24.446
  Dec 19 10:55:24.446: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename hostport @ 12/19/23 10:55:24.449
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:55:24.49
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:55:24.496
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 12/19/23 10:55:24.509
  E1219 10:55:25.309763      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:26.310420      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.121.83 on the node which pod1 resides and expect scheduled @ 12/19/23 10:55:26.557
  E1219 10:55:27.310808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:28.310971      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.121.83 but use UDP protocol on the node which pod2 resides @ 12/19/23 10:55:28.587
  E1219 10:55:29.311187      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:30.311896      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:31.311851      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:32.311834      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 12/19/23 10:55:32.662
  Dec 19 10:55:32.663: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.121.83 http://127.0.0.1:54323/hostname] Namespace:hostport-2672 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:55:32.663: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:55:32.665: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:55:32.666: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-2672/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.121.83+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.83, port: 54323 @ 12/19/23 10:55:32.889
  Dec 19 10:55:32.889: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.121.83:54323/hostname] Namespace:hostport-2672 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:55:32.890: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:55:32.892: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:55:32.892: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-2672/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.121.83%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.83, port: 54323 UDP @ 12/19/23 10:55:33.028
  Dec 19 10:55:33.028: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.121.83 54323] Namespace:hostport-2672 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:55:33.028: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:55:33.031: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:55:33.031: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-2672/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.121.83+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E1219 10:55:33.312792      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:34.314194      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:35.313728      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:36.314228      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:37.314698      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:38.147: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-2672" for this suite. @ 12/19/23 10:55:38.157
• [13.726 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 12/19/23 10:55:38.178
  Dec 19 10:55:38.178: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename dns @ 12/19/23 10:55:38.18
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:55:38.219
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:55:38.226
  STEP: Creating a test headless service @ 12/19/23 10:55:38.232
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9351 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9351;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9351 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9351;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9351.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9351.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9351.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9351.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9351.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9351.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9351.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9351.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9351.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9351.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9351.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9351.svc;check="$$(dig +notcp +noall +answer +search 128.59.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.59.128_udp@PTR;check="$$(dig +tcp +noall +answer +search 128.59.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.59.128_tcp@PTR;sleep 1; done
   @ 12/19/23 10:55:38.278
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9351 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9351;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9351 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9351;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9351.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9351.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9351.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9351.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9351.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9351.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9351.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9351.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9351.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9351.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9351.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9351.svc;check="$$(dig +notcp +noall +answer +search 128.59.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.59.128_udp@PTR;check="$$(dig +tcp +noall +answer +search 128.59.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.59.128_tcp@PTR;sleep 1; done
   @ 12/19/23 10:55:38.28
  STEP: creating a pod to probe DNS @ 12/19/23 10:55:38.28
  STEP: submitting the pod to kubernetes @ 12/19/23 10:55:38.28
  E1219 10:55:38.315683      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:39.315904      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:40.316018      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:41.316808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:42.317701      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/19/23 10:55:42.348
  STEP: looking for the results for each expected name from probers @ 12/19/23 10:55:42.365
  Dec 19 10:55:42.385: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:42.399: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:42.411: INFO: Unable to read wheezy_udp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:42.421: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:42.428: INFO: Unable to read wheezy_udp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:42.440: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:42.448: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:42.455: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:42.511: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:42.521: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:42.542: INFO: Unable to read jessie_udp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:42.556: INFO: Unable to read jessie_tcp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:42.567: INFO: Unable to read jessie_udp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:42.580: INFO: Unable to read jessie_tcp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:42.591: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:42.600: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:42.648: INFO: Lookups using dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9351 wheezy_tcp@dns-test-service.dns-9351 wheezy_udp@dns-test-service.dns-9351.svc wheezy_tcp@dns-test-service.dns-9351.svc wheezy_udp@_http._tcp.dns-test-service.dns-9351.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9351.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9351 jessie_tcp@dns-test-service.dns-9351 jessie_udp@dns-test-service.dns-9351.svc jessie_tcp@dns-test-service.dns-9351.svc jessie_udp@_http._tcp.dns-test-service.dns-9351.svc jessie_tcp@_http._tcp.dns-test-service.dns-9351.svc]

  Dec 19 10:55:42.668: INFO: Pod client logs for webserver: 
  Dec 19 10:55:42.689: INFO: Pod client logs for querier: 
  Dec 19 10:55:42.719: INFO: Pod client logs for jessie-querier: 
  E1219 10:55:43.317469      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:44.318340      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:45.318254      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:46.318450      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:47.324567      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:47.730: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:47.738: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:47.745: INFO: Unable to read wheezy_udp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:47.757: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:47.765: INFO: Unable to read wheezy_udp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:47.774: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:47.780: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:47.794: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:47.858: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:47.865: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:47.883: INFO: Unable to read jessie_udp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:47.898: INFO: Unable to read jessie_tcp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:47.911: INFO: Unable to read jessie_udp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:47.920: INFO: Unable to read jessie_tcp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:47.932: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:47.941: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:47.973: INFO: Lookups using dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9351 wheezy_tcp@dns-test-service.dns-9351 wheezy_udp@dns-test-service.dns-9351.svc wheezy_tcp@dns-test-service.dns-9351.svc wheezy_udp@_http._tcp.dns-test-service.dns-9351.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9351.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9351 jessie_tcp@dns-test-service.dns-9351 jessie_udp@dns-test-service.dns-9351.svc jessie_tcp@dns-test-service.dns-9351.svc jessie_udp@_http._tcp.dns-test-service.dns-9351.svc jessie_tcp@_http._tcp.dns-test-service.dns-9351.svc]

  Dec 19 10:55:47.988: INFO: Pod client logs for webserver: 
  Dec 19 10:55:48.004: INFO: Pod client logs for querier: 
  Dec 19 10:55:48.018: INFO: Pod client logs for jessie-querier: 
  E1219 10:55:48.322114      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:49.323669      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:50.323658      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:51.324071      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:52.325125      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:52.747: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:52.756: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:52.766: INFO: Unable to read wheezy_udp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:52.773: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:52.781: INFO: Unable to read wheezy_udp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:52.791: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:52.801: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:52.810: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:52.861: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:52.869: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:52.878: INFO: Unable to read jessie_udp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:52.885: INFO: Unable to read jessie_tcp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:52.894: INFO: Unable to read jessie_udp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:52.902: INFO: Unable to read jessie_tcp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:52.910: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:52.920: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:52.955: INFO: Lookups using dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9351 wheezy_tcp@dns-test-service.dns-9351 wheezy_udp@dns-test-service.dns-9351.svc wheezy_tcp@dns-test-service.dns-9351.svc wheezy_udp@_http._tcp.dns-test-service.dns-9351.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9351.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9351 jessie_tcp@dns-test-service.dns-9351 jessie_udp@dns-test-service.dns-9351.svc jessie_tcp@dns-test-service.dns-9351.svc jessie_udp@_http._tcp.dns-test-service.dns-9351.svc jessie_tcp@_http._tcp.dns-test-service.dns-9351.svc]

  Dec 19 10:55:52.968: INFO: Pod client logs for webserver: 
  Dec 19 10:55:52.983: INFO: Pod client logs for querier: 
  Dec 19 10:55:53.000: INFO: Pod client logs for jessie-querier: 
  E1219 10:55:53.325133      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:54.326706      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:55.328678      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:56.329775      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:57.329753      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:55:57.729: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:57.737: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:57.745: INFO: Unable to read wheezy_udp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:57.751: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:57.760: INFO: Unable to read wheezy_udp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:57.767: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:57.774: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:57.782: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:57.821: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:57.831: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:57.840: INFO: Unable to read jessie_udp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:57.849: INFO: Unable to read jessie_tcp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:57.858: INFO: Unable to read jessie_udp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:57.866: INFO: Unable to read jessie_tcp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:57.874: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:57.883: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:55:57.913: INFO: Lookups using dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9351 wheezy_tcp@dns-test-service.dns-9351 wheezy_udp@dns-test-service.dns-9351.svc wheezy_tcp@dns-test-service.dns-9351.svc wheezy_udp@_http._tcp.dns-test-service.dns-9351.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9351.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9351 jessie_tcp@dns-test-service.dns-9351 jessie_udp@dns-test-service.dns-9351.svc jessie_tcp@dns-test-service.dns-9351.svc jessie_udp@_http._tcp.dns-test-service.dns-9351.svc jessie_tcp@_http._tcp.dns-test-service.dns-9351.svc]

  Dec 19 10:55:57.927: INFO: Pod client logs for webserver: 
  Dec 19 10:55:57.940: INFO: Pod client logs for querier: 
  Dec 19 10:55:57.955: INFO: Pod client logs for jessie-querier: 
  E1219 10:55:58.330488      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:55:59.330867      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:00.331064      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:01.331347      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:02.331760      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:02.767: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:02.776: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:02.785: INFO: Unable to read wheezy_udp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:02.794: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:02.804: INFO: Unable to read wheezy_udp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:02.812: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:02.819: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:02.829: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:02.871: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:02.880: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:02.886: INFO: Unable to read jessie_udp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:02.893: INFO: Unable to read jessie_tcp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:02.902: INFO: Unable to read jessie_udp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:02.910: INFO: Unable to read jessie_tcp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:02.917: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:02.926: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:02.955: INFO: Lookups using dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9351 wheezy_tcp@dns-test-service.dns-9351 wheezy_udp@dns-test-service.dns-9351.svc wheezy_tcp@dns-test-service.dns-9351.svc wheezy_udp@_http._tcp.dns-test-service.dns-9351.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9351.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9351 jessie_tcp@dns-test-service.dns-9351 jessie_udp@dns-test-service.dns-9351.svc jessie_tcp@dns-test-service.dns-9351.svc jessie_udp@_http._tcp.dns-test-service.dns-9351.svc jessie_tcp@_http._tcp.dns-test-service.dns-9351.svc]

  Dec 19 10:56:02.970: INFO: Pod client logs for webserver: 
  Dec 19 10:56:02.983: INFO: Pod client logs for querier: 
  Dec 19 10:56:02.996: INFO: Pod client logs for jessie-querier: 
  E1219 10:56:03.333039      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:04.333153      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:05.333799      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:06.334398      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:07.334565      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:07.728: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:07.739: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:07.748: INFO: Unable to read wheezy_udp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:07.761: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:07.772: INFO: Unable to read wheezy_udp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:07.783: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:07.792: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:07.802: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:07.855: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:07.867: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:07.876: INFO: Unable to read jessie_udp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:07.884: INFO: Unable to read jessie_tcp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:07.900: INFO: Unable to read jessie_udp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:07.910: INFO: Unable to read jessie_tcp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:07.917: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:07.929: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:07.962: INFO: Lookups using dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9351 wheezy_tcp@dns-test-service.dns-9351 wheezy_udp@dns-test-service.dns-9351.svc wheezy_tcp@dns-test-service.dns-9351.svc wheezy_udp@_http._tcp.dns-test-service.dns-9351.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9351.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9351 jessie_tcp@dns-test-service.dns-9351 jessie_udp@dns-test-service.dns-9351.svc jessie_tcp@dns-test-service.dns-9351.svc jessie_udp@_http._tcp.dns-test-service.dns-9351.svc jessie_tcp@_http._tcp.dns-test-service.dns-9351.svc]

  Dec 19 10:56:07.974: INFO: Pod client logs for webserver: 
  Dec 19 10:56:07.987: INFO: Pod client logs for querier: 
  Dec 19 10:56:08.005: INFO: Pod client logs for jessie-querier: 
  E1219 10:56:08.335694      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:09.336075      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:10.336124      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:11.337188      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:12.337581      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:12.833: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:12.841: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:12.846: INFO: Unable to read jessie_udp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:12.851: INFO: Unable to read jessie_tcp@dns-test-service.dns-9351 from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:12.861: INFO: Unable to read jessie_udp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:12.870: INFO: Unable to read jessie_tcp@dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:12.876: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:12.885: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9351.svc from pod dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948: the server could not find the requested resource (get pods dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948)
  Dec 19 10:56:12.917: INFO: Lookups using dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948 failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9351 jessie_tcp@dns-test-service.dns-9351 jessie_udp@dns-test-service.dns-9351.svc jessie_tcp@dns-test-service.dns-9351.svc jessie_udp@_http._tcp.dns-test-service.dns-9351.svc jessie_tcp@_http._tcp.dns-test-service.dns-9351.svc]

  Dec 19 10:56:12.929: INFO: Pod client logs for webserver: 
  Dec 19 10:56:12.942: INFO: Pod client logs for querier: 
  Dec 19 10:56:12.956: INFO: Pod client logs for jessie-querier: 
  E1219 10:56:13.337733      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:14.339034      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:15.339869      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:16.340777      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:17.341634      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:17.899: INFO: DNS probes using dns-9351/dns-test-8c5b4611-88d9-47a6-9274-8bf3a8c94948 succeeded

  Dec 19 10:56:17.899: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/19/23 10:56:17.91
  STEP: deleting the test service @ 12/19/23 10:56:17.982
  STEP: deleting the test headless service @ 12/19/23 10:56:18.108
  STEP: Destroying namespace "dns-9351" for this suite. @ 12/19/23 10:56:18.142
• [39.978 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:176
  STEP: Creating a kubernetes client @ 12/19/23 10:56:18.21
  Dec 19 10:56:18.211: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename crd-webhook @ 12/19/23 10:56:18.23
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:56:18.273
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:56:18.283
  STEP: Setting up server cert @ 12/19/23 10:56:18.288
  E1219 10:56:18.341729      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 12/19/23 10:56:19.173
  STEP: Deploying the custom resource conversion webhook pod @ 12/19/23 10:56:19.191
  STEP: Wait for the deployment to be ready @ 12/19/23 10:56:19.22
  Dec 19 10:56:19.231: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
  E1219 10:56:19.342703      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:20.344033      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 10:56:21.255
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 10:56:21.278
  E1219 10:56:21.344299      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:22.279: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Dec 19 10:56:22.296: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 10:56:22.345315      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:23.346325      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:24.346867      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 12/19/23 10:56:25.111
  STEP: Create a v2 custom resource @ 12/19/23 10:56:25.15
  E1219 10:56:25.347320      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: List CRs in v1 @ 12/19/23 10:56:25.425
  STEP: List CRs in v2 @ 12/19/23 10:56:25.441
  Dec 19 10:56:25.454: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-3232" for this suite. @ 12/19/23 10:56:26.108
• [7.918 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]
test/e2e/apimachinery/webhook.go:371
  STEP: Creating a kubernetes client @ 12/19/23 10:56:26.134
  Dec 19 10:56:26.134: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename webhook @ 12/19/23 10:56:26.153
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:56:26.204
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:56:26.21
  STEP: Setting up server cert @ 12/19/23 10:56:26.266
  E1219 10:56:26.347493      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:27.347635      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 10:56:27.473
  STEP: Deploying the webhook pod @ 12/19/23 10:56:27.485
  STEP: Wait for the deployment to be ready @ 12/19/23 10:56:27.506
  Dec 19 10:56:27.517: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E1219 10:56:28.348320      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:29.348961      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 10:56:29.571
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 10:56:29.596
  E1219 10:56:30.349654      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:30.596: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 12/19/23 10:56:30.609
  STEP: Registering slow webhook via the AdmissionRegistration API @ 12/19/23 10:56:30.61
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 12/19/23 10:56:30.647
  E1219 10:56:31.349887      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 12/19/23 10:56:31.67
  STEP: Registering slow webhook via the AdmissionRegistration API @ 12/19/23 10:56:31.67
  E1219 10:56:32.350869      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 12/19/23 10:56:32.729
  STEP: Registering slow webhook via the AdmissionRegistration API @ 12/19/23 10:56:32.729
  E1219 10:56:33.351636      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:34.352163      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:35.352651      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:36.353659      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:37.354432      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 12/19/23 10:56:37.803
  STEP: Registering slow webhook via the AdmissionRegistration API @ 12/19/23 10:56:37.803
  E1219 10:56:38.354643      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:39.354788      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:40.355305      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:41.355455      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:42.355523      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:42.860: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-474" for this suite. @ 12/19/23 10:56:42.998
  STEP: Destroying namespace "webhook-markers-840" for this suite. @ 12/19/23 10:56:43.016
• [16.932 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]
test/e2e/apimachinery/webhook.go:332
  STEP: Creating a kubernetes client @ 12/19/23 10:56:43.077
  Dec 19 10:56:43.078: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename webhook @ 12/19/23 10:56:43.082
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:56:43.132
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:56:43.137
  STEP: Setting up server cert @ 12/19/23 10:56:43.187
  E1219 10:56:43.355543      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:44.355808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 10:56:44.79
  STEP: Deploying the webhook pod @ 12/19/23 10:56:44.801
  STEP: Wait for the deployment to be ready @ 12/19/23 10:56:44.828
  Dec 19 10:56:44.853: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1219 10:56:45.355969      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:46.356145      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 10:56:46.874
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 10:56:46.893
  E1219 10:56:47.356327      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:47.895: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Dec 19 10:56:47.907: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 10:56:48.356502      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-829-crds.webhook.example.com via the AdmissionRegistration API @ 12/19/23 10:56:48.444
  STEP: Creating a custom resource that should be mutated by the webhook @ 12/19/23 10:56:48.502
  E1219 10:56:49.357487      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:50.357557      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:56:50.804: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1219 10:56:51.357688      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-7139" for this suite. @ 12/19/23 10:56:51.522
  STEP: Destroying namespace "webhook-markers-5901" for this suite. @ 12/19/23 10:56:51.532
• [8.470 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]
test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 12/19/23 10:56:51.547
  Dec 19 10:56:51.548: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename secrets @ 12/19/23 10:56:51.551
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:56:51.578
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:56:51.584
  Dec 19 10:56:51.668: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5391" for this suite. @ 12/19/23 10:56:51.679
• [0.145 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:208
  STEP: Creating a kubernetes client @ 12/19/23 10:56:51.695
  Dec 19 10:56:51.696: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 10:56:51.698
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:56:51.75
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:56:51.76
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 10:56:51.771
  E1219 10:56:52.357823      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:53.358918      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:54.358940      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:55.359690      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:56:55.831
  Dec 19 10:56:55.838: INFO: Trying to get logs from node hiengux9ahcu-3 pod downwardapi-volume-6b962dab-86c2-4143-8213-c0734ac0be1b container client-container: <nil>
  STEP: delete the pod @ 12/19/23 10:56:55.855
  Dec 19 10:56:55.886: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1892" for this suite. @ 12/19/23 10:56:55.898
• [4.219 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:91
  STEP: Creating a kubernetes client @ 12/19/23 10:56:55.919
  Dec 19 10:56:55.919: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 10:56:55.922
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:56:55.961
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:56:55.971
  STEP: Creating a pod to test downward api env vars @ 12/19/23 10:56:55.977
  E1219 10:56:56.361793      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:57.362159      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:58.362236      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:56:59.367559      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:57:00.031
  Dec 19 10:57:00.039: INFO: Trying to get logs from node hiengux9ahcu-3 pod downward-api-e5c4ea89-2924-47bf-bd80-d574928471d9 container dapi-container: <nil>
  STEP: delete the pod @ 12/19/23 10:57:00.058
  Dec 19 10:57:00.090: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8380" for this suite. @ 12/19/23 10:57:00.103
• [4.198 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
test/e2e/apps/job.go:370
  STEP: Creating a kubernetes client @ 12/19/23 10:57:00.128
  Dec 19 10:57:00.128: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename job @ 12/19/23 10:57:00.133
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:57:00.171
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:57:00.178
  STEP: Creating Indexed job @ 12/19/23 10:57:00.187
  STEP: Ensuring job reaches completions @ 12/19/23 10:57:00.202
  E1219 10:57:00.363646      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:01.372180      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:02.367022      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:03.367762      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:04.368867      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:05.369819      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:06.370422      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:07.371127      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring pods with index for job exist @ 12/19/23 10:57:08.213
  Dec 19 10:57:08.224: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8252" for this suite. @ 12/19/23 10:57:08.243
• [8.131 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:357
  STEP: Creating a kubernetes client @ 12/19/23 10:57:08.266
  Dec 19 10:57:08.266: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/19/23 10:57:08.27
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:57:08.3
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:57:08.31
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 12/19/23 10:57:08.32
  Dec 19 10:57:08.322: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 10:57:08.371861      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:09.372173      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:10.376547      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:10.392: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 10:57:11.376912      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:12.377091      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:13.377861      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:14.378335      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:15.378899      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:16.379955      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:17.380134      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:17.728: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1573" for this suite. @ 12/19/23 10:57:17.752
• [9.500 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:184
  STEP: Creating a kubernetes client @ 12/19/23 10:57:17.767
  Dec 19 10:57:17.767: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubelet-test @ 12/19/23 10:57:17.77
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:57:17.797
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:57:17.803
  E1219 10:57:18.380486      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:19.380993      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:19.879: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-9275" for this suite. @ 12/19/23 10:57:19.89
• [2.139 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:276
  STEP: Creating a kubernetes client @ 12/19/23 10:57:19.908
  Dec 19 10:57:19.908: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/19/23 10:57:19.911
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:57:19.942
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:57:19.947
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 12/19/23 10:57:19.952
  Dec 19 10:57:19.953: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 10:57:20.381531      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:21.381207      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:21.717: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 10:57:22.382069      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:23.382424      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:24.391182      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:25.391253      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:26.391935      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:27.392345      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:28.392723      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:28.849: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-342" for this suite. @ 12/19/23 10:57:28.872
• [8.978 seconds]
------------------------------
SS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:213
  STEP: Creating a kubernetes client @ 12/19/23 10:57:28.888
  Dec 19 10:57:28.888: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 12/19/23 10:57:28.894
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:57:28.921
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:57:28.928
  STEP: create the container to handle the HTTPGet hook request. @ 12/19/23 10:57:28.942
  E1219 10:57:29.393283      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:30.393718      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 12/19/23 10:57:30.986
  E1219 10:57:31.394495      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:32.395738      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 12/19/23 10:57:33.026
  E1219 10:57:33.395622      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:34.395762      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 12/19/23 10:57:35.076
  Dec 19 10:57:35.111: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-6915" for this suite. @ 12/19/23 10:57:35.126
• [6.258 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 12/19/23 10:57:35.154
  Dec 19 10:57:35.154: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 12/19/23 10:57:35.157
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:57:35.183
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:57:35.189
  STEP: Setting up the test @ 12/19/23 10:57:35.194
  STEP: Creating hostNetwork=false pod @ 12/19/23 10:57:35.194
  E1219 10:57:35.397028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:36.397616      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating hostNetwork=true pod @ 12/19/23 10:57:37.235
  E1219 10:57:37.400273      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:38.398784      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Running the test @ 12/19/23 10:57:39.278
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 12/19/23 10:57:39.278
  Dec 19 10:57:39.278: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7290 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:57:39.279: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:57:39.281: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:57:39.281: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7290/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  E1219 10:57:39.398845      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:39.433: INFO: Exec stderr: ""
  Dec 19 10:57:39.433: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7290 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:57:39.433: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:57:39.436: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:57:39.436: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7290/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Dec 19 10:57:39.575: INFO: Exec stderr: ""
  Dec 19 10:57:39.575: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7290 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:57:39.576: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:57:39.579: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:57:39.579: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7290/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Dec 19 10:57:39.704: INFO: Exec stderr: ""
  Dec 19 10:57:39.705: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7290 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:57:39.705: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:57:39.710: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:57:39.711: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7290/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Dec 19 10:57:39.817: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 12/19/23 10:57:39.817
  Dec 19 10:57:39.817: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7290 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:57:39.817: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:57:39.820: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:57:39.820: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7290/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Dec 19 10:57:39.942: INFO: Exec stderr: ""
  Dec 19 10:57:39.942: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7290 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:57:39.942: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:57:39.943: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:57:39.944: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7290/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Dec 19 10:57:40.059: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 12/19/23 10:57:40.061
  Dec 19 10:57:40.061: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7290 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:57:40.062: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:57:40.065: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:57:40.067: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7290/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Dec 19 10:57:40.185: INFO: Exec stderr: ""
  Dec 19 10:57:40.185: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7290 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:57:40.185: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:57:40.187: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:57:40.188: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7290/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Dec 19 10:57:40.313: INFO: Exec stderr: ""
  Dec 19 10:57:40.313: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7290 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:57:40.313: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:57:40.316: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:57:40.316: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7290/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  E1219 10:57:40.400553      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:40.442: INFO: Exec stderr: ""
  Dec 19 10:57:40.443: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7290 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 10:57:40.443: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 10:57:40.449: INFO: ExecWithOptions: Clientset creation
  Dec 19 10:57:40.449: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-7290/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Dec 19 10:57:40.581: INFO: Exec stderr: ""
  Dec 19 10:57:40.584: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-7290" for this suite. @ 12/19/23 10:57:40.594
• [5.458 seconds]
------------------------------
S
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 12/19/23 10:57:40.615
  Dec 19 10:57:40.615: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename secrets @ 12/19/23 10:57:40.618
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:57:40.657
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:57:40.663
  STEP: Creating secret with name secret-test-ecad6264-8e5c-48f3-b7a9-9e4dc58e6859 @ 12/19/23 10:57:40.67
  STEP: Creating a pod to test consume secrets @ 12/19/23 10:57:40.683
  E1219 10:57:41.400295      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:42.400969      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:43.401033      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:44.401298      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:57:44.764
  Dec 19 10:57:44.771: INFO: Trying to get logs from node hiengux9ahcu-2 pod pod-secrets-9d29e379-d606-4a2b-878b-a14b4c219a31 container secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 10:57:44.813
  Dec 19 10:57:44.843: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9638" for this suite. @ 12/19/23 10:57:44.852
• [4.249 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod  [Conformance]
test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 12/19/23 10:57:44.876
  Dec 19 10:57:44.877: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename prestop @ 12/19/23 10:57:44.88
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:57:44.914
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:57:44.927
  STEP: Creating server pod server in namespace prestop-5049 @ 12/19/23 10:57:44.934
  STEP: Waiting for pods to come up. @ 12/19/23 10:57:44.956
  E1219 10:57:45.401361      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:46.401761      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating tester pod tester in namespace prestop-5049 @ 12/19/23 10:57:46.984
  E1219 10:57:47.402518      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:48.402839      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting pre-stop pod @ 12/19/23 10:57:49.027
  E1219 10:57:49.402960      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:50.403590      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:51.403989      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:52.404747      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:53.405353      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:57:54.049: INFO: Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  Dec 19 10:57:54.054: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Deleting the server pod @ 12/19/23 10:57:54.063
  STEP: Destroying namespace "prestop-5049" for this suite. @ 12/19/23 10:57:54.102
• [9.255 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
test/e2e/scheduling/limit_range.go:61
  STEP: Creating a kubernetes client @ 12/19/23 10:57:54.136
  Dec 19 10:57:54.136: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename limitrange @ 12/19/23 10:57:54.138
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:57:54.173
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:57:54.178
  STEP: Creating a LimitRange @ 12/19/23 10:57:54.191
  STEP: Setting up watch @ 12/19/23 10:57:54.192
  STEP: Submitting a LimitRange @ 12/19/23 10:57:54.304
  STEP: Verifying LimitRange creation was observed @ 12/19/23 10:57:54.318
  STEP: Fetching the LimitRange to ensure it has proper values @ 12/19/23 10:57:54.318
  Dec 19 10:57:54.328: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Dec 19 10:57:54.329: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 12/19/23 10:57:54.329
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 12/19/23 10:57:54.341
  Dec 19 10:57:54.354: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Dec 19 10:57:54.355: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 12/19/23 10:57:54.355
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 12/19/23 10:57:54.376
  Dec 19 10:57:54.385: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  Dec 19 10:57:54.386: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 12/19/23 10:57:54.386
  STEP: Failing to create a Pod with more than max resources @ 12/19/23 10:57:54.392
  STEP: Updating a LimitRange @ 12/19/23 10:57:54.398
  E1219 10:57:54.405666      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying LimitRange updating is effective @ 12/19/23 10:57:54.409
  E1219 10:57:55.405795      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:56.406891      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 12/19/23 10:57:56.42
  STEP: Failing to create a Pod with more than max resources @ 12/19/23 10:57:56.43
  STEP: Deleting a LimitRange @ 12/19/23 10:57:56.442
  STEP: Verifying the LimitRange was deleted @ 12/19/23 10:57:56.464
  E1219 10:57:57.407534      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:58.407640      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:57:59.408636      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:00.409064      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:01.410132      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:01.472: INFO: limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 12/19/23 10:58:01.472
  Dec 19 10:58:01.498: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-5638" for this suite. @ 12/19/23 10:58:01.555
• [7.435 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 12/19/23 10:58:01.573
  Dec 19 10:58:01.573: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 10:58:01.577
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:58:01.602
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:58:01.609
  STEP: Creating projection with secret that has name projected-secret-test-map-6489786e-b63d-4c84-8df9-8301f67134b6 @ 12/19/23 10:58:01.617
  STEP: Creating a pod to test consume secrets @ 12/19/23 10:58:01.63
  E1219 10:58:02.411705      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:03.411630      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:04.411926      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:05.413188      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:58:05.67
  Dec 19 10:58:05.676: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-projected-secrets-97f31901-ff63-45cc-bb3b-19e370b70540 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 10:58:05.693
  Dec 19 10:58:05.723: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2565" for this suite. @ 12/19/23 10:58:05.733
• [4.174 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]
test/e2e/kubectl/kubectl.go:396
  STEP: Creating a kubernetes client @ 12/19/23 10:58:05.748
  Dec 19 10:58:05.748: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 10:58:05.752
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:58:05.778
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:58:05.783
  STEP: creating all guestbook components @ 12/19/23 10:58:05.787
  Dec 19 10:58:05.788: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  Dec 19 10:58:05.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-5788 create -f -'
  E1219 10:58:06.414030      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:07.022: INFO: stderr: ""
  Dec 19 10:58:07.022: INFO: stdout: "service/agnhost-replica created\n"
  Dec 19 10:58:07.022: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  Dec 19 10:58:07.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-5788 create -f -'
  E1219 10:58:07.414557      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:07.774: INFO: stderr: ""
  Dec 19 10:58:07.774: INFO: stdout: "service/agnhost-primary created\n"
  Dec 19 10:58:07.775: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  Dec 19 10:58:07.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-5788 create -f -'
  E1219 10:58:08.414842      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:08.917: INFO: stderr: ""
  Dec 19 10:58:08.917: INFO: stdout: "service/frontend created\n"
  Dec 19 10:58:08.917: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.45
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  Dec 19 10:58:08.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-5788 create -f -'
  Dec 19 10:58:09.313: INFO: stderr: ""
  Dec 19 10:58:09.313: INFO: stdout: "deployment.apps/frontend created\n"
  Dec 19 10:58:09.313: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.45
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Dec 19 10:58:09.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-5788 create -f -'
  E1219 10:58:09.415241      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:10.127: INFO: stderr: ""
  Dec 19 10:58:10.127: INFO: stdout: "deployment.apps/agnhost-primary created\n"
  Dec 19 10:58:10.127: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.45
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Dec 19 10:58:10.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-5788 create -f -'
  E1219 10:58:10.415676      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:10.976: INFO: stderr: ""
  Dec 19 10:58:10.977: INFO: stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 12/19/23 10:58:10.977
  Dec 19 10:58:10.977: INFO: Waiting for all frontend pods to be Running.
  Dec 19 10:58:11.027: INFO: Waiting for frontend to serve content.
  Dec 19 10:58:11.077: INFO: Failed to get response from guestbook. err: the server responded with the status code 417 but did not return more information (get services frontend), response: 
  E1219 10:58:11.415986      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:12.416126      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:13.416404      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:14.416877      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:15.417352      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:16.106: INFO: Trying to add a new entry to the guestbook.
  Dec 19 10:58:16.133: INFO: Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 12/19/23 10:58:16.15
  Dec 19 10:58:16.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-5788 delete --grace-period=0 --force -f -'
  Dec 19 10:58:16.364: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec 19 10:58:16.364: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 12/19/23 10:58:16.364
  Dec 19 10:58:16.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-5788 delete --grace-period=0 --force -f -'
  E1219 10:58:16.417809      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:16.556: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec 19 10:58:16.556: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 12/19/23 10:58:16.556
  Dec 19 10:58:16.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-5788 delete --grace-period=0 --force -f -'
  Dec 19 10:58:16.734: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec 19 10:58:16.735: INFO: stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 12/19/23 10:58:16.735
  Dec 19 10:58:16.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-5788 delete --grace-period=0 --force -f -'
  Dec 19 10:58:16.896: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec 19 10:58:16.896: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 12/19/23 10:58:16.896
  Dec 19 10:58:16.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-5788 delete --grace-period=0 --force -f -'
  Dec 19 10:58:17.124: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec 19 10:58:17.124: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 12/19/23 10:58:17.125
  Dec 19 10:58:17.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-5788 delete --grace-period=0 --force -f -'
  Dec 19 10:58:17.354: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec 19 10:58:17.354: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  Dec 19 10:58:17.356: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5788" for this suite. @ 12/19/23 10:58:17.378
  E1219 10:58:17.417766      14 retrywatcher.go:129] "Watch failed" err="context canceled"
• [11.713 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:57
  STEP: Creating a kubernetes client @ 12/19/23 10:58:17.463
  Dec 19 10:58:17.463: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename configmap @ 12/19/23 10:58:17.475
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:58:17.56
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:58:17.577
  STEP: Creating configMap with name configmap-test-volume-1d0d94ac-530e-4636-9ae2-1a6cd0bc3604 @ 12/19/23 10:58:17.592
  STEP: Creating a pod to test consume configMaps @ 12/19/23 10:58:17.601
  E1219 10:58:18.421384      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:19.431384      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:20.427122      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:21.427398      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:58:21.672
  Dec 19 10:58:21.679: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-configmaps-d0b23420-2b52-4b92-9775-c87f6494e0b6 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 10:58:21.694
  Dec 19 10:58:21.734: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6302" for this suite. @ 12/19/23 10:58:21.744
• [4.299 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]
test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 12/19/23 10:58:21.768
  Dec 19 10:58:21.768: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename disruption @ 12/19/23 10:58:21.772
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:58:21.812
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:58:21.817
  STEP: Waiting for the pdb to be processed @ 12/19/23 10:58:21.836
  STEP: Waiting for all pods to be running @ 12/19/23 10:58:21.93
  Dec 19 10:58:21.937: INFO: running pods: 0 < 3
  E1219 10:58:22.428084      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:23.428609      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:23.959: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-1778" for this suite. @ 12/19/23 10:58:23.97
• [2.218 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]
test/e2e/apps/job.go:513
  STEP: Creating a kubernetes client @ 12/19/23 10:58:23.988
  Dec 19 10:58:23.988: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename job @ 12/19/23 10:58:23.992
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:58:24.024
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:58:24.029
  STEP: Creating a job @ 12/19/23 10:58:24.035
  STEP: Ensuring active pods == parallelism @ 12/19/23 10:58:24.048
  E1219 10:58:24.429518      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:25.429810      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 12/19/23 10:58:26.057
  E1219 10:58:26.430009      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:26.592: INFO: Successfully updated pod "adopt-release-5n4b5"
  STEP: Checking that the Job readopts the Pod @ 12/19/23 10:58:26.593
  E1219 10:58:27.430649      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:28.431312      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 12/19/23 10:58:28.614
  Dec 19 10:58:29.148: INFO: Successfully updated pod "adopt-release-5n4b5"
  STEP: Checking that the Job releases the Pod @ 12/19/23 10:58:29.149
  E1219 10:58:29.431333      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:30.431935      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:58:31.167: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4068" for this suite. @ 12/19/23 10:58:31.177
• [7.204 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]
test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 12/19/23 10:58:31.194
  Dec 19 10:58:31.194: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename subpath @ 12/19/23 10:58:31.198
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:58:31.231
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:58:31.239
  STEP: Setting up data @ 12/19/23 10:58:31.245
  STEP: Creating pod pod-subpath-test-downwardapi-5w6c @ 12/19/23 10:58:31.264
  STEP: Creating a pod to test atomic-volume-subpath @ 12/19/23 10:58:31.264
  E1219 10:58:31.432288      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:32.432525      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:33.433287      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:34.434179      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:35.434825      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:36.437244      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:37.436638      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:38.436794      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:39.437280      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:40.438435      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:41.438703      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:42.438549      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:43.439303      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:44.440130      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:45.441056      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:46.441825      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:47.442611      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:48.442877      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:49.443692      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:50.446064      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:51.444633      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:52.444849      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:53.445807      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:54.453797      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:55.448674      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:58:55.457
  Dec 19 10:58:55.466: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-subpath-test-downwardapi-5w6c container test-container-subpath-downwardapi-5w6c: <nil>
  STEP: delete the pod @ 12/19/23 10:58:55.484
  STEP: Deleting pod pod-subpath-test-downwardapi-5w6c @ 12/19/23 10:58:55.519
  Dec 19 10:58:55.519: INFO: Deleting pod "pod-subpath-test-downwardapi-5w6c" in namespace "subpath-6173"
  Dec 19 10:58:55.527: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-6173" for this suite. @ 12/19/23 10:58:55.54
• [24.370 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]
test/e2e/apimachinery/discovery.go:169
  STEP: Creating a kubernetes client @ 12/19/23 10:58:55.573
  Dec 19 10:58:55.573: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename discovery @ 12/19/23 10:58:55.584
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:58:55.621
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:58:55.628
  STEP: Setting up server cert @ 12/19/23 10:58:55.638
  E1219 10:58:56.451680      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Requesting APIResourceList from "/api/v1" @ 12/19/23 10:58:56.667
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 12/19/23 10:58:56.671
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 12/19/23 10:58:56.672
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 12/19/23 10:58:56.674
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 12/19/23 10:58:56.676
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 12/19/23 10:58:56.678
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 12/19/23 10:58:56.679
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 12/19/23 10:58:56.681
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 12/19/23 10:58:56.683
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 12/19/23 10:58:56.685
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 12/19/23 10:58:56.686
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 12/19/23 10:58:56.688
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 12/19/23 10:58:56.69
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 12/19/23 10:58:56.691
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 12/19/23 10:58:56.693
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 12/19/23 10:58:56.695
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 12/19/23 10:58:56.697
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 12/19/23 10:58:56.699
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 12/19/23 10:58:56.701
  Dec 19 10:58:56.703: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-1328" for this suite. @ 12/19/23 10:58:56.716
• [1.156 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:309
  STEP: Creating a kubernetes client @ 12/19/23 10:58:56.732
  Dec 19 10:58:56.732: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/19/23 10:58:56.739
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:58:56.77
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:58:56.774
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 12/19/23 10:58:56.779
  Dec 19 10:58:56.780: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 10:58:57.452458      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:58.452681      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:58:59.456026      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:00.456803      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:01.457543      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:02.458379      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:03.459535      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 12/19/23 10:59:04.407
  Dec 19 10:59:04.409: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 10:59:04.460550      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:05.461008      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:06.196: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 10:59:06.461949      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:07.462535      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:08.463299      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:09.464301      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:10.464695      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:11.464891      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:12.466045      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:13.466714      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:13.669: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-729" for this suite. @ 12/19/23 10:59:13.699
• [16.988 seconds]
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]
test/e2e/scheduling/predicates.go:444
  STEP: Creating a kubernetes client @ 12/19/23 10:59:13.722
  Dec 19 10:59:13.723: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename sched-pred @ 12/19/23 10:59:13.726
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:59:13.761
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:59:13.771
  Dec 19 10:59:13.777: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Dec 19 10:59:13.798: INFO: Waiting for terminating namespaces to be deleted...
  Dec 19 10:59:13.806: INFO: 
  Logging pods the apiserver thinks is on node hiengux9ahcu-1 before test
  Dec 19 10:59:13.826: INFO: coredns-5dd5756b68-z5h65 from kube-system started at 2023-12-19 10:09:21 +0000 UTC (1 container statuses recorded)
  Dec 19 10:59:13.826: INFO: 	Container coredns ready: true, restart count 0
  Dec 19 10:59:13.827: INFO: kube-addon-manager-hiengux9ahcu-1 from kube-system started at 2023-12-19 09:57:29 +0000 UTC (1 container statuses recorded)
  Dec 19 10:59:13.828: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Dec 19 10:59:13.828: INFO: kube-apiserver-hiengux9ahcu-1 from kube-system started at 2023-12-19 09:57:29 +0000 UTC (1 container statuses recorded)
  Dec 19 10:59:13.829: INFO: 	Container kube-apiserver ready: true, restart count 1
  Dec 19 10:59:13.829: INFO: kube-controller-manager-hiengux9ahcu-1 from kube-system started at 2023-12-19 09:57:29 +0000 UTC (1 container statuses recorded)
  Dec 19 10:59:13.830: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Dec 19 10:59:13.830: INFO: kube-flannel-ds-8nd22 from kube-system started at 2023-12-19 09:49:46 +0000 UTC (1 container statuses recorded)
  Dec 19 10:59:13.830: INFO: 	Container kube-flannel ready: true, restart count 1
  Dec 19 10:59:13.831: INFO: kube-proxy-lzkkc from kube-system started at 2023-12-19 09:46:48 +0000 UTC (1 container statuses recorded)
  Dec 19 10:59:13.831: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 10:59:13.832: INFO: kube-scheduler-hiengux9ahcu-1 from kube-system started at 2023-12-19 09:57:29 +0000 UTC (1 container statuses recorded)
  Dec 19 10:59:13.832: INFO: 	Container kube-scheduler ready: true, restart count 1
  Dec 19 10:59:13.833: INFO: sonobuoy-systemd-logs-daemon-set-c8f6e06512bd4c62-k4wtt from sonobuoy started at 2023-12-19 10:01:09 +0000 UTC (2 container statuses recorded)
  Dec 19 10:59:13.833: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 10:59:13.833: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec 19 10:59:13.834: INFO: 
  Logging pods the apiserver thinks is on node hiengux9ahcu-2 before test
  Dec 19 10:59:13.849: INFO: coredns-5dd5756b68-d5xhn from kube-system started at 2023-12-19 10:09:21 +0000 UTC (1 container statuses recorded)
  Dec 19 10:59:13.849: INFO: 	Container coredns ready: true, restart count 0
  Dec 19 10:59:13.849: INFO: kube-addon-manager-hiengux9ahcu-2 from kube-system started at 2023-12-19 09:53:01 +0000 UTC (1 container statuses recorded)
  Dec 19 10:59:13.849: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Dec 19 10:59:13.849: INFO: kube-apiserver-hiengux9ahcu-2 from kube-system started at 2023-12-19 09:53:01 +0000 UTC (1 container statuses recorded)
  Dec 19 10:59:13.849: INFO: 	Container kube-apiserver ready: true, restart count 1
  Dec 19 10:59:13.849: INFO: kube-controller-manager-hiengux9ahcu-2 from kube-system started at 2023-12-19 09:53:01 +0000 UTC (1 container statuses recorded)
  Dec 19 10:59:13.849: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Dec 19 10:59:13.849: INFO: kube-flannel-ds-nzb72 from kube-system started at 2023-12-19 09:49:46 +0000 UTC (1 container statuses recorded)
  Dec 19 10:59:13.849: INFO: 	Container kube-flannel ready: true, restart count 1
  Dec 19 10:59:13.849: INFO: kube-proxy-2k68s from kube-system started at 2023-12-19 09:47:35 +0000 UTC (1 container statuses recorded)
  Dec 19 10:59:13.849: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 10:59:13.849: INFO: kube-scheduler-hiengux9ahcu-2 from kube-system started at 2023-12-19 09:53:01 +0000 UTC (1 container statuses recorded)
  Dec 19 10:59:13.849: INFO: 	Container kube-scheduler ready: true, restart count 1
  Dec 19 10:59:13.849: INFO: sonobuoy-systemd-logs-daemon-set-c8f6e06512bd4c62-j8fvw from sonobuoy started at 2023-12-19 10:01:09 +0000 UTC (2 container statuses recorded)
  Dec 19 10:59:13.849: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 10:59:13.849: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec 19 10:59:13.849: INFO: 
  Logging pods the apiserver thinks is on node hiengux9ahcu-3 before test
  Dec 19 10:59:13.865: INFO: kube-flannel-ds-vt8hx from kube-system started at 2023-12-19 10:09:22 +0000 UTC (1 container statuses recorded)
  Dec 19 10:59:13.866: INFO: 	Container kube-flannel ready: true, restart count 0
  Dec 19 10:59:13.867: INFO: kube-proxy-2p94p from kube-system started at 2023-12-19 09:47:58 +0000 UTC (1 container statuses recorded)
  Dec 19 10:59:13.867: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 10:59:13.867: INFO: sonobuoy from sonobuoy started at 2023-12-19 10:00:58 +0000 UTC (1 container statuses recorded)
  Dec 19 10:59:13.868: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Dec 19 10:59:13.868: INFO: sonobuoy-e2e-job-f5f0378b7abe4dc3 from sonobuoy started at 2023-12-19 10:01:09 +0000 UTC (2 container statuses recorded)
  Dec 19 10:59:13.869: INFO: 	Container e2e ready: true, restart count 0
  Dec 19 10:59:13.870: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 10:59:13.870: INFO: sonobuoy-systemd-logs-daemon-set-c8f6e06512bd4c62-fgsng from sonobuoy started at 2023-12-19 10:01:09 +0000 UTC (2 container statuses recorded)
  Dec 19 10:59:13.870: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 10:59:13.871: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 12/19/23 10:59:13.871
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.17a23684fdb9ff45], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling..] @ 12/19/23 10:59:13.939
  E1219 10:59:14.466935      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:14.927: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-3249" for this suite. @ 12/19/23 10:59:14.939
• [1.234 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 12/19/23 10:59:14.97
  Dec 19 10:59:14.970: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename daemonsets @ 12/19/23 10:59:14.976
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:59:15.017
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:59:15.026
  Dec 19 10:59:15.103: INFO: Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/19/23 10:59:15.118
  Dec 19 10:59:15.147: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:59:15.147: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  E1219 10:59:15.467256      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:16.176: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:59:16.176: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  E1219 10:59:16.468287      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:17.166: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec 19 10:59:17.166: INFO: Node hiengux9ahcu-3 is running 0 daemon pod, expected 1
  E1219 10:59:17.468885      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:18.170: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec 19 10:59:18.170: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Update daemon pods image. @ 12/19/23 10:59:18.2
  STEP: Check that daemon pods images are updated. @ 12/19/23 10:59:18.257
  Dec 19 10:59:18.273: INFO: Wrong image for pod: daemon-set-8rq75. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec 19 10:59:18.273: INFO: Wrong image for pod: daemon-set-jfvhq. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec 19 10:59:18.274: INFO: Wrong image for pod: daemon-set-ldhkj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E1219 10:59:18.469174      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:19.451: INFO: Wrong image for pod: daemon-set-8rq75. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec 19 10:59:19.451: INFO: Pod daemon-set-9mfl9 is not available
  Dec 19 10:59:19.451: INFO: Wrong image for pod: daemon-set-ldhkj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E1219 10:59:19.470070      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:20.307: INFO: Wrong image for pod: daemon-set-ldhkj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec 19 10:59:20.307: INFO: Pod daemon-set-thn8x is not available
  E1219 10:59:20.471332      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:21.471755      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:22.307: INFO: Pod daemon-set-5jpnk is not available
  STEP: Check that daemon pods are still running on every node of the cluster. @ 12/19/23 10:59:22.324
  Dec 19 10:59:22.344: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec 19 10:59:22.344: INFO: Node hiengux9ahcu-2 is running 0 daemon pod, expected 1
  E1219 10:59:22.476355      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:23.381: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec 19 10:59:23.381: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  E1219 10:59:23.474693      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting DaemonSet "daemon-set" @ 12/19/23 10:59:23.483
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1261, will wait for the garbage collector to delete the pods @ 12/19/23 10:59:23.484
  Dec 19 10:59:23.573: INFO: Deleting DaemonSet.extensions daemon-set took: 23.13938ms
  Dec 19 10:59:23.675: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.675082ms
  E1219 10:59:24.476082      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:24.887: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 10:59:24.887: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec 19 10:59:24.894: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"17212"},"items":null}

  Dec 19 10:59:24.901: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"17212"},"items":null}

  Dec 19 10:59:24.935: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1261" for this suite. @ 12/19/23 10:59:24.948
• [9.994 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:85
  STEP: Creating a kubernetes client @ 12/19/23 10:59:24.964
  Dec 19 10:59:24.965: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 10:59:24.968
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:59:24.998
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:59:25.006
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 10:59:25.011
  E1219 10:59:25.477911      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:26.481701      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:27.482608      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:28.480907      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:59:29.068
  Dec 19 10:59:29.076: INFO: Trying to get logs from node hiengux9ahcu-3 pod downwardapi-volume-9fd4a59e-a35e-45ec-a064-56648a43ddbe container client-container: <nil>
  STEP: delete the pod @ 12/19/23 10:59:29.093
  Dec 19 10:59:29.142: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3007" for this suite. @ 12/19/23 10:59:29.159
• [4.210 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:110
  STEP: Creating a kubernetes client @ 12/19/23 10:59:29.178
  Dec 19 10:59:29.178: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubelet-test @ 12/19/23 10:59:29.181
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:59:29.222
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:59:29.227
  E1219 10:59:29.481898      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:30.483031      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:31.483210      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:32.483892      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:33.268: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-4123" for this suite. @ 12/19/23 10:59:33.279
• [4.120 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]
test/e2e/apimachinery/webhook.go:646
  STEP: Creating a kubernetes client @ 12/19/23 10:59:33.312
  Dec 19 10:59:33.313: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename webhook @ 12/19/23 10:59:33.317
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:59:33.351
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:59:33.356
  STEP: Setting up server cert @ 12/19/23 10:59:33.403
  E1219 10:59:33.483942      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:34.484084      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 10:59:34.675
  STEP: Deploying the webhook pod @ 12/19/23 10:59:34.709
  STEP: Wait for the deployment to be ready @ 12/19/23 10:59:34.786
  Dec 19 10:59:34.840: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1219 10:59:35.485264      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:36.485938      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 10:59:36.862
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 10:59:36.894
  E1219 10:59:37.486068      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:37.895: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 12/19/23 10:59:38.053
  STEP: Creating a configMap that should be mutated @ 12/19/23 10:59:38.089
  STEP: Deleting the collection of validation webhooks @ 12/19/23 10:59:38.151
  STEP: Creating a configMap that should not be mutated @ 12/19/23 10:59:38.27
  Dec 19 10:59:38.296: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7339" for this suite. @ 12/19/23 10:59:38.399
  STEP: Destroying namespace "webhook-markers-3887" for this suite. @ 12/19/23 10:59:38.415
• [5.131 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance]
test/e2e/common/node/podtemplates.go:176
  STEP: Creating a kubernetes client @ 12/19/23 10:59:38.444
  Dec 19 10:59:38.445: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename podtemplate @ 12/19/23 10:59:38.448
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:59:38.481
  E1219 10:59:38.486832      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:59:38.487
  STEP: Create a pod template @ 12/19/23 10:59:38.491
  STEP: Replace a pod template @ 12/19/23 10:59:38.502
  Dec 19 10:59:38.517: INFO: Found updated podtemplate annotation: "true"

  Dec 19 10:59:38.518: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-9629" for this suite. @ 12/19/23 10:59:38.528
• [0.099 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance]
test/e2e/instrumentation/core_events.go:57
  STEP: Creating a kubernetes client @ 12/19/23 10:59:38.549
  Dec 19 10:59:38.549: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename events @ 12/19/23 10:59:38.553
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:59:38.588
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:59:38.593
  STEP: creating a test event @ 12/19/23 10:59:38.599
  STEP: listing all events in all namespaces @ 12/19/23 10:59:38.607
  STEP: patching the test event @ 12/19/23 10:59:38.623
  STEP: fetching the test event @ 12/19/23 10:59:38.638
  STEP: updating the test event @ 12/19/23 10:59:38.65
  STEP: getting the test event @ 12/19/23 10:59:38.674
  STEP: deleting the test event @ 12/19/23 10:59:38.682
  STEP: listing all events in all namespaces @ 12/19/23 10:59:38.709
  Dec 19 10:59:38.721: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-6682" for this suite. @ 12/19/23 10:59:38.784
• [0.263 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:99
  STEP: Creating a kubernetes client @ 12/19/23 10:59:38.82
  Dec 19 10:59:38.820: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 10:59:38.825
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:59:38.856
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:59:38.862
  STEP: Creating configMap with name projected-configmap-test-volume-map-09c31f21-8db2-4ce2-a5bb-fea97d794127 @ 12/19/23 10:59:38.871
  STEP: Creating a pod to test consume configMaps @ 12/19/23 10:59:38.88
  E1219 10:59:39.488042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:40.488624      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:41.490020      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:42.490128      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:59:42.924
  Dec 19 10:59:42.932: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-projected-configmaps-7f5d63b7-418f-458d-814d-6843bdf6c128 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 10:59:42.949
  Dec 19 10:59:42.983: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4658" for this suite. @ 12/19/23 10:59:42.994
• [4.192 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
test/e2e/node/security_context.go:129
  STEP: Creating a kubernetes client @ 12/19/23 10:59:43.021
  Dec 19 10:59:43.021: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename security-context @ 12/19/23 10:59:43.024
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:59:43.053
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:59:43.058
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 12/19/23 10:59:43.064
  E1219 10:59:43.490811      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:44.491174      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:45.492066      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:46.492428      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 10:59:47.124
  Dec 19 10:59:47.132: INFO: Trying to get logs from node hiengux9ahcu-3 pod security-context-146307b8-07fc-4857-9b3b-f7aa3e26493a container test-container: <nil>
  STEP: delete the pod @ 12/19/23 10:59:47.146
  Dec 19 10:59:47.173: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-6050" for this suite. @ 12/19/23 10:59:47.183
• [4.175 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]
test/e2e/apimachinery/resource_quota.go:101
  STEP: Creating a kubernetes client @ 12/19/23 10:59:47.198
  Dec 19 10:59:47.198: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 10:59:47.201
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:59:47.229
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:59:47.234
  STEP: Counting existing ResourceQuota @ 12/19/23 10:59:47.24
  E1219 10:59:47.493699      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:48.494107      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:49.494527      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:50.494922      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:51.495926      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/19/23 10:59:52.25
  STEP: Ensuring resource quota status is calculated @ 12/19/23 10:59:52.262
  E1219 10:59:52.496279      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:53.496394      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 12/19/23 10:59:54.274
  STEP: Creating a NodePort Service @ 12/19/23 10:59:54.316
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 12/19/23 10:59:54.376
  STEP: Ensuring resource quota status captures service creation @ 12/19/23 10:59:54.439
  E1219 10:59:54.497091      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:55.497362      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 12/19/23 10:59:56.45
  E1219 10:59:56.497863      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota status released usage @ 12/19/23 10:59:56.553
  E1219 10:59:57.498221      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 10:59:58.498574      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 10:59:58.569: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4668" for this suite. @ 12/19/23 10:59:58.586
• [11.406 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]
test/e2e/apps/disruption.go:349
  STEP: Creating a kubernetes client @ 12/19/23 10:59:58.606
  Dec 19 10:59:58.606: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename disruption @ 12/19/23 10:59:58.611
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 10:59:58.651
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 10:59:58.656
  STEP: Creating a pdb that targets all three pods in a test replica set @ 12/19/23 10:59:58.662
  STEP: Waiting for the pdb to be processed @ 12/19/23 10:59:58.675
  E1219 10:59:59.498780      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:00.499519      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: First trying to evict a pod which shouldn't be evictable @ 12/19/23 11:00:00.719
  STEP: Waiting for all pods to be running @ 12/19/23 11:00:00.72
  Dec 19 11:00:00.729: INFO: pods: 0 < 3
  E1219 11:00:01.499869      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:02.499998      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 12/19/23 11:00:02.741
  STEP: Updating the pdb to allow a pod to be evicted @ 12/19/23 11:00:02.825
  STEP: Waiting for the pdb to be processed @ 12/19/23 11:00:02.839
  E1219 11:00:03.501038      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:04.501878      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 12/19/23 11:00:04.862
  STEP: Waiting for all pods to be running @ 12/19/23 11:00:04.862
  STEP: Waiting for the pdb to observed all healthy pods @ 12/19/23 11:00:04.874
  STEP: Patching the pdb to disallow a pod to be evicted @ 12/19/23 11:00:04.952
  STEP: Waiting for the pdb to be processed @ 12/19/23 11:00:05.01
  E1219 11:00:05.502339      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:06.503451      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 12/19/23 11:00:07.034
  STEP: locating a running pod @ 12/19/23 11:00:07.044
  STEP: Deleting the pdb to allow a pod to be evicted @ 12/19/23 11:00:07.069
  STEP: Waiting for the pdb to be deleted @ 12/19/23 11:00:07.082
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 12/19/23 11:00:07.088
  STEP: Waiting for all pods to be running @ 12/19/23 11:00:07.088
  Dec 19 11:00:07.134: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-3912" for this suite. @ 12/19/23 11:00:07.15
• [8.568 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance]
test/e2e/network/service.go:1280
  STEP: Creating a kubernetes client @ 12/19/23 11:00:07.176
  Dec 19 11:00:07.176: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename services @ 12/19/23 11:00:07.18
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:00:07.225
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:00:07.232
  STEP: creating service nodeport-test with type=NodePort in namespace services-2086 @ 12/19/23 11:00:07.238
  STEP: creating replication controller nodeport-test in namespace services-2086 @ 12/19/23 11:00:07.277
  I1219 11:00:07.316313      14 runners.go:197] Created replication controller with name: nodeport-test, namespace: services-2086, replica count: 2
  E1219 11:00:07.504105      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:08.504975      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:09.506520      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 11:00:10.368013      14 runners.go:197] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec 19 11:00:10.368: INFO: Creating new exec pod
  E1219 11:00:10.505978      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:11.506061      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:12.506678      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:00:13.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-2086 exec execpod7n8vz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  E1219 11:00:13.507500      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:00:13.870: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  Dec 19 11:00:13.870: INFO: stdout: "nodeport-test-b486g"
  Dec 19 11:00:13.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-2086 exec execpod7n8vz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.20.24 80'
  Dec 19 11:00:14.158: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.20.24 80\nConnection to 10.233.20.24 80 port [tcp/http] succeeded!\n"
  Dec 19 11:00:14.158: INFO: stdout: ""
  E1219 11:00:14.508042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:00:15.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-2086 exec execpod7n8vz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.20.24 80'
  E1219 11:00:15.508319      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:00:15.546: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.20.24 80\nConnection to 10.233.20.24 80 port [tcp/http] succeeded!\n"
  Dec 19 11:00:15.546: INFO: stdout: "nodeport-test-b486g"
  Dec 19 11:00:15.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-2086 exec execpod7n8vz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.17 31324'
  Dec 19 11:00:15.823: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.17 31324\nConnection to 192.168.121.17 31324 port [tcp/*] succeeded!\n"
  Dec 19 11:00:15.823: INFO: stdout: "nodeport-test-b486g"
  Dec 19 11:00:15.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-2086 exec execpod7n8vz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.83 31324'
  Dec 19 11:00:16.108: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.83 31324\nConnection to 192.168.121.83 31324 port [tcp/*] succeeded!\n"
  Dec 19 11:00:16.108: INFO: stdout: "nodeport-test-b486g"
  Dec 19 11:00:16.109: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2086" for this suite. @ 12/19/23 11:00:16.12
• [8.959 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:99
  STEP: Creating a kubernetes client @ 12/19/23 11:00:16.144
  Dec 19 11:00:16.144: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename configmap @ 12/19/23 11:00:16.149
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:00:16.197
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:00:16.206
  STEP: Creating configMap with name configmap-test-volume-map-be79ad65-ec8b-4b55-8935-3de099e04aa1 @ 12/19/23 11:00:16.214
  STEP: Creating a pod to test consume configMaps @ 12/19/23 11:00:16.227
  E1219 11:00:16.508360      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:17.509259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:18.509540      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:19.509979      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:00:20.294
  Dec 19 11:00:20.308: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-configmaps-f5185f60-7fb8-437b-9b6c-7b3dd5508703 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 11:00:20.323
  Dec 19 11:00:20.358: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-889" for this suite. @ 12/19/23 11:00:20.37
• [4.240 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]
test/e2e/apimachinery/webhook.go:315
  STEP: Creating a kubernetes client @ 12/19/23 11:00:20.385
  Dec 19 11:00:20.385: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename webhook @ 12/19/23 11:00:20.388
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:00:20.414
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:00:20.422
  STEP: Setting up server cert @ 12/19/23 11:00:20.478
  E1219 11:00:20.510038      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 11:00:21.091
  STEP: Deploying the webhook pod @ 12/19/23 11:00:21.108
  STEP: Wait for the deployment to be ready @ 12/19/23 11:00:21.156
  Dec 19 11:00:21.184: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1219 11:00:21.510272      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:22.511201      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:00:23.222
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:00:23.241
  E1219 11:00:23.512328      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:00:24.242: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Dec 19 11:00:24.259: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 11:00:24.513395      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8211-crds.webhook.example.com via the AdmissionRegistration API @ 12/19/23 11:00:24.826
  STEP: Creating a custom resource while v1 is storage version @ 12/19/23 11:00:24.874
  E1219 11:00:25.514298      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:26.514687      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Patching Custom Resource Definition to set v2 as storage @ 12/19/23 11:00:27.196
  STEP: Patching the custom resource while v2 is storage version @ 12/19/23 11:00:27.234
  E1219 11:00:27.515819      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:00:27.554: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3734" for this suite. @ 12/19/23 11:00:28.245
  STEP: Destroying namespace "webhook-markers-7349" for this suite. @ 12/19/23 11:00:28.262
• [7.891 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]
test/e2e/kubectl/kubectl.go:1342
  STEP: Creating a kubernetes client @ 12/19/23 11:00:28.286
  Dec 19 11:00:28.286: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 11:00:28.289
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:00:28.327
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:00:28.334
  Dec 19 11:00:28.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-2420 create -f -'
  E1219 11:00:28.515983      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:00:29.018: INFO: stderr: ""
  Dec 19 11:00:29.019: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  Dec 19 11:00:29.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-2420 create -f -'
  E1219 11:00:29.517059      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:00:30.343: INFO: stderr: ""
  Dec 19 11:00:30.343: INFO: stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 12/19/23 11:00:30.343
  E1219 11:00:30.518131      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:00:31.354: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec 19 11:00:31.354: INFO: Found 1 / 1
  Dec 19 11:00:31.355: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Dec 19 11:00:31.361: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec 19 11:00:31.361: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Dec 19 11:00:31.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-2420 describe pod agnhost-primary-kgltd'
  E1219 11:00:31.519000      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:00:31.578: INFO: stderr: ""
  Dec 19 11:00:31.578: INFO: stdout: "Name:             agnhost-primary-kgltd\nNamespace:        kubectl-2420\nPriority:         0\nService Account:  default\nNode:             hiengux9ahcu-3/192.168.121.172\nStart Time:       Tue, 19 Dec 2023 11:00:29 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.233.66.198\nIPs:\n  IP:           10.233.66.198\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   cri-o://1b3525e46c6d5c2ea6e94cffb7854e9f2b76e3d2b134deb1ef4ec73b1ab462e6\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.45\n    Image ID:       077cda6b1f5995dcc056c00f92d40b5147132839f522d46d9ca84acd44ad76a7\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 19 Dec 2023 11:00:29 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-5njhl (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-5njhl:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-2420/agnhost-primary-kgltd to hiengux9ahcu-3\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.45\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    2s    kubelet            Started container agnhost-primary\n"
  Dec 19 11:00:31.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-2420 describe rc agnhost-primary'
  Dec 19 11:00:31.790: INFO: stderr: ""
  Dec 19 11:00:31.790: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-2420\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.45\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-kgltd\n"
  Dec 19 11:00:31.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-2420 describe service agnhost-primary'
  Dec 19 11:00:31.968: INFO: stderr: ""
  Dec 19 11:00:31.968: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-2420\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.233.36.13\nIPs:               10.233.36.13\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.233.66.198:6379\nSession Affinity:  None\nEvents:            <none>\n"
  Dec 19 11:00:31.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-2420 describe node hiengux9ahcu-1'
  Dec 19 11:00:32.207: INFO: stderr: ""
  Dec 19 11:00:32.208: INFO: stdout: "Name:               hiengux9ahcu-1\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=hiengux9ahcu-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"9a:2c:50:55:1e:6a\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.121.83\n                    kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/crio/crio.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 19 Dec 2023 09:46:29 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  hiengux9ahcu-1\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 19 Dec 2023 11:00:30 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 19 Dec 2023 09:58:36 +0000   Tue, 19 Dec 2023 09:58:36 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Tue, 19 Dec 2023 10:56:03 +0000   Tue, 19 Dec 2023 09:46:19 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 19 Dec 2023 10:56:03 +0000   Tue, 19 Dec 2023 09:46:19 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 19 Dec 2023 10:56:03 +0000   Tue, 19 Dec 2023 09:46:19 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 19 Dec 2023 10:56:03 +0000   Tue, 19 Dec 2023 09:50:16 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  192.168.121.83\n  Hostname:    hiengux9ahcu-1\nCapacity:\n  cpu:                    2\n  ephemeral-storage:      115008636Ki\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 8123976Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nAllocatable:\n  cpu:                    1600m\n  ephemeral-storage:      111880401014\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 3274312Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nSystem Info:\n  Machine ID:                 0f234b7053a647aea0cbcb76f62dd119\n  System UUID:                0f234b70-53a6-47ae-a0cb-cb76f62dd119\n  Boot ID:                    6c6eb5c0-1e27-4a5a-860a-e3742d20116f\n  Kernel Version:             6.2.0-39-generic\n  OS Image:                   Ubuntu 22.04.3 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  cri-o://1.28.2\n  Kubelet Version:            v1.28.4\n  Kube-Proxy Version:         v1.28.4\nPodCIDR:                      10.233.64.0/24\nPodCIDRs:                     10.233.64.0/24\nNon-terminated Pods:          (8 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 coredns-5dd5756b68-z5h65                                   100m (6%)     0 (0%)      70Mi (2%)        170Mi (5%)     51m\n  kube-system                 kube-addon-manager-hiengux9ahcu-1                          5m (0%)       0 (0%)      50Mi (1%)        0 (0%)         70m\n  kube-system                 kube-apiserver-hiengux9ahcu-1                              250m (15%)    0 (0%)      0 (0%)           0 (0%)         73m\n  kube-system                 kube-controller-manager-hiengux9ahcu-1                     200m (12%)    0 (0%)      0 (0%)           0 (0%)         73m\n  kube-system                 kube-flannel-ds-8nd22                                      100m (6%)     0 (0%)      50Mi (1%)        0 (0%)         70m\n  kube-system                 kube-proxy-lzkkc                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         73m\n  kube-system                 kube-scheduler-hiengux9ahcu-1                              100m (6%)     0 (0%)      0 (0%)           0 (0%)         73m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-c8f6e06512bd4c62-k4wtt    0 (0%)        0 (0%)      0 (0%)           0 (0%)         59m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource               Requests    Limits\n  --------               --------    ------\n  cpu                    755m (47%)  0 (0%)\n  memory                 170Mi (5%)  170Mi (5%)\n  ephemeral-storage      0 (0%)      0 (0%)\n  hugepages-1Gi          0 (0%)      0 (0%)\n  hugepages-2Mi          0 (0%)      0 (0%)\n  scheduling.k8s.io/foo  0           0\nEvents:                  <none>\n"
  Dec 19 11:00:32.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-2420 describe namespace kubectl-2420'
  Dec 19 11:00:32.423: INFO: stderr: ""
  Dec 19 11:00:32.423: INFO: stdout: "Name:         kubectl-2420\nLabels:       e2e-framework=kubectl\n              e2e-run=e1bc3cfb-3863-4649-bff3-a9b53002ab1b\n              kubernetes.io/metadata.name=kubectl-2420\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  Dec 19 11:00:32.423: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2420" for this suite. @ 12/19/23 11:00:32.432
• [4.161 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
test/e2e/common/node/expansion.go:155
  STEP: Creating a kubernetes client @ 12/19/23 11:00:32.448
  Dec 19 11:00:32.448: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename var-expansion @ 12/19/23 11:00:32.452
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:00:32.486
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:00:32.494
  E1219 11:00:32.520446      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:33.520617      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:34.521261      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:00:34.549: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec 19 11:00:34.561: INFO: Deleting pod "var-expansion-e2188192-1042-4075-8ac6-a7800fe95dab" in namespace "var-expansion-9239"
  Dec 19 11:00:34.579: INFO: Wait up to 5m0s for pod "var-expansion-e2188192-1042-4075-8ac6-a7800fe95dab" to be fully deleted
  E1219 11:00:35.521466      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:36.521841      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "var-expansion-9239" for this suite. @ 12/19/23 11:00:36.601
• [4.169 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]
test/e2e/kubectl/kubectl.go:1641
  STEP: Creating a kubernetes client @ 12/19/23 11:00:36.623
  Dec 19 11:00:36.623: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 11:00:36.626
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:00:36.661
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:00:36.666
  STEP: creating Agnhost RC @ 12/19/23 11:00:36.674
  Dec 19 11:00:36.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-9622 create -f -'
  Dec 19 11:00:37.192: INFO: stderr: ""
  Dec 19 11:00:37.192: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 12/19/23 11:00:37.193
  E1219 11:00:37.523020      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:00:38.204: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec 19 11:00:38.204: INFO: Found 0 / 1
  E1219 11:00:38.522996      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:00:39.201: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec 19 11:00:39.201: INFO: Found 1 / 1
  Dec 19 11:00:39.201: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 12/19/23 11:00:39.202
  Dec 19 11:00:39.211: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec 19 11:00:39.211: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Dec 19 11:00:39.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-9622 patch pod agnhost-primary-2wdv6 -p {"metadata":{"annotations":{"x":"y"}}}'
  E1219 11:00:39.523763      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:00:39.536: INFO: stderr: ""
  Dec 19 11:00:39.536: INFO: stdout: "pod/agnhost-primary-2wdv6 patched\n"
  STEP: checking annotations @ 12/19/23 11:00:39.536
  Dec 19 11:00:39.549: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec 19 11:00:39.549: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Dec 19 11:00:39.550: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9622" for this suite. @ 12/19/23 11:00:39.566
• [2.961 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 12/19/23 11:00:39.599
  Dec 19 11:00:39.599: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename secrets @ 12/19/23 11:00:39.603
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:00:39.638
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:00:39.643
  STEP: Creating secret with name secret-test-map-ff33f822-df69-43e7-b41e-1e773fdb0456 @ 12/19/23 11:00:39.648
  STEP: Creating a pod to test consume secrets @ 12/19/23 11:00:39.658
  E1219 11:00:40.533982      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:41.536078      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:42.540621      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:43.537453      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:00:43.713
  Dec 19 11:00:43.725: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-secrets-afb29b42-ac30-4a31-ad9a-31de602ce72f container secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 11:00:43.75
  Dec 19 11:00:43.786: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1399" for this suite. @ 12/19/23 11:00:43.803
• [4.220 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]
test/e2e/kubectl/kubectl.go:1707
  STEP: Creating a kubernetes client @ 12/19/23 11:00:43.825
  Dec 19 11:00:43.825: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 11:00:43.832
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:00:43.863
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:00:43.87
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 12/19/23 11:00:43.875
  Dec 19 11:00:43.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-2428 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  Dec 19 11:00:44.079: INFO: stderr: ""
  Dec 19 11:00:44.079: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 12/19/23 11:00:44.079
  Dec 19 11:00:44.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-2428 delete pods e2e-test-httpd-pod'
  E1219 11:00:44.537666      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:45.537830      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:00:45.653: INFO: stderr: ""
  Dec 19 11:00:45.653: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Dec 19 11:00:45.653: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2428" for this suite. @ 12/19/23 11:00:45.666
• [1.859 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]
test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 12/19/23 11:00:45.685
  Dec 19 11:00:45.685: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename subpath @ 12/19/23 11:00:45.688
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:00:45.718
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:00:45.725
  STEP: Setting up data @ 12/19/23 11:00:45.73
  STEP: Creating pod pod-subpath-test-secret-lrvq @ 12/19/23 11:00:45.748
  STEP: Creating a pod to test atomic-volume-subpath @ 12/19/23 11:00:45.749
  E1219 11:00:46.539104      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:47.540111      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:48.540376      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:49.541045      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:50.541323      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:51.541532      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:52.541896      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:53.541827      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:54.542659      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:55.542861      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:56.543879      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:57.544732      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:58.545250      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:00:59.546517      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:00.546246      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:01.546594      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:02.547240      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:03.548146      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:04.548742      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:05.549603      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:06.550632      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:07.550979      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:08.551868      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:09.552496      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:01:09.882
  Dec 19 11:01:09.889: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-subpath-test-secret-lrvq container test-container-subpath-secret-lrvq: <nil>
  STEP: delete the pod @ 12/19/23 11:01:09.906
  STEP: Deleting pod pod-subpath-test-secret-lrvq @ 12/19/23 11:01:09.93
  Dec 19 11:01:09.931: INFO: Deleting pod "pod-subpath-test-secret-lrvq" in namespace "subpath-3705"
  Dec 19 11:01:09.938: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3705" for this suite. @ 12/19/23 11:01:09.947
• [24.280 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]
test/e2e/apps/replica_set.go:176
  STEP: Creating a kubernetes client @ 12/19/23 11:01:09.972
  Dec 19 11:01:09.972: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename replicaset @ 12/19/23 11:01:09.975
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:01:10.008
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:01:10.014
  STEP: Create a Replicaset @ 12/19/23 11:01:10.027
  STEP: Verify that the required pods have come up. @ 12/19/23 11:01:10.037
  Dec 19 11:01:10.046: INFO: Pod name sample-pod: Found 0 pods out of 1
  E1219 11:01:10.552600      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:11.553791      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:12.554037      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:13.557262      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:14.557507      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:01:15.067: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/19/23 11:01:15.067
  STEP: Getting /status @ 12/19/23 11:01:15.067
  Dec 19 11:01:15.083: INFO: Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 12/19/23 11:01:15.084
  Dec 19 11:01:15.110: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 12/19/23 11:01:15.111
  Dec 19 11:01:15.117: INFO: Observed &ReplicaSet event: ADDED
  Dec 19 11:01:15.118: INFO: Observed &ReplicaSet event: MODIFIED
  Dec 19 11:01:15.118: INFO: Observed &ReplicaSet event: MODIFIED
  Dec 19 11:01:15.118: INFO: Observed &ReplicaSet event: MODIFIED
  Dec 19 11:01:15.118: INFO: Found replicaset test-rs in namespace replicaset-6812 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Dec 19 11:01:15.119: INFO: Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 12/19/23 11:01:15.119
  Dec 19 11:01:15.119: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Dec 19 11:01:15.138: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 12/19/23 11:01:15.139
  Dec 19 11:01:15.146: INFO: Observed &ReplicaSet event: ADDED
  Dec 19 11:01:15.146: INFO: Observed &ReplicaSet event: MODIFIED
  Dec 19 11:01:15.147: INFO: Observed &ReplicaSet event: MODIFIED
  Dec 19 11:01:15.148: INFO: Observed &ReplicaSet event: MODIFIED
  Dec 19 11:01:15.148: INFO: Observed replicaset test-rs in namespace replicaset-6812 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec 19 11:01:15.148: INFO: Observed &ReplicaSet event: MODIFIED
  Dec 19 11:01:15.148: INFO: Found replicaset test-rs in namespace replicaset-6812 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  Dec 19 11:01:15.149: INFO: Replicaset test-rs has a patched status
  Dec 19 11:01:15.149: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-6812" for this suite. @ 12/19/23 11:01:15.162
• [5.213 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]
test/e2e/apimachinery/webhook.go:238
  STEP: Creating a kubernetes client @ 12/19/23 11:01:15.204
  Dec 19 11:01:15.204: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename webhook @ 12/19/23 11:01:15.209
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:01:15.241
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:01:15.249
  STEP: Setting up server cert @ 12/19/23 11:01:15.294
  E1219 11:01:15.557771      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 11:01:15.937
  STEP: Deploying the webhook pod @ 12/19/23 11:01:15.966
  STEP: Wait for the deployment to be ready @ 12/19/23 11:01:15.995
  Dec 19 11:01:16.013: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1219 11:01:16.559902      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:17.560660      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:01:18.038: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 1, 16, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 1, 16, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 1, 16, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 1, 16, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:01:18.561118      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:19.561772      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:01:20.047
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:01:20.068
  E1219 11:01:20.562600      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:01:21.069: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 12/19/23 11:01:21.088
  STEP: create a namespace for the webhook @ 12/19/23 11:01:21.13
  STEP: create a configmap should be unconditionally rejected by the webhook @ 12/19/23 11:01:21.165
  Dec 19 11:01:21.210: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2702" for this suite. @ 12/19/23 11:01:21.344
  STEP: Destroying namespace "webhook-markers-1767" for this suite. @ 12/19/23 11:01:21.378
  STEP: Destroying namespace "fail-closed-namespace-5238" for this suite. @ 12/19/23 11:01:21.406
• [6.229 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:398
  STEP: Creating a kubernetes client @ 12/19/23 11:01:21.439
  Dec 19 11:01:21.439: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename namespaces @ 12/19/23 11:01:21.444
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:01:21.484
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:01:21.49
  STEP: Creating namespace "e2e-ns-c8m95" @ 12/19/23 11:01:21.497
  Dec 19 11:01:21.529: INFO: Namespace "e2e-ns-c8m95-9722" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-c8m95-9722" @ 12/19/23 11:01:21.529
  E1219 11:01:21.562524      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:01:21.592: INFO: Namespace "e2e-ns-c8m95-9722" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-c8m95-9722" @ 12/19/23 11:01:21.593
  Dec 19 11:01:21.676: INFO: Namespace "e2e-ns-c8m95-9722" has []v1.FinalizerName{"kubernetes"}
  Dec 19 11:01:21.676: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-740" for this suite. @ 12/19/23 11:01:21.7
  STEP: Destroying namespace "e2e-ns-c8m95-9722" for this suite. @ 12/19/23 11:01:21.716
• [0.293 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]
test/e2e/apimachinery/namespace.go:252
  STEP: Creating a kubernetes client @ 12/19/23 11:01:21.732
  Dec 19 11:01:21.732: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename namespaces @ 12/19/23 11:01:21.735
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:01:21.762
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:01:21.767
  STEP: Creating a test namespace @ 12/19/23 11:01:21.772
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:01:21.805
  STEP: Creating a service in the namespace @ 12/19/23 11:01:21.811
  STEP: Deleting the namespace @ 12/19/23 11:01:21.835
  STEP: Waiting for the namespace to be removed. @ 12/19/23 11:01:21.853
  E1219 11:01:22.563534      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:23.564091      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:24.565556      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:25.565221      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:26.566016      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:27.566012      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:28.566189      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 12/19/23 11:01:28.862
  STEP: Verifying there is no service in the namespace @ 12/19/23 11:01:28.889
  Dec 19 11:01:28.897: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-7874" for this suite. @ 12/19/23 11:01:28.91
  STEP: Destroying namespace "nsdeletetest-9373" for this suite. @ 12/19/23 11:01:28.928
  Dec 19 11:01:28.936: INFO: Namespace nsdeletetest-9373 was already deleted
  STEP: Destroying namespace "nsdeletetest-4530" for this suite. @ 12/19/23 11:01:28.936
• [7.216 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:85
  STEP: Creating a kubernetes client @ 12/19/23 11:01:28.951
  Dec 19 11:01:28.952: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename custom-resource-definition @ 12/19/23 11:01:28.955
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:01:28.982
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:01:28.99
  Dec 19 11:01:28.995: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 11:01:29.566677      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:30.567774      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:31.568628      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:32.569513      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:33.570769      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:34.571707      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:01:35.499: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-2713" for this suite. @ 12/19/23 11:01:35.51
• [6.579 seconds]
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]
test/e2e/scheduling/predicates.go:467
  STEP: Creating a kubernetes client @ 12/19/23 11:01:35.532
  Dec 19 11:01:35.532: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename sched-pred @ 12/19/23 11:01:35.535
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:01:35.571
  E1219 11:01:35.572136      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:01:35.579
  Dec 19 11:01:35.584: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Dec 19 11:01:35.605: INFO: Waiting for terminating namespaces to be deleted...
  Dec 19 11:01:35.611: INFO: 
  Logging pods the apiserver thinks is on node hiengux9ahcu-1 before test
  Dec 19 11:01:35.631: INFO: coredns-5dd5756b68-z5h65 from kube-system started at 2023-12-19 10:09:21 +0000 UTC (1 container statuses recorded)
  Dec 19 11:01:35.631: INFO: 	Container coredns ready: true, restart count 0
  Dec 19 11:01:35.631: INFO: kube-addon-manager-hiengux9ahcu-1 from kube-system started at 2023-12-19 09:57:29 +0000 UTC (1 container statuses recorded)
  Dec 19 11:01:35.631: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Dec 19 11:01:35.631: INFO: kube-apiserver-hiengux9ahcu-1 from kube-system started at 2023-12-19 09:57:29 +0000 UTC (1 container statuses recorded)
  Dec 19 11:01:35.631: INFO: 	Container kube-apiserver ready: true, restart count 1
  Dec 19 11:01:35.631: INFO: kube-controller-manager-hiengux9ahcu-1 from kube-system started at 2023-12-19 09:57:29 +0000 UTC (1 container statuses recorded)
  Dec 19 11:01:35.631: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Dec 19 11:01:35.631: INFO: kube-flannel-ds-8nd22 from kube-system started at 2023-12-19 09:49:46 +0000 UTC (1 container statuses recorded)
  Dec 19 11:01:35.631: INFO: 	Container kube-flannel ready: true, restart count 1
  Dec 19 11:01:35.631: INFO: kube-proxy-lzkkc from kube-system started at 2023-12-19 09:46:48 +0000 UTC (1 container statuses recorded)
  Dec 19 11:01:35.631: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 11:01:35.631: INFO: kube-scheduler-hiengux9ahcu-1 from kube-system started at 2023-12-19 09:57:29 +0000 UTC (1 container statuses recorded)
  Dec 19 11:01:35.631: INFO: 	Container kube-scheduler ready: true, restart count 1
  Dec 19 11:01:35.631: INFO: sonobuoy-systemd-logs-daemon-set-c8f6e06512bd4c62-k4wtt from sonobuoy started at 2023-12-19 10:01:09 +0000 UTC (2 container statuses recorded)
  Dec 19 11:01:35.631: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 11:01:35.631: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec 19 11:01:35.631: INFO: 
  Logging pods the apiserver thinks is on node hiengux9ahcu-2 before test
  Dec 19 11:01:35.650: INFO: coredns-5dd5756b68-d5xhn from kube-system started at 2023-12-19 10:09:21 +0000 UTC (1 container statuses recorded)
  Dec 19 11:01:35.650: INFO: 	Container coredns ready: true, restart count 0
  Dec 19 11:01:35.650: INFO: kube-addon-manager-hiengux9ahcu-2 from kube-system started at 2023-12-19 09:53:01 +0000 UTC (1 container statuses recorded)
  Dec 19 11:01:35.650: INFO: 	Container kube-addon-manager ready: true, restart count 1
  Dec 19 11:01:35.650: INFO: kube-apiserver-hiengux9ahcu-2 from kube-system started at 2023-12-19 09:53:01 +0000 UTC (1 container statuses recorded)
  Dec 19 11:01:35.650: INFO: 	Container kube-apiserver ready: true, restart count 1
  Dec 19 11:01:35.650: INFO: kube-controller-manager-hiengux9ahcu-2 from kube-system started at 2023-12-19 09:53:01 +0000 UTC (1 container statuses recorded)
  Dec 19 11:01:35.650: INFO: 	Container kube-controller-manager ready: true, restart count 1
  Dec 19 11:01:35.650: INFO: kube-flannel-ds-nzb72 from kube-system started at 2023-12-19 09:49:46 +0000 UTC (1 container statuses recorded)
  Dec 19 11:01:35.650: INFO: 	Container kube-flannel ready: true, restart count 1
  Dec 19 11:01:35.650: INFO: kube-proxy-2k68s from kube-system started at 2023-12-19 09:47:35 +0000 UTC (1 container statuses recorded)
  Dec 19 11:01:35.650: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 11:01:35.650: INFO: kube-scheduler-hiengux9ahcu-2 from kube-system started at 2023-12-19 09:53:01 +0000 UTC (1 container statuses recorded)
  Dec 19 11:01:35.650: INFO: 	Container kube-scheduler ready: true, restart count 1
  Dec 19 11:01:35.651: INFO: sonobuoy-systemd-logs-daemon-set-c8f6e06512bd4c62-j8fvw from sonobuoy started at 2023-12-19 10:01:09 +0000 UTC (2 container statuses recorded)
  Dec 19 11:01:35.651: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 11:01:35.651: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec 19 11:01:35.651: INFO: 
  Logging pods the apiserver thinks is on node hiengux9ahcu-3 before test
  Dec 19 11:01:35.669: INFO: kube-flannel-ds-vt8hx from kube-system started at 2023-12-19 10:09:22 +0000 UTC (1 container statuses recorded)
  Dec 19 11:01:35.670: INFO: 	Container kube-flannel ready: true, restart count 0
  Dec 19 11:01:35.671: INFO: kube-proxy-2p94p from kube-system started at 2023-12-19 09:47:58 +0000 UTC (1 container statuses recorded)
  Dec 19 11:01:35.671: INFO: 	Container kube-proxy ready: true, restart count 1
  Dec 19 11:01:35.672: INFO: sonobuoy from sonobuoy started at 2023-12-19 10:00:58 +0000 UTC (1 container statuses recorded)
  Dec 19 11:01:35.672: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Dec 19 11:01:35.672: INFO: sonobuoy-e2e-job-f5f0378b7abe4dc3 from sonobuoy started at 2023-12-19 10:01:09 +0000 UTC (2 container statuses recorded)
  Dec 19 11:01:35.673: INFO: 	Container e2e ready: true, restart count 0
  Dec 19 11:01:35.673: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 11:01:35.674: INFO: sonobuoy-systemd-logs-daemon-set-c8f6e06512bd4c62-fgsng from sonobuoy started at 2023-12-19 10:01:09 +0000 UTC (2 container statuses recorded)
  Dec 19 11:01:35.674: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec 19 11:01:35.675: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 12/19/23 11:01:35.676
  E1219 11:01:36.572163      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:37.572974      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 12/19/23 11:01:37.722
  STEP: Trying to apply a random label on the found node. @ 12/19/23 11:01:37.757
  STEP: verifying the node has the label kubernetes.io/e2e-d2156851-eb5a-44e6-b413-e457b6620148 42 @ 12/19/23 11:01:37.839
  STEP: Trying to relaunch the pod, now with labels. @ 12/19/23 11:01:37.853
  E1219 11:01:38.573309      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:39.574241      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-d2156851-eb5a-44e6-b413-e457b6620148 off the node hiengux9ahcu-3 @ 12/19/23 11:01:39.891
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-d2156851-eb5a-44e6-b413-e457b6620148 @ 12/19/23 11:01:39.92
  Dec 19 11:01:39.932: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-1480" for this suite. @ 12/19/23 11:01:39.946
• [4.437 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:89
  STEP: Creating a kubernetes client @ 12/19/23 11:01:39.982
  Dec 19 11:01:39.982: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:01:39.987
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:01:40.019
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:01:40.026
  STEP: Creating configMap with name projected-configmap-test-volume-map-1cd35970-2a44-449b-b81f-8a734c3c79eb @ 12/19/23 11:01:40.035
  STEP: Creating a pod to test consume configMaps @ 12/19/23 11:01:40.045
  E1219 11:01:40.574439      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:41.574636      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:42.575460      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:43.575800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:01:44.117
  Dec 19 11:01:44.125: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-projected-configmaps-86f3a52f-4852-4076-90b8-ff632210f448 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 11:01:44.143
  Dec 19 11:01:44.176: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3580" for this suite. @ 12/19/23 11:01:44.188
• [4.222 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]
test/e2e/apimachinery/resource_quota.go:395
  STEP: Creating a kubernetes client @ 12/19/23 11:01:44.206
  Dec 19 11:01:44.206: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 11:01:44.209
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:01:44.246
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:01:44.253
  STEP: Counting existing ResourceQuota @ 12/19/23 11:01:44.261
  E1219 11:01:44.576469      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:45.577162      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:46.577867      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:47.578797      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:48.579330      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/19/23 11:01:49.269
  STEP: Ensuring resource quota status is calculated @ 12/19/23 11:01:49.283
  E1219 11:01:49.579724      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:50.579935      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicationController @ 12/19/23 11:01:51.292
  STEP: Ensuring resource quota status captures replication controller creation @ 12/19/23 11:01:51.33
  E1219 11:01:51.580928      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:52.582992      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicationController @ 12/19/23 11:01:53.342
  STEP: Ensuring resource quota status released usage @ 12/19/23 11:01:53.358
  E1219 11:01:53.582132      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:54.583040      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:01:55.401: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5730" for this suite. @ 12/19/23 11:01:55.412
• [11.225 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]
test/e2e/network/ingressclass.go:266
  STEP: Creating a kubernetes client @ 12/19/23 11:01:55.434
  Dec 19 11:01:55.434: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename ingressclass @ 12/19/23 11:01:55.441
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:01:55.482
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:01:55.489
  STEP: getting /apis @ 12/19/23 11:01:55.498
  STEP: getting /apis/networking.k8s.io @ 12/19/23 11:01:55.513
  STEP: getting /apis/networking.k8s.iov1 @ 12/19/23 11:01:55.518
  STEP: creating @ 12/19/23 11:01:55.522
  STEP: getting @ 12/19/23 11:01:55.555
  STEP: listing @ 12/19/23 11:01:55.565
  STEP: watching @ 12/19/23 11:01:55.573
  Dec 19 11:01:55.573: INFO: starting watch
  STEP: patching @ 12/19/23 11:01:55.574
  E1219 11:01:55.583833      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating @ 12/19/23 11:01:55.584
  Dec 19 11:01:55.595: INFO: waiting for watch events with expected annotations
  Dec 19 11:01:55.595: INFO: saw patched and updated annotations
  STEP: deleting @ 12/19/23 11:01:55.595
  STEP: deleting a collection @ 12/19/23 11:01:55.621
  Dec 19 11:01:55.657: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-6485" for this suite. @ 12/19/23 11:01:55.669
• [0.249 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]
test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 12/19/23 11:01:55.694
  Dec 19 11:01:55.694: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename tables @ 12/19/23 11:01:55.697
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:01:55.736
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:01:55.742
  Dec 19 11:01:55.753: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-5737" for this suite. @ 12/19/23 11:01:55.766
• [0.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:76
  STEP: Creating a kubernetes client @ 12/19/23 11:01:55.793
  Dec 19 11:01:55.793: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename var-expansion @ 12/19/23 11:01:55.797
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:01:55.834
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:01:55.848
  STEP: Creating a pod to test substitution in container's command @ 12/19/23 11:01:55.854
  E1219 11:01:56.584980      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:57.586206      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:58.587165      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:01:59.587503      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:01:59.934
  Dec 19 11:01:59.940: INFO: Trying to get logs from node hiengux9ahcu-3 pod var-expansion-9b2eb12b-ff52-4047-a996-400789921ff8 container dapi-container: <nil>
  STEP: delete the pod @ 12/19/23 11:01:59.958
  Dec 19 11:01:59.995: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1162" for this suite. @ 12/19/23 11:02:00.004
• [4.225 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]
test/e2e/apps/replica_set.go:111
  STEP: Creating a kubernetes client @ 12/19/23 11:02:00.023
  Dec 19 11:02:00.023: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename replicaset @ 12/19/23 11:02:00.026
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:02:00.056
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:02:00.062
  Dec 19 11:02:00.067: INFO: Creating ReplicaSet my-hostname-basic-29b9f332-9b8b-42a5-83dc-04dee099f404
  Dec 19 11:02:00.085: INFO: Pod name my-hostname-basic-29b9f332-9b8b-42a5-83dc-04dee099f404: Found 0 pods out of 1
  E1219 11:02:00.587800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:01.588769      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:02.589191      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:03.603521      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:04.594216      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:02:05.097: INFO: Pod name my-hostname-basic-29b9f332-9b8b-42a5-83dc-04dee099f404: Found 1 pods out of 1
  Dec 19 11:02:05.097: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-29b9f332-9b8b-42a5-83dc-04dee099f404" is running
  Dec 19 11:02:05.110: INFO: Pod "my-hostname-basic-29b9f332-9b8b-42a5-83dc-04dee099f404-xzthk" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-19 11:02:00 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-19 11:02:01 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-19 11:02:01 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-19 11:02:00 +0000 UTC Reason: Message:}])
  Dec 19 11:02:05.110: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 12/19/23 11:02:05.11
  Dec 19 11:02:05.137: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3756" for this suite. @ 12/19/23 11:02:05.148
• [5.139 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance]
test/e2e/apps/rc.go:103
  STEP: Creating a kubernetes client @ 12/19/23 11:02:05.163
  Dec 19 11:02:05.163: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename replication-controller @ 12/19/23 11:02:05.171
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:02:05.219
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:02:05.228
  STEP: Given a ReplicationController is created @ 12/19/23 11:02:05.235
  STEP: When the matched label of one of its pods change @ 12/19/23 11:02:05.25
  Dec 19 11:02:05.262: INFO: Pod name pod-release: Found 0 pods out of 1
  E1219 11:02:05.594946      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:06.598019      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:07.603560      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:08.598757      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:09.598981      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:02:10.275: INFO: Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 12/19/23 11:02:10.316
  E1219 11:02:10.601147      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:02:11.340: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-603" for this suite. @ 12/19/23 11:02:11.365
• [6.219 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]
test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 12/19/23 11:02:11.385
  Dec 19 11:02:11.386: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 12/19/23 11:02:11.388
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:02:11.442
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:02:11.45
  STEP: creating a target pod @ 12/19/23 11:02:11.456
  E1219 11:02:11.601889      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:12.602517      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 12/19/23 11:02:13.546
  E1219 11:02:13.602520      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:14.602817      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:15.602945      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 12/19/23 11:02:15.609
  Dec 19 11:02:15.610: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-6896 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:02:15.610: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 11:02:15.613: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:02:15.613: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/ephemeral-containers-test-6896/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Dec 19 11:02:15.737: INFO: Exec stderr: ""
  Dec 19 11:02:15.756: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-6896" for this suite. @ 12/19/23 11:02:15.767
• [4.398 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:289
  STEP: Creating a kubernetes client @ 12/19/23 11:02:15.79
  Dec 19 11:02:15.790: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename field-validation @ 12/19/23 11:02:15.797
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:02:15.875
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:02:15.881
  Dec 19 11:02:15.890: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 11:02:16.603666      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:17.604602      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:18.604657      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:02:19.339: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8544" for this suite. @ 12/19/23 11:02:19.398
• [3.622 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance]
test/e2e/apps/job.go:485
  STEP: Creating a kubernetes client @ 12/19/23 11:02:19.42
  Dec 19 11:02:19.420: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename job @ 12/19/23 11:02:19.424
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:02:19.465
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:02:19.472
  STEP: Creating a job @ 12/19/23 11:02:19.478
  STEP: Ensuring active pods == parallelism @ 12/19/23 11:02:19.496
  E1219 11:02:19.605705      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:20.606022      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete a job @ 12/19/23 11:02:21.564
  STEP: deleting Job.batch foo in namespace job-7838, will wait for the garbage collector to delete the pods @ 12/19/23 11:02:21.564
  E1219 11:02:21.606841      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:02:21.640: INFO: Deleting Job.batch foo took: 16.634965ms
  Dec 19 11:02:21.742: INFO: Terminating Job.batch foo pods took: 101.909967ms
  E1219 11:02:22.607031      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:23.607760      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:24.608087      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:25.609021      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:26.609137      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:27.610053      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:28.611132      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:29.611985      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:30.612624      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:31.613369      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:32.613501      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:33.614361      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:34.615531      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:35.615808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:36.616752      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:37.617139      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:38.617370      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:39.618366      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:40.619064      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:41.619261      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:42.619853      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:43.620973      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:44.622086      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:45.622892      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:46.624088      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:47.624568      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:48.624890      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:49.625529      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:50.625689      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:51.626622      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:52.626893      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 12/19/23 11:02:53.444
  Dec 19 11:02:53.451: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7838" for this suite. @ 12/19/23 11:02:53.464
• [34.066 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]
test/e2e/apimachinery/webhook.go:221
  STEP: Creating a kubernetes client @ 12/19/23 11:02:53.486
  Dec 19 11:02:53.487: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename webhook @ 12/19/23 11:02:53.49
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:02:53.523
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:02:53.528
  STEP: Setting up server cert @ 12/19/23 11:02:53.584
  E1219 11:02:53.627360      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 11:02:54.192
  STEP: Deploying the webhook pod @ 12/19/23 11:02:54.21
  STEP: Wait for the deployment to be ready @ 12/19/23 11:02:54.246
  Dec 19 11:02:54.270: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1219 11:02:54.629077      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:55.629140      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:02:56.294
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:02:56.318
  E1219 11:02:56.630015      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:02:57.318: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Dec 19 11:02:57.334: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 11:02:57.630619      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 12/19/23 11:02:57.855
  STEP: Creating a custom resource that should be denied by the webhook @ 12/19/23 11:02:57.89
  E1219 11:02:58.631579      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:02:59.631715      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 12/19/23 11:03:00.009
  STEP: Updating the custom resource with disallowed data should be denied @ 12/19/23 11:03:00.023
  STEP: Deleting the custom resource should be denied @ 12/19/23 11:03:00.045
  STEP: Remove the offending key and value from the custom resource data @ 12/19/23 11:03:00.067
  STEP: Deleting the updated custom resource should be successful @ 12/19/23 11:03:00.109
  Dec 19 11:03:00.126: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1219 11:03:00.632499      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-5220" for this suite. @ 12/19/23 11:03:00.884
  STEP: Destroying namespace "webhook-markers-6148" for this suite. @ 12/19/23 11:03:00.903
• [7.436 seconds]
------------------------------
S
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]
test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 12/19/23 11:03:00.924
  Dec 19 11:03:00.924: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename deployment @ 12/19/23 11:03:00.929
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:03:00.964
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:03:00.969
  Dec 19 11:03:00.975: INFO: Creating deployment "test-recreate-deployment"
  Dec 19 11:03:00.987: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
  Dec 19 11:03:01.010: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
  E1219 11:03:01.632450      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:02.634444      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:03.027: INFO: Waiting deployment "test-recreate-deployment" to complete
  Dec 19 11:03:03.034: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
  Dec 19 11:03:03.059: INFO: Updating deployment test-recreate-deployment
  Dec 19 11:03:03.059: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  Dec 19 11:03:03.256: INFO: Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-308",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "da90c644-1460-4595-9918-a97ceee2fc4d",
      ResourceVersion: (string) (len=5) "18999",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580580,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580581,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=63) "ReplicaSet \"test-recreate-deployment-76fb77d45\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec 19 11:03:03.272: INFO: New ReplicaSet "test-recreate-deployment-76fb77d45" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-308",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1973ecce-9a84-4f8a-9a5e-4fb71460a6e5",
      ResourceVersion: (string) (len=5) "18996",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580583,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "da90c644-1460-4595-9918-a97ceee2fc4d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 64 61 39 30 63 36  34 34 2d 31 34 36 30 2d  |\"da90c644-1460-|
              00000120  34 35 39 35 2d 39 39 31  38 2d 61 39 37 63 65 65  |4595-9918-a97cee|
              00000130  65 32 66 63 34 64 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |e2fc4d\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 11:03:03.277: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
  Dec 19 11:03:03.278: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-dd4bc9d6d",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-308",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0837dfc5-fe39-42e8-8846-f4beeecff278",
      ResourceVersion: (string) (len=5) "18986",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580580,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "dd4bc9d6d"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "da90c644-1460-4595-9918-a97ceee2fc4d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 64 61 39 30 63 36  34 34 2d 31 34 36 30 2d  |\"da90c644-1460-|
              00000120  34 35 39 35 2d 39 39 31  38 2d 61 39 37 63 65 65  |4595-9918-a97cee|
              00000130  65 32 66 63 34 64 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |e2fc4d\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=9) "dd4bc9d6d"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "dd4bc9d6d"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 11:03:03.288: INFO: Pod "test-recreate-deployment-76fb77d45-cvljv" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-recreate-deployment-76fb77d45-cvljv",
      GenerateName: (string) (len=35) "test-recreate-deployment-76fb77d45-",
      Namespace: (string) (len=14) "deployment-308",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6baaf18d-ec27-4a7c-9e0d-06a7599b5ec7",
      ResourceVersion: (string) (len=5) "18998",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580583,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
          UID: (types.UID) (len=36) "1973ecce-9a84-4f8a-9a5e-4fb71460a6e5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 39  37 33 65 63 63 65 2d 39  |d\":\"1973ecce-9|
              00000090  61 38 34 2d 34 66 38 61  2d 39 61 35 65 2d 34 66  |a84-4f8a-9a5e-4f|
              000000a0  62 37 31 34 36 30 61 36  65 35 5c 22 7d 22 3a 7b  |b71460a6e5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=482) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000001e0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bggdh",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bggdh",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580583,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.172",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580583,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 11:03:03.294: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-308" for this suite. @ 12/19/23 11:03:03.327
• [2.423 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]
test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 12/19/23 11:03:03.35
  Dec 19 11:03:03.350: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename proxy @ 12/19/23 11:03:03.366
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:03:03.408
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:03:03.413
  Dec 19 11:03:03.419: INFO: Creating pod...
  E1219 11:03:03.634275      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:04.634844      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:05.477: INFO: Creating service...
  Dec 19 11:03:05.503: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3445/pods/agnhost/proxy?method=DELETE
  Dec 19 11:03:05.516: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Dec 19 11:03:05.516: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3445/pods/agnhost/proxy?method=OPTIONS
  Dec 19 11:03:05.578: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Dec 19 11:03:05.578: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3445/pods/agnhost/proxy?method=PATCH
  Dec 19 11:03:05.592: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Dec 19 11:03:05.592: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3445/pods/agnhost/proxy?method=POST
  Dec 19 11:03:05.602: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Dec 19 11:03:05.602: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3445/pods/agnhost/proxy?method=PUT
  Dec 19 11:03:05.613: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Dec 19 11:03:05.613: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3445/services/e2e-proxy-test-service/proxy?method=DELETE
  Dec 19 11:03:05.625: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Dec 19 11:03:05.625: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3445/services/e2e-proxy-test-service/proxy?method=OPTIONS
  E1219 11:03:05.635626      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:05.636: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Dec 19 11:03:05.636: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3445/services/e2e-proxy-test-service/proxy?method=PATCH
  Dec 19 11:03:05.650: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Dec 19 11:03:05.650: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3445/services/e2e-proxy-test-service/proxy?method=POST
  Dec 19 11:03:05.660: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Dec 19 11:03:05.660: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3445/services/e2e-proxy-test-service/proxy?method=PUT
  Dec 19 11:03:05.670: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Dec 19 11:03:05.670: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3445/pods/agnhost/proxy?method=GET
  Dec 19 11:03:05.677: INFO: http.Client request:GET StatusCode:301
  Dec 19 11:03:05.677: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3445/services/e2e-proxy-test-service/proxy?method=GET
  Dec 19 11:03:05.685: INFO: http.Client request:GET StatusCode:301
  Dec 19 11:03:05.685: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3445/pods/agnhost/proxy?method=HEAD
  Dec 19 11:03:05.690: INFO: http.Client request:HEAD StatusCode:301
  Dec 19 11:03:05.691: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3445/services/e2e-proxy-test-service/proxy?method=HEAD
  Dec 19 11:03:05.701: INFO: http.Client request:HEAD StatusCode:301
  Dec 19 11:03:05.701: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-3445" for this suite. @ 12/19/23 11:03:05.713
• [2.378 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]
test/e2e/kubectl/kubectl.go:830
  STEP: Creating a kubernetes client @ 12/19/23 11:03:05.735
  Dec 19 11:03:05.735: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 11:03:05.738
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:03:05.769
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:03:05.774
  STEP: validating api versions @ 12/19/23 11:03:05.78
  Dec 19 11:03:05.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-78 api-versions'
  Dec 19 11:03:05.998: INFO: stderr: ""
  Dec 19 11:03:05.998: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta2\nflowcontrol.apiserver.k8s.io/v1beta3\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  Dec 19 11:03:05.998: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-78" for this suite. @ 12/19/23 11:03:06.016
• [0.301 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance]
test/e2e/network/service.go:3117
  STEP: Creating a kubernetes client @ 12/19/23 11:03:06.038
  Dec 19 11:03:06.038: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename services @ 12/19/23 11:03:06.042
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:03:06.082
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:03:06.087
  STEP: fetching services @ 12/19/23 11:03:06.094
  Dec 19 11:03:06.106: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6158" for this suite. @ 12/19/23 11:03:06.118
• [0.096 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]
test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 12/19/23 11:03:06.137
  Dec 19 11:03:06.138: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename disruption @ 12/19/23 11:03:06.141
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:03:06.175
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:03:06.181
  STEP: Creating a kubernetes client @ 12/19/23 11:03:06.194
  Dec 19 11:03:06.194: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename disruption-2 @ 12/19/23 11:03:06.199
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:03:06.231
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:03:06.242
  STEP: Waiting for the pdb to be processed @ 12/19/23 11:03:06.262
  E1219 11:03:06.635766      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:07.636125      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 12/19/23 11:03:08.291
  E1219 11:03:08.636392      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:09.636575      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 12/19/23 11:03:10.337
  E1219 11:03:10.637599      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:11.638350      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: listing a collection of PDBs across all namespaces @ 12/19/23 11:03:12.364
  STEP: listing a collection of PDBs in namespace disruption-7559 @ 12/19/23 11:03:12.374
  STEP: deleting a collection of PDBs @ 12/19/23 11:03:12.388
  STEP: Waiting for the PDB collection to be deleted @ 12/19/23 11:03:12.434
  Dec 19 11:03:12.443: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec 19 11:03:12.461: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-943" for this suite. @ 12/19/23 11:03:12.474
  STEP: Destroying namespace "disruption-7559" for this suite. @ 12/19/23 11:03:12.491
• [6.366 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]
test/e2e/apimachinery/webhook.go:572
  STEP: Creating a kubernetes client @ 12/19/23 11:03:12.507
  Dec 19 11:03:12.508: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename webhook @ 12/19/23 11:03:12.511
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:03:12.542
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:03:12.548
  STEP: Setting up server cert @ 12/19/23 11:03:12.587
  E1219 11:03:12.637992      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 11:03:13.28
  STEP: Deploying the webhook pod @ 12/19/23 11:03:13.292
  STEP: Wait for the deployment to be ready @ 12/19/23 11:03:13.32
  Dec 19 11:03:13.344: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1219 11:03:13.642487      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:14.639092      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:03:15.368
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:03:15.409
  E1219 11:03:15.639968      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:16.410: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 12/19/23 11:03:16.578
  E1219 11:03:16.648272      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 12/19/23 11:03:16.657
  STEP: Deleting the collection of validation webhooks @ 12/19/23 11:03:16.737
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 12/19/23 11:03:16.908
  Dec 19 11:03:16.937: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2475" for this suite. @ 12/19/23 11:03:17.069
  STEP: Destroying namespace "webhook-markers-3381" for this suite. @ 12/19/23 11:03:17.093
• [4.604 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
test/e2e/apimachinery/garbage_collector.go:713
  STEP: Creating a kubernetes client @ 12/19/23 11:03:17.115
  Dec 19 11:03:17.115: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename gc @ 12/19/23 11:03:17.119
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:03:17.155
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:03:17.162
  STEP: create the rc1 @ 12/19/23 11:03:17.183
  STEP: create the rc2 @ 12/19/23 11:03:17.196
  E1219 11:03:17.650575      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:18.651205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:19.653385      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:20.653291      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:21.654893      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:22.657991      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 12/19/23 11:03:23.336
  E1219 11:03:23.658866      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:24.660108      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:25.660739      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:26.661665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc simpletest-rc-to-be-deleted @ 12/19/23 11:03:27.535
  STEP: wait for the rc to be deleted @ 12/19/23 11:03:27.644
  E1219 11:03:27.662686      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:28.663095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:29.663504      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:30.663692      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:31.664096      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:32.666618      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:32.775: INFO: 71 pods remaining
  Dec 19 11:03:32.775: INFO: 71 pods has nil DeletionTimestamp
  Dec 19 11:03:32.775: INFO: 
  E1219 11:03:33.665735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:34.696094      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:35.684477      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:36.682180      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 12/19/23 11:03:37.671
  E1219 11:03:37.682216      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:38.175: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec 19 11:03:38.179: INFO: Deleting pod "simpletest-rc-to-be-deleted-262gg" in namespace "gc-9052"
  Dec 19 11:03:38.231: INFO: Deleting pod "simpletest-rc-to-be-deleted-2fwwt" in namespace "gc-9052"
  Dec 19 11:03:38.310: INFO: Deleting pod "simpletest-rc-to-be-deleted-2g2lk" in namespace "gc-9052"
  Dec 19 11:03:38.366: INFO: Deleting pod "simpletest-rc-to-be-deleted-2pnb5" in namespace "gc-9052"
  Dec 19 11:03:38.455: INFO: Deleting pod "simpletest-rc-to-be-deleted-2txdw" in namespace "gc-9052"
  Dec 19 11:03:38.500: INFO: Deleting pod "simpletest-rc-to-be-deleted-2vq92" in namespace "gc-9052"
  Dec 19 11:03:38.528: INFO: Deleting pod "simpletest-rc-to-be-deleted-49w4h" in namespace "gc-9052"
  Dec 19 11:03:38.572: INFO: Deleting pod "simpletest-rc-to-be-deleted-4hl4f" in namespace "gc-9052"
  E1219 11:03:38.683674      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:38.706: INFO: Deleting pod "simpletest-rc-to-be-deleted-4htd6" in namespace "gc-9052"
  Dec 19 11:03:38.978: INFO: Deleting pod "simpletest-rc-to-be-deleted-4pg7h" in namespace "gc-9052"
  Dec 19 11:03:39.061: INFO: Deleting pod "simpletest-rc-to-be-deleted-4qjkv" in namespace "gc-9052"
  Dec 19 11:03:39.112: INFO: Deleting pod "simpletest-rc-to-be-deleted-4rjt5" in namespace "gc-9052"
  Dec 19 11:03:39.152: INFO: Deleting pod "simpletest-rc-to-be-deleted-4sf6b" in namespace "gc-9052"
  Dec 19 11:03:39.208: INFO: Deleting pod "simpletest-rc-to-be-deleted-4vrfk" in namespace "gc-9052"
  Dec 19 11:03:39.270: INFO: Deleting pod "simpletest-rc-to-be-deleted-58m7h" in namespace "gc-9052"
  Dec 19 11:03:39.358: INFO: Deleting pod "simpletest-rc-to-be-deleted-59bw8" in namespace "gc-9052"
  Dec 19 11:03:39.448: INFO: Deleting pod "simpletest-rc-to-be-deleted-5rmh7" in namespace "gc-9052"
  Dec 19 11:03:39.502: INFO: Deleting pod "simpletest-rc-to-be-deleted-5x8x8" in namespace "gc-9052"
  Dec 19 11:03:39.623: INFO: Deleting pod "simpletest-rc-to-be-deleted-6n89w" in namespace "gc-9052"
  Dec 19 11:03:39.656: INFO: Deleting pod "simpletest-rc-to-be-deleted-6zcvg" in namespace "gc-9052"
  E1219 11:03:39.684463      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:39.700: INFO: Deleting pod "simpletest-rc-to-be-deleted-754n6" in namespace "gc-9052"
  Dec 19 11:03:39.783: INFO: Deleting pod "simpletest-rc-to-be-deleted-85cxj" in namespace "gc-9052"
  Dec 19 11:03:39.831: INFO: Deleting pod "simpletest-rc-to-be-deleted-8gwgt" in namespace "gc-9052"
  Dec 19 11:03:39.880: INFO: Deleting pod "simpletest-rc-to-be-deleted-8pkwn" in namespace "gc-9052"
  Dec 19 11:03:39.927: INFO: Deleting pod "simpletest-rc-to-be-deleted-99xt9" in namespace "gc-9052"
  Dec 19 11:03:39.969: INFO: Deleting pod "simpletest-rc-to-be-deleted-9qjdh" in namespace "gc-9052"
  Dec 19 11:03:40.034: INFO: Deleting pod "simpletest-rc-to-be-deleted-9tzvm" in namespace "gc-9052"
  Dec 19 11:03:40.105: INFO: Deleting pod "simpletest-rc-to-be-deleted-9vqvw" in namespace "gc-9052"
  Dec 19 11:03:40.180: INFO: Deleting pod "simpletest-rc-to-be-deleted-9xxgp" in namespace "gc-9052"
  Dec 19 11:03:40.233: INFO: Deleting pod "simpletest-rc-to-be-deleted-b7ngz" in namespace "gc-9052"
  Dec 19 11:03:40.278: INFO: Deleting pod "simpletest-rc-to-be-deleted-bsk6l" in namespace "gc-9052"
  Dec 19 11:03:40.338: INFO: Deleting pod "simpletest-rc-to-be-deleted-bx2gg" in namespace "gc-9052"
  Dec 19 11:03:40.423: INFO: Deleting pod "simpletest-rc-to-be-deleted-bxcrk" in namespace "gc-9052"
  Dec 19 11:03:40.548: INFO: Deleting pod "simpletest-rc-to-be-deleted-c4v9q" in namespace "gc-9052"
  E1219 11:03:40.685025      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:40.692: INFO: Deleting pod "simpletest-rc-to-be-deleted-c6dwj" in namespace "gc-9052"
  Dec 19 11:03:40.798: INFO: Deleting pod "simpletest-rc-to-be-deleted-c9vhh" in namespace "gc-9052"
  Dec 19 11:03:40.850: INFO: Deleting pod "simpletest-rc-to-be-deleted-cbnbl" in namespace "gc-9052"
  Dec 19 11:03:40.872: INFO: Deleting pod "simpletest-rc-to-be-deleted-chk44" in namespace "gc-9052"
  Dec 19 11:03:40.915: INFO: Deleting pod "simpletest-rc-to-be-deleted-cmgnp" in namespace "gc-9052"
  Dec 19 11:03:40.983: INFO: Deleting pod "simpletest-rc-to-be-deleted-cpl8t" in namespace "gc-9052"
  Dec 19 11:03:41.042: INFO: Deleting pod "simpletest-rc-to-be-deleted-cvl6x" in namespace "gc-9052"
  Dec 19 11:03:41.094: INFO: Deleting pod "simpletest-rc-to-be-deleted-df746" in namespace "gc-9052"
  Dec 19 11:03:41.156: INFO: Deleting pod "simpletest-rc-to-be-deleted-dsfm7" in namespace "gc-9052"
  Dec 19 11:03:41.348: INFO: Deleting pod "simpletest-rc-to-be-deleted-dvn7k" in namespace "gc-9052"
  Dec 19 11:03:41.458: INFO: Deleting pod "simpletest-rc-to-be-deleted-f77cq" in namespace "gc-9052"
  Dec 19 11:03:41.579: INFO: Deleting pod "simpletest-rc-to-be-deleted-gcnz7" in namespace "gc-9052"
  Dec 19 11:03:41.617: INFO: Deleting pod "simpletest-rc-to-be-deleted-gpkfx" in namespace "gc-9052"
  E1219 11:03:41.685753      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:03:41.689: INFO: Deleting pod "simpletest-rc-to-be-deleted-hd9mw" in namespace "gc-9052"
  Dec 19 11:03:41.785: INFO: Deleting pod "simpletest-rc-to-be-deleted-hm6vs" in namespace "gc-9052"
  Dec 19 11:03:41.856: INFO: Deleting pod "simpletest-rc-to-be-deleted-hm8sh" in namespace "gc-9052"
  Dec 19 11:03:41.928: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-9052" for this suite. @ 12/19/23 11:03:42.001
• [24.942 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 12/19/23 11:03:42.061
  Dec 19 11:03:42.061: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename taint-multiple-pods @ 12/19/23 11:03:42.067
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:03:42.13
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:03:42.134
  Dec 19 11:03:42.139: INFO: Waiting up to 1m0s for all nodes to be ready
  E1219 11:03:42.686485      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:43.686704      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:44.687461      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:45.688337      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:46.688992      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:47.689373      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:48.690503      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:49.691149      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:50.691445      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:51.692236      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:52.692302      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:53.692617      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:54.693637      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:55.693693      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:56.693881      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:57.694175      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:58.694276      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:03:59.694857      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:00.695620      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:01.695829      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:02.696188      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:03.698803      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:04.697536      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:05.698489      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:06.699426      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:07.699985      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:08.701133      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:09.700790      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:10.701151      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:11.701825      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:12.703706      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:13.702287      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:14.702478      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:15.702659      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:16.702909      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:17.703561      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:18.704435      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:19.704647      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:20.705082      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:21.705531      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:22.705718      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:23.706148      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:24.708229      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:25.706575      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:26.707433      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:27.707940      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:28.708238      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:29.709048      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:30.709193      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:31.709609      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:32.710855      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:33.710916      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:34.711305      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:35.711805      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:36.712488      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:37.713141      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:38.713827      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:39.714759      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:40.714915      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:41.715193      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:04:42.178: INFO: Waiting for terminating namespaces to be deleted...
  Dec 19 11:04:42.187: INFO: Starting informer...
  STEP: Starting pods... @ 12/19/23 11:04:42.187
  Dec 19 11:04:42.425: INFO: Pod1 is running on hiengux9ahcu-3. Tainting Node
  E1219 11:04:42.716105      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:43.717522      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:04:44.664: INFO: Pod2 is running on hiengux9ahcu-3. Tainting Node
  STEP: Trying to apply a taint on the Node @ 12/19/23 11:04:44.664
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 12/19/23 11:04:44.692
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 12/19/23 11:04:44.707
  E1219 11:04:44.719717      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:45.720100      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:46.720203      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:47.720553      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:48.721192      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:49.721658      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:04:50.480: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
  E1219 11:04:50.721777      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:51.722300      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:52.722543      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:53.723275      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:54.723511      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:55.723706      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:56.723874      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:57.724310      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:58.725271      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:04:59.725913      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:00.725962      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:01.726243      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:02.726428      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:03.726592      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:04.727277      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:05.727573      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:06.727723      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:07.728106      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:08.729363      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:09.729968      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:10.528: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
  Dec 19 11:05:10.528: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 12/19/23 11:05:10.564
  STEP: Destroying namespace "taint-multiple-pods-7610" for this suite. @ 12/19/23 11:05:10.577
• [88.530 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:370
  STEP: Creating a kubernetes client @ 12/19/23 11:05:10.599
  Dec 19 11:05:10.600: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename namespaces @ 12/19/23 11:05:10.603
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:10.663
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:10.671
  STEP: Updating Namespace "namespaces-6874" @ 12/19/23 11:05:10.681
  Dec 19 11:05:10.695: INFO: Namespace "namespaces-6874" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"e1bc3cfb-3863-4649-bff3-a9b53002ab1b", "kubernetes.io/metadata.name":"namespaces-6874", "namespaces-6874":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  Dec 19 11:05:10.696: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6874" for this suite. @ 12/19/23 11:05:10.704
• [0.117 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 12/19/23 11:05:10.719
  Dec 19 11:05:10.719: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:05:10.723
  E1219 11:05:10.731057      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:10.78
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:10.785
  STEP: Creating projection with secret that has name projected-secret-test-6b046a53-ea8d-453b-80b7-bb7f524bb37e @ 12/19/23 11:05:10.79
  STEP: Creating a pod to test consume secrets @ 12/19/23 11:05:10.801
  E1219 11:05:11.731777      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:12.732135      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:13.732107      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:14.737645      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:05:14.853
  Dec 19 11:05:14.860: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-projected-secrets-d7a84d20-025b-4d2e-b9ce-c98082f55e53 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 11:05:14.893
  Dec 19 11:05:14.936: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8996" for this suite. @ 12/19/23 11:05:14.946
• [4.238 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:167
  STEP: Creating a kubernetes client @ 12/19/23 11:05:14.963
  Dec 19 11:05:14.963: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 11:05:14.969
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:14.989
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:14.995
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 12/19/23 11:05:14.998
  E1219 11:05:15.733896      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:16.734210      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:17.734835      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:18.759422      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:05:19.051
  Dec 19 11:05:19.056: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-f9fdecb2-c132-4ca7-90eb-0f1422654150 container test-container: <nil>
  STEP: delete the pod @ 12/19/23 11:05:19.069
  Dec 19 11:05:19.101: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1674" for this suite. @ 12/19/23 11:05:19.115
• [4.164 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:222
  STEP: Creating a kubernetes client @ 12/19/23 11:05:19.137
  Dec 19 11:05:19.137: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:05:19.14
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:19.169
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:19.175
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:05:19.179
  E1219 11:05:19.749044      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:20.749179      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:21.749462      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:22.749830      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:05:23.22
  Dec 19 11:05:23.227: INFO: Trying to get logs from node hiengux9ahcu-3 pod downwardapi-volume-aa7883bb-0f19-4949-ad45-e824ba0dbdad container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:05:23.241
  Dec 19 11:05:23.285: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5762" for this suite. @ 12/19/23 11:05:23.298
• [4.182 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]
test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 12/19/23 11:05:23.322
  Dec 19 11:05:23.322: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename deployment @ 12/19/23 11:05:23.328
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:23.369
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:23.375
  Dec 19 11:05:23.381: INFO: Creating simple deployment test-new-deployment
  Dec 19 11:05:23.417: INFO: new replicaset for deployment "test-new-deployment" is yet to be created
  E1219 11:05:23.750426      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:24.751160      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 12/19/23 11:05:25.443
  STEP: updating a scale subresource @ 12/19/23 11:05:25.45
  STEP: verifying the deployment Spec.Replicas was modified @ 12/19/23 11:05:25.462
  STEP: Patch a scale subresource @ 12/19/23 11:05:25.49
  Dec 19 11:05:25.636: INFO: Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5908",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e680522e-d665-4cc8-a2a5-2e3819e1a955",
      ResourceVersion: (string) (len=5) "21446",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580723,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580725,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580724,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-557759b7c7\" has successfully progressed."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580725,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580725,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec 19 11:05:25.655: INFO: New ReplicaSet "test-new-deployment-557759b7c7" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5908",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4e5dd889-475e-41b8-b60e-559fd300aa69",
      ResourceVersion: (string) (len=5) "21453",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580723,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "4",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "5",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "e680522e-d665-4cc8-a2a5-2e3819e1a955",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580725,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 65 36 38 30 35 32  32 65 2d 64 36 36 35 2d  |\"e680522e-d665-|
              00000120  34 63 63 38 2d 61 32 61  35 2d 32 65 33 38 31 39  |4cc8-a2a5-2e3819|
              00000130  65 31 61 39 35 35 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |e1a955\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580725,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(4),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 2,
      FullyLabeledReplicas: (int32) 2,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 11:05:25.683: INFO: Pod "test-new-deployment-557759b7c7-8jz76" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-8jz76",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-5908",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4728e732-87d8-4da0-87ad-aed951756021",
      ResourceVersion: (string) (len=5) "21457",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580725,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4e5dd889-475e-41b8-b60e-559fd300aa69",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580725,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 65  35 64 64 38 38 39 2d 34  |d\":\"4e5dd889-4|
              00000090  37 35 65 2d 34 31 62 38  2d 62 36 30 65 2d 35 35  |75e-41b8-b60e-55|
              000000a0  39 66 64 33 30 30 61 61  36 39 5c 22 7d 22 3a 7b  |9fd300aa69\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-p9pbn",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-p9pbn",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 11:05:25.685: INFO: Pod "test-new-deployment-557759b7c7-8t2bp" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-8t2bp",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-5908",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2425c33c-e6e6-45c3-8980-3ffe82885492",
      ResourceVersion: (string) (len=5) "21452",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580725,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4e5dd889-475e-41b8-b60e-559fd300aa69",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580725,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 65  35 64 64 38 38 39 2d 34  |d\":\"4e5dd889-4|
              00000090  37 35 65 2d 34 31 62 38  2d 62 36 30 65 2d 35 35  |75e-41b8-b60e-55|
              000000a0  39 66 64 33 30 30 61 61  36 39 5c 22 7d 22 3a 7b  |9fd300aa69\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580725,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=482) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000001e0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-68qxq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-68qxq",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580725,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580725,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580725,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580725,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.17",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580725,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 11:05:25.689: INFO: Pod "test-new-deployment-557759b7c7-s22jk" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-s22jk",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-5908",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "724ac284-be64-4f8e-ad20-271b92c58664",
      ResourceVersion: (string) (len=5) "21435",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580723,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4e5dd889-475e-41b8-b60e-559fd300aa69",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 65  35 64 64 38 38 39 2d 34  |d\":\"4e5dd889-4|
              00000090  37 35 65 2d 34 31 62 38  2d 62 36 30 65 2d 35 35  |75e-41b8-b60e-55|
              000000a0  39 66 64 33 30 30 61 61  36 39 5c 22 7d 22 3a 7b  |9fd300aa69\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580724,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=518) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  36 2e 39 5c 22 7d 22 3a  |10.233.66.9\"}":|
              000001e0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              000001f0  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000200  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-njdl5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-njdl5",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580724,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580724,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580723,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.172",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=11) "10.233.66.9",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.233.66.9"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580723,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838580724,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=64) "987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089",
          ContainerID: (string) (len=72) "cri-o://4133b5501b707fa59e5b38d1b679d039ced578bc1eb5cd59646e2016c420057a",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 11:05:25.727: INFO: Pod "test-new-deployment-557759b7c7-w2n7d" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-w2n7d",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-5908",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2695767e-4e6c-439d-a35b-50b711a21d01",
      ResourceVersion: (string) (len=5) "21459",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580725,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4e5dd889-475e-41b8-b60e-559fd300aa69",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580725,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 65  35 64 64 38 38 39 2d 34  |d\":\"4e5dd889-4|
              00000090  37 35 65 2d 34 31 62 38  2d 62 36 30 65 2d 35 35  |75e-41b8-b60e-55|
              000000a0  39 66 64 33 30 30 61 61  36 39 5c 22 7d 22 3a 7b  |9fd300aa69\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9gk2t",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9gk2t",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580725,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 11:05:25.734: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1219 11:05:25.751764      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "deployment-5908" for this suite. @ 12/19/23 11:05:25.758
• [2.457 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:250
  STEP: Creating a kubernetes client @ 12/19/23 11:05:25.782
  Dec 19 11:05:25.782: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:05:25.785
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:25.818
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:25.825
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:05:25.832
  E1219 11:05:26.751980      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:27.752438      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:05:27.886
  Dec 19 11:05:27.894: INFO: Trying to get logs from node hiengux9ahcu-3 pod downwardapi-volume-816739dd-cc4c-43d8-bcc0-b09b037263d1 container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:05:27.906
  Dec 19 11:05:27.930: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-688" for this suite. @ 12/19/23 11:05:27.937
• [2.166 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]
test/e2e/common/node/configmap.go:93
  STEP: Creating a kubernetes client @ 12/19/23 11:05:27.956
  Dec 19 11:05:27.956: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename configmap @ 12/19/23 11:05:27.958
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:27.986
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:27.995
  STEP: Creating configMap configmap-9322/configmap-test-90f19de5-254e-45e7-9705-945de2f1ea3f @ 12/19/23 11:05:28.002
  STEP: Creating a pod to test consume configMaps @ 12/19/23 11:05:28.018
  E1219 11:05:28.752882      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:29.753586      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:30.754638      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:31.755093      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:05:32.064
  Dec 19 11:05:32.068: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-configmaps-213f1b59-4fb4-4b6b-81a1-ee1402f1306c container env-test: <nil>
  STEP: delete the pod @ 12/19/23 11:05:32.081
  Dec 19 11:05:32.106: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9322" for this suite. @ 12/19/23 11:05:32.116
• [4.171 seconds]
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance]
test/e2e/apps/rc.go:94
  STEP: Creating a kubernetes client @ 12/19/23 11:05:32.127
  Dec 19 11:05:32.127: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename replication-controller @ 12/19/23 11:05:32.13
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:32.156
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:32.159
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 12/19/23 11:05:32.163
  E1219 11:05:32.756351      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:33.757027      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 12/19/23 11:05:34.201
  STEP: Then the orphan pod is adopted @ 12/19/23 11:05:34.212
  E1219 11:05:34.757612      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:35.229: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-1416" for this suite. @ 12/19/23 11:05:35.238
• [3.127 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance]
test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 12/19/23 11:05:35.26
  Dec 19 11:05:35.260: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename pods @ 12/19/23 11:05:35.263
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:35.305
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:35.312
  STEP: Create a pod @ 12/19/23 11:05:35.318
  E1219 11:05:35.757886      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:36.758314      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 12/19/23 11:05:37.375
  Dec 19 11:05:37.400: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
  Dec 19 11:05:37.401: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2640" for this suite. @ 12/19/23 11:05:37.42
• [2.176 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 12/19/23 11:05:37.45
  Dec 19 11:05:37.450: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename containers @ 12/19/23 11:05:37.454
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:37.514
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:37.522
  STEP: Creating a pod to test override command @ 12/19/23 11:05:37.529
  E1219 11:05:37.758258      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:38.759418      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:39.759392      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:40.761522      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:05:41.584
  Dec 19 11:05:41.590: INFO: Trying to get logs from node hiengux9ahcu-3 pod client-containers-bdbcc879-f3f1-474e-a3b6-bc8d7a792b51 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 11:05:41.619
  Dec 19 11:05:41.654: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-8233" for this suite. @ 12/19/23 11:05:41.665
• [4.233 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]
test/e2e/kubectl/kubectl.go:341
  STEP: Creating a kubernetes client @ 12/19/23 11:05:41.698
  Dec 19 11:05:41.698: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 11:05:41.702
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:41.735
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:41.739
  STEP: creating a replication controller @ 12/19/23 11:05:41.744
  Dec 19 11:05:41.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-4159 create -f -'
  E1219 11:05:41.762549      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:42.366: INFO: stderr: ""
  Dec 19 11:05:42.367: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 12/19/23 11:05:42.367
  Dec 19 11:05:42.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-4159 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec 19 11:05:42.615: INFO: stderr: ""
  Dec 19 11:05:42.615: INFO: stdout: "update-demo-nautilus-hvxbt update-demo-nautilus-n6vlc "
  Dec 19 11:05:42.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-4159 get pods update-demo-nautilus-hvxbt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E1219 11:05:42.769896      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:42.988: INFO: stderr: ""
  Dec 19 11:05:42.988: INFO: stdout: ""
  Dec 19 11:05:42.988: INFO: update-demo-nautilus-hvxbt is created but not running
  E1219 11:05:43.776319      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:44.771646      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:45.773622      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:46.772634      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:47.774038      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:47.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-4159 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec 19 11:05:48.204: INFO: stderr: ""
  Dec 19 11:05:48.205: INFO: stdout: "update-demo-nautilus-hvxbt update-demo-nautilus-n6vlc "
  Dec 19 11:05:48.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-4159 get pods update-demo-nautilus-hvxbt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 11:05:48.380: INFO: stderr: ""
  Dec 19 11:05:48.380: INFO: stdout: "true"
  Dec 19 11:05:48.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-4159 get pods update-demo-nautilus-hvxbt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec 19 11:05:48.531: INFO: stderr: ""
  Dec 19 11:05:48.531: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec 19 11:05:48.531: INFO: validating pod update-demo-nautilus-hvxbt
  Dec 19 11:05:48.549: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec 19 11:05:48.550: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec 19 11:05:48.550: INFO: update-demo-nautilus-hvxbt is verified up and running
  Dec 19 11:05:48.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-4159 get pods update-demo-nautilus-n6vlc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec 19 11:05:48.704: INFO: stderr: ""
  Dec 19 11:05:48.704: INFO: stdout: "true"
  Dec 19 11:05:48.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-4159 get pods update-demo-nautilus-n6vlc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  E1219 11:05:48.773367      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:48.857: INFO: stderr: ""
  Dec 19 11:05:48.857: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec 19 11:05:48.857: INFO: validating pod update-demo-nautilus-n6vlc
  Dec 19 11:05:48.874: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec 19 11:05:48.874: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec 19 11:05:48.874: INFO: update-demo-nautilus-n6vlc is verified up and running
  STEP: using delete to clean up resources @ 12/19/23 11:05:48.874
  Dec 19 11:05:48.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-4159 delete --grace-period=0 --force -f -'
  Dec 19 11:05:49.040: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec 19 11:05:49.040: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Dec 19 11:05:49.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-4159 get rc,svc -l name=update-demo --no-headers'
  Dec 19 11:05:49.271: INFO: stderr: "No resources found in kubectl-4159 namespace.\n"
  Dec 19 11:05:49.271: INFO: stdout: ""
  Dec 19 11:05:49.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-4159 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Dec 19 11:05:49.500: INFO: stderr: ""
  Dec 19 11:05:49.500: INFO: stdout: ""
  Dec 19 11:05:49.500: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4159" for this suite. @ 12/19/23 11:05:49.53
• [7.851 seconds]
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]
test/e2e/auth/service_accounts.go:740
  STEP: Creating a kubernetes client @ 12/19/23 11:05:49.549
  Dec 19 11:05:49.549: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename svcaccounts @ 12/19/23 11:05:49.553
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:49.599
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:49.606
  Dec 19 11:05:49.622: INFO: Got root ca configmap in namespace "svcaccounts-6991"
  Dec 19 11:05:49.641: INFO: Deleted root ca configmap in namespace "svcaccounts-6991"
  E1219 11:05:49.774458      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for a new root ca configmap created @ 12/19/23 11:05:50.142
  Dec 19 11:05:50.151: INFO: Recreated root ca configmap in namespace "svcaccounts-6991"
  Dec 19 11:05:50.161: INFO: Updated root ca configmap in namespace "svcaccounts-6991"
  STEP: waiting for the root ca configmap reconciled @ 12/19/23 11:05:50.662
  Dec 19 11:05:50.670: INFO: Reconciled root ca configmap in namespace "svcaccounts-6991"
  Dec 19 11:05:50.670: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-6991" for this suite. @ 12/19/23 11:05:50.681
• [1.146 seconds]
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:131
  STEP: Creating a kubernetes client @ 12/19/23 11:05:50.696
  Dec 19 11:05:50.696: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:05:50.699
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:50.752
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:50.758
  STEP: Creating the pod @ 12/19/23 11:05:50.766
  E1219 11:05:50.774933      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:51.775798      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:52.776938      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:53.378: INFO: Successfully updated pod "labelsupdateef2ef975-7df0-4247-90c6-47d266cfdbe8"
  E1219 11:05:53.778126      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:54.778421      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:05:55.413: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-426" for this suite. @ 12/19/23 11:05:55.424
• [4.740 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance]
test/e2e/common/node/secrets.go:140
  STEP: Creating a kubernetes client @ 12/19/23 11:05:55.438
  Dec 19 11:05:55.439: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename secrets @ 12/19/23 11:05:55.442
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:55.473
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:55.48
  STEP: Creating projection with secret that has name secret-emptykey-test-4ebd4457-5f0a-40aa-bffa-13f21093290f @ 12/19/23 11:05:55.491
  Dec 19 11:05:55.495: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3965" for this suite. @ 12/19/23 11:05:55.507
• [0.086 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:375
  STEP: Creating a kubernetes client @ 12/19/23 11:05:55.529
  Dec 19 11:05:55.530: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:05:55.533
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:55.572
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:55.577
  STEP: Creating configMap with name projected-configmap-test-volume-856f37d4-324c-4c94-8776-1bae3b80b33c @ 12/19/23 11:05:55.584
  STEP: Creating a pod to test consume configMaps @ 12/19/23 11:05:55.598
  E1219 11:05:55.779370      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:56.779649      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:57.780652      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:05:58.781448      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:05:59.65
  Dec 19 11:05:59.659: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-projected-configmaps-081c4f6c-0d8e-41e6-b118-1de2b079a87a container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 11:05:59.676
  Dec 19 11:05:59.725: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5929" for this suite. @ 12/19/23 11:05:59.736
• [4.224 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]
test/e2e/apimachinery/namespace.go:243
  STEP: Creating a kubernetes client @ 12/19/23 11:05:59.754
  Dec 19 11:05:59.754: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename namespaces @ 12/19/23 11:05:59.757
  E1219 11:05:59.781365      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:59.791
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:05:59.797
  STEP: Creating a test namespace @ 12/19/23 11:05:59.808
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:05:59.841
  STEP: Creating a pod in the namespace @ 12/19/23 11:05:59.846
  STEP: Waiting for the pod to have running status @ 12/19/23 11:05:59.864
  E1219 11:06:00.782163      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:01.783109      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the namespace @ 12/19/23 11:06:01.885
  STEP: Waiting for the namespace to be removed. @ 12/19/23 11:06:01.902
  E1219 11:06:02.783663      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:03.784133      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:04.784156      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:05.784982      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:06.785707      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:07.785243      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:08.785771      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:09.785824      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:10.787082      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:11.787303      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:12.787426      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 12/19/23 11:06:12.911
  STEP: Verifying there are no pods in the namespace @ 12/19/23 11:06:12.949
  Dec 19 11:06:12.957: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-4179" for this suite. @ 12/19/23 11:06:12.969
  STEP: Destroying namespace "nsdeletetest-9145" for this suite. @ 12/19/23 11:06:12.986
  Dec 19 11:06:12.996: INFO: Namespace nsdeletetest-9145 was already deleted
  STEP: Destroying namespace "nsdeletetest-5351" for this suite. @ 12/19/23 11:06:12.996
• [13.257 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]
test/e2e/apimachinery/resource_quota.go:1013
  STEP: Creating a kubernetes client @ 12/19/23 11:06:13.018
  Dec 19 11:06:13.018: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 11:06:13.023
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:06:13.06
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:06:13.066
  STEP: Creating resourceQuota "e2e-rq-status-bjrwr" @ 12/19/23 11:06:13.082
  Dec 19 11:06:13.111: INFO: Resource quota "e2e-rq-status-bjrwr" reports spec: hard cpu limit of 500m
  Dec 19 11:06:13.111: INFO: Resource quota "e2e-rq-status-bjrwr" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-bjrwr" /status @ 12/19/23 11:06:13.111
  STEP: Confirm /status for "e2e-rq-status-bjrwr" resourceQuota via watch @ 12/19/23 11:06:13.144
  Dec 19 11:06:13.147: INFO: observed resourceQuota "e2e-rq-status-bjrwr" in namespace "resourcequota-4229" with hard status: v1.ResourceList(nil)
  Dec 19 11:06:13.147: INFO: Found resourceQuota "e2e-rq-status-bjrwr" in namespace "resourcequota-4229" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Dec 19 11:06:13.147: INFO: ResourceQuota "e2e-rq-status-bjrwr" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 12/19/23 11:06:13.156
  Dec 19 11:06:13.175: INFO: Resource quota "e2e-rq-status-bjrwr" reports spec: hard cpu limit of 1
  Dec 19 11:06:13.175: INFO: Resource quota "e2e-rq-status-bjrwr" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-bjrwr" /status @ 12/19/23 11:06:13.175
  STEP: Confirm /status for "e2e-rq-status-bjrwr" resourceQuota via watch @ 12/19/23 11:06:13.192
  Dec 19 11:06:13.197: INFO: observed resourceQuota "e2e-rq-status-bjrwr" in namespace "resourcequota-4229" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Dec 19 11:06:13.197: INFO: Found resourceQuota "e2e-rq-status-bjrwr" in namespace "resourcequota-4229" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  Dec 19 11:06:13.198: INFO: ResourceQuota "e2e-rq-status-bjrwr" /status was patched
  STEP: Get "e2e-rq-status-bjrwr" /status @ 12/19/23 11:06:13.198
  Dec 19 11:06:13.217: INFO: Resourcequota "e2e-rq-status-bjrwr" reports status: hard cpu of 1
  Dec 19 11:06:13.218: INFO: Resourcequota "e2e-rq-status-bjrwr" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-bjrwr" /status before checking Spec is unchanged @ 12/19/23 11:06:13.233
  Dec 19 11:06:13.252: INFO: Resourcequota "e2e-rq-status-bjrwr" reports status: hard cpu of 2
  Dec 19 11:06:13.252: INFO: Resourcequota "e2e-rq-status-bjrwr" reports status: hard memory of 2Gi
  Dec 19 11:06:13.256: INFO: Found resourceQuota "e2e-rq-status-bjrwr" in namespace "resourcequota-4229" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  E1219 11:06:13.788821      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:14.789285      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:15.790379      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:16.791113      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:17.791529      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:18.792596      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:19.792879      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:20.793255      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:21.793930      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:22.794941      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:23.795539      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:24.802284      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:25.803407      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:26.803567      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:27.803625      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:28.803864      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:29.804022      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:30.804463      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:31.805190      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:32.805689      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:33.806502      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:34.806430      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:35.809647      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:36.809120      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:37.809782      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:38.810371      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:39.810427      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:40.810987      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:41.813214      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:42.813224      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:43.813696      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:44.813918      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:45.814129      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:46.814356      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:47.814987      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:48.817245      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:49.816097      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:50.815821      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:51.816130      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:52.816369      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:53.817243      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:54.819187      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:55.818908      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:56.819053      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:57.819743      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:58.819998      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:06:59.821911      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:00.820794      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:01.821083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:02.821392      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:03.821442      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:04.822070      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:05.822165      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:06.822620      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:07.823665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:08.823867      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:09.823984      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:10.824488      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:11.825594      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:12.826270      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:13.826675      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:14.826704      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:15.827312      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:16.827491      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:17.828124      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:18.828243      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:19.828425      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:20.829658      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:21.829949      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:22.830221      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:23.274: INFO: ResourceQuota "e2e-rq-status-bjrwr" Spec was unchanged and /status reset
  Dec 19 11:07:23.275: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4229" for this suite. @ 12/19/23 11:07:23.287
• [70.294 seconds]
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:107
  STEP: Creating a kubernetes client @ 12/19/23 11:07:23.314
  Dec 19 11:07:23.314: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename pod-network-test @ 12/19/23 11:07:23.32
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:07:23.362
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:07:23.374
  STEP: Performing setup for networking test in namespace pod-network-test-4309 @ 12/19/23 11:07:23.386
  STEP: creating a selector @ 12/19/23 11:07:23.387
  STEP: Creating the service pods in kubernetes @ 12/19/23 11:07:23.388
  Dec 19 11:07:23.388: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E1219 11:07:23.831413      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:24.831428      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:25.832133      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:26.832512      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:27.833652      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:28.834393      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:29.836082      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:30.835899      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:31.836204      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:32.836477      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:33.837345      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:34.837981      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:35.838287      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:36.838925      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:37.839597      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:38.839750      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:39.840302      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:40.841008      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:41.842024      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:42.842041      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:43.842850      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:44.843985      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 12/19/23 11:07:45.666
  E1219 11:07:45.843704      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:46.844921      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:47.751: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Dec 19 11:07:47.751: INFO: Going to poll 10.233.64.114 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Dec 19 11:07:47.758: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.64.114:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4309 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:07:47.758: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 11:07:47.761: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:07:47.761: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-4309/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.64.114%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E1219 11:07:47.845548      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:47.940: INFO: Found all 1 expected endpoints: [netserver-0]
  Dec 19 11:07:47.941: INFO: Going to poll 10.233.65.107 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Dec 19 11:07:47.949: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.65.107:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4309 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:07:47.949: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 11:07:47.951: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:07:47.951: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-4309/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.65.107%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Dec 19 11:07:48.086: INFO: Found all 1 expected endpoints: [netserver-1]
  Dec 19 11:07:48.087: INFO: Going to poll 10.233.66.19 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Dec 19 11:07:48.097: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.66.19:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4309 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:07:48.097: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 11:07:48.099: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:07:48.099: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-4309/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.66.19%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Dec 19 11:07:48.218: INFO: Found all 1 expected endpoints: [netserver-2]
  Dec 19 11:07:48.219: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-4309" for this suite. @ 12/19/23 11:07:48.232
• [24.935 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]
test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 12/19/23 11:07:48.266
  Dec 19 11:07:48.266: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename daemonsets @ 12/19/23 11:07:48.269
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:07:48.305
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:07:48.314
  STEP: Creating a simple DaemonSet "daemon-set" @ 12/19/23 11:07:48.373
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/19/23 11:07:48.388
  Dec 19 11:07:48.404: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 11:07:48.404: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  E1219 11:07:48.846611      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:49.428: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 11:07:49.428: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  E1219 11:07:49.846749      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:50.422: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec 19 11:07:50.422: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 12/19/23 11:07:50.428
  Dec 19 11:07:50.469: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec 19 11:07:50.469: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 12/19/23 11:07:50.469
  E1219 11:07:50.852729      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting DaemonSet "daemon-set" @ 12/19/23 11:07:51.491
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6221, will wait for the garbage collector to delete the pods @ 12/19/23 11:07:51.491
  Dec 19 11:07:51.582: INFO: Deleting DaemonSet.extensions daemon-set took: 34.134607ms
  Dec 19 11:07:51.784: INFO: Terminating DaemonSet.extensions daemon-set pods took: 201.638731ms
  E1219 11:07:51.851716      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:52.852385      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:07:53.694: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 11:07:53.694: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec 19 11:07:53.699: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"22220"},"items":null}

  Dec 19 11:07:53.707: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"22221"},"items":null}

  Dec 19 11:07:53.742: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6221" for this suite. @ 12/19/23 11:07:53.751
• [5.503 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:95
  STEP: Creating a kubernetes client @ 12/19/23 11:07:53.786
  Dec 19 11:07:53.786: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename var-expansion @ 12/19/23 11:07:53.793
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:07:53.828
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:07:53.836
  STEP: Creating a pod to test substitution in container's args @ 12/19/23 11:07:53.851
  E1219 11:07:53.852765      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:54.853191      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:55.853043      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:56.853828      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:57.854134      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:07:57.948
  Dec 19 11:07:57.955: INFO: Trying to get logs from node hiengux9ahcu-3 pod var-expansion-70232d0f-ca8e-4ea1-87e4-f2e35b5bb6cc container dapi-container: <nil>
  STEP: delete the pod @ 12/19/23 11:07:57.984
  Dec 19 11:07:58.011: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4045" for this suite. @ 12/19/23 11:07:58.02
• [4.249 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:109
  STEP: Creating a kubernetes client @ 12/19/23 11:07:58.04
  Dec 19 11:07:58.040: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename configmap @ 12/19/23 11:07:58.042
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:07:58.072
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:07:58.077
  STEP: Creating configMap with name configmap-test-volume-map-c715f721-b25a-4f26-b2f7-ff92c6678cf0 @ 12/19/23 11:07:58.083
  STEP: Creating a pod to test consume configMaps @ 12/19/23 11:07:58.091
  E1219 11:07:58.854498      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:07:59.854753      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:00.854994      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:01.855257      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:08:02.152
  Dec 19 11:08:02.158: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-configmaps-3288f430-89e8-440e-a245-a7caa50b4892 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 11:08:02.171
  Dec 19 11:08:02.198: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1063" for this suite. @ 12/19/23 11:08:02.206
• [4.178 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:74
  STEP: Creating a kubernetes client @ 12/19/23 11:08:02.232
  Dec 19 11:08:02.232: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:08:02.234
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:08:02.263
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:08:02.267
  STEP: Creating configMap with name projected-configmap-test-volume-7dcffc82-0bda-48d4-806c-3307c499e91d @ 12/19/23 11:08:02.272
  STEP: Creating a pod to test consume configMaps @ 12/19/23 11:08:02.282
  E1219 11:08:02.856086      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:03.856874      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:04.856911      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:05.857138      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:08:06.328
  Dec 19 11:08:06.334: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-projected-configmaps-e87e1545-e2f3-4db0-976c-c456cd67774c container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 11:08:06.352
  Dec 19 11:08:06.379: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5386" for this suite. @ 12/19/23 11:08:06.393
• [4.175 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]
test/e2e/apimachinery/webhook.go:250
  STEP: Creating a kubernetes client @ 12/19/23 11:08:06.409
  Dec 19 11:08:06.409: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename webhook @ 12/19/23 11:08:06.412
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:08:06.449
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:08:06.455
  STEP: Setting up server cert @ 12/19/23 11:08:06.508
  E1219 11:08:06.857818      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 11:08:07.817
  STEP: Deploying the webhook pod @ 12/19/23 11:08:07.836
  E1219 11:08:07.858659      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Wait for the deployment to be ready @ 12/19/23 11:08:07.859
  Dec 19 11:08:07.873: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E1219 11:08:08.859060      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:09.859705      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:08:09.896
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:08:09.92
  E1219 11:08:10.859584      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:10.920: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 12/19/23 11:08:10.932
  STEP: create a configmap that should be updated by the webhook @ 12/19/23 11:08:10.972
  Dec 19 11:08:11.005: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8567" for this suite. @ 12/19/23 11:08:11.167
  STEP: Destroying namespace "webhook-markers-3254" for this suite. @ 12/19/23 11:08:11.187
• [4.803 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]
test/e2e/apimachinery/resource_quota.go:693
  STEP: Creating a kubernetes client @ 12/19/23 11:08:11.213
  Dec 19 11:08:11.213: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 11:08:11.222
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:08:11.256
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:08:11.265
  STEP: Creating a ResourceQuota with terminating scope @ 12/19/23 11:08:11.274
  STEP: Ensuring ResourceQuota status is calculated @ 12/19/23 11:08:11.29
  E1219 11:08:11.860413      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:12.861154      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not terminating scope @ 12/19/23 11:08:13.298
  STEP: Ensuring ResourceQuota status is calculated @ 12/19/23 11:08:13.307
  E1219 11:08:13.861935      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:14.861906      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a long running pod @ 12/19/23 11:08:15.32
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 12/19/23 11:08:15.353
  E1219 11:08:15.862466      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:16.862623      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 12/19/23 11:08:17.363
  E1219 11:08:17.862776      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:18.862810      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 12/19/23 11:08:19.37
  STEP: Ensuring resource quota status released the pod usage @ 12/19/23 11:08:19.441
  E1219 11:08:19.863263      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:20.864142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a terminating pod @ 12/19/23 11:08:21.448
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 12/19/23 11:08:21.47
  E1219 11:08:21.865041      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:22.865946      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 12/19/23 11:08:23.483
  E1219 11:08:23.866071      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:24.866789      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 12/19/23 11:08:25.51
  STEP: Ensuring resource quota status released the pod usage @ 12/19/23 11:08:25.574
  E1219 11:08:25.867175      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:26.867926      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:27.583: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6322" for this suite. @ 12/19/23 11:08:27.596
• [16.399 seconds]
------------------------------
S
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 12/19/23 11:08:27.616
  Dec 19 11:08:27.616: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename pods @ 12/19/23 11:08:27.621
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:08:27.656
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:08:27.662
  STEP: creating the pod @ 12/19/23 11:08:27.674
  STEP: submitting the pod to kubernetes @ 12/19/23 11:08:27.675
  E1219 11:08:27.868106      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:28.869022      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 12/19/23 11:08:29.723
  STEP: updating the pod @ 12/19/23 11:08:29.728
  E1219 11:08:29.870010      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:30.254: INFO: Successfully updated pod "pod-update-c43b0ea1-525b-44e5-a537-02d169c1ed89"
  STEP: verifying the updated pod is in kubernetes @ 12/19/23 11:08:30.261
  Dec 19 11:08:30.271: INFO: Pod update OK
  Dec 19 11:08:30.272: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-983" for this suite. @ 12/19/23 11:08:30.284
• [2.685 seconds]
------------------------------
SSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]
test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 12/19/23 11:08:30.301
  Dec 19 11:08:30.301: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename pods @ 12/19/23 11:08:30.305
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:08:30.347
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:08:30.354
  STEP: creating a Pod with a static label @ 12/19/23 11:08:30.383
  STEP: watching for Pod to be ready @ 12/19/23 11:08:30.4
  Dec 19 11:08:30.404: INFO: observed Pod pod-test in namespace pods-5781 in phase Pending with labels: map[test-pod-static:true] & conditions []
  Dec 19 11:08:30.424: INFO: observed Pod pod-test in namespace pods-5781 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:08:30 +0000 UTC  }]
  Dec 19 11:08:30.459: INFO: observed Pod pod-test in namespace pods-5781 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:08:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:08:30 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:08:30 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:08:30 +0000 UTC  }]
  E1219 11:08:30.870548      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:31.730: INFO: Found Pod pod-test in namespace pods-5781 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:08:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:08:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:08:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:08:30 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 12/19/23 11:08:31.738
  STEP: getting the Pod and ensuring that it's patched @ 12/19/23 11:08:31.764
  STEP: replacing the Pod's status Ready condition to False @ 12/19/23 11:08:31.773
  STEP: check the Pod again to ensure its Ready conditions are False @ 12/19/23 11:08:31.8
  STEP: deleting the Pod via a Collection with a LabelSelector @ 12/19/23 11:08:31.8
  STEP: watching for the Pod to be deleted @ 12/19/23 11:08:31.818
  Dec 19 11:08:31.824: INFO: observed event type MODIFIED
  E1219 11:08:31.871192      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:32.675: INFO: observed event type MODIFIED
  E1219 11:08:32.871719      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:33.737: INFO: observed event type MODIFIED
  Dec 19 11:08:33.863: INFO: observed event type MODIFIED
  E1219 11:08:33.871978      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:08:34.787: INFO: observed event type MODIFIED
  Dec 19 11:08:34.808: INFO: observed event type MODIFIED
  Dec 19 11:08:34.821: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5781" for this suite. @ 12/19/23 11:08:34.829
• [4.538 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS  E1219 11:08:34.872622      14 retrywatcher.go:129] "Watch failed" err="context canceled"
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]
test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 12/19/23 11:08:34.894
  Dec 19 11:08:34.894: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename sched-preemption @ 12/19/23 11:08:34.898
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:08:34.928
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:08:34.933
  Dec 19 11:08:34.961: INFO: Waiting up to 1m0s for all nodes to be ready
  E1219 11:08:35.873193      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:36.873319      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:37.874284      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:38.874434      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:39.874960      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:40.875883      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:41.876021      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:42.876380      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:43.877354      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:44.878072      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:45.879133      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:46.879282      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:47.879486      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:48.879826      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:49.879978      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:50.880968      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:51.881612      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:52.882140      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:53.882165      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:54.883175      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:55.883158      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:56.883453      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:57.883599      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:58.884106      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:08:59.885003      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:00.885921      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:01.886789      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:02.887572      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:03.887820      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:04.888027      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:05.888063      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:06.888381      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:07.888495      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:08.890781      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:09.889668      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:10.890002      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:11.891210      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:12.891638      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:13.893586      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:14.892580      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:15.893513      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:16.895693      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:17.894967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:18.899065      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:19.896879      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:20.897205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:21.897536      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:22.899531      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:23.898573      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:24.899353      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:25.900266      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:26.900961      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:27.901291      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:28.901983      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:29.902863      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:30.902931      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:31.903401      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:32.904024      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:33.904217      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:34.904534      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:35.028: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 12/19/23 11:09:35.04
  Dec 19 11:09:35.089: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Dec 19 11:09:35.107: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Dec 19 11:09:35.172: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Dec 19 11:09:35.188: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  Dec 19 11:09:35.308: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Dec 19 11:09:35.373: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 12/19/23 11:09:35.373
  E1219 11:09:35.905374      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:36.905831      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:37.906480      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:38.906505      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 12/19/23 11:09:39.458
  E1219 11:09:39.906585      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:40.907541      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:41.907832      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:42.908123      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:43.612: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-4731" for this suite. @ 12/19/23 11:09:43.807
• [68.931 seconds]
------------------------------
[sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]
test/e2e/common/node/runtimeclass.go:189
  STEP: Creating a kubernetes client @ 12/19/23 11:09:43.826
  Dec 19 11:09:43.826: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename runtimeclass @ 12/19/23 11:09:43.831
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:09:43.869
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:09:43.877
  STEP: getting /apis @ 12/19/23 11:09:43.887
  STEP: getting /apis/node.k8s.io @ 12/19/23 11:09:43.9
  STEP: getting /apis/node.k8s.io/v1 @ 12/19/23 11:09:43.903
  E1219 11:09:43.908096      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating @ 12/19/23 11:09:43.908
  STEP: watching @ 12/19/23 11:09:43.958
  Dec 19 11:09:43.958: INFO: starting watch
  STEP: getting @ 12/19/23 11:09:43.974
  STEP: listing @ 12/19/23 11:09:43.988
  STEP: patching @ 12/19/23 11:09:44.004
  STEP: updating @ 12/19/23 11:09:44.019
  Dec 19 11:09:44.038: INFO: waiting for watch events with expected annotations
  STEP: deleting @ 12/19/23 11:09:44.039
  STEP: deleting a collection @ 12/19/23 11:09:44.081
  Dec 19 11:09:44.122: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-6611" for this suite. @ 12/19/23 11:09:44.131
• [0.321 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]
test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 12/19/23 11:09:44.151
  Dec 19 11:09:44.151: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename deployment @ 12/19/23 11:09:44.154
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:09:44.23
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:09:44.237
  Dec 19 11:09:44.242: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
  Dec 19 11:09:44.262: INFO: Pod name sample-pod: Found 0 pods out of 1
  E1219 11:09:44.908404      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:45.909464      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:46.910014      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:47.910621      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:48.911136      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:49.276: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/19/23 11:09:49.277
  Dec 19 11:09:49.277: INFO: Creating deployment "test-rolling-update-deployment"
  Dec 19 11:09:49.303: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  Dec 19 11:09:49.350: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  E1219 11:09:49.925566      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:50.911604      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:51.381: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
  Dec 19 11:09:51.391: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 9, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 9, 49, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 9, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 9, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-7f5c55c64\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:09:51.911834      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:52.912118      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:09:53.397: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  Dec 19 11:09:53.419: INFO: Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6975",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "076318a6-a2ac-4d4e-ad13-e2609ea9383a",
      ResourceVersion: (string) (len=5) "22916",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580989,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580989,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580991,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580989,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580989,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580991,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580989,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=82) "ReplicaSet \"test-rolling-update-deployment-7f5c55c64\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec 19 11:09:53.441: INFO: New ReplicaSet "test-rolling-update-deployment-7f5c55c64" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-rolling-update-deployment-7f5c55c64",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6975",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0f8bc273-edbd-4808-b9c6-16e2cb4e1841",
      ResourceVersion: (string) (len=5) "22899",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580989,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "076318a6-a2ac-4d4e-ad13-e2609ea9383a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580989,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 30 37 36 33 31 38  61 36 2d 61 32 61 63 2d  |\"076318a6-a2ac-|
              00000120  34 64 34 65 2d 61 64 31  33 2d 65 32 36 30 39 65  |4d4e-ad13-e2609e|
              00000130  61 39 33 38 33 61 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |a9383a\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580991,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 11:09:53.448: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
  Dec 19 11:09:53.448: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6975",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0eda8176-9775-4e96-9526-dc038991861b",
      ResourceVersion: (string) (len=5) "22913",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580984,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "076318a6-a2ac-4d4e-ad13-e2609ea9383a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580984,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580991,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 30 37 36 33 31 38 61  |"uid\":\"076318a|
              000000b0  36 2d 61 32 61 63 2d 34  64 34 65 2d 61 64 31 33  |6-a2ac-4d4e-ad13|
              000000c0  2d 65 32 36 30 39 65 61  39 33 38 33 61 5c 22 7d  |-e2609ea9383a\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580991,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 11:09:53.466: INFO: Pod "test-rolling-update-deployment-7f5c55c64-2lqqw" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=46) "test-rolling-update-deployment-7f5c55c64-2lqqw",
      GenerateName: (string) (len=41) "test-rolling-update-deployment-7f5c55c64-",
      Namespace: (string) (len=15) "deployment-6975",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a25c61e1-8c2a-4a9e-8e56-30921be72c6a",
      ResourceVersion: (string) (len=5) "22898",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580989,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=40) "test-rolling-update-deployment-7f5c55c64",
          UID: (types.UID) (len=36) "0f8bc273-edbd-4808-b9c6-16e2cb4e1841",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580989,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 66  38 62 63 32 37 33 2d 65  |d\":\"0f8bc273-e|
              00000090  64 62 64 2d 34 38 30 38  2d 62 39 63 36 2d 31 36  |dbd-4808-b9c6-16|
              000000a0  65 32 63 62 34 65 31 38  34 31 5c 22 7d 22 3a 7b  |e2cb4e1841\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580991,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=519) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  36 2e 33 31 5c 22 7d 22  |10.233.66.31\"}"|
              000001e0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              000001f0  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000200  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-wvll8",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-wvll8",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580989,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580991,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580991,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838580989,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.172",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=12) "10.233.66.31",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.66.31"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838580989,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838580990,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          ImageID: (string) (len=64) "077cda6b1f5995dcc056c00f92d40b5147132839f522d46d9ca84acd44ad76a7",
          ContainerID: (string) (len=72) "cri-o://65eb177f5404a9accfb16c54de3b6889d21f90913ed93b076b51e536c2f3ed39",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 11:09:53.471: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6975" for this suite. @ 12/19/23 11:09:53.481
• [9.344 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]
test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 12/19/23 11:09:53.496
  Dec 19 11:09:53.496: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename sched-preemption @ 12/19/23 11:09:53.499
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:09:53.529
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:09:53.537
  Dec 19 11:09:53.570: INFO: Waiting up to 1m0s for all nodes to be ready
  E1219 11:09:53.913192      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:54.913734      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:55.914672      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:56.914868      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:57.915960      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:58.917367      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:09:59.917725      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:00.918022      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:01.918832      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:02.919520      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:03.919841      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:04.920163      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:05.920696      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:06.920975      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:07.921911      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:08.922078      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:09.922754      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:10.923348      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:11.924022      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:12.924186      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:13.924319      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:14.926188      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:15.925656      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:16.926106      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:17.926325      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:18.926602      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:19.927342      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:20.928447      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:21.929457      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:22.930033      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:23.930971      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:24.931210      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:25.931394      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:26.932107      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:27.933014      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:28.933011      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:29.933350      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:30.934316      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:31.935449      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:32.935619      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:33.936142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:34.936392      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:35.937281      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:36.937576      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:37.938365      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:38.939429      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:39.940289      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:40.940776      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:41.941570      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:42.942125      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:43.942428      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:44.942699      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:45.943671      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:46.943988      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:47.945042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:48.945709      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:49.945992      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:50.946417      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:51.946874      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:52.946753      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:10:53.640: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 12/19/23 11:10:53.655
  Dec 19 11:10:53.656: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename sched-preemption-path @ 12/19/23 11:10:53.661
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:10:53.698
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:10:53.704
  STEP: Finding an available node @ 12/19/23 11:10:53.709
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 12/19/23 11:10:53.71
  E1219 11:10:53.947667      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:54.947888      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 12/19/23 11:10:55.766
  Dec 19 11:10:55.784: INFO: found a healthy node: hiengux9ahcu-3
  E1219 11:10:55.948041      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:56.948212      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:57.954016      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:58.954436      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:10:59.955397      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:00.956082      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:01.931: INFO: pods created so far: [1 1 1]
  Dec 19 11:11:01.932: INFO: length of pods created so far: 3
  E1219 11:11:01.957982      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:02.957607      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:03.956: INFO: pods created so far: [2 2 1]
  E1219 11:11:03.957252      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:04.958830      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:05.958776      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:06.958738      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:07.959265      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:08.959270      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:09.977541      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:10.958: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1219 11:11:10.963780      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:11.035: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-2683" for this suite. @ 12/19/23 11:11:11.13
  STEP: Destroying namespace "sched-preemption-1805" for this suite. @ 12/19/23 11:11:11.145
• [77.660 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance]
test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 12/19/23 11:11:11.16
  Dec 19 11:11:11.160: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename pods @ 12/19/23 11:11:11.164
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:11:11.193
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:11:11.199
  STEP: Create set of pods @ 12/19/23 11:11:11.204
  Dec 19 11:11:11.218: INFO: created test-pod-1
  Dec 19 11:11:11.233: INFO: created test-pod-2
  Dec 19 11:11:11.252: INFO: created test-pod-3
  STEP: waiting for all 3 pods to be running @ 12/19/23 11:11:11.252
  E1219 11:11:11.972306      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:12.965744      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for all pods to be deleted @ 12/19/23 11:11:13.366
  Dec 19 11:11:13.372: INFO: Pod quantity 3 is different from expected quantity 0
  E1219 11:11:13.965724      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:14.383: INFO: Pod quantity 3 is different from expected quantity 0
  E1219 11:11:14.966717      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:15.381: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9755" for this suite. @ 12/19/23 11:11:15.389
• [4.241 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]
test/e2e/apps/replica_set.go:143
  STEP: Creating a kubernetes client @ 12/19/23 11:11:15.404
  Dec 19 11:11:15.404: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename replicaset @ 12/19/23 11:11:15.407
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:11:15.438
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:11:15.446
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 12/19/23 11:11:15.459
  Dec 19 11:11:15.475: INFO: Pod name sample-pod: Found 0 pods out of 1
  E1219 11:11:15.967259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:16.967523      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:17.968231      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:18.968810      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:19.968764      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:20.482: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/19/23 11:11:20.482
  STEP: getting scale subresource @ 12/19/23 11:11:20.482
  STEP: updating a scale subresource @ 12/19/23 11:11:20.489
  STEP: verifying the replicaset Spec.Replicas was modified @ 12/19/23 11:11:20.498
  STEP: Patch a scale subresource @ 12/19/23 11:11:20.508
  Dec 19 11:11:20.541: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-629" for this suite. @ 12/19/23 11:11:20.552
• [5.163 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]
test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 12/19/23 11:11:20.569
  Dec 19 11:11:20.569: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename dns @ 12/19/23 11:11:20.578
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:11:20.625
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:11:20.632
  STEP: Creating a test headless service @ 12/19/23 11:11:20.639
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8148.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-8148.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8148.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-8148.svc.cluster.local;sleep 1; done
   @ 12/19/23 11:11:20.652
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8148.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-8148.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8148.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-8148.svc.cluster.local;sleep 1; done
   @ 12/19/23 11:11:20.652
  STEP: creating a pod to probe DNS @ 12/19/23 11:11:20.652
  STEP: submitting the pod to kubernetes @ 12/19/23 11:11:20.652
  E1219 11:11:20.969792      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:21.970072      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/19/23 11:11:22.705
  STEP: looking for the results for each expected name from probers @ 12/19/23 11:11:22.712
  Dec 19 11:11:22.750: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:22.788: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:22.797: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:22.805: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:22.813: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:22.823: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:22.833: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:22.841: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:22.842: INFO: Lookups using dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8148.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8148.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local jessie_udp@dns-test-service-2.dns-8148.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8148.svc.cluster.local]

  Dec 19 11:11:22.880: INFO: Pod client logs for webserver: 
  Dec 19 11:11:22.890: INFO: Pod client logs for querier: 
  Dec 19 11:11:22.901: INFO: Pod client logs for jessie-querier: 
  E1219 11:11:22.973370      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:23.973839      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:24.973980      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:25.974406      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:26.974431      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:27.911: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:27.918: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:27.925: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:27.931: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:27.937: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:27.944: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:27.950: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:27.956: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:27.956: INFO: Lookups using dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8148.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8148.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local jessie_udp@dns-test-service-2.dns-8148.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8148.svc.cluster.local]

  Dec 19 11:11:27.969: INFO: Pod client logs for webserver: 
  E1219 11:11:27.974928      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:27.981: INFO: Pod client logs for querier: 
  Dec 19 11:11:27.992: INFO: Pod client logs for jessie-querier: 
  E1219 11:11:28.975757      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:29.975910      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:30.976199      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:31.978558      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:32.909: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:32.918: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:32.926: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:32.935: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:32.945: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:32.953: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:32.961: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:32.968: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:32.969: INFO: Lookups using dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8148.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8148.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local jessie_udp@dns-test-service-2.dns-8148.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8148.svc.cluster.local]

  E1219 11:11:32.979479      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:32.981: INFO: Pod client logs for webserver: 
  Dec 19 11:11:32.993: INFO: Pod client logs for querier: 
  Dec 19 11:11:33.005: INFO: Pod client logs for jessie-querier: 
  E1219 11:11:33.980409      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:34.980689      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:35.981580      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:36.982214      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:37.913: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:37.925: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:37.933: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:37.946: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:37.957: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:37.965: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:37.974: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:37.981: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:37.982: INFO: Lookups using dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8148.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8148.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local jessie_udp@dns-test-service-2.dns-8148.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8148.svc.cluster.local]

  E1219 11:11:37.982865      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:37.999: INFO: Pod client logs for webserver: 
  Dec 19 11:11:38.012: INFO: Pod client logs for querier: 
  Dec 19 11:11:38.026: INFO: Pod client logs for jessie-querier: 
  E1219 11:11:38.983110      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:39.984104      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:40.984878      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:41.985617      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:42.913: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:42.922: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:42.930: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:42.939: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:42.948: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:42.956: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:42.964: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  E1219 11:11:42.985852      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:42.985: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:42.987: INFO: Lookups using dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8148.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8148.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local jessie_udp@dns-test-service-2.dns-8148.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8148.svc.cluster.local]

  Dec 19 11:11:43.012: INFO: Pod client logs for webserver: 
  Dec 19 11:11:43.029: INFO: Pod client logs for querier: 
  Dec 19 11:11:43.051: INFO: Pod client logs for jessie-querier: 
  E1219 11:11:43.986188      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:44.986531      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:45.987482      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:46.988041      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:47.918: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:47.927: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:47.937: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:47.947: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:47.956: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:47.969: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:47.978: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:47.986: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:47.986: INFO: Lookups using dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8148.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8148.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8148.svc.cluster.local jessie_udp@dns-test-service-2.dns-8148.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8148.svc.cluster.local]

  E1219 11:11:47.989546      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:48.003: INFO: Pod client logs for webserver: 
  Dec 19 11:11:48.016: INFO: Pod client logs for querier: 
  Dec 19 11:11:48.033: INFO: Pod client logs for jessie-querier: 
  E1219 11:11:48.990371      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:49.990784      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:50.990823      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:51.992281      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:52.939: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:52.949: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8148.svc.cluster.local from pod dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc: the server could not find the requested resource (get pods dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc)
  Dec 19 11:11:52.990: INFO: Lookups using dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc failed for: [wheezy_udp@dns-test-service-2.dns-8148.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8148.svc.cluster.local]

  E1219 11:11:52.991633      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:53.007: INFO: Pod client logs for webserver: 
  Dec 19 11:11:53.027: INFO: Pod client logs for querier: 
  Dec 19 11:11:53.044: INFO: Pod client logs for jessie-querier: 
  E1219 11:11:53.992581      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:54.992665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:55.992989      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:56.992752      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:57.993192      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:11:57.993: INFO: DNS probes using dns-8148/dns-test-eb5a7636-f8a9-4649-a592-c99e1a0565cc succeeded

  Dec 19 11:11:57.994: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/19/23 11:11:58.006
  STEP: deleting the test headless service @ 12/19/23 11:11:58.07
  STEP: Destroying namespace "dns-8148" for this suite. @ 12/19/23 11:11:58.125
• [37.590 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]
test/e2e/apimachinery/webhook.go:498
  STEP: Creating a kubernetes client @ 12/19/23 11:11:58.176
  Dec 19 11:11:58.176: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename webhook @ 12/19/23 11:11:58.181
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:11:58.224
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:11:58.23
  STEP: Setting up server cert @ 12/19/23 11:11:58.283
  E1219 11:11:58.993741      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:11:59.993668      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 11:12:00.768
  STEP: Deploying the webhook pod @ 12/19/23 11:12:00.79
  STEP: Wait for the deployment to be ready @ 12/19/23 11:12:00.817
  Dec 19 11:12:00.845: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1219 11:12:00.994251      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:01.994584      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:12:02.87
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:12:02.898
  E1219 11:12:02.995568      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:12:03.898: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 12/19/23 11:12:03.931
  E1219 11:12:03.996268      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 12/19/23 11:12:04
  STEP: Creating a configMap that should not be mutated @ 12/19/23 11:12:04.018
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 12/19/23 11:12:04.044
  STEP: Creating a configMap that should be mutated @ 12/19/23 11:12:04.06
  Dec 19 11:12:04.142: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-719" for this suite. @ 12/19/23 11:12:04.268
  STEP: Destroying namespace "webhook-markers-4032" for this suite. @ 12/19/23 11:12:04.285
• [6.147 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:54
  STEP: Creating a kubernetes client @ 12/19/23 11:12:04.327
  Dec 19 11:12:04.327: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 11:12:04.331
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:12:04.368
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:12:04.376
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:12:04.389
  E1219 11:12:04.996477      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:05.997193      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:06.998504      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:07.998542      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:12:08.443
  Dec 19 11:12:08.453: INFO: Trying to get logs from node hiengux9ahcu-3 pod downwardapi-volume-0216c3c8-98f2-4fc7-bb52-840d750d7a57 container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:12:08.469
  Dec 19 11:12:08.508: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3946" for this suite. @ 12/19/23 11:12:08.519
• [4.207 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:131
  STEP: Creating a kubernetes client @ 12/19/23 11:12:08.536
  Dec 19 11:12:08.536: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 11:12:08.538
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:12:08.568
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:12:08.582
  STEP: Creating the pod @ 12/19/23 11:12:08.59
  E1219 11:12:08.999118      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:09.999883      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:10.999915      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:12:11.195: INFO: Successfully updated pod "labelsupdatec5401825-0aad-46ae-b330-5dfe9d9ddd8c"
  E1219 11:12:12.000437      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:13.000787      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:12:13.233: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4800" for this suite. @ 12/19/23 11:12:13.247
• [4.724 seconds]
------------------------------
SS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance]
test/e2e/apps/job.go:713
  STEP: Creating a kubernetes client @ 12/19/23 11:12:13.261
  Dec 19 11:12:13.261: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename job @ 12/19/23 11:12:13.274
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:12:13.315
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:12:13.325
  STEP: Creating a suspended job @ 12/19/23 11:12:13.345
  STEP: Patching the Job @ 12/19/23 11:12:13.359
  STEP: Watching for Job to be patched @ 12/19/23 11:12:13.411
  Dec 19 11:12:13.416: INFO: Event ADDED observed for Job e2e-qvw5j in namespace job-7364 with labels: map[e2e-job-label:e2e-qvw5j] and annotations: map[]
  Dec 19 11:12:13.417: INFO: Event MODIFIED observed for Job e2e-qvw5j in namespace job-7364 with labels: map[e2e-job-label:e2e-qvw5j] and annotations: map[]
  Dec 19 11:12:13.417: INFO: Event MODIFIED found for Job e2e-qvw5j in namespace job-7364 with labels: map[e2e-job-label:e2e-qvw5j e2e-qvw5j:patched] and annotations: map[]
  STEP: Updating the job @ 12/19/23 11:12:13.418
  STEP: Watching for Job to be updated @ 12/19/23 11:12:13.438
  Dec 19 11:12:13.446: INFO: Event MODIFIED found for Job e2e-qvw5j in namespace job-7364 with labels: map[e2e-job-label:e2e-qvw5j e2e-qvw5j:patched] and annotations: map[updated:true]
  Dec 19 11:12:13.448: INFO: Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 12/19/23 11:12:13.448
  Dec 19 11:12:13.457: INFO: Job: e2e-qvw5j as labels: map[e2e-job-label:e2e-qvw5j e2e-qvw5j:patched]
  STEP: Waiting for job to complete @ 12/19/23 11:12:13.457
  E1219 11:12:14.001083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:15.001475      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:16.002337      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:17.002851      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:18.003348      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:19.004224      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:20.004141      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:21.003763      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 12/19/23 11:12:21.477
  STEP: Watching for Job to be deleted @ 12/19/23 11:12:21.495
  Dec 19 11:12:21.503: INFO: Event MODIFIED observed for Job e2e-qvw5j in namespace job-7364 with labels: map[e2e-job-label:e2e-qvw5j e2e-qvw5j:patched] and annotations: map[updated:true]
  Dec 19 11:12:21.503: INFO: Event MODIFIED observed for Job e2e-qvw5j in namespace job-7364 with labels: map[e2e-job-label:e2e-qvw5j e2e-qvw5j:patched] and annotations: map[updated:true]
  Dec 19 11:12:21.504: INFO: Event MODIFIED observed for Job e2e-qvw5j in namespace job-7364 with labels: map[e2e-job-label:e2e-qvw5j e2e-qvw5j:patched] and annotations: map[updated:true]
  Dec 19 11:12:21.504: INFO: Event MODIFIED observed for Job e2e-qvw5j in namespace job-7364 with labels: map[e2e-job-label:e2e-qvw5j e2e-qvw5j:patched] and annotations: map[updated:true]
  Dec 19 11:12:21.504: INFO: Event MODIFIED observed for Job e2e-qvw5j in namespace job-7364 with labels: map[e2e-job-label:e2e-qvw5j e2e-qvw5j:patched] and annotations: map[updated:true]
  Dec 19 11:12:21.504: INFO: Event DELETED found for Job e2e-qvw5j in namespace job-7364 with labels: map[e2e-job-label:e2e-qvw5j e2e-qvw5j:patched] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 12/19/23 11:12:21.505
  Dec 19 11:12:21.559: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7364" for this suite. @ 12/19/23 11:12:21.615
• [8.378 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]
test/e2e/apimachinery/resource_quota.go:161
  STEP: Creating a kubernetes client @ 12/19/23 11:12:21.64
  Dec 19 11:12:21.640: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 11:12:21.647
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:12:21.691
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:12:21.698
  STEP: Discovering how many secrets are in namespace by default @ 12/19/23 11:12:21.704
  E1219 11:12:22.004041      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:23.005809      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:24.006575      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:25.007272      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:26.008613      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 12/19/23 11:12:26.712
  E1219 11:12:27.009187      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:28.009395      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:29.010047      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:30.010530      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:31.010480      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/19/23 11:12:31.723
  STEP: Ensuring resource quota status is calculated @ 12/19/23 11:12:31.739
  E1219 11:12:32.011373      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:33.011858      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 12/19/23 11:12:33.75
  STEP: Ensuring resource quota status captures secret creation @ 12/19/23 11:12:33.776
  E1219 11:12:34.012661      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:35.013019      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 12/19/23 11:12:35.795
  STEP: Ensuring resource quota status released usage @ 12/19/23 11:12:35.815
  E1219 11:12:36.013603      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:37.014258      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:12:37.831: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6056" for this suite. @ 12/19/23 11:12:37.844
• [16.228 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:47
  STEP: Creating a kubernetes client @ 12/19/23 11:12:37.886
  Dec 19 11:12:37.886: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename configmap @ 12/19/23 11:12:37.89
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:12:37.926
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:12:37.93
  STEP: Creating configMap with name configmap-test-volume-8b5f60e5-346a-4f52-ad57-604a35571498 @ 12/19/23 11:12:37.936
  STEP: Creating a pod to test consume configMaps @ 12/19/23 11:12:37.95
  E1219 11:12:38.015950      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:39.015667      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:40.016893      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:41.017398      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:12:42.011
  E1219 11:12:42.018057      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:12:42.023: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-configmaps-9c30ab56-3986-4a65-91c1-d3d09ca6e153 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 11:12:42.04
  Dec 19 11:12:42.078: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2879" for this suite. @ 12/19/23 11:12:42.092
• [4.223 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]
test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 12/19/23 11:12:42.114
  Dec 19 11:12:42.114: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename watch @ 12/19/23 11:12:42.118
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:12:42.161
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:12:42.168
  STEP: getting a starting resourceVersion @ 12/19/23 11:12:42.175
  STEP: starting a background goroutine to produce watch events @ 12/19/23 11:12:42.185
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 12/19/23 11:12:42.185
  E1219 11:12:43.018734      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:44.019695      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:12:44.930: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-191" for this suite. @ 12/19/23 11:12:44.979
  E1219 11:12:45.019884      14 retrywatcher.go:129] "Watch failed" err="context canceled"
• [2.921 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance]
test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 12/19/23 11:12:45.038
  Dec 19 11:12:45.039: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename csiinlinevolumes @ 12/19/23 11:12:45.043
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:12:45.127
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:12:45.133
  STEP: Creating two CSIDrivers @ 12/19/23 11:12:45.139
  STEP: Getting "inline-driver-e9377a46-6d7d-4573-8051-21dd0e039b07" & "inline-driver-b799adb7-5edb-4068-be79-239a118561a2" @ 12/19/23 11:12:45.177
  STEP: Patching the CSIDriver "inline-driver-b799adb7-5edb-4068-be79-239a118561a2" @ 12/19/23 11:12:45.189
  STEP: Updating the CSIDriver "inline-driver-b799adb7-5edb-4068-be79-239a118561a2" @ 12/19/23 11:12:45.204
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-7544" @ 12/19/23 11:12:45.219
  STEP: Deleting CSIDriver "inline-driver-e9377a46-6d7d-4573-8051-21dd0e039b07" @ 12/19/23 11:12:45.227
  STEP: Confirm deletion of CSIDriver "inline-driver-e9377a46-6d7d-4573-8051-21dd0e039b07" @ 12/19/23 11:12:45.24
  STEP: Deleting CSIDriver "inline-driver-b799adb7-5edb-4068-be79-239a118561a2" via DeleteCollection @ 12/19/23 11:12:45.247
  STEP: Confirm deletion of CSIDriver "inline-driver-b799adb7-5edb-4068-be79-239a118561a2" @ 12/19/23 11:12:45.264
  Dec 19 11:12:45.269: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-7544" for this suite. @ 12/19/23 11:12:45.279
• [0.255 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
test/e2e/network/service.go:2224
  STEP: Creating a kubernetes client @ 12/19/23 11:12:45.306
  Dec 19 11:12:45.306: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename services @ 12/19/23 11:12:45.309
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:12:45.342
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:12:45.347
  STEP: creating service in namespace services-4360 @ 12/19/23 11:12:45.353
  STEP: creating service affinity-nodeport-transition in namespace services-4360 @ 12/19/23 11:12:45.353
  STEP: creating replication controller affinity-nodeport-transition in namespace services-4360 @ 12/19/23 11:12:45.386
  I1219 11:12:45.402025      14 runners.go:197] Created replication controller with name: affinity-nodeport-transition, namespace: services-4360, replica count: 3
  E1219 11:12:46.020560      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:47.021715      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:48.021824      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 11:12:48.462062      14 runners.go:197] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec 19 11:12:48.490: INFO: Creating new exec pod
  E1219 11:12:49.021692      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:50.022180      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:51.022867      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:12:51.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-4360 exec execpod-affinityhppgf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  Dec 19 11:12:51.946: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  Dec 19 11:12:51.946: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 11:12:51.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-4360 exec execpod-affinityhppgf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.6.20 80'
  E1219 11:12:52.022873      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:12:52.270: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.6.20 80\nConnection to 10.233.6.20 80 port [tcp/http] succeeded!\n"
  Dec 19 11:12:52.270: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 11:12:52.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-4360 exec execpod-affinityhppgf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.83 31792'
  Dec 19 11:12:52.595: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.83 31792\nConnection to 192.168.121.83 31792 port [tcp/*] succeeded!\n"
  Dec 19 11:12:52.595: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 11:12:52.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-4360 exec execpod-affinityhppgf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.172 31792'
  Dec 19 11:12:52.893: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.172 31792\nConnection to 192.168.121.172 31792 port [tcp/*] succeeded!\n"
  Dec 19 11:12:52.893: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 11:12:52.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-4360 exec execpod-affinityhppgf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.83:31792/ ; done'
  E1219 11:12:53.023789      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:12:53.469: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n"
  Dec 19 11:12:53.469: INFO: stdout: "\naffinity-nodeport-transition-ps4bn\naffinity-nodeport-transition-mrvrt\naffinity-nodeport-transition-lk8jz\naffinity-nodeport-transition-lk8jz\naffinity-nodeport-transition-mrvrt\naffinity-nodeport-transition-ps4bn\naffinity-nodeport-transition-mrvrt\naffinity-nodeport-transition-lk8jz\naffinity-nodeport-transition-ps4bn\naffinity-nodeport-transition-ps4bn\naffinity-nodeport-transition-lk8jz\naffinity-nodeport-transition-ps4bn\naffinity-nodeport-transition-ps4bn\naffinity-nodeport-transition-mrvrt\naffinity-nodeport-transition-lk8jz\naffinity-nodeport-transition-ps4bn"
  Dec 19 11:12:53.469: INFO: Received response from host: affinity-nodeport-transition-ps4bn
  Dec 19 11:12:53.469: INFO: Received response from host: affinity-nodeport-transition-mrvrt
  Dec 19 11:12:53.469: INFO: Received response from host: affinity-nodeport-transition-lk8jz
  Dec 19 11:12:53.469: INFO: Received response from host: affinity-nodeport-transition-lk8jz
  Dec 19 11:12:53.469: INFO: Received response from host: affinity-nodeport-transition-mrvrt
  Dec 19 11:12:53.469: INFO: Received response from host: affinity-nodeport-transition-ps4bn
  Dec 19 11:12:53.469: INFO: Received response from host: affinity-nodeport-transition-mrvrt
  Dec 19 11:12:53.469: INFO: Received response from host: affinity-nodeport-transition-lk8jz
  Dec 19 11:12:53.469: INFO: Received response from host: affinity-nodeport-transition-ps4bn
  Dec 19 11:12:53.469: INFO: Received response from host: affinity-nodeport-transition-ps4bn
  Dec 19 11:12:53.469: INFO: Received response from host: affinity-nodeport-transition-lk8jz
  Dec 19 11:12:53.469: INFO: Received response from host: affinity-nodeport-transition-ps4bn
  Dec 19 11:12:53.469: INFO: Received response from host: affinity-nodeport-transition-ps4bn
  Dec 19 11:12:53.469: INFO: Received response from host: affinity-nodeport-transition-mrvrt
  Dec 19 11:12:53.469: INFO: Received response from host: affinity-nodeport-transition-lk8jz
  Dec 19 11:12:53.469: INFO: Received response from host: affinity-nodeport-transition-ps4bn
  Dec 19 11:12:53.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-4360 exec execpod-affinityhppgf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.83:31792/ ; done'
  E1219 11:12:54.024090      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:12:54.039: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.83:31792/\n"
  Dec 19 11:12:54.039: INFO: stdout: "\naffinity-nodeport-transition-lk8jz\naffinity-nodeport-transition-lk8jz\naffinity-nodeport-transition-lk8jz\naffinity-nodeport-transition-lk8jz\naffinity-nodeport-transition-lk8jz\naffinity-nodeport-transition-lk8jz\naffinity-nodeport-transition-lk8jz\naffinity-nodeport-transition-lk8jz\naffinity-nodeport-transition-lk8jz\naffinity-nodeport-transition-lk8jz\naffinity-nodeport-transition-lk8jz\naffinity-nodeport-transition-lk8jz\naffinity-nodeport-transition-lk8jz\naffinity-nodeport-transition-lk8jz\naffinity-nodeport-transition-lk8jz\naffinity-nodeport-transition-lk8jz"
  Dec 19 11:12:54.039: INFO: Received response from host: affinity-nodeport-transition-lk8jz
  Dec 19 11:12:54.039: INFO: Received response from host: affinity-nodeport-transition-lk8jz
  Dec 19 11:12:54.039: INFO: Received response from host: affinity-nodeport-transition-lk8jz
  Dec 19 11:12:54.039: INFO: Received response from host: affinity-nodeport-transition-lk8jz
  Dec 19 11:12:54.039: INFO: Received response from host: affinity-nodeport-transition-lk8jz
  Dec 19 11:12:54.039: INFO: Received response from host: affinity-nodeport-transition-lk8jz
  Dec 19 11:12:54.039: INFO: Received response from host: affinity-nodeport-transition-lk8jz
  Dec 19 11:12:54.039: INFO: Received response from host: affinity-nodeport-transition-lk8jz
  Dec 19 11:12:54.039: INFO: Received response from host: affinity-nodeport-transition-lk8jz
  Dec 19 11:12:54.039: INFO: Received response from host: affinity-nodeport-transition-lk8jz
  Dec 19 11:12:54.039: INFO: Received response from host: affinity-nodeport-transition-lk8jz
  Dec 19 11:12:54.039: INFO: Received response from host: affinity-nodeport-transition-lk8jz
  Dec 19 11:12:54.039: INFO: Received response from host: affinity-nodeport-transition-lk8jz
  Dec 19 11:12:54.039: INFO: Received response from host: affinity-nodeport-transition-lk8jz
  Dec 19 11:12:54.039: INFO: Received response from host: affinity-nodeport-transition-lk8jz
  Dec 19 11:12:54.039: INFO: Received response from host: affinity-nodeport-transition-lk8jz
  Dec 19 11:12:54.039: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec 19 11:12:54.047: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-4360, will wait for the garbage collector to delete the pods @ 12/19/23 11:12:54.074
  Dec 19 11:12:54.153: INFO: Deleting ReplicationController affinity-nodeport-transition took: 14.064323ms
  Dec 19 11:12:54.253: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.661008ms
  E1219 11:12:55.024515      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:56.025285      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:57.025996      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-4360" for this suite. @ 12/19/23 11:12:57.429
• [12.138 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
test/e2e/network/service.go:2187
  STEP: Creating a kubernetes client @ 12/19/23 11:12:57.45
  Dec 19 11:12:57.450: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename services @ 12/19/23 11:12:57.453
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:12:57.508
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:12:57.513
  STEP: creating service in namespace services-1041 @ 12/19/23 11:12:57.518
  STEP: creating service affinity-clusterip-transition in namespace services-1041 @ 12/19/23 11:12:57.518
  STEP: creating replication controller affinity-clusterip-transition in namespace services-1041 @ 12/19/23 11:12:57.546
  I1219 11:12:57.565487      14 runners.go:197] Created replication controller with name: affinity-clusterip-transition, namespace: services-1041, replica count: 3
  E1219 11:12:58.026946      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:12:59.027895      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:00.027786      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 11:13:00.617281      14 runners.go:197] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec 19 11:13:00.637: INFO: Creating new exec pod
  E1219 11:13:01.027687      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:02.028508      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:03.030412      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:03.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-1041 exec execpod-affinitymqt4n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  Dec 19 11:13:04.003: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  Dec 19 11:13:04.004: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 11:13:04.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-1041 exec execpod-affinitymqt4n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.6.7 80'
  E1219 11:13:04.029986      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:04.284: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.6.7 80\nConnection to 10.233.6.7 80 port [tcp/http] succeeded!\n"
  Dec 19 11:13:04.284: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 11:13:04.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-1041 exec execpod-affinitymqt4n -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.6.7:80/ ; done'
  Dec 19 11:13:04.870: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n"
  Dec 19 11:13:04.870: INFO: stdout: "\naffinity-clusterip-transition-gpzcr\naffinity-clusterip-transition-zdsfg\naffinity-clusterip-transition-zdrtj\naffinity-clusterip-transition-zdsfg\naffinity-clusterip-transition-zdsfg\naffinity-clusterip-transition-zdrtj\naffinity-clusterip-transition-zdsfg\naffinity-clusterip-transition-zdrtj\naffinity-clusterip-transition-zdrtj\naffinity-clusterip-transition-zdrtj\naffinity-clusterip-transition-gpzcr\naffinity-clusterip-transition-gpzcr\naffinity-clusterip-transition-zdrtj\naffinity-clusterip-transition-zdrtj\naffinity-clusterip-transition-zdsfg\naffinity-clusterip-transition-zdrtj"
  Dec 19 11:13:04.870: INFO: Received response from host: affinity-clusterip-transition-gpzcr
  Dec 19 11:13:04.871: INFO: Received response from host: affinity-clusterip-transition-zdsfg
  Dec 19 11:13:04.871: INFO: Received response from host: affinity-clusterip-transition-zdrtj
  Dec 19 11:13:04.871: INFO: Received response from host: affinity-clusterip-transition-zdsfg
  Dec 19 11:13:04.871: INFO: Received response from host: affinity-clusterip-transition-zdsfg
  Dec 19 11:13:04.871: INFO: Received response from host: affinity-clusterip-transition-zdrtj
  Dec 19 11:13:04.871: INFO: Received response from host: affinity-clusterip-transition-zdsfg
  Dec 19 11:13:04.871: INFO: Received response from host: affinity-clusterip-transition-zdrtj
  Dec 19 11:13:04.871: INFO: Received response from host: affinity-clusterip-transition-zdrtj
  Dec 19 11:13:04.871: INFO: Received response from host: affinity-clusterip-transition-zdrtj
  Dec 19 11:13:04.871: INFO: Received response from host: affinity-clusterip-transition-gpzcr
  Dec 19 11:13:04.871: INFO: Received response from host: affinity-clusterip-transition-gpzcr
  Dec 19 11:13:04.871: INFO: Received response from host: affinity-clusterip-transition-zdrtj
  Dec 19 11:13:04.871: INFO: Received response from host: affinity-clusterip-transition-zdrtj
  Dec 19 11:13:04.872: INFO: Received response from host: affinity-clusterip-transition-zdsfg
  Dec 19 11:13:04.872: INFO: Received response from host: affinity-clusterip-transition-zdrtj
  Dec 19 11:13:04.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-1041 exec execpod-affinitymqt4n -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.6.7:80/ ; done'
  E1219 11:13:05.030915      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:05.385: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.6.7:80/\n"
  Dec 19 11:13:05.385: INFO: stdout: "\naffinity-clusterip-transition-gpzcr\naffinity-clusterip-transition-gpzcr\naffinity-clusterip-transition-gpzcr\naffinity-clusterip-transition-gpzcr\naffinity-clusterip-transition-gpzcr\naffinity-clusterip-transition-gpzcr\naffinity-clusterip-transition-gpzcr\naffinity-clusterip-transition-gpzcr\naffinity-clusterip-transition-gpzcr\naffinity-clusterip-transition-gpzcr\naffinity-clusterip-transition-gpzcr\naffinity-clusterip-transition-gpzcr\naffinity-clusterip-transition-gpzcr\naffinity-clusterip-transition-gpzcr\naffinity-clusterip-transition-gpzcr\naffinity-clusterip-transition-gpzcr"
  Dec 19 11:13:05.385: INFO: Received response from host: affinity-clusterip-transition-gpzcr
  Dec 19 11:13:05.385: INFO: Received response from host: affinity-clusterip-transition-gpzcr
  Dec 19 11:13:05.385: INFO: Received response from host: affinity-clusterip-transition-gpzcr
  Dec 19 11:13:05.385: INFO: Received response from host: affinity-clusterip-transition-gpzcr
  Dec 19 11:13:05.385: INFO: Received response from host: affinity-clusterip-transition-gpzcr
  Dec 19 11:13:05.385: INFO: Received response from host: affinity-clusterip-transition-gpzcr
  Dec 19 11:13:05.385: INFO: Received response from host: affinity-clusterip-transition-gpzcr
  Dec 19 11:13:05.385: INFO: Received response from host: affinity-clusterip-transition-gpzcr
  Dec 19 11:13:05.385: INFO: Received response from host: affinity-clusterip-transition-gpzcr
  Dec 19 11:13:05.385: INFO: Received response from host: affinity-clusterip-transition-gpzcr
  Dec 19 11:13:05.385: INFO: Received response from host: affinity-clusterip-transition-gpzcr
  Dec 19 11:13:05.385: INFO: Received response from host: affinity-clusterip-transition-gpzcr
  Dec 19 11:13:05.385: INFO: Received response from host: affinity-clusterip-transition-gpzcr
  Dec 19 11:13:05.385: INFO: Received response from host: affinity-clusterip-transition-gpzcr
  Dec 19 11:13:05.385: INFO: Received response from host: affinity-clusterip-transition-gpzcr
  Dec 19 11:13:05.385: INFO: Received response from host: affinity-clusterip-transition-gpzcr
  Dec 19 11:13:05.386: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec 19 11:13:05.396: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-1041, will wait for the garbage collector to delete the pods @ 12/19/23 11:13:05.443
  Dec 19 11:13:05.578: INFO: Deleting ReplicationController affinity-clusterip-transition took: 73.184806ms
  Dec 19 11:13:05.679: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 101.385514ms
  E1219 11:13:06.031599      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:07.032727      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:08.033791      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-1041" for this suite. @ 12/19/23 11:13:08.928
• [11.494 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]
test/e2e/apimachinery/webhook.go:403
  STEP: Creating a kubernetes client @ 12/19/23 11:13:08.947
  Dec 19 11:13:08.947: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename webhook @ 12/19/23 11:13:08.952
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:13:08.99
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:13:08.997
  E1219 11:13:09.035155      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Setting up server cert @ 12/19/23 11:13:09.068
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 11:13:09.713
  STEP: Deploying the webhook pod @ 12/19/23 11:13:09.73
  STEP: Wait for the deployment to be ready @ 12/19/23 11:13:09.758
  Dec 19 11:13:09.776: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1219 11:13:10.035270      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:11.035759      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:11.807: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 13, 9, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 13, 9, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 13, 9, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 13, 9, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:13:12.036528      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:13.037378      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:13:13.816
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:13:13.846
  E1219 11:13:14.037888      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:14.846: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 12/19/23 11:13:14.862
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 12/19/23 11:13:14.905
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 12/19/23 11:13:14.926
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 12/19/23 11:13:14.948
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 12/19/23 11:13:14.972
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 12/19/23 11:13:14.991
  Dec 19 11:13:15.016: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1219 11:13:15.038863      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-7931" for this suite. @ 12/19/23 11:13:15.163
  STEP: Destroying namespace "webhook-markers-9543" for this suite. @ 12/19/23 11:13:15.187
• [6.267 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]
test/e2e/common/storage/empty_dir.go:227
  STEP: Creating a kubernetes client @ 12/19/23 11:13:15.219
  Dec 19 11:13:15.219: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 11:13:15.223
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:13:15.277
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:13:15.289
  STEP: Creating Pod @ 12/19/23 11:13:15.296
  E1219 11:13:16.038868      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:17.039782      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 12/19/23 11:13:17.359
  Dec 19 11:13:17.359: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-2304 PodName:pod-sharedvolume-ebc4e72e-676d-43dc-b39f-8570ccb9ede3 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:13:17.360: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 11:13:17.362: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:13:17.362: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/emptydir-2304/pods/pod-sharedvolume-ebc4e72e-676d-43dc-b39f-8570ccb9ede3/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  Dec 19 11:13:17.527: INFO: Exec stderr: ""
  Dec 19 11:13:17.528: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2304" for this suite. @ 12/19/23 11:13:17.54
• [2.339 seconds]
------------------------------
S
------------------------------
[sig-network] DNS should provide DNS for services  [Conformance]
test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 12/19/23 11:13:17.558
  Dec 19 11:13:17.558: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename dns @ 12/19/23 11:13:17.562
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:13:17.601
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:13:17.607
  STEP: Creating a test headless service @ 12/19/23 11:13:17.612
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8760.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8760.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8760.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8760.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8760.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8760.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8760.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8760.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8760.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8760.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 14.56.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.56.14_udp@PTR;check="$$(dig +tcp +noall +answer +search 14.56.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.56.14_tcp@PTR;sleep 1; done
   @ 12/19/23 11:13:17.657
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8760.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8760.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8760.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8760.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8760.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8760.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8760.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8760.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8760.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8760.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 14.56.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.56.14_udp@PTR;check="$$(dig +tcp +noall +answer +search 14.56.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.56.14_tcp@PTR;sleep 1; done
   @ 12/19/23 11:13:17.657
  STEP: creating a pod to probe DNS @ 12/19/23 11:13:17.657
  STEP: submitting the pod to kubernetes @ 12/19/23 11:13:17.657
  E1219 11:13:18.039579      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:19.040013      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/19/23 11:13:19.702
  STEP: looking for the results for each expected name from probers @ 12/19/23 11:13:19.712
  Dec 19 11:13:19.725: INFO: Unable to read wheezy_udp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:19.733: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:19.741: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:19.751: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:19.789: INFO: Unable to read jessie_udp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:19.797: INFO: Unable to read jessie_tcp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:19.803: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:19.811: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:19.841: INFO: Lookups using dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea failed for: [wheezy_udp@dns-test-service.dns-8760.svc.cluster.local wheezy_tcp@dns-test-service.dns-8760.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local jessie_udp@dns-test-service.dns-8760.svc.cluster.local jessie_tcp@dns-test-service.dns-8760.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local]

  Dec 19 11:13:19.854: INFO: Pod client logs for webserver: 
  Dec 19 11:13:19.868: INFO: Pod client logs for querier: 
  Dec 19 11:13:19.883: INFO: Pod client logs for jessie-querier: 
  E1219 11:13:20.041692      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:21.042465      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:22.042804      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:23.042957      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:24.043161      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:24.893: INFO: Unable to read wheezy_udp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:24.904: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:24.917: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:24.929: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:24.982: INFO: Unable to read jessie_udp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:24.992: INFO: Unable to read jessie_tcp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:25.000: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:25.009: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  E1219 11:13:25.043578      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:25.066: INFO: Lookups using dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea failed for: [wheezy_udp@dns-test-service.dns-8760.svc.cluster.local wheezy_tcp@dns-test-service.dns-8760.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local jessie_udp@dns-test-service.dns-8760.svc.cluster.local jessie_tcp@dns-test-service.dns-8760.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local]

  Dec 19 11:13:25.089: INFO: Pod client logs for webserver: 
  Dec 19 11:13:25.106: INFO: Pod client logs for querier: 
  Dec 19 11:13:25.134: INFO: Pod client logs for jessie-querier: 
  E1219 11:13:26.044544      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:27.045731      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:28.045840      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:29.045920      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:29.891: INFO: Unable to read wheezy_udp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:29.900: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:29.909: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:29.918: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:29.958: INFO: Unable to read jessie_udp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:29.966: INFO: Unable to read jessie_tcp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:29.974: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:29.982: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:30.015: INFO: Lookups using dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea failed for: [wheezy_udp@dns-test-service.dns-8760.svc.cluster.local wheezy_tcp@dns-test-service.dns-8760.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local jessie_udp@dns-test-service.dns-8760.svc.cluster.local jessie_tcp@dns-test-service.dns-8760.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local]

  Dec 19 11:13:30.032: INFO: Pod client logs for webserver: 
  E1219 11:13:30.046399      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:30.048: INFO: Pod client logs for querier: 
  Dec 19 11:13:30.064: INFO: Pod client logs for jessie-querier: 
  E1219 11:13:31.046469      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:32.049982      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:33.050323      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:34.050810      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:34.894: INFO: Unable to read wheezy_udp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:34.903: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:34.912: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:34.922: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:34.980: INFO: Unable to read jessie_udp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:34.995: INFO: Unable to read jessie_tcp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:35.006: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:35.017: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  E1219 11:13:35.052765      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:35.053: INFO: Lookups using dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea failed for: [wheezy_udp@dns-test-service.dns-8760.svc.cluster.local wheezy_tcp@dns-test-service.dns-8760.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local jessie_udp@dns-test-service.dns-8760.svc.cluster.local jessie_tcp@dns-test-service.dns-8760.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local]

  Dec 19 11:13:35.066: INFO: Pod client logs for webserver: 
  Dec 19 11:13:35.084: INFO: Pod client logs for querier: 
  Dec 19 11:13:35.099: INFO: Pod client logs for jessie-querier: 
  E1219 11:13:36.053511      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:37.053779      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:38.054138      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:39.054851      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:39.897: INFO: Unable to read wheezy_udp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:39.904: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:39.912: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:39.922: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:39.963: INFO: Unable to read jessie_udp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:39.972: INFO: Unable to read jessie_tcp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:39.979: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:39.987: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:40.025: INFO: Lookups using dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea failed for: [wheezy_udp@dns-test-service.dns-8760.svc.cluster.local wheezy_tcp@dns-test-service.dns-8760.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local jessie_udp@dns-test-service.dns-8760.svc.cluster.local jessie_tcp@dns-test-service.dns-8760.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local]

  Dec 19 11:13:40.041: INFO: Pod client logs for webserver: 
  E1219 11:13:40.057587      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:40.058: INFO: Pod client logs for querier: 
  Dec 19 11:13:40.076: INFO: Pod client logs for jessie-querier: 
  E1219 11:13:41.059446      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:42.057729      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:43.057937      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:44.059145      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:44.894: INFO: Unable to read wheezy_udp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:44.904: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:44.917: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:44.927: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:44.979: INFO: Unable to read jessie_udp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:44.990: INFO: Unable to read jessie_tcp@dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:45.001: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:45.013: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local from pod dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea: the server could not find the requested resource (get pods dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea)
  Dec 19 11:13:45.048: INFO: Lookups using dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea failed for: [wheezy_udp@dns-test-service.dns-8760.svc.cluster.local wheezy_tcp@dns-test-service.dns-8760.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local jessie_udp@dns-test-service.dns-8760.svc.cluster.local jessie_tcp@dns-test-service.dns-8760.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8760.svc.cluster.local]

  E1219 11:13:45.059563      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:45.061: INFO: Pod client logs for webserver: 
  Dec 19 11:13:45.075: INFO: Pod client logs for querier: 
  Dec 19 11:13:45.096: INFO: Pod client logs for jessie-querier: 
  E1219 11:13:46.060370      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:47.060630      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:48.061351      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:49.061964      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:50.025: INFO: DNS probes using dns-8760/dns-test-6f4859f0-5684-4e68-a199-65d2909fd4ea succeeded

  Dec 19 11:13:50.026: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/19/23 11:13:50.039
  E1219 11:13:50.062931      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the test service @ 12/19/23 11:13:50.069
  STEP: deleting the test headless service @ 12/19/23 11:13:50.184
  STEP: Destroying namespace "dns-8760" for this suite. @ 12/19/23 11:13:50.217
• [32.678 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]
test/e2e/apimachinery/webhook.go:285
  STEP: Creating a kubernetes client @ 12/19/23 11:13:50.252
  Dec 19 11:13:50.252: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename webhook @ 12/19/23 11:13:50.264
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:13:50.296
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:13:50.304
  STEP: Setting up server cert @ 12/19/23 11:13:50.352
  E1219 11:13:51.063651      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 11:13:51.325
  STEP: Deploying the webhook pod @ 12/19/23 11:13:51.349
  STEP: Wait for the deployment to be ready @ 12/19/23 11:13:51.396
  Dec 19 11:13:51.454: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1219 11:13:52.064309      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:53.064575      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:13:53.489
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:13:53.516
  E1219 11:13:54.065679      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:54.518: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Dec 19 11:13:54.536: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 11:13:55.066261      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7526-crds.webhook.example.com via the AdmissionRegistration API @ 12/19/23 11:13:55.069
  STEP: Creating a custom resource that should be mutated by the webhook @ 12/19/23 11:13:55.11
  E1219 11:13:56.067621      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:13:57.067752      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:13:57.259: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2920" for this suite. @ 12/19/23 11:13:57.979
  STEP: Destroying namespace "webhook-markers-8955" for this suite. @ 12/19/23 11:13:57.995
• [7.763 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 12/19/23 11:13:58.02
  Dec 19 11:13:58.020: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename container-runtime @ 12/19/23 11:13:58.026
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:13:58.063
  E1219 11:13:58.067664      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:13:58.07
  STEP: create the container @ 12/19/23 11:13:58.075
  W1219 11:13:58.094626      14 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 12/19/23 11:13:58.095
  E1219 11:13:59.068036      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:00.068471      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:01.069289      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 12/19/23 11:14:01.133
  STEP: the container should be terminated @ 12/19/23 11:14:01.142
  STEP: the termination message should be set @ 12/19/23 11:14:01.142
  Dec 19 11:14:01.142: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 12/19/23 11:14:01.143
  Dec 19 11:14:01.178: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-3175" for this suite. @ 12/19/23 11:14:01.197
• [3.196 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:197
  STEP: Creating a kubernetes client @ 12/19/23 11:14:01.231
  Dec 19 11:14:01.231: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 11:14:01.235
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:14:01.269
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:14:01.274
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 12/19/23 11:14:01.28
  E1219 11:14:02.069455      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:03.069809      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:04.070389      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:05.070818      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:14:05.351
  Dec 19 11:14:05.357: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-4d79035b-3363-4c5b-8253-a5c1791e5906 container test-container: <nil>
  STEP: delete the pod @ 12/19/23 11:14:05.371
  Dec 19 11:14:05.402: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6723" for this suite. @ 12/19/23 11:14:05.413
• [4.200 seconds]
------------------------------
SS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
test/e2e/network/endpointslice.go:104
  STEP: Creating a kubernetes client @ 12/19/23 11:14:05.432
  Dec 19 11:14:05.433: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename endpointslice @ 12/19/23 11:14:05.436
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:14:05.47
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:14:05.481
  E1219 11:14:06.071402      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:07.072020      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:14:07.619: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-5829" for this suite. @ 12/19/23 11:14:07.64
• [2.226 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:71
  STEP: Creating a kubernetes client @ 12/19/23 11:14:07.673
  Dec 19 11:14:07.673: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename container-probe @ 12/19/23 11:14:07.678
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:14:07.708
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:14:07.713
  E1219 11:14:08.072357      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:09.072790      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:10.073257      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:11.074262      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:12.075499      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:13.076156      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:14.077115      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:15.077670      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:16.078774      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:17.078703      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:18.078847      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:19.079581      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:20.080809      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:21.081475      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:22.081890      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:23.082664      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:24.084126      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:25.087033      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:26.085738      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:27.086122      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:28.086861      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:29.086834      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:30.087327      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:31.088615      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:32.090135      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:33.088923      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:34.089582      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:35.090447      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:36.090945      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:37.091679      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:38.092200      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:39.093471      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:14:39.925: INFO: Container started at 2023-12-19 11:14:08 +0000 UTC, pod became ready at 2023-12-19 11:14:38 +0000 UTC
  Dec 19 11:14:39.927: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8806" for this suite. @ 12/19/23 11:14:39.94
• [32.283 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:54
  STEP: Creating a kubernetes client @ 12/19/23 11:14:39.959
  Dec 19 11:14:39.959: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:14:39.964
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:14:40
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:14:40.007
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:14:40.014
  E1219 11:14:40.093795      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:41.094846      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:42.095945      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:43.096204      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:14:44.066
  Dec 19 11:14:44.074: INFO: Trying to get logs from node hiengux9ahcu-3 pod downwardapi-volume-4da3e5d3-c5ff-49bd-bfcf-79b330fe7e70 container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:14:44.091
  E1219 11:14:44.097901      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:14:44.120: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3242" for this suite. @ 12/19/23 11:14:44.129
• [4.183 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:163
  STEP: Creating a kubernetes client @ 12/19/23 11:14:44.149
  Dec 19 11:14:44.149: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:14:44.153
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:14:44.183
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:14:44.189
  STEP: Creating the pod @ 12/19/23 11:14:44.194
  E1219 11:14:45.097208      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:46.097334      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:14:46.779: INFO: Successfully updated pod "annotationupdatee2333662-407c-4d98-8b3d-eb5a5aee412f"
  E1219 11:14:47.097566      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:48.097713      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:14:48.825: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3670" for this suite. @ 12/19/23 11:14:48.837
• [4.703 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
test/e2e/node/security_context.go:164
  STEP: Creating a kubernetes client @ 12/19/23 11:14:48.886
  Dec 19 11:14:48.886: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename security-context @ 12/19/23 11:14:48.894
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:14:48.922
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:14:48.927
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 12/19/23 11:14:48.935
  E1219 11:14:49.097972      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:50.098483      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:51.099497      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:52.101175      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:14:52.978
  Dec 19 11:14:52.984: INFO: Trying to get logs from node hiengux9ahcu-3 pod security-context-10bd85e8-d83a-4d60-b3dc-69d5a486a9bb container test-container: <nil>
  STEP: delete the pod @ 12/19/23 11:14:53.001
  Dec 19 11:14:53.032: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-8888" for this suite. @ 12/19/23 11:14:53.041
• [4.172 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]
test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 12/19/23 11:14:53.076
  Dec 19 11:14:53.076: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename init-container @ 12/19/23 11:14:53.08
  E1219 11:14:53.099535      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:14:53.112
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:14:53.117
  STEP: creating the pod @ 12/19/23 11:14:53.123
  Dec 19 11:14:53.123: INFO: PodSpec: initContainers in spec.initContainers
  E1219 11:14:54.100419      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:55.101211      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:14:55.902: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-6396" for this suite. @ 12/19/23 11:14:55.915
• [2.859 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:218
  STEP: Creating a kubernetes client @ 12/19/23 11:14:55.939
  Dec 19 11:14:55.939: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 11:14:55.942
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:14:55.98
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:14:55.986
  STEP: Creating a pod to test downward api env vars @ 12/19/23 11:14:55.991
  E1219 11:14:56.101485      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:57.102092      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:58.102499      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:14:59.103201      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:15:00.042
  Dec 19 11:15:00.048: INFO: Trying to get logs from node hiengux9ahcu-3 pod downward-api-3dce2404-0c7f-4d91-8f17-5aac76896640 container dapi-container: <nil>
  STEP: delete the pod @ 12/19/23 11:15:00.063
  Dec 19 11:15:00.099: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1219 11:15:00.103519      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "downward-api-8015" for this suite. @ 12/19/23 11:15:00.11
• [4.185 seconds]
------------------------------
SS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]
test/e2e/common/node/expansion.go:300
  STEP: Creating a kubernetes client @ 12/19/23 11:15:00.124
  Dec 19 11:15:00.124: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename var-expansion @ 12/19/23 11:15:00.127
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:15:00.165
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:15:00.17
  STEP: creating the pod @ 12/19/23 11:15:00.175
  STEP: waiting for pod running @ 12/19/23 11:15:00.192
  E1219 11:15:01.103914      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:02.104293      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:03.104705      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:04.105549      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating a file in subpath @ 12/19/23 11:15:04.219
  Dec 19 11:15:04.227: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-7436 PodName:var-expansion-18ac010a-5e2d-45b5-b264-21c9e2f842eb ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:15:04.227: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 11:15:04.230: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:15:04.230: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-7436/pods/var-expansion-18ac010a-5e2d-45b5-b264-21c9e2f842eb/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 12/19/23 11:15:04.388
  Dec 19 11:15:04.397: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-7436 PodName:var-expansion-18ac010a-5e2d-45b5-b264-21c9e2f842eb ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:15:04.397: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 11:15:04.400: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:15:04.400: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-7436/pods/var-expansion-18ac010a-5e2d-45b5-b264-21c9e2f842eb/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 12/19/23 11:15:04.497
  Dec 19 11:15:05.019: INFO: Successfully updated pod "var-expansion-18ac010a-5e2d-45b5-b264-21c9e2f842eb"
  STEP: waiting for annotated pod running @ 12/19/23 11:15:05.019
  STEP: deleting the pod gracefully @ 12/19/23 11:15:05.036
  Dec 19 11:15:05.036: INFO: Deleting pod "var-expansion-18ac010a-5e2d-45b5-b264-21c9e2f842eb" in namespace "var-expansion-7436"
  Dec 19 11:15:05.052: INFO: Wait up to 5m0s for pod "var-expansion-18ac010a-5e2d-45b5-b264-21c9e2f842eb" to be fully deleted
  E1219 11:15:05.105664      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:06.106291      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:07.106746      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:08.107832      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:09.108016      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:10.108410      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:11.109335      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:12.109831      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:13.110458      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:14.111051      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:15.111582      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:16.111807      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:17.112296      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:18.112498      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:19.112753      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:20.113849      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:21.114855      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:22.115037      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:23.115150      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:24.115830      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:25.116317      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:26.116371      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:27.116570      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:28.116832      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:29.117033      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:30.117259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:31.118034      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:32.118435      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:33.119240      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:34.119414      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:35.120527      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:36.126177      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:37.122855      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:15:37.212: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7436" for this suite. @ 12/19/23 11:15:37.222
• [37.116 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:236
  STEP: Creating a kubernetes client @ 12/19/23 11:15:37.244
  Dec 19 11:15:37.244: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 11:15:37.248
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:15:37.292
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:15:37.299
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:15:37.305
  E1219 11:15:38.123333      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:39.124099      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:40.127139      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:41.124613      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:15:41.354
  Dec 19 11:15:41.360: INFO: Trying to get logs from node hiengux9ahcu-3 pod downwardapi-volume-41e33d0f-812d-4c77-a168-96ddae36272a container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:15:41.376
  Dec 19 11:15:41.412: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7376" for this suite. @ 12/19/23 11:15:41.423
• [4.198 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]
test/e2e/network/service.go:1416
  STEP: Creating a kubernetes client @ 12/19/23 11:15:41.444
  Dec 19 11:15:41.445: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename services @ 12/19/23 11:15:41.447
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:15:41.487
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:15:41.494
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-6130 @ 12/19/23 11:15:41.502
  STEP: changing the ExternalName service to type=ClusterIP @ 12/19/23 11:15:41.524
  STEP: creating replication controller externalname-service in namespace services-6130 @ 12/19/23 11:15:41.575
  I1219 11:15:41.596309      14 runners.go:197] Created replication controller with name: externalname-service, namespace: services-6130, replica count: 2
  E1219 11:15:42.125737      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:43.126030      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:44.127127      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 11:15:44.650349      14 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec 19 11:15:44.652: INFO: Creating new exec pod
  E1219 11:15:45.127608      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:46.129341      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:47.129837      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:15:47.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-6130 exec execpodl5ll9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Dec 19 11:15:48.010: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Dec 19 11:15:48.010: INFO: stdout: "externalname-service-99zcx"
  Dec 19 11:15:48.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-6130 exec execpodl5ll9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.16.222 80'
  E1219 11:15:48.130177      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:15:48.300: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.16.222 80\nConnection to 10.233.16.222 80 port [tcp/http] succeeded!\n"
  Dec 19 11:15:48.300: INFO: stdout: ""
  E1219 11:15:49.131057      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:15:49.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-6130 exec execpodl5ll9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.16.222 80'
  Dec 19 11:15:49.679: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.16.222 80\nConnection to 10.233.16.222 80 port [tcp/http] succeeded!\n"
  Dec 19 11:15:49.679: INFO: stdout: ""
  E1219 11:15:50.132314      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:15:50.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-6130 exec execpodl5ll9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.16.222 80'
  Dec 19 11:15:50.656: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.16.222 80\nConnection to 10.233.16.222 80 port [tcp/http] succeeded!\n"
  Dec 19 11:15:50.656: INFO: stdout: "externalname-service-99zcx"
  Dec 19 11:15:50.656: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec 19 11:15:50.667: INFO: Cleaning up the ExternalName to ClusterIP test service
  STEP: Destroying namespace "services-6130" for this suite. @ 12/19/23 11:15:50.748
• [9.338 seconds]
------------------------------
SS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 12/19/23 11:15:50.783
  Dec 19 11:15:50.783: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename pods @ 12/19/23 11:15:50.787
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:15:50.828
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:15:50.836
  STEP: creating the pod @ 12/19/23 11:15:50.841
  STEP: setting up watch @ 12/19/23 11:15:50.841
  STEP: submitting the pod to kubernetes @ 12/19/23 11:15:50.96
  STEP: verifying the pod is in kubernetes @ 12/19/23 11:15:50.982
  STEP: verifying pod creation was observed @ 12/19/23 11:15:50.988
  E1219 11:15:51.132762      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:52.133061      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 12/19/23 11:15:53.022
  STEP: verifying pod deletion was observed @ 12/19/23 11:15:53.041
  E1219 11:15:53.133627      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:54.134801      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:15:54.240: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7565" for this suite. @ 12/19/23 11:15:54.252
• [3.487 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:107
  STEP: Creating a kubernetes client @ 12/19/23 11:15:54.281
  Dec 19 11:15:54.281: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename container-probe @ 12/19/23 11:15:54.286
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:15:54.325
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:15:54.331
  E1219 11:15:55.134791      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:56.135711      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:57.136360      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:58.136988      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:15:59.138027      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:00.138373      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:01.139419      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:02.141014      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:03.141046      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:04.141632      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:05.141891      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:06.142861      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:07.143878      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:08.144231      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:09.144466      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:10.144698      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:11.145621      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:12.146091      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:13.146145      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:14.146522      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:15.146674      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:16.146773      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:17.147175      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:18.147261      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:19.147478      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:20.148232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:21.149143      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:22.149394      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:23.149628      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:24.150628      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:25.151226      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:26.151791      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:27.152742      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:28.152913      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:29.153307      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:30.153651      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:31.153852      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:32.154497      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:33.154920      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:34.156148      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:35.155905      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:36.157028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:37.157190      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:38.157191      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:39.157914      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:40.158716      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:41.158725      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:42.159050      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:43.160357      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:44.160223      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:45.160649      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:46.160800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:47.161757      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:48.162801      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:49.164662      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:50.164827      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:51.166118      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:52.168197      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:53.166817      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:54.166858      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:16:54.365: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9446" for this suite. @ 12/19/23 11:16:54.379
• [60.116 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
test/e2e/common/node/expansion.go:228
  STEP: Creating a kubernetes client @ 12/19/23 11:16:54.403
  Dec 19 11:16:54.403: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename var-expansion @ 12/19/23 11:16:54.407
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:16:54.44
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:16:54.446
  STEP: creating the pod with failed condition @ 12/19/23 11:16:54.453
  E1219 11:16:55.168100      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:56.168180      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:57.169255      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:58.170319      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:16:59.169880      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:00.170186      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:01.170648      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:02.170979      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:03.171364      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:04.171567      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:05.171610      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:06.172031      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:07.172193      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:08.172424      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:09.172553      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:10.173288      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:11.173618      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:12.174334      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:13.174547      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:14.174913      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:15.175086      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:16.175379      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:17.175593      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:18.175936      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:19.176322      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:20.176664      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:21.177551      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:22.178372      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:23.178334      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:24.178694      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:25.179641      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:26.180480      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:27.180919      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:28.180983      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:29.182016      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:30.182747      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:31.183550      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:32.183693      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:33.184916      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:34.184783      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:35.185526      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:36.185760      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:37.185994      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:38.186101      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:39.187259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:40.188203      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:41.189096      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:42.189808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:43.189996      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:44.190547      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:45.190781      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:46.190871      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:47.191802      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:48.192558      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:49.193280      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:50.193887      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:51.193971      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:52.194594      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:53.195549      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:54.196322      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:55.196664      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:56.198900      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:57.198981      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:58.199104      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:17:59.200212      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:00.202810      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:01.202204      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:02.202376      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:03.202741      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:04.202794      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:05.203532      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:06.204030      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:07.203804      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:08.204136      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:09.205076      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:10.205803      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:11.206075      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:12.207098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:13.207727      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:14.208645      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:15.209374      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:16.210413      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:17.211205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:18.211447      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:19.211726      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:20.212762      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:21.212882      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:22.213605      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:23.214320      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:24.214937      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:25.215247      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:26.215325      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:27.215679      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:28.216596      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:29.217625      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:30.217926      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:31.218695      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:32.219411      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:33.219683      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:34.219904      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:35.220368      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:36.220623      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:37.221295      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:38.221605      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:39.222441      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:40.223224      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:41.223640      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:42.223769      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:43.224873      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:44.225661      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:45.226572      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:46.227635      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:47.228679      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:48.228883      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:49.228925      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:50.229627      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:51.230214      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:52.230525      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:53.231860      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:54.232137      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pod @ 12/19/23 11:18:54.475
  Dec 19 11:18:55.008: INFO: Successfully updated pod "var-expansion-7bc3c672-cc4b-4f63-a7e4-16c4b0bcc825"
  STEP: waiting for pod running @ 12/19/23 11:18:55.008
  E1219 11:18:55.232526      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:56.232752      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 12/19/23 11:18:57.031
  Dec 19 11:18:57.032: INFO: Deleting pod "var-expansion-7bc3c672-cc4b-4f63-a7e4-16c4b0bcc825" in namespace "var-expansion-677"
  Dec 19 11:18:57.052: INFO: Wait up to 5m0s for pod "var-expansion-7bc3c672-cc4b-4f63-a7e4-16c4b0bcc825" to be fully deleted
  E1219 11:18:57.232974      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:58.234076      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:18:59.234666      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:00.235021      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:01.236522      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:02.236906      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:03.237959      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:04.238263      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:05.239236      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:06.242090      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:07.240435      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:08.241172      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:09.241280      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:10.241804      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:11.242432      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:12.242568      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:13.243442      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:14.244403      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:15.244963      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:16.244982      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:17.245500      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:18.245789      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:19.246751      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:20.246900      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:21.247593      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:22.249106      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:23.249206      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:24.249690      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:25.249869      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:26.250474      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:27.251582      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:28.252308      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:19:29.239: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1219 11:19:29.253925      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "var-expansion-677" for this suite. @ 12/19/23 11:19:29.264
• [154.881 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 12/19/23 11:19:29.295
  Dec 19 11:19:29.295: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename secrets @ 12/19/23 11:19:29.302
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:19:29.34
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:19:29.345
  STEP: Creating secret with name secret-test-ff09f0c1-4663-4830-b858-cf9c7e969483 @ 12/19/23 11:19:29.39
  STEP: Creating a pod to test consume secrets @ 12/19/23 11:19:29.401
  E1219 11:19:30.253891      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:31.255015      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:32.256055      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:33.257122      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:19:33.45
  Dec 19 11:19:33.459: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-secrets-5aabc309-e432-4f89-9c18-fa99f0beaf56 container secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 11:19:33.508
  Dec 19 11:19:33.583: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1487" for this suite. @ 12/19/23 11:19:33.598
  STEP: Destroying namespace "secret-namespace-1467" for this suite. @ 12/19/23 11:19:33.627
• [4.351 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]
test/e2e/apps/controller_revision.go:124
  STEP: Creating a kubernetes client @ 12/19/23 11:19:33.651
  Dec 19 11:19:33.651: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename controllerrevisions @ 12/19/23 11:19:33.654
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:19:33.693
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:19:33.701
  STEP: Creating DaemonSet "e2e-q9kqd-daemon-set" @ 12/19/23 11:19:33.756
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/19/23 11:19:33.77
  Dec 19 11:19:33.806: INFO: Number of nodes with available pods controlled by daemonset e2e-q9kqd-daemon-set: 0
  Dec 19 11:19:33.806: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  E1219 11:19:34.258049      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:19:34.833: INFO: Number of nodes with available pods controlled by daemonset e2e-q9kqd-daemon-set: 0
  Dec 19 11:19:34.833: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  E1219 11:19:35.258577      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:19:35.830: INFO: Number of nodes with available pods controlled by daemonset e2e-q9kqd-daemon-set: 2
  Dec 19 11:19:35.831: INFO: Node hiengux9ahcu-3 is running 0 daemon pod, expected 1
  E1219 11:19:36.259405      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:19:36.828: INFO: Number of nodes with available pods controlled by daemonset e2e-q9kqd-daemon-set: 2
  Dec 19 11:19:36.828: INFO: Node hiengux9ahcu-3 is running 0 daemon pod, expected 1
  E1219 11:19:37.260360      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:19:37.829: INFO: Number of nodes with available pods controlled by daemonset e2e-q9kqd-daemon-set: 3
  Dec 19 11:19:37.829: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-q9kqd-daemon-set
  STEP: Confirm DaemonSet "e2e-q9kqd-daemon-set" successfully created with "daemonset-name=e2e-q9kqd-daemon-set" label @ 12/19/23 11:19:37.837
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-q9kqd-daemon-set" @ 12/19/23 11:19:37.854
  Dec 19 11:19:37.864: INFO: Located ControllerRevision: "e2e-q9kqd-daemon-set-8f654cd4f"
  STEP: Patching ControllerRevision "e2e-q9kqd-daemon-set-8f654cd4f" @ 12/19/23 11:19:37.877
  Dec 19 11:19:37.895: INFO: e2e-q9kqd-daemon-set-8f654cd4f has been patched
  STEP: Create a new ControllerRevision @ 12/19/23 11:19:37.897
  Dec 19 11:19:37.909: INFO: Created ControllerRevision: e2e-q9kqd-daemon-set-5c557c4445
  STEP: Confirm that there are two ControllerRevisions @ 12/19/23 11:19:37.91
  Dec 19 11:19:37.910: INFO: Requesting list of ControllerRevisions to confirm quantity
  Dec 19 11:19:37.917: INFO: Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-q9kqd-daemon-set-8f654cd4f" @ 12/19/23 11:19:37.918
  STEP: Confirm that there is only one ControllerRevision @ 12/19/23 11:19:37.934
  Dec 19 11:19:37.934: INFO: Requesting list of ControllerRevisions to confirm quantity
  Dec 19 11:19:37.943: INFO: Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-q9kqd-daemon-set-5c557c4445" @ 12/19/23 11:19:37.949
  Dec 19 11:19:37.966: INFO: e2e-q9kqd-daemon-set-5c557c4445 has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 12/19/23 11:19:37.966
  W1219 11:19:37.978380      14 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 12/19/23 11:19:37.978
  Dec 19 11:19:37.979: INFO: Requesting list of ControllerRevisions to confirm quantity
  E1219 11:19:38.260734      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:19:38.985: INFO: Requesting list of ControllerRevisions to confirm quantity
  Dec 19 11:19:38.994: INFO: Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-q9kqd-daemon-set-5c557c4445=updated" @ 12/19/23 11:19:38.994
  STEP: Confirm that there is only one ControllerRevision @ 12/19/23 11:19:39.015
  Dec 19 11:19:39.015: INFO: Requesting list of ControllerRevisions to confirm quantity
  Dec 19 11:19:39.025: INFO: Found 1 ControllerRevisions
  Dec 19 11:19:39.039: INFO: ControllerRevision "e2e-q9kqd-daemon-set-68c8444b9b" has revision 3
  STEP: Deleting DaemonSet "e2e-q9kqd-daemon-set" @ 12/19/23 11:19:39.061
  STEP: deleting DaemonSet.extensions e2e-q9kqd-daemon-set in namespace controllerrevisions-2873, will wait for the garbage collector to delete the pods @ 12/19/23 11:19:39.061
  Dec 19 11:19:39.149: INFO: Deleting DaemonSet.extensions e2e-q9kqd-daemon-set took: 28.395096ms
  E1219 11:19:39.261610      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:19:39.350: INFO: Terminating DaemonSet.extensions e2e-q9kqd-daemon-set pods took: 201.007501ms
  E1219 11:19:40.261940      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:19:40.758: INFO: Number of nodes with available pods controlled by daemonset e2e-q9kqd-daemon-set: 0
  Dec 19 11:19:40.758: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-q9kqd-daemon-set
  Dec 19 11:19:40.764: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"25752"},"items":null}

  Dec 19 11:19:40.770: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"25752"},"items":null}

  Dec 19 11:19:40.815: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-2873" for this suite. @ 12/19/23 11:19:40.827
• [7.192 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:147
  STEP: Creating a kubernetes client @ 12/19/23 11:19:40.844
  Dec 19 11:19:40.845: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 11:19:40.847
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:19:40.882
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:19:40.887
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 12/19/23 11:19:40.898
  E1219 11:19:41.262630      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:42.262774      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:43.263659      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:44.264669      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:19:44.942
  Dec 19 11:19:44.948: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-73e91036-dfaa-440a-8093-f17dcfe24485 container test-container: <nil>
  STEP: delete the pod @ 12/19/23 11:19:44.962
  Dec 19 11:19:44.996: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4140" for this suite. @ 12/19/23 11:19:45.01
• [4.185 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 12/19/23 11:19:45.035
  Dec 19 11:19:45.036: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename pods @ 12/19/23 11:19:45.038
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:19:45.067
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:19:45.078
  STEP: creating the pod @ 12/19/23 11:19:45.087
  STEP: submitting the pod to kubernetes @ 12/19/23 11:19:45.087
  STEP: verifying QOS class is set on the pod @ 12/19/23 11:19:45.107
  Dec 19 11:19:45.127: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6426" for this suite. @ 12/19/23 11:19:45.146
• [0.147 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 12/19/23 11:19:45.191
  Dec 19 11:19:45.191: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename pods @ 12/19/23 11:19:45.195
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:19:45.224
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:19:45.23
  Dec 19 11:19:45.239: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: creating the pod @ 12/19/23 11:19:45.242
  STEP: submitting the pod to kubernetes @ 12/19/23 11:19:45.242
  E1219 11:19:45.265623      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:46.265252      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:47.265503      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:19:47.319: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8191" for this suite. @ 12/19/23 11:19:47.34
• [2.173 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
test/e2e/common/node/sysctl.go:123
  STEP: Creating a kubernetes client @ 12/19/23 11:19:47.378
  Dec 19 11:19:47.379: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename sysctl @ 12/19/23 11:19:47.382
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:19:47.421
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:19:47.427
  STEP: Creating a pod with one valid and two invalid sysctls @ 12/19/23 11:19:47.435
  Dec 19 11:19:47.451: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-8136" for this suite. @ 12/19/23 11:19:47.463
• [0.099 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]
test/e2e/apps/statefulset.go:1030
  STEP: Creating a kubernetes client @ 12/19/23 11:19:47.478
  Dec 19 11:19:47.478: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename statefulset @ 12/19/23 11:19:47.481
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:19:47.51
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:19:47.518
  STEP: Creating service test in namespace statefulset-6645 @ 12/19/23 11:19:47.527
  STEP: Creating statefulset ss in namespace statefulset-6645 @ 12/19/23 11:19:47.563
  Dec 19 11:19:47.583: INFO: Found 0 stateful pods, waiting for 1
  E1219 11:19:48.265839      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:49.265823      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:50.266125      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:51.266430      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:52.266679      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:53.266694      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:54.267534      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:55.267745      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:56.268280      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:57.269038      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:19:57.593: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 12/19/23 11:19:57.606
  STEP: Getting /status @ 12/19/23 11:19:57.636
  Dec 19 11:19:57.650: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 12/19/23 11:19:57.65
  Dec 19 11:19:57.674: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 12/19/23 11:19:57.674
  Dec 19 11:19:57.682: INFO: Observed &StatefulSet event: ADDED
  Dec 19 11:19:57.682: INFO: Found Statefulset ss in namespace statefulset-6645 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec 19 11:19:57.682: INFO: Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 12/19/23 11:19:57.682
  Dec 19 11:19:57.682: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Dec 19 11:19:57.713: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 12/19/23 11:19:57.713
  Dec 19 11:19:57.717: INFO: Observed &StatefulSet event: ADDED
  Dec 19 11:19:57.718: INFO: Deleting all statefulset in ns statefulset-6645
  Dec 19 11:19:57.725: INFO: Scaling statefulset ss to 0
  E1219 11:19:58.269269      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:19:59.269727      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:00.270295      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:01.270593      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:02.270786      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:03.270946      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:04.272127      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:05.271844      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:06.272718      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:07.272857      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:20:07.792: INFO: Waiting for statefulset status.replicas updated to 0
  Dec 19 11:20:07.798: INFO: Deleting statefulset ss
  Dec 19 11:20:07.833: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-6645" for this suite. @ 12/19/23 11:20:07.848
• [20.392 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:137
  STEP: Creating a kubernetes client @ 12/19/23 11:20:07.883
  Dec 19 11:20:07.884: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 11:20:07.89
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:20:07.921
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:20:07.928
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 12/19/23 11:20:07.932
  E1219 11:20:08.273243      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:09.274320      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:10.274836      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:11.275978      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:20:11.979
  Dec 19 11:20:11.990: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-276c4b35-10e9-410d-8044-29bc614f2ec9 container test-container: <nil>
  STEP: delete the pod @ 12/19/23 11:20:12.007
  Dec 19 11:20:12.054: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4140" for this suite. @ 12/19/23 11:20:12.067
• [4.203 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:207
  STEP: Creating a kubernetes client @ 12/19/23 11:20:12.096
  Dec 19 11:20:12.096: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 11:20:12.101
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:20:12.151
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:20:12.159
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 12/19/23 11:20:12.168
  E1219 11:20:12.276275      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:13.277075      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:14.278254      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:15.279095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:20:16.224
  Dec 19 11:20:16.231: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-22696f28-011f-4b3a-8b2c-686c32940a27 container test-container: <nil>
  STEP: delete the pod @ 12/19/23 11:20:16.246
  E1219 11:20:16.279248      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:20:16.281: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7520" for this suite. @ 12/19/23 11:20:16.292
• [4.212 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 12/19/23 11:20:16.31
  Dec 19 11:20:16.310: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename containers @ 12/19/23 11:20:16.312
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:20:16.347
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:20:16.352
  STEP: Creating a pod to test override all @ 12/19/23 11:20:16.358
  E1219 11:20:17.280280      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:18.280084      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:19.280636      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:20.280761      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:20:20.402
  Dec 19 11:20:20.410: INFO: Trying to get logs from node hiengux9ahcu-3 pod client-containers-6963642d-a71d-4c83-8fb1-fcf4a91f65b6 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 11:20:20.428
  Dec 19 11:20:20.466: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-9576" for this suite. @ 12/19/23 11:20:20.478
• [4.183 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
test/e2e/apps/statefulset.go:640
  STEP: Creating a kubernetes client @ 12/19/23 11:20:20.495
  Dec 19 11:20:20.495: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename statefulset @ 12/19/23 11:20:20.499
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:20:20.536
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:20:20.541
  STEP: Creating service test in namespace statefulset-6382 @ 12/19/23 11:20:20.55
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 12/19/23 11:20:20.563
  STEP: Creating stateful set ss in namespace statefulset-6382 @ 12/19/23 11:20:20.571
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6382 @ 12/19/23 11:20:20.586
  Dec 19 11:20:20.594: INFO: Found 0 stateful pods, waiting for 1
  E1219 11:20:21.281667      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:22.282133      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:23.282454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:24.283153      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:25.283431      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:26.283330      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:27.283902      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:28.284086      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:29.284688      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:30.284857      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:20:30.603: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 12/19/23 11:20:30.604
  Dec 19 11:20:30.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=statefulset-6382 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec 19 11:20:30.992: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec 19 11:20:30.992: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec 19 11:20:30.992: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec 19 11:20:31.000: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E1219 11:20:31.285119      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:32.285676      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:33.285793      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:34.285990      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:35.286301      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:36.287210      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:37.287378      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:38.287637      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:39.288043      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:40.288266      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:20:41.011: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Dec 19 11:20:41.011: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Dec 19 11:20:41.063: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999468s
  E1219 11:20:41.289119      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:20:42.073: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.989840209s
  E1219 11:20:42.289391      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:20:43.083: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.981170876s
  E1219 11:20:43.289629      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:20:44.094: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.970418431s
  E1219 11:20:44.290905      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:20:45.107: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.958932032s
  E1219 11:20:45.292464      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:20:46.116: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.945542458s
  E1219 11:20:46.292392      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:20:47.129: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.93793863s
  E1219 11:20:47.293524      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:20:48.136: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.9256727s
  E1219 11:20:48.293337      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:20:49.148: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.917530525s
  E1219 11:20:49.293741      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:20:50.160: INFO: Verifying statefulset ss doesn't scale past 1 for another 905.978889ms
  E1219 11:20:50.293893      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6382 @ 12/19/23 11:20:51.161
  Dec 19 11:20:51.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=statefulset-6382 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E1219 11:20:51.294372      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:20:51.535: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec 19 11:20:51.535: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec 19 11:20:51.536: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec 19 11:20:51.546: INFO: Found 1 stateful pods, waiting for 3
  E1219 11:20:52.295602      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:53.295831      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:54.297893      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:55.297072      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:56.297476      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:57.297796      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:58.298023      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:20:59.298255      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:00.298479      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:01.299168      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:01.568: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 11:21:01.568: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 11:21:01.568: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 12/19/23 11:21:01.568
  STEP: Scale down will halt with unhealthy stateful pod @ 12/19/23 11:21:01.569
  Dec 19 11:21:01.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=statefulset-6382 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec 19 11:21:01.890: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec 19 11:21:01.890: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec 19 11:21:01.890: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec 19 11:21:01.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=statefulset-6382 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec 19 11:21:02.237: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec 19 11:21:02.237: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec 19 11:21:02.237: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec 19 11:21:02.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=statefulset-6382 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E1219 11:21:02.300116      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:02.597: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec 19 11:21:02.597: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec 19 11:21:02.597: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec 19 11:21:02.597: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Dec 19 11:21:02.607: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 1
  E1219 11:21:03.300735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:04.301042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:05.301782      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:06.302760      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:07.303373      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:08.303739      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:09.303955      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:10.304161      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:11.304310      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:12.304464      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:12.629: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Dec 19 11:21:12.629: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Dec 19 11:21:12.630: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Dec 19 11:21:12.662: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999076s
  E1219 11:21:13.304837      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:13.679: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.988753507s
  E1219 11:21:14.305186      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:14.703: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.971486393s
  E1219 11:21:15.306192      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:15.714: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.947512562s
  E1219 11:21:16.306758      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:16.725: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.936976018s
  E1219 11:21:17.306964      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:17.735: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.9255832s
  E1219 11:21:18.307599      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:18.766: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.914975229s
  E1219 11:21:19.308022      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:19.776: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.885750382s
  E1219 11:21:20.310888      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:20.787: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.875332324s
  E1219 11:21:21.311382      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:21.803: INFO: Verifying statefulset ss doesn't scale past 3 for another 863.778464ms
  E1219 11:21:22.311702      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6382 @ 12/19/23 11:21:22.804
  Dec 19 11:21:22.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=statefulset-6382 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec 19 11:21:23.115: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec 19 11:21:23.115: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec 19 11:21:23.115: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec 19 11:21:23.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=statefulset-6382 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E1219 11:21:23.312087      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:23.472: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec 19 11:21:23.472: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec 19 11:21:23.472: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec 19 11:21:23.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=statefulset-6382 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec 19 11:21:23.829: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec 19 11:21:23.829: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec 19 11:21:23.829: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec 19 11:21:23.829: INFO: Scaling statefulset ss to 0
  E1219 11:21:24.313038      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:25.313244      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:26.314356      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:27.315245      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:28.315922      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:29.316138      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:30.316691      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:31.317058      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:32.317812      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:33.317637      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 12/19/23 11:21:33.872
  Dec 19 11:21:33.873: INFO: Deleting all statefulset in ns statefulset-6382
  Dec 19 11:21:33.880: INFO: Scaling statefulset ss to 0
  Dec 19 11:21:33.904: INFO: Waiting for statefulset status.replicas updated to 0
  Dec 19 11:21:33.911: INFO: Deleting statefulset ss
  Dec 19 11:21:33.943: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-6382" for this suite. @ 12/19/23 11:21:33.963
• [73.485 seconds]
------------------------------
S
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
test/e2e/network/service.go:2165
  STEP: Creating a kubernetes client @ 12/19/23 11:21:33.983
  Dec 19 11:21:33.984: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename services @ 12/19/23 11:21:33.989
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:21:34.028
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:21:34.034
  STEP: creating service in namespace services-1616 @ 12/19/23 11:21:34.04
  STEP: creating service affinity-clusterip in namespace services-1616 @ 12/19/23 11:21:34.04
  STEP: creating replication controller affinity-clusterip in namespace services-1616 @ 12/19/23 11:21:34.071
  I1219 11:21:34.089695      14 runners.go:197] Created replication controller with name: affinity-clusterip, namespace: services-1616, replica count: 3
  E1219 11:21:34.317814      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:35.318681      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:36.319228      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 11:21:37.141215      14 runners.go:197] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec 19 11:21:37.162: INFO: Creating new exec pod
  E1219 11:21:37.319619      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:38.319874      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:39.320485      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:40.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-1616 exec execpod-affinity9dc54 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  E1219 11:21:40.321352      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:40.516: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  Dec 19 11:21:40.516: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 11:21:40.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-1616 exec execpod-affinity9dc54 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.31.56 80'
  Dec 19 11:21:40.824: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.31.56 80\nConnection to 10.233.31.56 80 port [tcp/http] succeeded!\n"
  Dec 19 11:21:40.824: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 11:21:40.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-1616 exec execpod-affinity9dc54 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.31.56:80/ ; done'
  E1219 11:21:41.325720      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:41.341: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.31.56:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.31.56:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.31.56:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.31.56:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.31.56:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.31.56:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.31.56:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.31.56:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.31.56:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.31.56:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.31.56:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.31.56:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.31.56:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.31.56:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.31.56:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.31.56:80/\n"
  Dec 19 11:21:41.342: INFO: stdout: "\naffinity-clusterip-68cmr\naffinity-clusterip-68cmr\naffinity-clusterip-68cmr\naffinity-clusterip-68cmr\naffinity-clusterip-68cmr\naffinity-clusterip-68cmr\naffinity-clusterip-68cmr\naffinity-clusterip-68cmr\naffinity-clusterip-68cmr\naffinity-clusterip-68cmr\naffinity-clusterip-68cmr\naffinity-clusterip-68cmr\naffinity-clusterip-68cmr\naffinity-clusterip-68cmr\naffinity-clusterip-68cmr\naffinity-clusterip-68cmr"
  Dec 19 11:21:41.342: INFO: Received response from host: affinity-clusterip-68cmr
  Dec 19 11:21:41.342: INFO: Received response from host: affinity-clusterip-68cmr
  Dec 19 11:21:41.342: INFO: Received response from host: affinity-clusterip-68cmr
  Dec 19 11:21:41.342: INFO: Received response from host: affinity-clusterip-68cmr
  Dec 19 11:21:41.342: INFO: Received response from host: affinity-clusterip-68cmr
  Dec 19 11:21:41.342: INFO: Received response from host: affinity-clusterip-68cmr
  Dec 19 11:21:41.342: INFO: Received response from host: affinity-clusterip-68cmr
  Dec 19 11:21:41.342: INFO: Received response from host: affinity-clusterip-68cmr
  Dec 19 11:21:41.342: INFO: Received response from host: affinity-clusterip-68cmr
  Dec 19 11:21:41.342: INFO: Received response from host: affinity-clusterip-68cmr
  Dec 19 11:21:41.342: INFO: Received response from host: affinity-clusterip-68cmr
  Dec 19 11:21:41.342: INFO: Received response from host: affinity-clusterip-68cmr
  Dec 19 11:21:41.342: INFO: Received response from host: affinity-clusterip-68cmr
  Dec 19 11:21:41.342: INFO: Received response from host: affinity-clusterip-68cmr
  Dec 19 11:21:41.342: INFO: Received response from host: affinity-clusterip-68cmr
  Dec 19 11:21:41.342: INFO: Received response from host: affinity-clusterip-68cmr
  Dec 19 11:21:41.342: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec 19 11:21:41.351: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-1616, will wait for the garbage collector to delete the pods @ 12/19/23 11:21:41.374
  Dec 19 11:21:41.452: INFO: Deleting ReplicationController affinity-clusterip took: 13.684466ms
  Dec 19 11:21:41.554: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.486587ms
  E1219 11:21:42.322667      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:43.326308      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:44.325471      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-1616" for this suite. @ 12/19/23 11:21:44.94
• [10.973 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]
test/e2e/kubectl/kubectl.go:1674
  STEP: Creating a kubernetes client @ 12/19/23 11:21:44.958
  Dec 19 11:21:44.958: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 11:21:44.964
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:21:45.007
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:21:45.014
  Dec 19 11:21:45.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-9679 version'
  Dec 19 11:21:45.178: INFO: stderr: ""
  Dec 19 11:21:45.178: INFO: stdout: "Client Version: v1.28.4\nKustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\nServer Version: v1.28.4\n"
  Dec 19 11:21:45.179: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9679" for this suite. @ 12/19/23 11:21:45.188
• [0.242 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods  [Conformance]
test/e2e/network/service.go:785
  STEP: Creating a kubernetes client @ 12/19/23 11:21:45.204
  Dec 19 11:21:45.204: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename services @ 12/19/23 11:21:45.208
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:21:45.238
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:21:45.244
  STEP: creating service endpoint-test2 in namespace services-7833 @ 12/19/23 11:21:45.254
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7833 to expose endpoints map[] @ 12/19/23 11:21:45.274
  Dec 19 11:21:45.283: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
  E1219 11:21:45.325154      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:46.304: INFO: successfully validated that service endpoint-test2 in namespace services-7833 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-7833 @ 12/19/23 11:21:46.305
  E1219 11:21:46.325704      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:47.326359      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:48.326228      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7833 to expose endpoints map[pod1:[80]] @ 12/19/23 11:21:48.363
  Dec 19 11:21:48.390: INFO: successfully validated that service endpoint-test2 in namespace services-7833 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 12/19/23 11:21:48.391
  Dec 19 11:21:48.391: INFO: Creating new exec pod
  E1219 11:21:49.327174      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:50.327522      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:51.328255      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:51.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-7833 exec execpod4m8q4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Dec 19 11:21:51.750: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Dec 19 11:21:51.750: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 11:21:51.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-7833 exec execpod4m8q4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.13.196 80'
  Dec 19 11:21:52.041: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.13.196 80\nConnection to 10.233.13.196 80 port [tcp/http] succeeded!\n"
  Dec 19 11:21:52.041: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-7833 @ 12/19/23 11:21:52.041
  E1219 11:21:52.328391      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:21:53.328805      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7833 to expose endpoints map[pod1:[80] pod2:[80]] @ 12/19/23 11:21:54.079
  Dec 19 11:21:54.106: INFO: successfully validated that service endpoint-test2 in namespace services-7833 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 12/19/23 11:21:54.106
  E1219 11:21:54.328910      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:55.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-7833 exec execpod4m8q4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  E1219 11:21:55.329509      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:55.407: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Dec 19 11:21:55.408: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 11:21:55.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-7833 exec execpod4m8q4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.13.196 80'
  Dec 19 11:21:55.684: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.13.196 80\nConnection to 10.233.13.196 80 port [tcp/http] succeeded!\n"
  Dec 19 11:21:55.684: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-7833 @ 12/19/23 11:21:55.684
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7833 to expose endpoints map[pod2:[80]] @ 12/19/23 11:21:55.727
  Dec 19 11:21:55.762: INFO: successfully validated that service endpoint-test2 in namespace services-7833 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 12/19/23 11:21:55.762
  E1219 11:21:56.330066      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:56.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-7833 exec execpod4m8q4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Dec 19 11:21:57.114: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Dec 19 11:21:57.115: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec 19 11:21:57.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-7833 exec execpod4m8q4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.13.196 80'
  E1219 11:21:57.330223      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:57.413: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.13.196 80\nConnection to 10.233.13.196 80 port [tcp/http] succeeded!\n"
  Dec 19 11:21:57.413: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-7833 @ 12/19/23 11:21:57.413
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7833 to expose endpoints map[] @ 12/19/23 11:21:57.511
  E1219 11:21:58.330477      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:21:58.575: INFO: successfully validated that service endpoint-test2 in namespace services-7833 exposes endpoints map[]
  Dec 19 11:21:58.576: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7833" for this suite. @ 12/19/23 11:21:58.628
• [13.451 seconds]
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]
test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 12/19/23 11:21:58.655
  Dec 19 11:21:58.655: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename watch @ 12/19/23 11:21:58.658
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:21:58.696
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:21:58.703
  STEP: creating a watch on configmaps @ 12/19/23 11:21:58.709
  STEP: creating a new configmap @ 12/19/23 11:21:58.712
  STEP: modifying the configmap once @ 12/19/23 11:21:58.724
  STEP: closing the watch once it receives two notifications @ 12/19/23 11:21:58.787
  Dec 19 11:21:58.787: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2829  fe0b0fb2-fd3a-4a00-b0ba-7d05606027e8 26636 0 2023-12-19 11:21:58 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-12-19 11:21:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:21:58.788: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2829  fe0b0fb2-fd3a-4a00-b0ba-7d05606027e8 26637 0 2023-12-19 11:21:58 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-12-19 11:21:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 12/19/23 11:21:58.789
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 12/19/23 11:21:58.822
  STEP: deleting the configmap @ 12/19/23 11:21:58.824
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 12/19/23 11:21:58.837
  Dec 19 11:21:58.837: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2829  fe0b0fb2-fd3a-4a00-b0ba-7d05606027e8 26639 0 2023-12-19 11:21:58 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-12-19 11:21:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:21:58.838: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2829  fe0b0fb2-fd3a-4a00-b0ba-7d05606027e8 26640 0 2023-12-19 11:21:58 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-12-19 11:21:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:21:58.838: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-2829" for this suite. @ 12/19/23 11:21:58.848
• [0.209 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance]
test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 12/19/23 11:21:58.876
  Dec 19 11:21:58.876: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename deployment @ 12/19/23 11:21:58.88
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:21:58.91
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:21:58.917
  Dec 19 11:21:58.944: INFO: Pod name rollover-pod: Found 0 pods out of 1
  E1219 11:21:59.331882      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:00.331833      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:01.331911      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:02.332104      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:03.332252      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:03.958: INFO: Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/19/23 11:22:03.959
  Dec 19 11:22:03.959: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E1219 11:22:04.332449      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:05.333134      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:05.969: INFO: Creating deployment "test-rollover-deployment"
  Dec 19 11:22:05.988: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
  E1219 11:22:06.333890      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:07.334061      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:08.005: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
  Dec 19 11:22:08.019: INFO: Ensure that both replica sets have 1 created replica
  Dec 19 11:22:08.034: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  Dec 19 11:22:08.053: INFO: Updating deployment test-rollover-deployment
  Dec 19 11:22:08.054: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E1219 11:22:08.334769      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:09.335514      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:10.070: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
  Dec 19 11:22:10.089: INFO: Make sure deployment "test-rollover-deployment" is complete
  Dec 19 11:22:10.104: INFO: all replica sets need to contain the pod-template-hash label
  Dec 19 11:22:10.105: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 22, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 22, 6, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 22, 9, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 22, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:22:10.336182      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:11.336374      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:12.123: INFO: all replica sets need to contain the pod-template-hash label
  Dec 19 11:22:12.124: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 22, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 22, 6, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 22, 9, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 22, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:22:12.337080      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:13.337204      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:14.124: INFO: all replica sets need to contain the pod-template-hash label
  Dec 19 11:22:14.125: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 22, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 22, 6, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 22, 9, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 22, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:22:14.337939      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:15.338259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:16.131: INFO: all replica sets need to contain the pod-template-hash label
  Dec 19 11:22:16.132: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 22, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 22, 6, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 22, 9, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 22, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:22:16.338936      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:17.339785      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:18.127: INFO: all replica sets need to contain the pod-template-hash label
  Dec 19 11:22:18.128: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 22, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 22, 6, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 22, 9, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 22, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:22:18.340693      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:19.341821      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:20.120: INFO: 
  Dec 19 11:22:20.120: INFO: Ensure that both old replica sets have no replicas
  Dec 19 11:22:20.145: INFO: Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5431",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "02256a75-663e-4ec9-ac9a-f175c554aae5",
      ResourceVersion: (string) (len=5) "26777",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581725,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581728,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581740,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581726,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581726,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581740,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581726,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-5d484bf7f9\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec 19 11:22:20.165: INFO: New ReplicaSet "test-rollover-deployment-5d484bf7f9" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-5d484bf7f9",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5431",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f0d499a6-eaaa-49f5-965b-b7687ac12622",
      ResourceVersion: (string) (len=5) "26767",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581728,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "02256a75-663e-4ec9-ac9a-f175c554aae5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581728,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 30 32 32 35 36 61  37 35 2d 36 36 33 65 2d  |\"02256a75-663e-|
              00000120  34 65 63 39 2d 61 63 39  61 2d 66 31 37 35 63 35  |4ec9-ac9a-f175c5|
              00000130  35 34 61 61 65 35 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |54aae5\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581739,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9",
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 11:22:20.167: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
  Dec 19 11:22:20.167: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5431",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6cfe4aed-47ea-4e8f-9d9c-6797cd24adc0",
      ResourceVersion: (string) (len=5) "26776",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581718,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "02256a75-663e-4ec9-ac9a-f175c554aae5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581718,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581739,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  30 32 32 35 36 61 37 35  2d 36 36 33 65 2d 34 65  |02256a75-663e-4e|
              000000c0  63 39 2d 61 63 39 61 2d  66 31 37 35 63 35 35 34  |c9-ac9a-f175c554|
              000000d0  61 61 65 35 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |aae5\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581739,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 11:22:20.180: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-664fc6c874",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5431",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2bf21636-8034-471d-aeb5-5bd9d42a6e16",
      ResourceVersion: (string) (len=5) "26738",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581726,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "02256a75-663e-4ec9-ac9a-f175c554aae5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581728,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 30 32 32 35 36 61  37 35 2d 36 36 33 65 2d  |\"02256a75-663e-|
              00000120  34 65 63 39 2d 61 63 39  61 2d 66 31 37 35 63 35  |4ec9-ac9a-f175c5|
              00000130  35 34 61 61 65 35 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |54aae5\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581728,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec 19 11:22:20.195: INFO: Pod "test-rollover-deployment-5d484bf7f9-2ts82" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-5d484bf7f9-2ts82",
      GenerateName: (string) (len=36) "test-rollover-deployment-5d484bf7f9-",
      Namespace: (string) (len=15) "deployment-5431",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7b5b2ed4-3a91-40dc-8f0f-caaf6baa6608",
      ResourceVersion: (string) (len=5) "26747",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581728,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-5d484bf7f9",
          UID: (types.UID) (len=36) "f0d499a6-eaaa-49f5-965b-b7687ac12622",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581728,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 30  64 34 39 39 61 36 2d 65  |d\":\"f0d499a6-e|
              00000090  61 61 61 2d 34 39 66 35  2d 39 36 35 62 2d 62 37  |aaa-49f5-965b-b7|
              000000a0  36 38 37 61 63 31 32 36  32 32 5c 22 7d 22 3a 7b  |687ac12622\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581729,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=519) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  36 2e 38 38 5c 22 7d 22  |10.233.66.88\"}"|
              000001e0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              000001f0  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000200  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-h8ssp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-h8ssp",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "hiengux9ahcu-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581728,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581729,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581729,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63838581728,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.172",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=12) "10.233.66.88",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.66.88"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63838581728,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63838581728,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          ImageID: (string) (len=64) "077cda6b1f5995dcc056c00f92d40b5147132839f522d46d9ca84acd44ad76a7",
          ContainerID: (string) (len=72) "cri-o://264e86eeac417a0dc4ec2585ffa16039a2939f44eca1eb57fc09bc446015ebe8",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec 19 11:22:20.223: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5431" for this suite. @ 12/19/23 11:22:20.238
• [21.380 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
test/e2e/apimachinery/webhook.go:273
  STEP: Creating a kubernetes client @ 12/19/23 11:22:20.261
  Dec 19 11:22:20.261: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename webhook @ 12/19/23 11:22:20.267
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:22:20.307
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:22:20.326
  E1219 11:22:20.346348      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Setting up server cert @ 12/19/23 11:22:20.384
  E1219 11:22:21.345788      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 11:22:22.032
  STEP: Deploying the webhook pod @ 12/19/23 11:22:22.047
  STEP: Wait for the deployment to be ready @ 12/19/23 11:22:22.069
  Dec 19 11:22:22.085: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E1219 11:22:22.346467      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:23.346908      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:24.124: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 22, 22, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 22, 22, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 22, 22, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 22, 22, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:22:24.347790      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:25.347899      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:26.135: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 22, 22, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 22, 22, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 22, 22, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 22, 22, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:22:26.348913      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:27.350391      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:28.131: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 22, 22, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 22, 22, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 22, 22, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 22, 22, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:22:28.349759      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:29.350905      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:30.133: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 22, 22, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 22, 22, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 22, 22, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 22, 22, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:22:30.351770      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:31.351919      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:32.135: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 22, 22, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 22, 22, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 22, 22, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 22, 22, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:22:32.352481      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:33.353038      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:22:34.132
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:22:34.149
  E1219 11:22:34.353393      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:35.150: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 12/19/23 11:22:35.165
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 12/19/23 11:22:35.202
  STEP: Creating a dummy validating-webhook-configuration object @ 12/19/23 11:22:35.237
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 12/19/23 11:22:35.254
  STEP: Creating a dummy mutating-webhook-configuration object @ 12/19/23 11:22:35.267
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 12/19/23 11:22:35.285
  Dec 19 11:22:35.300: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1219 11:22:35.354577      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-5873" for this suite. @ 12/19/23 11:22:35.547
  STEP: Destroying namespace "webhook-markers-8969" for this suite. @ 12/19/23 11:22:35.576
• [15.335 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]
test/e2e/apps/rc.go:85
  STEP: Creating a kubernetes client @ 12/19/23 11:22:35.599
  Dec 19 11:22:35.599: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename replication-controller @ 12/19/23 11:22:35.604
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:22:35.647
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:22:35.656
  Dec 19 11:22:35.669: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 12/19/23 11:22:35.717
  STEP: Checking rc "condition-test" has the desired failure condition set @ 12/19/23 11:22:35.732
  E1219 11:22:36.354866      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 12/19/23 11:22:36.754
  Dec 19 11:22:36.775: INFO: Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 12/19/23 11:22:36.776
  Dec 19 11:22:36.789: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-3367" for this suite. @ 12/19/23 11:22:36.801
• [1.220 seconds]
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]
test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 12/19/23 11:22:36.82
  Dec 19 11:22:36.820: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename watch @ 12/19/23 11:22:36.825
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:22:36.855
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:22:36.86
  STEP: creating a new configmap @ 12/19/23 11:22:36.866
  STEP: modifying the configmap once @ 12/19/23 11:22:36.876
  STEP: modifying the configmap a second time @ 12/19/23 11:22:36.889
  STEP: deleting the configmap @ 12/19/23 11:22:36.906
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 12/19/23 11:22:36.924
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 12/19/23 11:22:36.927
  Dec 19 11:22:36.928: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6337  44b5cea5-964b-45f3-a14c-c40e1604b5d8 26945 0 2023-12-19 11:22:36 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-12-19 11:22:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:22:36.930: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6337  44b5cea5-964b-45f3-a14c-c40e1604b5d8 26946 0 2023-12-19 11:22:36 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-12-19 11:22:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:22:36.931: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-6337" for this suite. @ 12/19/23 11:22:36.944
• [0.147 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:423
  STEP: Creating a kubernetes client @ 12/19/23 11:22:36.975
  Dec 19 11:22:36.975: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename configmap @ 12/19/23 11:22:36.978
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:22:37.005
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:22:37.009
  STEP: Creating configMap with name configmap-test-volume-ccd8ca59-00e3-4884-ac5a-5a1d96d8c366 @ 12/19/23 11:22:37.015
  STEP: Creating a pod to test consume configMaps @ 12/19/23 11:22:37.022
  E1219 11:22:37.355802      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:38.356471      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:39.356832      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:40.357176      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:22:41.095
  Dec 19 11:22:41.106: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-configmaps-8bcf5285-39b8-486b-97f0-f32887b7abd9 container configmap-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 11:22:41.156
  Dec 19 11:22:41.189: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4739" for this suite. @ 12/19/23 11:22:41.216
• [4.262 seconds]
------------------------------
SSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance]
test/e2e/scheduling/limit_range.go:239
  STEP: Creating a kubernetes client @ 12/19/23 11:22:41.238
  Dec 19 11:22:41.238: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename limitrange @ 12/19/23 11:22:41.242
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:22:41.291
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:22:41.302
  STEP: Creating LimitRange "e2e-limitrange-ww7h9" in namespace "limitrange-2231" @ 12/19/23 11:22:41.31
  STEP: Creating another limitRange in another namespace @ 12/19/23 11:22:41.334
  E1219 11:22:41.357281      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:41.368: INFO: Namespace "e2e-limitrange-ww7h9-9404" created
  Dec 19 11:22:41.369: INFO: Creating LimitRange "e2e-limitrange-ww7h9" in namespace "e2e-limitrange-ww7h9-9404"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-ww7h9" @ 12/19/23 11:22:41.386
  Dec 19 11:22:41.395: INFO: Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-ww7h9" in "limitrange-2231" namespace @ 12/19/23 11:22:41.396
  Dec 19 11:22:41.425: INFO: LimitRange "e2e-limitrange-ww7h9" has been patched
  STEP: Delete LimitRange "e2e-limitrange-ww7h9" by Collection with labelSelector: "e2e-limitrange-ww7h9=patched" @ 12/19/23 11:22:41.426
  STEP: Confirm that the limitRange "e2e-limitrange-ww7h9" has been deleted @ 12/19/23 11:22:41.448
  Dec 19 11:22:41.448: INFO: Requesting list of LimitRange to confirm quantity
  Dec 19 11:22:41.454: INFO: Found 0 LimitRange with label "e2e-limitrange-ww7h9=patched"
  Dec 19 11:22:41.454: INFO: LimitRange "e2e-limitrange-ww7h9" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-ww7h9" @ 12/19/23 11:22:41.454
  Dec 19 11:22:41.462: INFO: Found 1 limitRange
  Dec 19 11:22:41.462: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-2231" for this suite. @ 12/19/23 11:22:41.476
  STEP: Destroying namespace "e2e-limitrange-ww7h9-9404" for this suite. @ 12/19/23 11:22:41.496
• [0.274 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:152
  STEP: Creating a kubernetes client @ 12/19/23 11:22:41.519
  Dec 19 11:22:41.519: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 12/19/23 11:22:41.524
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:22:41.561
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:22:41.567
  STEP: create the container to handle the HTTPGet hook request. @ 12/19/23 11:22:41.584
  E1219 11:22:42.357757      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:43.358821      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 12/19/23 11:22:43.632
  E1219 11:22:44.359983      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:45.360218      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 12/19/23 11:22:45.667
  E1219 11:22:46.362543      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:47.363072      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 12/19/23 11:22:47.699
  Dec 19 11:22:47.717: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-299" for this suite. @ 12/19/23 11:22:47.728
• [6.224 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]
test/e2e/apimachinery/webhook.go:119
  STEP: Creating a kubernetes client @ 12/19/23 11:22:47.753
  Dec 19 11:22:47.753: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename webhook @ 12/19/23 11:22:47.756
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:22:47.786
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:22:47.792
  STEP: Setting up server cert @ 12/19/23 11:22:47.837
  E1219 11:22:48.363315      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 11:22:48.85
  STEP: Deploying the webhook pod @ 12/19/23 11:22:48.859
  STEP: Wait for the deployment to be ready @ 12/19/23 11:22:48.883
  Dec 19 11:22:48.905: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1219 11:22:49.363509      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:50.363909      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:22:50.926
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:22:50.949
  E1219 11:22:51.364988      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:51.950: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 12/19/23 11:22:51.969
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 12/19/23 11:22:51.974
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 12/19/23 11:22:51.975
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 12/19/23 11:22:51.975
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 12/19/23 11:22:51.977
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 12/19/23 11:22:51.977
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 12/19/23 11:22:51.981
  Dec 19 11:22:51.982: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1485" for this suite. @ 12/19/23 11:22:52.118
  STEP: Destroying namespace "webhook-markers-1495" for this suite. @ 12/19/23 11:22:52.13
• [4.396 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:168
  STEP: Creating a kubernetes client @ 12/19/23 11:22:52.152
  Dec 19 11:22:52.153: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 12/19/23 11:22:52.16
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:22:52.189
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:22:52.194
  STEP: create the container to handle the HTTPGet hook request. @ 12/19/23 11:22:52.209
  E1219 11:22:52.365321      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:53.366625      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 12/19/23 11:22:54.26
  E1219 11:22:54.366470      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:55.367108      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 12/19/23 11:22:56.31
  STEP: delete the pod with lifecycle hook @ 12/19/23 11:22:56.351
  E1219 11:22:56.367193      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:57.367408      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:22:58.367723      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:22:58.383: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-3471" for this suite. @ 12/19/23 11:22:58.393
• [6.254 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:52
  STEP: Creating a kubernetes client @ 12/19/23 11:22:58.412
  Dec 19 11:22:58.412: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubelet-test @ 12/19/23 11:22:58.415
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:22:58.445
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:22:58.451
  E1219 11:22:59.368561      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:00.368838      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:00.517: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-9769" for this suite. @ 12/19/23 11:23:00.529
• [2.132 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:268
  STEP: Creating a kubernetes client @ 12/19/23 11:23:00.551
  Dec 19 11:23:00.551: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 11:23:00.554
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:23:00.592
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:23:00.601
  STEP: Creating a pod to test downward api env vars @ 12/19/23 11:23:00.607
  E1219 11:23:01.370639      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:02.370434      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:03.370683      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:04.371653      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:23:04.658
  Dec 19 11:23:04.668: INFO: Trying to get logs from node hiengux9ahcu-3 pod downward-api-5117ebee-65c0-4b66-8fba-ffdb7bd6e26e container dapi-container: <nil>
  STEP: delete the pod @ 12/19/23 11:23:04.687
  Dec 19 11:23:04.728: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4513" for this suite. @ 12/19/23 11:23:04.748
• [4.215 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]
test/e2e/auth/service_accounts.go:161
  STEP: Creating a kubernetes client @ 12/19/23 11:23:04.812
  Dec 19 11:23:04.812: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename svcaccounts @ 12/19/23 11:23:04.816
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:23:04.865
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:23:04.872
  Dec 19 11:23:04.927: INFO: created pod pod-service-account-defaultsa
  Dec 19 11:23:04.928: INFO: pod pod-service-account-defaultsa service account token volume mount: true
  Dec 19 11:23:04.951: INFO: created pod pod-service-account-mountsa
  Dec 19 11:23:04.952: INFO: pod pod-service-account-mountsa service account token volume mount: true
  Dec 19 11:23:04.965: INFO: created pod pod-service-account-nomountsa
  Dec 19 11:23:04.966: INFO: pod pod-service-account-nomountsa service account token volume mount: false
  Dec 19 11:23:04.988: INFO: created pod pod-service-account-defaultsa-mountspec
  Dec 19 11:23:04.988: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  Dec 19 11:23:05.018: INFO: created pod pod-service-account-mountsa-mountspec
  Dec 19 11:23:05.018: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
  Dec 19 11:23:05.043: INFO: created pod pod-service-account-nomountsa-mountspec
  Dec 19 11:23:05.043: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  Dec 19 11:23:05.107: INFO: created pod pod-service-account-defaultsa-nomountspec
  Dec 19 11:23:05.107: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  Dec 19 11:23:05.157: INFO: created pod pod-service-account-mountsa-nomountspec
  Dec 19 11:23:05.157: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  Dec 19 11:23:05.191: INFO: created pod pod-service-account-nomountsa-nomountspec
  Dec 19 11:23:05.191: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  Dec 19 11:23:05.192: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-6792" for this suite. @ 12/19/23 11:23:05.227
• [0.450 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:609
  STEP: Creating a kubernetes client @ 12/19/23 11:23:05.271
  Dec 19 11:23:05.271: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename security-context-test @ 12/19/23 11:23:05.279
  E1219 11:23:05.372349      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:23:05.376
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:23:05.386
  E1219 11:23:06.372202      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:07.373959      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:08.372627      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:09.372965      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:10.373677      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:11.374049      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:12.374681      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:13.374971      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:13.550: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-3675" for this suite. @ 12/19/23 11:23:13.562
• [8.321 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:57
  STEP: Creating a kubernetes client @ 12/19/23 11:23:13.595
  Dec 19 11:23:13.595: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:23:13.601
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:23:13.635
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:23:13.643
  STEP: Creating configMap with name projected-configmap-test-volume-eabf05a7-efff-494d-acf8-9296891dcb58 @ 12/19/23 11:23:13.652
  STEP: Creating a pod to test consume configMaps @ 12/19/23 11:23:13.661
  E1219 11:23:14.375348      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:15.375924      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:23:15.715
  Dec 19 11:23:15.725: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-projected-configmaps-491f62c5-7aaf-4546-8c43-1df6e1a1e858 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 11:23:15.747
  Dec 19 11:23:15.780: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5794" for this suite. @ 12/19/23 11:23:15.793
• [2.221 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:124
  STEP: Creating a kubernetes client @ 12/19/23 11:23:15.819
  Dec 19 11:23:15.819: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:23:15.821
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:23:15.857
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:23:15.866
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-b4883e9e-1a4b-49a7-859a-7dce5e8e313a @ 12/19/23 11:23:15.887
  STEP: Creating the pod @ 12/19/23 11:23:15.896
  E1219 11:23:16.376815      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:17.376574      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-b4883e9e-1a4b-49a7-859a-7dce5e8e313a @ 12/19/23 11:23:17.97
  STEP: waiting to observe update in volume @ 12/19/23 11:23:17.982
  E1219 11:23:18.376954      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:19.377116      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:20.016: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2352" for this suite. @ 12/19/23 11:23:20.028
• [4.228 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance]
test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 12/19/23 11:23:20.049
  Dec 19 11:23:20.049: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename dns @ 12/19/23 11:23:20.053
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:23:20.082
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:23:20.089
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 12/19/23 11:23:20.095
  Dec 19 11:23:20.110: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-3072  6f432c0d-3283-4819-a641-e96f4641e49a 27484 0 2023-12-19 11:23:20 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-12-19 11:23:20 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m5cz6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.45,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m5cz6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  E1219 11:23:20.378098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:21.378873      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS suffix list is configured on pod... @ 12/19/23 11:23:22.131
  Dec 19 11:23:22.131: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-3072 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:23:22.131: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 11:23:22.134: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:23:22.134: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-3072/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 12/19/23 11:23:22.316
  Dec 19 11:23:22.316: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-3072 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:23:22.316: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 11:23:22.318: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:23:22.318: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-3072/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E1219 11:23:22.379612      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:22.491: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec 19 11:23:22.501: INFO: Deleting pod test-dns-nameservers...
  STEP: Destroying namespace "dns-3072" for this suite. @ 12/19/23 11:23:22.527
• [2.494 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 12/19/23 11:23:22.545
  Dec 19 11:23:22.546: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename events @ 12/19/23 11:23:22.552
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:23:22.606
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:23:22.614
  STEP: creating a test event @ 12/19/23 11:23:22.621
  STEP: listing events in all namespaces @ 12/19/23 11:23:22.633
  STEP: listing events in test namespace @ 12/19/23 11:23:22.644
  STEP: listing events with field selection filtering on source @ 12/19/23 11:23:22.652
  STEP: listing events with field selection filtering on reportingController @ 12/19/23 11:23:22.66
  STEP: getting the test event @ 12/19/23 11:23:22.67
  STEP: patching the test event @ 12/19/23 11:23:22.677
  STEP: getting the test event @ 12/19/23 11:23:22.7
  STEP: updating the test event @ 12/19/23 11:23:22.708
  STEP: getting the test event @ 12/19/23 11:23:22.739
  STEP: deleting the test event @ 12/19/23 11:23:22.748
  STEP: listing events in all namespaces @ 12/19/23 11:23:22.766
  STEP: listing events in test namespace @ 12/19/23 11:23:22.781
  Dec 19 11:23:22.794: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-7603" for this suite. @ 12/19/23 11:23:22.809
• [0.287 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]
test/e2e/common/node/podtemplates.go:53
  STEP: Creating a kubernetes client @ 12/19/23 11:23:22.836
  Dec 19 11:23:22.836: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename podtemplate @ 12/19/23 11:23:22.841
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:23:22.869
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:23:22.879
  Dec 19 11:23:22.958: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-3895" for this suite. @ 12/19/23 11:23:22.969
• [0.150 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 12/19/23 11:23:22.992
  Dec 19 11:23:22.993: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename init-container @ 12/19/23 11:23:22.996
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:23:23.029
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:23:23.035
  STEP: creating the pod @ 12/19/23 11:23:23.045
  Dec 19 11:23:23.045: INFO: PodSpec: initContainers in spec.initContainers
  E1219 11:23:23.380513      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:24.380959      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:25.381399      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:26.381809      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:26.842: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-8961" for this suite. @ 12/19/23 11:23:26.855
• [3.878 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]
test/e2e/apimachinery/webhook.go:199
  STEP: Creating a kubernetes client @ 12/19/23 11:23:26.873
  Dec 19 11:23:26.873: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename webhook @ 12/19/23 11:23:26.876
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:23:26.911
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:23:26.917
  STEP: Setting up server cert @ 12/19/23 11:23:26.975
  E1219 11:23:27.382794      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 11:23:28.135
  STEP: Deploying the webhook pod @ 12/19/23 11:23:28.158
  STEP: Wait for the deployment to be ready @ 12/19/23 11:23:28.187
  Dec 19 11:23:28.228: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1219 11:23:28.384361      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:29.384644      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:23:30.249
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:23:30.267
  E1219 11:23:30.385726      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:31.267: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 12/19/23 11:23:31.285
  STEP: create a pod that should be denied by the webhook @ 12/19/23 11:23:31.338
  STEP: create a pod that causes the webhook to hang @ 12/19/23 11:23:31.367
  E1219 11:23:31.386917      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:32.387513      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:33.387937      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:34.387955      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:35.388581      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:36.388755      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:37.388903      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:38.389121      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:39.389327      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:40.390665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create a configmap that should be denied by the webhook @ 12/19/23 11:23:41.381
  E1219 11:23:41.393697      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create a configmap that should be admitted by the webhook @ 12/19/23 11:23:41.403
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 12/19/23 11:23:41.425
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 12/19/23 11:23:41.445
  STEP: create a namespace that bypass the webhook @ 12/19/23 11:23:41.46
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 12/19/23 11:23:41.503
  Dec 19 11:23:41.528: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2" for this suite. @ 12/19/23 11:23:41.695
  STEP: Destroying namespace "webhook-markers-9311" for this suite. @ 12/19/23 11:23:41.738
  STEP: Destroying namespace "exempted-namespace-2974" for this suite. @ 12/19/23 11:23:41.751
• [14.890 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:69
  STEP: Creating a kubernetes client @ 12/19/23 11:23:41.766
  Dec 19 11:23:41.766: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 11:23:41.77
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:23:41.796
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:23:41.802
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:23:41.808
  E1219 11:23:42.395754      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:43.395708      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:44.395365      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:45.395528      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:23:45.869
  Dec 19 11:23:45.876: INFO: Trying to get logs from node hiengux9ahcu-3 pod downwardapi-volume-c0c0baa8-78d4-46a9-a6a1-5b3424531106 container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:23:45.893
  Dec 19 11:23:45.931: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1510" for this suite. @ 12/19/23 11:23:45.943
• [4.192 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 12/19/23 11:23:45.963
  Dec 19 11:23:45.964: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename secrets @ 12/19/23 11:23:45.967
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:23:46.004
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:23:46.011
  STEP: Creating secret with name secret-test-b464f7a4-46da-482f-ac20-5393089a7f9b @ 12/19/23 11:23:46.016
  STEP: Creating a pod to test consume secrets @ 12/19/23 11:23:46.026
  E1219 11:23:46.396237      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:47.396891      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:48.397809      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:49.398040      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:23:50.074
  Dec 19 11:23:50.078: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-secrets-6f7a213d-54e8-49bd-b585-f47a62079752 container secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 11:23:50.092
  Dec 19 11:23:50.125: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4362" for this suite. @ 12/19/23 11:23:50.14
• [4.192 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
test/e2e/apimachinery/aggregator.go:96
  STEP: Creating a kubernetes client @ 12/19/23 11:23:50.157
  Dec 19 11:23:50.157: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename aggregator @ 12/19/23 11:23:50.162
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:23:50.189
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:23:50.195
  Dec 19 11:23:50.200: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Registering the sample API server. @ 12/19/23 11:23:50.202
  E1219 11:23:50.399028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:51.400089      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:51.667: INFO: Found ClusterRoles; assuming RBAC is enabled.
  Dec 19 11:23:51.749: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
  E1219 11:23:52.400403      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:53.400615      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:53.851: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:23:54.400763      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:55.401016      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:55.859: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:23:56.401159      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:57.401714      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:57.859: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:23:58.401831      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:23:59.402184      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:23:59.867: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:00.403165      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:01.404111      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:01.864: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:02.404442      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:03.405154      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:03.859: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:04.406218      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:05.406779      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:05.864: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:06.407359      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:07.407432      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:07.867: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:08.409604      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:09.408699      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:09.859: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:10.408910      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:11.409360      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:11.861: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:12.409668      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:13.410461      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:13.866: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:14.412104      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:15.411174      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:15.862: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:16.412044      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:17.412260      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:17.862: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:18.412003      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:19.412841      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:19.860: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:20.413569      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:21.413624      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:21.859: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:22.414192      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:23.414579      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:23.861: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:24.414704      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:25.415047      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:25.868: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:26.415941      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:27.416186      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:27.860: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:28.421652      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:29.417043      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:29.860: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:30.417181      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:31.417543      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:31.863: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:32.417800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:33.418816      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:33.861: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:34.419008      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:35.423661      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:35.864: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:36.419872      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:37.420501      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:37.858: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:38.422195      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:39.421788      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:39.860: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:40.422731      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:41.423439      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:41.861: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:42.424987      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:43.425127      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:43.859: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:44.425954      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:45.426833      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:45.862: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:46.427112      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:47.428166      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:47.862: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:48.429023      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:49.429845      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:49.859: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:50.429802      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:51.430067      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:51.860: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:52.430173      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:53.430897      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:53.859: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:54.431169      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:55.431549      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:55.860: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 23, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:24:56.431846      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:24:57.432608      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:58.029: INFO: Waited 137.469517ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 12/19/23 11:24:58.127
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 12/19/23 11:24:58.138
  STEP: List APIServices @ 12/19/23 11:24:58.158
  Dec 19 11:24:58.173: INFO: Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 12/19/23 11:24:58.173
  Dec 19 11:24:58.202: INFO: APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 12/19/23 11:24:58.203
  Dec 19 11:24:58.220: INFO: updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2023, time.December, 19, 11, 24, 57, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 12/19/23 11:24:58.22
  Dec 19 11:24:58.234: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2023-12-19 11:24:57 +0000 UTC Passed all checks passed}
  Dec 19 11:24:58.235: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec 19 11:24:58.235: INFO: Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 12/19/23 11:24:58.235
  Dec 19 11:24:58.254: INFO: Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete APIService "dynamic-flunder-1230355298" @ 12/19/23 11:24:58.255
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 12/19/23 11:24:58.285
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 12/19/23 11:24:58.3
  STEP: Patch APIService Status @ 12/19/23 11:24:58.306
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 12/19/23 11:24:58.325
  Dec 19 11:24:58.334: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2023-12-19 11:24:57 +0000 UTC Passed all checks passed}
  Dec 19 11:24:58.334: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec 19 11:24:58.334: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  Dec 19 11:24:58.334: INFO: Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "e2e-apiservice=patched" @ 12/19/23 11:24:58.334
  STEP: Confirm that the generated APIService has been deleted @ 12/19/23 11:24:58.346
  Dec 19 11:24:58.346: INFO: Requesting list of APIServices to confirm quantity
  Dec 19 11:24:58.354: INFO: Found 0 APIService with label "e2e-apiservice=patched"
  Dec 19 11:24:58.354: INFO: APIService v1alpha1.wardle.example.com has been deleted.
  E1219 11:24:58.433764      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:24:58.644: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-582" for this suite. @ 12/19/23 11:24:58.761
• [68.643 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
test/e2e/apimachinery/resource_quota.go:76
  STEP: Creating a kubernetes client @ 12/19/23 11:24:58.81
  Dec 19 11:24:58.810: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 11:24:58.824
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:24:58.857
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:24:58.864
  STEP: Counting existing ResourceQuota @ 12/19/23 11:24:58.87
  E1219 11:24:59.434220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:00.434866      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:01.434915      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:02.434868      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:03.435721      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/19/23 11:25:03.878
  STEP: Ensuring resource quota status is calculated @ 12/19/23 11:25:03.892
  E1219 11:25:04.435939      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:05.436465      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:25:05.906: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9371" for this suite. @ 12/19/23 11:25:05.92
• [7.128 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance]
test/e2e/network/ingress.go:556
  STEP: Creating a kubernetes client @ 12/19/23 11:25:05.95
  Dec 19 11:25:05.950: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename ingress @ 12/19/23 11:25:05.954
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:25:05.991
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:25:05.998
  STEP: getting /apis @ 12/19/23 11:25:06.006
  STEP: getting /apis/networking.k8s.io @ 12/19/23 11:25:06.017
  STEP: getting /apis/networking.k8s.iov1 @ 12/19/23 11:25:06.021
  STEP: creating @ 12/19/23 11:25:06.025
  STEP: getting @ 12/19/23 11:25:06.069
  STEP: listing @ 12/19/23 11:25:06.077
  STEP: watching @ 12/19/23 11:25:06.085
  Dec 19 11:25:06.085: INFO: starting watch
  STEP: cluster-wide listing @ 12/19/23 11:25:06.087
  STEP: cluster-wide watching @ 12/19/23 11:25:06.094
  Dec 19 11:25:06.094: INFO: starting watch
  STEP: patching @ 12/19/23 11:25:06.096
  STEP: updating @ 12/19/23 11:25:06.108
  Dec 19 11:25:06.124: INFO: waiting for watch events with expected annotations
  Dec 19 11:25:06.125: INFO: saw patched and updated annotations
  STEP: patching /status @ 12/19/23 11:25:06.126
  STEP: updating /status @ 12/19/23 11:25:06.138
  STEP: get /status @ 12/19/23 11:25:06.155
  STEP: deleting @ 12/19/23 11:25:06.162
  STEP: deleting a collection @ 12/19/23 11:25:06.186
  Dec 19 11:25:06.218: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-3125" for this suite. @ 12/19/23 11:25:06.228
• [0.296 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]
test/e2e/common/node/secrets.go:95
  STEP: Creating a kubernetes client @ 12/19/23 11:25:06.249
  Dec 19 11:25:06.249: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename secrets @ 12/19/23 11:25:06.252
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:25:06.283
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:25:06.29
  STEP: creating secret secrets-3658/secret-test-5b8a6688-687c-4276-ac49-76dc6e773afe @ 12/19/23 11:25:06.296
  STEP: Creating a pod to test consume secrets @ 12/19/23 11:25:06.306
  E1219 11:25:06.436583      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:07.436779      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:08.436944      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:09.437241      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:25:10.356
  Dec 19 11:25:10.364: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-configmaps-79d5636e-76d4-47ba-b601-86c5a4677743 container env-test: <nil>
  STEP: delete the pod @ 12/19/23 11:25:10.385
  Dec 19 11:25:10.421: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3658" for this suite. @ 12/19/23 11:25:10.432
  E1219 11:25:10.437928      14 retrywatcher.go:129] "Watch failed" err="context canceled"
• [4.198 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:175
  STEP: Creating a kubernetes client @ 12/19/23 11:25:10.449
  Dec 19 11:25:10.449: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename configmap @ 12/19/23 11:25:10.456
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:25:10.488
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:25:10.495
  STEP: Creating configMap with name configmap-test-upd-08c09774-781d-41cb-880f-91c61582a1da @ 12/19/23 11:25:10.509
  STEP: Creating the pod @ 12/19/23 11:25:10.519
  E1219 11:25:11.440319      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:12.440462      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 12/19/23 11:25:12.551
  STEP: Waiting for pod with binary data @ 12/19/23 11:25:12.563
  Dec 19 11:25:12.579: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7183" for this suite. @ 12/19/23 11:25:12.59
• [2.158 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]
test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 12/19/23 11:25:12.611
  Dec 19 11:25:12.611: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename init-container @ 12/19/23 11:25:12.614
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:25:12.652
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:25:12.659
  STEP: creating the pod @ 12/19/23 11:25:12.667
  Dec 19 11:25:12.667: INFO: PodSpec: initContainers in spec.initContainers
  E1219 11:25:13.441586      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:14.442507      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:15.443164      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:16.443967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:17.444521      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:25:17.583: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-3772" for this suite. @ 12/19/23 11:25:17.6
• [5.007 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]
test/e2e/common/node/configmap.go:138
  STEP: Creating a kubernetes client @ 12/19/23 11:25:17.621
  Dec 19 11:25:17.621: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename configmap @ 12/19/23 11:25:17.624
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:25:17.661
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:25:17.667
  STEP: Creating configMap that has name configmap-test-emptyKey-61398972-5fb3-4524-8ee7-14ceb81dcf95 @ 12/19/23 11:25:17.674
  Dec 19 11:25:17.680: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-236" for this suite. @ 12/19/23 11:25:17.694
• [0.089 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]
test/e2e/apimachinery/discovery.go:125
  STEP: Creating a kubernetes client @ 12/19/23 11:25:17.712
  Dec 19 11:25:17.712: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename discovery @ 12/19/23 11:25:17.716
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:25:17.767
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:25:17.779
  STEP: Setting up server cert @ 12/19/23 11:25:17.788
  E1219 11:25:18.445391      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:25:18.532: INFO: Checking APIGroup: apiregistration.k8s.io
  Dec 19 11:25:18.539: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  Dec 19 11:25:18.539: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
  Dec 19 11:25:18.539: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  Dec 19 11:25:18.539: INFO: Checking APIGroup: apps
  Dec 19 11:25:18.545: INFO: PreferredVersion.GroupVersion: apps/v1
  Dec 19 11:25:18.545: INFO: Versions found [{apps/v1 v1}]
  Dec 19 11:25:18.545: INFO: apps/v1 matches apps/v1
  Dec 19 11:25:18.545: INFO: Checking APIGroup: events.k8s.io
  Dec 19 11:25:18.547: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
  Dec 19 11:25:18.547: INFO: Versions found [{events.k8s.io/v1 v1}]
  Dec 19 11:25:18.547: INFO: events.k8s.io/v1 matches events.k8s.io/v1
  Dec 19 11:25:18.547: INFO: Checking APIGroup: authentication.k8s.io
  Dec 19 11:25:18.549: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
  Dec 19 11:25:18.549: INFO: Versions found [{authentication.k8s.io/v1 v1}]
  Dec 19 11:25:18.549: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
  Dec 19 11:25:18.549: INFO: Checking APIGroup: authorization.k8s.io
  Dec 19 11:25:18.550: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
  Dec 19 11:25:18.550: INFO: Versions found [{authorization.k8s.io/v1 v1}]
  Dec 19 11:25:18.550: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
  Dec 19 11:25:18.550: INFO: Checking APIGroup: autoscaling
  Dec 19 11:25:18.552: INFO: PreferredVersion.GroupVersion: autoscaling/v2
  Dec 19 11:25:18.552: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  Dec 19 11:25:18.553: INFO: autoscaling/v2 matches autoscaling/v2
  Dec 19 11:25:18.553: INFO: Checking APIGroup: batch
  Dec 19 11:25:18.555: INFO: PreferredVersion.GroupVersion: batch/v1
  Dec 19 11:25:18.555: INFO: Versions found [{batch/v1 v1}]
  Dec 19 11:25:18.556: INFO: batch/v1 matches batch/v1
  Dec 19 11:25:18.556: INFO: Checking APIGroup: certificates.k8s.io
  Dec 19 11:25:18.559: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
  Dec 19 11:25:18.559: INFO: Versions found [{certificates.k8s.io/v1 v1}]
  Dec 19 11:25:18.559: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
  Dec 19 11:25:18.559: INFO: Checking APIGroup: networking.k8s.io
  Dec 19 11:25:18.561: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
  Dec 19 11:25:18.562: INFO: Versions found [{networking.k8s.io/v1 v1}]
  Dec 19 11:25:18.562: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
  Dec 19 11:25:18.562: INFO: Checking APIGroup: policy
  Dec 19 11:25:18.564: INFO: PreferredVersion.GroupVersion: policy/v1
  Dec 19 11:25:18.564: INFO: Versions found [{policy/v1 v1}]
  Dec 19 11:25:18.565: INFO: policy/v1 matches policy/v1
  Dec 19 11:25:18.565: INFO: Checking APIGroup: rbac.authorization.k8s.io
  Dec 19 11:25:18.569: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  Dec 19 11:25:18.570: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
  Dec 19 11:25:18.570: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  Dec 19 11:25:18.570: INFO: Checking APIGroup: storage.k8s.io
  Dec 19 11:25:18.573: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
  Dec 19 11:25:18.573: INFO: Versions found [{storage.k8s.io/v1 v1}]
  Dec 19 11:25:18.574: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
  Dec 19 11:25:18.574: INFO: Checking APIGroup: admissionregistration.k8s.io
  Dec 19 11:25:18.576: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  Dec 19 11:25:18.577: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
  Dec 19 11:25:18.577: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  Dec 19 11:25:18.578: INFO: Checking APIGroup: apiextensions.k8s.io
  Dec 19 11:25:18.583: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  Dec 19 11:25:18.583: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
  Dec 19 11:25:18.584: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  Dec 19 11:25:18.584: INFO: Checking APIGroup: scheduling.k8s.io
  Dec 19 11:25:18.586: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  Dec 19 11:25:18.586: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
  Dec 19 11:25:18.586: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  Dec 19 11:25:18.586: INFO: Checking APIGroup: coordination.k8s.io
  Dec 19 11:25:18.588: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
  Dec 19 11:25:18.589: INFO: Versions found [{coordination.k8s.io/v1 v1}]
  Dec 19 11:25:18.589: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
  Dec 19 11:25:18.590: INFO: Checking APIGroup: node.k8s.io
  Dec 19 11:25:18.592: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
  Dec 19 11:25:18.592: INFO: Versions found [{node.k8s.io/v1 v1}]
  Dec 19 11:25:18.592: INFO: node.k8s.io/v1 matches node.k8s.io/v1
  Dec 19 11:25:18.592: INFO: Checking APIGroup: discovery.k8s.io
  Dec 19 11:25:18.594: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
  Dec 19 11:25:18.594: INFO: Versions found [{discovery.k8s.io/v1 v1}]
  Dec 19 11:25:18.594: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
  Dec 19 11:25:18.595: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
  Dec 19 11:25:18.597: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta3
  Dec 19 11:25:18.597: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta3 v1beta3} {flowcontrol.apiserver.k8s.io/v1beta2 v1beta2}]
  Dec 19 11:25:18.598: INFO: flowcontrol.apiserver.k8s.io/v1beta3 matches flowcontrol.apiserver.k8s.io/v1beta3
  Dec 19 11:25:18.598: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-1128" for this suite. @ 12/19/23 11:25:18.608
• [0.915 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]
test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 12/19/23 11:25:18.631
  Dec 19 11:25:18.631: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename watch @ 12/19/23 11:25:18.635
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:25:18.661
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:25:18.667
  STEP: creating a watch on configmaps with label A @ 12/19/23 11:25:18.673
  STEP: creating a watch on configmaps with label B @ 12/19/23 11:25:18.675
  STEP: creating a watch on configmaps with label A or B @ 12/19/23 11:25:18.678
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 12/19/23 11:25:18.683
  Dec 19 11:25:18.695: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9984  179b9806-a1ad-468e-a0ef-64fe065b0eb9 28116 0 2023-12-19 11:25:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-19 11:25:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:25:18.695: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9984  179b9806-a1ad-468e-a0ef-64fe065b0eb9 28116 0 2023-12-19 11:25:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-19 11:25:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 12/19/23 11:25:18.696
  Dec 19 11:25:18.710: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9984  179b9806-a1ad-468e-a0ef-64fe065b0eb9 28117 0 2023-12-19 11:25:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-19 11:25:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:25:18.711: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9984  179b9806-a1ad-468e-a0ef-64fe065b0eb9 28117 0 2023-12-19 11:25:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-19 11:25:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 12/19/23 11:25:18.711
  Dec 19 11:25:18.757: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9984  179b9806-a1ad-468e-a0ef-64fe065b0eb9 28118 0 2023-12-19 11:25:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-19 11:25:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:25:18.758: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9984  179b9806-a1ad-468e-a0ef-64fe065b0eb9 28118 0 2023-12-19 11:25:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-19 11:25:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 12/19/23 11:25:18.758
  Dec 19 11:25:18.774: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9984  179b9806-a1ad-468e-a0ef-64fe065b0eb9 28119 0 2023-12-19 11:25:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-19 11:25:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:25:18.774: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9984  179b9806-a1ad-468e-a0ef-64fe065b0eb9 28119 0 2023-12-19 11:25:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-19 11:25:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 12/19/23 11:25:18.774
  Dec 19 11:25:18.786: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9984  925f2fe4-4304-4417-9476-68b53b41d780 28120 0 2023-12-19 11:25:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-12-19 11:25:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:25:18.787: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9984  925f2fe4-4304-4417-9476-68b53b41d780 28120 0 2023-12-19 11:25:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-12-19 11:25:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E1219 11:25:19.445772      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:20.446105      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:21.446305      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:22.446777      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:23.447200      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:24.447947      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:25.448644      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:26.448876      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:27.449470      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:28.449358      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 12/19/23 11:25:28.79
  Dec 19 11:25:28.805: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9984  925f2fe4-4304-4417-9476-68b53b41d780 28162 0 2023-12-19 11:25:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-12-19 11:25:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:25:28.806: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9984  925f2fe4-4304-4417-9476-68b53b41d780 28162 0 2023-12-19 11:25:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-12-19 11:25:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E1219 11:25:29.449722      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:30.450445      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:31.450666      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:32.450975      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:33.451779      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:34.452726      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:35.453316      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:36.453514      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:37.455880      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:38.456068      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:25:38.809: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-9984" for this suite. @ 12/19/23 11:25:38.82
• [20.203 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]
test/e2e/apimachinery/resource_quota.go:887
  STEP: Creating a kubernetes client @ 12/19/23 11:25:38.846
  Dec 19 11:25:38.847: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 11:25:38.851
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:25:38.886
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:25:38.892
  STEP: Creating a ResourceQuota @ 12/19/23 11:25:38.896
  STEP: Getting a ResourceQuota @ 12/19/23 11:25:38.905
  STEP: Updating a ResourceQuota @ 12/19/23 11:25:38.912
  STEP: Verifying a ResourceQuota was modified @ 12/19/23 11:25:38.933
  STEP: Deleting a ResourceQuota @ 12/19/23 11:25:38.943
  STEP: Verifying the deleted ResourceQuota @ 12/19/23 11:25:38.958
  Dec 19 11:25:38.964: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-843" for this suite. @ 12/19/23 11:25:38.972
• [0.138 seconds]
------------------------------
SSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 12/19/23 11:25:38.986
  Dec 19 11:25:38.986: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename container-runtime @ 12/19/23 11:25:38.988
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:25:39.014
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:25:39.018
  STEP: create the container @ 12/19/23 11:25:39.024
  W1219 11:25:39.047796      14 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 12/19/23 11:25:39.048
  E1219 11:25:39.456533      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:40.457033      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:41.457772      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 12/19/23 11:25:42.084
  STEP: the container should be terminated @ 12/19/23 11:25:42.093
  STEP: the termination message should be set @ 12/19/23 11:25:42.093
  Dec 19 11:25:42.094: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 12/19/23 11:25:42.094
  Dec 19 11:25:42.122: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-5896" for this suite. @ 12/19/23 11:25:42.148
• [3.176 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]
test/e2e/apps/replica_set.go:165
  STEP: Creating a kubernetes client @ 12/19/23 11:25:42.17
  Dec 19 11:25:42.171: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename replicaset @ 12/19/23 11:25:42.174
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:25:42.213
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:25:42.219
  STEP: Create a ReplicaSet @ 12/19/23 11:25:42.228
  STEP: Verify that the required pods have come up @ 12/19/23 11:25:42.24
  Dec 19 11:25:42.245: INFO: Pod name sample-pod: Found 0 pods out of 3
  E1219 11:25:42.459158      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:43.459520      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:44.460525      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:45.461817      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:46.461568      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:25:47.257: INFO: Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 12/19/23 11:25:47.257
  Dec 19 11:25:47.268: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 12/19/23 11:25:47.27
  STEP: DeleteCollection of the ReplicaSets @ 12/19/23 11:25:47.278
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 12/19/23 11:25:47.302
  Dec 19 11:25:47.335: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-243" for this suite. @ 12/19/23 11:25:47.351
• [5.276 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:168
  STEP: Creating a kubernetes client @ 12/19/23 11:25:47.448
  Dec 19 11:25:47.448: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename container-probe @ 12/19/23 11:25:47.452
  E1219 11:25:47.462502      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:25:47.511
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:25:47.52
  STEP: Creating pod liveness-c46fd487-583a-4f44-8f80-44a7faacd157 in namespace container-probe-8184 @ 12/19/23 11:25:47.533
  E1219 11:25:48.462958      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:49.463843      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/19/23 11:25:49.725
  Dec 19 11:25:49.732: INFO: Initial restart count of pod liveness-c46fd487-583a-4f44-8f80-44a7faacd157 is 0
  Dec 19 11:25:49.740: INFO: Get pod liveness-c46fd487-583a-4f44-8f80-44a7faacd157 in namespace container-probe-8184
  E1219 11:25:50.464409      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:51.465088      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:25:51.748: INFO: Get pod liveness-c46fd487-583a-4f44-8f80-44a7faacd157 in namespace container-probe-8184
  E1219 11:25:52.466224      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:53.466842      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:25:53.755: INFO: Get pod liveness-c46fd487-583a-4f44-8f80-44a7faacd157 in namespace container-probe-8184
  E1219 11:25:54.467028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:55.467604      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:25:55.767: INFO: Get pod liveness-c46fd487-583a-4f44-8f80-44a7faacd157 in namespace container-probe-8184
  E1219 11:25:56.468606      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:57.468820      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:25:57.773: INFO: Get pod liveness-c46fd487-583a-4f44-8f80-44a7faacd157 in namespace container-probe-8184
  E1219 11:25:58.469098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:25:59.470259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:25:59.783: INFO: Get pod liveness-c46fd487-583a-4f44-8f80-44a7faacd157 in namespace container-probe-8184
  E1219 11:26:00.471145      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:01.471408      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:01.790: INFO: Get pod liveness-c46fd487-583a-4f44-8f80-44a7faacd157 in namespace container-probe-8184
  E1219 11:26:02.471710      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:03.472768      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:03.802: INFO: Get pod liveness-c46fd487-583a-4f44-8f80-44a7faacd157 in namespace container-probe-8184
  E1219 11:26:04.473930      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:05.474030      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:05.810: INFO: Get pod liveness-c46fd487-583a-4f44-8f80-44a7faacd157 in namespace container-probe-8184
  E1219 11:26:06.474353      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:07.474498      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:07.820: INFO: Get pod liveness-c46fd487-583a-4f44-8f80-44a7faacd157 in namespace container-probe-8184
  E1219 11:26:08.475245      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:09.475515      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:09.831: INFO: Get pod liveness-c46fd487-583a-4f44-8f80-44a7faacd157 in namespace container-probe-8184
  Dec 19 11:26:09.831: INFO: Restart count of pod container-probe-8184/liveness-c46fd487-583a-4f44-8f80-44a7faacd157 is now 1 (20.098482114s elapsed)
  Dec 19 11:26:09.831: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/19/23 11:26:09.843
  STEP: Destroying namespace "container-probe-8184" for this suite. @ 12/19/23 11:26:09.874
• [22.464 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]
test/e2e/kubectl/kubectl.go:1575
  STEP: Creating a kubernetes client @ 12/19/23 11:26:09.923
  Dec 19 11:26:09.923: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 11:26:09.929
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:26:09.978
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:26:09.983
  STEP: creating the pod @ 12/19/23 11:26:09.992
  Dec 19 11:26:09.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-9066 create -f -'
  E1219 11:26:10.476539      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:10.818: INFO: stderr: ""
  Dec 19 11:26:10.818: INFO: stdout: "pod/pause created\n"
  E1219 11:26:11.477614      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:12.478114      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 12/19/23 11:26:12.857
  Dec 19 11:26:12.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-9066 label pods pause testing-label=testing-label-value'
  Dec 19 11:26:13.066: INFO: stderr: ""
  Dec 19 11:26:13.066: INFO: stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 12/19/23 11:26:13.066
  Dec 19 11:26:13.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-9066 get pod pause -L testing-label'
  Dec 19 11:26:13.277: INFO: stderr: ""
  Dec 19 11:26:13.277: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 12/19/23 11:26:13.277
  Dec 19 11:26:13.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-9066 label pods pause testing-label-'
  E1219 11:26:13.478999      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:13.567: INFO: stderr: ""
  Dec 19 11:26:13.567: INFO: stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 12/19/23 11:26:13.567
  Dec 19 11:26:13.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-9066 get pod pause -L testing-label'
  Dec 19 11:26:13.787: INFO: stderr: ""
  Dec 19 11:26:13.787: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
  STEP: using delete to clean up resources @ 12/19/23 11:26:13.787
  Dec 19 11:26:13.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-9066 delete --grace-period=0 --force -f -'
  Dec 19 11:26:13.991: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec 19 11:26:13.991: INFO: stdout: "pod \"pause\" force deleted\n"
  Dec 19 11:26:13.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-9066 get rc,svc -l name=pause --no-headers'
  Dec 19 11:26:14.188: INFO: stderr: "No resources found in kubectl-9066 namespace.\n"
  Dec 19 11:26:14.188: INFO: stdout: ""
  Dec 19 11:26:14.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-9066 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Dec 19 11:26:14.387: INFO: stderr: ""
  Dec 19 11:26:14.387: INFO: stdout: ""
  Dec 19 11:26:14.387: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9066" for this suite. @ 12/19/23 11:26:14.399
• [4.491 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]
test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 12/19/23 11:26:14.425
  Dec 19 11:26:14.425: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename certificates @ 12/19/23 11:26:14.428
  E1219 11:26:14.480206      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:26:14.48
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:26:14.489
  E1219 11:26:15.479604      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting /apis @ 12/19/23 11:26:16.086
  STEP: getting /apis/certificates.k8s.io @ 12/19/23 11:26:16.095
  STEP: getting /apis/certificates.k8s.io/v1 @ 12/19/23 11:26:16.098
  STEP: creating @ 12/19/23 11:26:16.104
  STEP: getting @ 12/19/23 11:26:16.149
  STEP: listing @ 12/19/23 11:26:16.158
  STEP: watching @ 12/19/23 11:26:16.169
  Dec 19 11:26:16.170: INFO: starting watch
  STEP: patching @ 12/19/23 11:26:16.173
  STEP: updating @ 12/19/23 11:26:16.187
  Dec 19 11:26:16.202: INFO: waiting for watch events with expected annotations
  Dec 19 11:26:16.202: INFO: saw patched and updated annotations
  STEP: getting /approval @ 12/19/23 11:26:16.203
  STEP: patching /approval @ 12/19/23 11:26:16.213
  STEP: updating /approval @ 12/19/23 11:26:16.232
  STEP: getting /status @ 12/19/23 11:26:16.247
  STEP: patching /status @ 12/19/23 11:26:16.255
  STEP: updating /status @ 12/19/23 11:26:16.273
  STEP: deleting @ 12/19/23 11:26:16.291
  STEP: deleting a collection @ 12/19/23 11:26:16.335
  Dec 19 11:26:16.371: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-6291" for this suite. @ 12/19/23 11:26:16.382
• [1.972 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:217
  STEP: Creating a kubernetes client @ 12/19/23 11:26:16.406
  Dec 19 11:26:16.406: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 11:26:16.409
  E1219 11:26:16.480033      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:26:16.488
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:26:16.493
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 12/19/23 11:26:16.5
  E1219 11:26:17.480685      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:18.481106      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:19.481007      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:20.481812      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:26:20.55
  Dec 19 11:26:20.558: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-a1ac7709-53ad-4d21-8775-6d406de73f21 container test-container: <nil>
  STEP: delete the pod @ 12/19/23 11:26:20.58
  Dec 19 11:26:20.613: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-358" for this suite. @ 12/19/23 11:26:20.626
• [4.239 seconds]
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]
test/e2e/apps/replica_set.go:131
  STEP: Creating a kubernetes client @ 12/19/23 11:26:20.645
  Dec 19 11:26:20.645: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename replicaset @ 12/19/23 11:26:20.649
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:26:20.689
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:26:20.697
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 12/19/23 11:26:20.709
  E1219 11:26:21.483040      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:22.482772      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 12/19/23 11:26:22.794
  STEP: Then the orphan pod is adopted @ 12/19/23 11:26:22.819
  E1219 11:26:23.483507      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 12/19/23 11:26:23.845
  Dec 19 11:26:23.854: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 12/19/23 11:26:23.884
  E1219 11:26:24.484306      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:24.913: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-2542" for this suite. @ 12/19/23 11:26:24.93
• [4.303 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance]
test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 12/19/23 11:26:24.954
  Dec 19 11:26:24.954: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename events @ 12/19/23 11:26:24.956
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:26:24.999
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:26:25.01
  STEP: Create set of events @ 12/19/23 11:26:25.017
  STEP: get a list of Events with a label in the current namespace @ 12/19/23 11:26:25.052
  STEP: delete a list of events @ 12/19/23 11:26:25.062
  Dec 19 11:26:25.062: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 12/19/23 11:26:25.118
  Dec 19 11:26:25.133: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-715" for this suite. @ 12/19/23 11:26:25.15
• [0.217 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 12/19/23 11:26:25.176
  Dec 19 11:26:25.176: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename container-runtime @ 12/19/23 11:26:25.181
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:26:25.273
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:26:25.281
  STEP: create the container @ 12/19/23 11:26:25.287
  W1219 11:26:25.311751      14 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 12/19/23 11:26:25.312
  E1219 11:26:25.484825      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:26.484942      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:27.485292      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 12/19/23 11:26:28.364
  STEP: the container should be terminated @ 12/19/23 11:26:28.372
  STEP: the termination message should be set @ 12/19/23 11:26:28.372
  Dec 19 11:26:28.372: INFO: Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 12/19/23 11:26:28.372
  Dec 19 11:26:28.393: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-4228" for this suite. @ 12/19/23 11:26:28.417
• [3.254 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:183
  STEP: Creating a kubernetes client @ 12/19/23 11:26:28.439
  Dec 19 11:26:28.439: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename container-probe @ 12/19/23 11:26:28.442
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:26:28.477
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:26:28.483
  E1219 11:26:28.485326      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108 @ 12/19/23 11:26:28.49
  E1219 11:26:29.486321      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:30.486866      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/19/23 11:26:30.526
  Dec 19 11:26:30.541: INFO: Initial restart count of pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca is 0
  Dec 19 11:26:30.552: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:26:31.486660      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:32.487085      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:32.560: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:26:33.487967      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:34.488210      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:34.571: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:26:35.488545      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:36.488910      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:36.578: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:26:37.489300      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:38.489331      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:38.586: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:26:39.489983      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:40.489884      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:40.595: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:26:41.492612      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:42.491152      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:42.606: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:26:43.491571      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:44.491737      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:44.616: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:26:45.492301      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:46.492803      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:46.627: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:26:47.492870      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:48.492797      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:48.638: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:26:49.492961      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:50.494367      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:50.658: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:26:51.493668      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:52.494953      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:52.670: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:26:53.495157      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:54.495362      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:54.688: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:26:55.495553      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:56.495464      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:56.699: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:26:57.495722      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:26:58.495908      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:26:58.712: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:26:59.496125      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:00.496402      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:00.722: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:01.497856      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:02.497570      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:02.732: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:03.497757      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:04.497786      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:04.742: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:05.498368      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:06.498549      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:06.770: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:07.499100      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:08.499606      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:08.778: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:09.499823      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:10.500275      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:10.794: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:11.500471      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:12.500735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:12.804: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:13.501038      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:14.501539      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:14.814: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:15.501598      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:16.501734      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:16.829: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:17.501965      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:18.502590      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:18.841: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:19.502792      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:20.503623      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:20.853: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:21.503940      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:22.504060      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:22.861: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:23.504585      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:24.505236      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:24.872: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:25.506260      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:26.506578      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:26.881: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:27.506892      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:28.507504      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:28.890: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:29.507650      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:30.507819      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:30.900: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:31.508538      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:32.509027      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:32.906: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:33.509175      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:34.509509      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:34.916: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:35.509853      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:36.510838      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:36.926: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:37.512847      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:38.513067      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:38.934: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:39.513995      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:40.514134      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:40.941: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:41.514275      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:42.514985      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:42.954: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:43.515949      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:44.516514      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:44.966: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:45.517237      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:46.517325      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:46.974: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:47.517739      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:48.517744      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:48.984: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:49.519067      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:50.519325      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:50.994: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:51.519286      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:52.519860      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:53.002: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:53.520094      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:54.520975      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:55.013: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:55.522111      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:56.522952      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:57.020: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:57.523149      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:27:58.523404      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:27:59.030: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:27:59.523795      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:00.524136      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:01.037: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:01.524242      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:02.524615      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:03.052: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:03.525315      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:04.526109      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:05.065: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:05.526472      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:06.526621      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:07.076: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:07.527697      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:08.527872      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:09.083: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:09.528076      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:10.529244      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:11.094: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:11.530021      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:12.530456      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:13.106: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:13.531561      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:14.532740      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:15.124: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:15.532987      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:16.533137      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:17.134: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:17.533962      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:18.534107      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:19.145: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:19.535759      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:20.536524      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:21.157: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:21.537095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:22.537309      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:23.165: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:23.537887      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:24.539579      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:25.175: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:25.539660      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:26.539718      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:27.184: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:27.540808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:28.545368      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:29.197: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:29.545010      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:30.545844      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:31.210: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:31.546436      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:32.546763      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:33.221: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:33.546881      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:34.547021      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:35.228: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:35.547991      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:36.548857      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:37.238: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:37.549672      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:38.549902      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:39.246: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:39.550753      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:40.551426      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:41.255: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:41.552132      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:42.552403      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:43.266: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:43.553492      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:44.553672      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:45.274: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:45.553761      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:46.555066      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:47.283: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:47.556143      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:48.557135      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:49.296: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:49.557746      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:50.558299      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:51.330: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:51.559025      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:52.559190      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:53.339: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:53.559559      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:54.559756      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:55.350: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:55.560388      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:56.560195      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:57.356: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:57.561167      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:28:58.561975      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:28:59.402: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:28:59.561977      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:00.562407      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:01.411: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:01.562858      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:02.563388      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:03.424: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:03.563543      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:04.568575      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:05.434: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:05.569451      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:06.569680      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:07.441: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:07.570616      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:08.571019      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:09.451: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:09.571550      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:10.572056      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:11.461: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:11.572448      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:12.573590      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:13.482: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:13.573713      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:14.574083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:15.491: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:15.574575      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:16.574781      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:17.510: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:17.575408      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:18.576370      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:19.521: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:19.577152      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:20.577777      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:21.538: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:21.577615      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:22.578046      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:23.545: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:23.578418      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:24.579399      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:25.554: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:25.579681      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:26.579686      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:27.563: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:27.580440      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:28.580766      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:29.580664      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:29.581: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:30.580887      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:31.581143      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:31.593: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:32.581317      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:33.581747      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:33.603: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:34.584272      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:35.582776      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:35.613: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:36.584021      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:37.584028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:37.624: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:38.584263      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:39.596332      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:39.634: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:40.587049      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:41.588063      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:41.645: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:42.588338      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:43.599204      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:43.661: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:44.592359      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:45.592538      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:45.676: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:46.596848      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:47.595599      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:47.684: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:48.596424      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:49.597338      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:49.695: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:50.598259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:51.598575      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:51.705: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:52.598904      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:53.599354      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:53.714: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:54.600020      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:55.600106      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:55.725: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:56.601221      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:57.601521      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:57.733: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:29:58.601777      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:29:59.602163      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:29:59.746: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:30:00.602792      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:01.602806      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:30:01.756: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:30:02.603044      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:03.603564      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:30:03.766: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:30:04.603735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:05.603930      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:30:05.774: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:30:06.603924      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:07.604631      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:30:07.784: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:30:08.605088      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:09.605222      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:30:09.794: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:30:10.606771      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:11.606942      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:30:11.810: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:30:12.607202      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:13.607475      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:30:13.820: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:30:14.607728      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:15.608849      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:30:15.830: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:30:16.609784      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:17.609829      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:30:17.844: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:30:18.609805      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:19.610467      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:30:19.858: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:30:20.610955      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:21.610779      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:30:21.870: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:30:22.611550      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:23.611674      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:30:23.879: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:30:24.612388      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:25.612539      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:30:25.890: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:30:26.612860      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:27.614660      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:30:27.900: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:30:28.614297      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:29.615683      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:30:29.913: INFO: Get pod liveness-1a4081ec-4f61-4879-8a30-3ddc048a14ca in namespace container-probe-1108
  E1219 11:30:30.615686      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:31.615860      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:30:31.914: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/19/23 11:30:31.929
  STEP: Destroying namespace "container-probe-1108" for this suite. @ 12/19/23 11:30:31.965
• [243.555 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:528
  STEP: Creating a kubernetes client @ 12/19/23 11:30:31.998
  Dec 19 11:30:31.999: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename security-context-test @ 12/19/23 11:30:32.006
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:30:32.036
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:30:32.042
  E1219 11:30:32.616296      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:33.616665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:34.616668      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:35.617076      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:30:36.133: INFO: Got logs for pod "busybox-privileged-false-46a3b3a7-4423-4934-a097-7248acff8538": "ip: RTNETLINK answers: Operation not permitted\n"
  Dec 19 11:30:36.135: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-6847" for this suite. @ 12/19/23 11:30:36.149
• [4.166 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 12/19/23 11:30:36.172
  Dec 19 11:30:36.173: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename field-validation @ 12/19/23 11:30:36.178
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:30:36.21
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:30:36.215
  Dec 19 11:30:36.223: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 11:30:36.617569      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:37.617744      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:38.617895      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  W1219 11:30:39.017731      14 warnings.go:70] unknown field "alpha"
  W1219 11:30:39.018044      14 warnings.go:70] unknown field "beta"
  W1219 11:30:39.018271      14 warnings.go:70] unknown field "delta"
  W1219 11:30:39.018438      14 warnings.go:70] unknown field "epsilon"
  W1219 11:30:39.018456      14 warnings.go:70] unknown field "gamma"
  Dec 19 11:30:39.584: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1219 11:30:39.618004      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "field-validation-5256" for this suite. @ 12/19/23 11:30:39.624
• [3.467 seconds]
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]
test/e2e/kubectl/kubectl.go:1781
  STEP: Creating a kubernetes client @ 12/19/23 11:30:39.642
  Dec 19 11:30:39.642: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 11:30:39.644
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:30:39.674
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:30:39.68
  STEP: starting the proxy server @ 12/19/23 11:30:39.725
  Dec 19 11:30:39.726: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-8212 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 12/19/23 11:30:39.879
  Dec 19 11:30:39.900: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8212" for this suite. @ 12/19/23 11:30:39.91
• [0.282 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 12/19/23 11:30:39.932
  Dec 19 11:30:39.932: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename sched-preemption @ 12/19/23 11:30:39.935
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:30:39.968
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:30:39.975
  Dec 19 11:30:40.019: INFO: Waiting up to 1m0s for all nodes to be ready
  E1219 11:30:40.619063      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:41.619199      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:42.620214      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:43.620535      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:44.621331      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:45.621890      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:46.621980      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:47.622936      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:48.623124      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:49.623436      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:50.623698      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:51.623973      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:52.624258      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:53.624435      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:54.625600      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:55.627498      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:56.626769      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:57.626898      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:58.627083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:30:59.627490      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:00.627587      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:01.628383      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:02.629070      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:03.631282      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:04.630709      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:05.630850      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:06.631399      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:07.631840      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:08.631780      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:09.632382      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:10.632580      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:11.634460      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:12.633711      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:13.635607      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:14.634070      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:15.634449      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:16.634658      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:17.634884      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:18.635078      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:19.635827      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:20.635959      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:21.636419      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:22.636665      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:23.637540      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:24.637860      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:25.637963      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:26.638148      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:27.638359      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:28.638974      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:29.639710      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:30.640563      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:31.640868      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:32.644851      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:33.645007      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:34.645185      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:35.646058      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:36.646781      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:37.647284      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:38.647896      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:39.648022      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:40.072: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 12/19/23 11:31:40.081
  Dec 19 11:31:40.081: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename sched-preemption-path @ 12/19/23 11:31:40.086
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:31:40.12
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:31:40.127
  Dec 19 11:31:40.164: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  Dec 19 11:31:40.174: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  Dec 19 11:31:40.216: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec 19 11:31:40.256: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-2769" for this suite. @ 12/19/23 11:31:40.375
  STEP: Destroying namespace "sched-preemption-3931" for this suite. @ 12/19/23 11:31:40.388
• [60.473 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:145
  STEP: Creating a kubernetes client @ 12/19/23 11:31:40.406
  Dec 19 11:31:40.406: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename custom-resource-definition @ 12/19/23 11:31:40.409
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:31:40.437
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:31:40.443
  Dec 19 11:31:40.448: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 11:31:40.649221      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:41.061: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-5152" for this suite. @ 12/19/23 11:31:41.077
• [0.693 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]
test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 12/19/23 11:31:41.108
  Dec 19 11:31:41.108: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename proxy @ 12/19/23 11:31:41.112
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:31:41.145
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:31:41.151
  STEP: starting an echo server on multiple ports @ 12/19/23 11:31:41.184
  STEP: creating replication controller proxy-service-knqps in namespace proxy-7861 @ 12/19/23 11:31:41.185
  I1219 11:31:41.216947      14 runners.go:197] Created replication controller with name: proxy-service-knqps, namespace: proxy-7861, replica count: 1
  E1219 11:31:41.650276      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 11:31:42.269089      14 runners.go:197] proxy-service-knqps Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
  E1219 11:31:42.650438      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 11:31:43.270728      14 runners.go:197] proxy-service-knqps Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec 19 11:31:43.281: INFO: setup took 2.123471742s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 12/19/23 11:31:43.281
  Dec 19 11:31:43.316: INFO: (0) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:160/proxy/: foo (200; 33.712939ms)
  Dec 19 11:31:43.316: INFO: (0) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/rewriteme">... (200; 33.816302ms)
  Dec 19 11:31:43.326: INFO: (0) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/rewriteme">test</a> (200; 43.733499ms)
  Dec 19 11:31:43.326: INFO: (0) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname1/proxy/: foo (200; 43.398856ms)
  Dec 19 11:31:43.326: INFO: (0) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/rewriteme">test<... (200; 43.305005ms)
  Dec 19 11:31:43.327: INFO: (0) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname2/proxy/: bar (200; 43.926723ms)
  Dec 19 11:31:43.327: INFO: (0) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:162/proxy/: bar (200; 43.832284ms)
  Dec 19 11:31:43.333: INFO: (0) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname2/proxy/: bar (200; 50.416328ms)
  Dec 19 11:31:43.350: INFO: (0) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname1/proxy/: foo (200; 67.042567ms)
  Dec 19 11:31:43.352: INFO: (0) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:160/proxy/: foo (200; 68.559634ms)
  Dec 19 11:31:43.352: INFO: (0) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:162/proxy/: bar (200; 68.417057ms)
  Dec 19 11:31:43.352: INFO: (0) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname1/proxy/: tls baz (200; 69.381022ms)
  Dec 19 11:31:43.352: INFO: (0) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:460/proxy/: tls baz (200; 68.789929ms)
  Dec 19 11:31:43.357: INFO: (0) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/tlsrewritem... (200; 74.619939ms)
  Dec 19 11:31:43.374: INFO: (0) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:462/proxy/: tls qux (200; 90.86263ms)
  Dec 19 11:31:43.374: INFO: (0) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname2/proxy/: tls qux (200; 91.101446ms)
  Dec 19 11:31:43.406: INFO: (1) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/rewriteme">... (200; 30.270761ms)
  Dec 19 11:31:43.406: INFO: (1) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:162/proxy/: bar (200; 31.396364ms)
  Dec 19 11:31:43.407: INFO: (1) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:460/proxy/: tls baz (200; 30.814536ms)
  Dec 19 11:31:43.407: INFO: (1) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:160/proxy/: foo (200; 32.101588ms)
  Dec 19 11:31:43.410: INFO: (1) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname1/proxy/: tls baz (200; 34.044481ms)
  Dec 19 11:31:43.412: INFO: (1) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname2/proxy/: tls qux (200; 36.795043ms)
  Dec 19 11:31:43.412: INFO: (1) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname1/proxy/: foo (200; 36.200953ms)
  Dec 19 11:31:43.412: INFO: (1) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/rewriteme">test<... (200; 36.404488ms)
  Dec 19 11:31:43.414: INFO: (1) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/tlsrewritem... (200; 38.334218ms)
  Dec 19 11:31:43.441: INFO: (1) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/rewriteme">test</a> (200; 66.119681ms)
  Dec 19 11:31:43.452: INFO: (1) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname2/proxy/: bar (200; 74.750048ms)
  Dec 19 11:31:43.452: INFO: (1) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:462/proxy/: tls qux (200; 77.005867ms)
  Dec 19 11:31:43.453: INFO: (1) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:162/proxy/: bar (200; 76.453326ms)
  Dec 19 11:31:43.453: INFO: (1) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:160/proxy/: foo (200; 77.052899ms)
  Dec 19 11:31:43.470: INFO: (1) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname1/proxy/: foo (200; 94.006877ms)
  Dec 19 11:31:43.470: INFO: (1) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname2/proxy/: bar (200; 94.513802ms)
  Dec 19 11:31:43.494: INFO: (2) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname1/proxy/: foo (200; 19.732248ms)
  Dec 19 11:31:43.494: INFO: (2) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname1/proxy/: foo (200; 20.318453ms)
  Dec 19 11:31:43.501: INFO: (2) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname2/proxy/: bar (200; 26.075615ms)
  Dec 19 11:31:43.501: INFO: (2) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/rewriteme">test</a> (200; 25.289164ms)
  Dec 19 11:31:43.502: INFO: (2) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname2/proxy/: bar (200; 27.430252ms)
  Dec 19 11:31:43.508: INFO: (2) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:462/proxy/: tls qux (200; 31.600288ms)
  Dec 19 11:31:43.511: INFO: (2) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:160/proxy/: foo (200; 32.431206ms)
  Dec 19 11:31:43.511: INFO: (2) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:160/proxy/: foo (200; 35.203418ms)
  Dec 19 11:31:43.511: INFO: (2) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:162/proxy/: bar (200; 26.164894ms)
  Dec 19 11:31:43.511: INFO: (2) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/rewriteme">test<... (200; 33.097648ms)
  Dec 19 11:31:43.511: INFO: (2) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/tlsrewritem... (200; 35.104345ms)
  Dec 19 11:31:43.512: INFO: (2) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname2/proxy/: tls qux (200; 33.366865ms)
  Dec 19 11:31:43.512: INFO: (2) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:460/proxy/: tls baz (200; 36.17712ms)
  Dec 19 11:31:43.513: INFO: (2) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:162/proxy/: bar (200; 36.663179ms)
  Dec 19 11:31:43.513: INFO: (2) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/rewriteme">... (200; 34.823286ms)
  Dec 19 11:31:43.516: INFO: (2) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname1/proxy/: tls baz (200; 39.519543ms)
  Dec 19 11:31:43.530: INFO: (3) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/rewriteme">test<... (200; 14.039041ms)
  Dec 19 11:31:43.530: INFO: (3) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:162/proxy/: bar (200; 13.402382ms)
  Dec 19 11:31:43.532: INFO: (3) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/rewriteme">... (200; 16.508678ms)
  Dec 19 11:31:43.534: INFO: (3) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:160/proxy/: foo (200; 17.210332ms)
  Dec 19 11:31:43.535: INFO: (3) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:462/proxy/: tls qux (200; 17.880938ms)
  Dec 19 11:31:43.539: INFO: (3) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname2/proxy/: tls qux (200; 23.042161ms)
  Dec 19 11:31:43.542: INFO: (3) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname2/proxy/: bar (200; 24.107976ms)
  Dec 19 11:31:43.543: INFO: (3) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:160/proxy/: foo (200; 25.279776ms)
  Dec 19 11:31:43.546: INFO: (3) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:162/proxy/: bar (200; 29.842738ms)
  Dec 19 11:31:43.547: INFO: (3) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/rewriteme">test</a> (200; 28.564099ms)
  Dec 19 11:31:43.548: INFO: (3) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname1/proxy/: foo (200; 30.2989ms)
  Dec 19 11:31:43.548: INFO: (3) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/tlsrewritem... (200; 30.909603ms)
  Dec 19 11:31:43.549: INFO: (3) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname1/proxy/: foo (200; 30.888895ms)
  Dec 19 11:31:43.549: INFO: (3) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:460/proxy/: tls baz (200; 32.162951ms)
  Dec 19 11:31:43.551: INFO: (3) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname2/proxy/: bar (200; 32.62075ms)
  Dec 19 11:31:43.551: INFO: (3) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname1/proxy/: tls baz (200; 33.472692ms)
  Dec 19 11:31:43.569: INFO: (4) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:162/proxy/: bar (200; 17.158103ms)
  Dec 19 11:31:43.569: INFO: (4) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/rewriteme">test<... (200; 17.101844ms)
  Dec 19 11:31:43.570: INFO: (4) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:160/proxy/: foo (200; 16.342225ms)
  Dec 19 11:31:43.571: INFO: (4) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/tlsrewritem... (200; 16.615935ms)
  Dec 19 11:31:43.571: INFO: (4) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:160/proxy/: foo (200; 19.050401ms)
  Dec 19 11:31:43.571: INFO: (4) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:162/proxy/: bar (200; 18.157792ms)
  Dec 19 11:31:43.572: INFO: (4) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:460/proxy/: tls baz (200; 20.077269ms)
  Dec 19 11:31:43.573: INFO: (4) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/rewriteme">... (200; 19.189885ms)
  Dec 19 11:31:43.573: INFO: (4) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/rewriteme">test</a> (200; 19.711138ms)
  Dec 19 11:31:43.577: INFO: (4) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname1/proxy/: tls baz (200; 26.059584ms)
  Dec 19 11:31:43.578: INFO: (4) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:462/proxy/: tls qux (200; 25.014957ms)
  Dec 19 11:31:43.579: INFO: (4) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname1/proxy/: foo (200; 26.005919ms)
  Dec 19 11:31:43.579: INFO: (4) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname2/proxy/: bar (200; 26.654569ms)
  Dec 19 11:31:43.582: INFO: (4) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname2/proxy/: tls qux (200; 29.921766ms)
  Dec 19 11:31:43.583: INFO: (4) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname2/proxy/: bar (200; 29.229449ms)
  Dec 19 11:31:43.586: INFO: (4) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname1/proxy/: foo (200; 33.042574ms)
  Dec 19 11:31:43.600: INFO: (5) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:162/proxy/: bar (200; 14.315671ms)
  Dec 19 11:31:43.611: INFO: (5) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:460/proxy/: tls baz (200; 25.316489ms)
  Dec 19 11:31:43.612: INFO: (5) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/rewriteme">... (200; 25.072675ms)
  Dec 19 11:31:43.612: INFO: (5) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:160/proxy/: foo (200; 24.974009ms)
  Dec 19 11:31:43.612: INFO: (5) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:160/proxy/: foo (200; 25.65364ms)
  Dec 19 11:31:43.613: INFO: (5) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/rewriteme">test</a> (200; 25.838159ms)
  Dec 19 11:31:43.613: INFO: (5) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:162/proxy/: bar (200; 26.241271ms)
  Dec 19 11:31:43.613: INFO: (5) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/tlsrewritem... (200; 27.24137ms)
  Dec 19 11:31:43.613: INFO: (5) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:462/proxy/: tls qux (200; 26.418014ms)
  Dec 19 11:31:43.616: INFO: (5) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/rewriteme">test<... (200; 29.448679ms)
  Dec 19 11:31:43.618: INFO: (5) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname1/proxy/: foo (200; 32.734626ms)
  Dec 19 11:31:43.619: INFO: (5) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname2/proxy/: bar (200; 33.409511ms)
  Dec 19 11:31:43.620: INFO: (5) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname1/proxy/: tls baz (200; 34.124797ms)
  Dec 19 11:31:43.622: INFO: (5) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname2/proxy/: bar (200; 35.687488ms)
  Dec 19 11:31:43.623: INFO: (5) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname2/proxy/: tls qux (200; 36.626332ms)
  Dec 19 11:31:43.624: INFO: (5) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname1/proxy/: foo (200; 37.48978ms)
  Dec 19 11:31:43.640: INFO: (6) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/tlsrewritem... (200; 15.474637ms)
  Dec 19 11:31:43.640: INFO: (6) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/rewriteme">test<... (200; 15.105899ms)
  Dec 19 11:31:43.642: INFO: (6) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:162/proxy/: bar (200; 16.891093ms)
  Dec 19 11:31:43.643: INFO: (6) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:160/proxy/: foo (200; 16.812819ms)
  Dec 19 11:31:43.648: INFO: (6) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:460/proxy/: tls baz (200; 22.160146ms)
  Dec 19 11:31:43.648: INFO: (6) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/rewriteme">test</a> (200; 21.518706ms)
  Dec 19 11:31:43.649: INFO: (6) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname2/proxy/: bar (200; 22.596524ms)
  Dec 19 11:31:43.649: INFO: (6) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:162/proxy/: bar (200; 22.293953ms)
  Dec 19 11:31:43.649: INFO: (6) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname2/proxy/: tls qux (200; 24.378268ms)
  Dec 19 11:31:43.649: INFO: (6) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:160/proxy/: foo (200; 21.981007ms)
  E1219 11:31:43.651262      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:43.655: INFO: (6) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname1/proxy/: foo (200; 28.858827ms)
  Dec 19 11:31:43.657: INFO: (6) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:462/proxy/: tls qux (200; 30.287885ms)
  Dec 19 11:31:43.658: INFO: (6) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/rewriteme">... (200; 30.378069ms)
  Dec 19 11:31:43.658: INFO: (6) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname2/proxy/: bar (200; 31.12565ms)
  Dec 19 11:31:43.659: INFO: (6) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname1/proxy/: foo (200; 33.520632ms)
  Dec 19 11:31:43.659: INFO: (6) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname1/proxy/: tls baz (200; 32.135068ms)
  Dec 19 11:31:43.687: INFO: (7) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/rewriteme">test</a> (200; 27.846911ms)
  Dec 19 11:31:43.687: INFO: (7) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/rewriteme">test<... (200; 26.766443ms)
  Dec 19 11:31:43.688: INFO: (7) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:160/proxy/: foo (200; 27.967366ms)
  Dec 19 11:31:43.689: INFO: (7) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:460/proxy/: tls baz (200; 28.191162ms)
  Dec 19 11:31:43.689: INFO: (7) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:160/proxy/: foo (200; 28.902038ms)
  Dec 19 11:31:43.690: INFO: (7) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:462/proxy/: tls qux (200; 29.559878ms)
  Dec 19 11:31:43.690: INFO: (7) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/rewriteme">... (200; 29.305846ms)
  Dec 19 11:31:43.690: INFO: (7) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:162/proxy/: bar (200; 30.067068ms)
  Dec 19 11:31:43.690: INFO: (7) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:162/proxy/: bar (200; 29.479571ms)
  Dec 19 11:31:43.690: INFO: (7) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/tlsrewritem... (200; 29.791528ms)
  Dec 19 11:31:43.696: INFO: (7) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname1/proxy/: foo (200; 34.862102ms)
  Dec 19 11:31:43.696: INFO: (7) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname1/proxy/: foo (200; 35.239487ms)
  Dec 19 11:31:43.698: INFO: (7) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname1/proxy/: tls baz (200; 38.136611ms)
  Dec 19 11:31:43.700: INFO: (7) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname2/proxy/: bar (200; 40.308465ms)
  Dec 19 11:31:43.701: INFO: (7) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname2/proxy/: bar (200; 39.425774ms)
  Dec 19 11:31:43.703: INFO: (7) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname2/proxy/: tls qux (200; 42.597327ms)
  Dec 19 11:31:43.721: INFO: (8) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/tlsrewritem... (200; 17.983121ms)
  Dec 19 11:31:43.721: INFO: (8) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:162/proxy/: bar (200; 17.246344ms)
  Dec 19 11:31:43.725: INFO: (8) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname2/proxy/: bar (200; 22.194353ms)
  Dec 19 11:31:43.728: INFO: (8) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:160/proxy/: foo (200; 24.038336ms)
  Dec 19 11:31:43.728: INFO: (8) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:160/proxy/: foo (200; 22.849479ms)
  Dec 19 11:31:43.732: INFO: (8) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:162/proxy/: bar (200; 28.006781ms)
  Dec 19 11:31:43.732: INFO: (8) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:462/proxy/: tls qux (200; 28.269739ms)
  Dec 19 11:31:43.733: INFO: (8) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/rewriteme">test<... (200; 28.807628ms)
  Dec 19 11:31:43.734: INFO: (8) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname2/proxy/: bar (200; 29.742308ms)
  Dec 19 11:31:43.734: INFO: (8) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/rewriteme">... (200; 29.722217ms)
  Dec 19 11:31:43.735: INFO: (8) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname2/proxy/: tls qux (200; 31.333023ms)
  Dec 19 11:31:43.739: INFO: (8) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname1/proxy/: foo (200; 34.841042ms)
  Dec 19 11:31:43.740: INFO: (8) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:460/proxy/: tls baz (200; 35.363603ms)
  Dec 19 11:31:43.741: INFO: (8) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/rewriteme">test</a> (200; 37.415982ms)
  Dec 19 11:31:43.742: INFO: (8) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname1/proxy/: foo (200; 37.193204ms)
  Dec 19 11:31:43.742: INFO: (8) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname1/proxy/: tls baz (200; 37.205844ms)
  Dec 19 11:31:43.770: INFO: (9) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:162/proxy/: bar (200; 28.161432ms)
  Dec 19 11:31:43.771: INFO: (9) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:462/proxy/: tls qux (200; 28.790329ms)
  Dec 19 11:31:43.782: INFO: (9) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname2/proxy/: bar (200; 39.645185ms)
  Dec 19 11:31:43.782: INFO: (9) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname1/proxy/: tls baz (200; 39.618868ms)
  Dec 19 11:31:43.782: INFO: (9) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname1/proxy/: foo (200; 39.387089ms)
  Dec 19 11:31:43.782: INFO: (9) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname1/proxy/: foo (200; 39.334926ms)
  Dec 19 11:31:43.782: INFO: (9) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname2/proxy/: bar (200; 39.194849ms)
  Dec 19 11:31:43.782: INFO: (9) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/rewriteme">test</a> (200; 39.026741ms)
  Dec 19 11:31:43.782: INFO: (9) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:460/proxy/: tls baz (200; 39.679248ms)
  Dec 19 11:31:43.782: INFO: (9) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:160/proxy/: foo (200; 39.46388ms)
  Dec 19 11:31:43.784: INFO: (9) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/rewriteme">... (200; 40.907721ms)
  Dec 19 11:31:43.785: INFO: (9) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:162/proxy/: bar (200; 41.896157ms)
  Dec 19 11:31:43.787: INFO: (9) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/rewriteme">test<... (200; 43.537155ms)
  Dec 19 11:31:43.788: INFO: (9) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:160/proxy/: foo (200; 44.274679ms)
  Dec 19 11:31:43.789: INFO: (9) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname2/proxy/: tls qux (200; 44.841917ms)
  Dec 19 11:31:43.790: INFO: (9) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/tlsrewritem... (200; 46.345026ms)
  Dec 19 11:31:43.815: INFO: (10) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/rewriteme">... (200; 23.174559ms)
  Dec 19 11:31:43.816: INFO: (10) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:162/proxy/: bar (200; 22.888815ms)
  Dec 19 11:31:43.817: INFO: (10) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:462/proxy/: tls qux (200; 26.38383ms)
  Dec 19 11:31:43.818: INFO: (10) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:460/proxy/: tls baz (200; 24.822525ms)
  Dec 19 11:31:43.827: INFO: (10) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/tlsrewritem... (200; 35.545652ms)
  Dec 19 11:31:43.828: INFO: (10) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/rewriteme">test<... (200; 34.509115ms)
  Dec 19 11:31:43.828: INFO: (10) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:162/proxy/: bar (200; 36.551801ms)
  Dec 19 11:31:43.830: INFO: (10) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname2/proxy/: tls qux (200; 36.602645ms)
  Dec 19 11:31:43.832: INFO: (10) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname2/proxy/: bar (200; 40.206536ms)
  Dec 19 11:31:43.833: INFO: (10) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:160/proxy/: foo (200; 39.335234ms)
  Dec 19 11:31:43.833: INFO: (10) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname2/proxy/: bar (200; 39.788456ms)
  Dec 19 11:31:43.833: INFO: (10) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname1/proxy/: tls baz (200; 41.005925ms)
  Dec 19 11:31:43.834: INFO: (10) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname1/proxy/: foo (200; 43.446442ms)
  Dec 19 11:31:43.834: INFO: (10) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/rewriteme">test</a> (200; 42.941756ms)
  Dec 19 11:31:43.834: INFO: (10) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:160/proxy/: foo (200; 42.137596ms)
  Dec 19 11:31:43.835: INFO: (10) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname1/proxy/: foo (200; 40.849708ms)
  Dec 19 11:31:43.856: INFO: (11) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:460/proxy/: tls baz (200; 15.593354ms)
  Dec 19 11:31:43.861: INFO: (11) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/rewriteme">test<... (200; 18.719385ms)
  Dec 19 11:31:43.863: INFO: (11) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/tlsrewritem... (200; 20.68019ms)
  Dec 19 11:31:43.863: INFO: (11) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/rewriteme">test</a> (200; 21.229214ms)
  Dec 19 11:31:43.867: INFO: (11) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/rewriteme">... (200; 25.421909ms)
  Dec 19 11:31:43.867: INFO: (11) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:162/proxy/: bar (200; 25.929724ms)
  Dec 19 11:31:43.868: INFO: (11) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname1/proxy/: foo (200; 26.423357ms)
  Dec 19 11:31:43.868: INFO: (11) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:462/proxy/: tls qux (200; 25.805837ms)
  Dec 19 11:31:43.868: INFO: (11) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname2/proxy/: bar (200; 26.31401ms)
  Dec 19 11:31:43.868: INFO: (11) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:160/proxy/: foo (200; 26.233249ms)
  Dec 19 11:31:43.869: INFO: (11) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:162/proxy/: bar (200; 26.421444ms)
  Dec 19 11:31:43.869: INFO: (11) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:160/proxy/: foo (200; 26.896848ms)
  Dec 19 11:31:43.869: INFO: (11) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname1/proxy/: foo (200; 28.23873ms)
  Dec 19 11:31:43.870: INFO: (11) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname2/proxy/: tls qux (200; 27.371286ms)
  Dec 19 11:31:43.873: INFO: (11) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname1/proxy/: tls baz (200; 31.396212ms)
  Dec 19 11:31:43.874: INFO: (11) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname2/proxy/: bar (200; 32.104794ms)
  Dec 19 11:31:43.883: INFO: (12) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/tlsrewritem... (200; 8.90286ms)
  Dec 19 11:31:43.887: INFO: (12) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:160/proxy/: foo (200; 12.368987ms)
  Dec 19 11:31:43.892: INFO: (12) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:162/proxy/: bar (200; 17.227821ms)
  Dec 19 11:31:43.896: INFO: (12) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/rewriteme">... (200; 21.38345ms)
  Dec 19 11:31:43.898: INFO: (12) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:462/proxy/: tls qux (200; 23.161386ms)
  Dec 19 11:31:43.899: INFO: (12) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/rewriteme">test</a> (200; 24.335201ms)
  Dec 19 11:31:43.899: INFO: (12) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:160/proxy/: foo (200; 23.893677ms)
  Dec 19 11:31:43.899: INFO: (12) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:460/proxy/: tls baz (200; 23.835316ms)
  Dec 19 11:31:43.899: INFO: (12) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:162/proxy/: bar (200; 23.703186ms)
  Dec 19 11:31:43.906: INFO: (12) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname2/proxy/: bar (200; 30.982254ms)
  Dec 19 11:31:43.906: INFO: (12) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname2/proxy/: tls qux (200; 32.134445ms)
  Dec 19 11:31:43.907: INFO: (12) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname1/proxy/: foo (200; 31.087294ms)
  Dec 19 11:31:43.908: INFO: (12) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname1/proxy/: foo (200; 32.47917ms)
  Dec 19 11:31:43.908: INFO: (12) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname2/proxy/: bar (200; 32.821246ms)
  Dec 19 11:31:43.908: INFO: (12) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/rewriteme">test<... (200; 33.291134ms)
  Dec 19 11:31:43.909: INFO: (12) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname1/proxy/: tls baz (200; 33.846016ms)
  Dec 19 11:31:43.930: INFO: (13) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:160/proxy/: foo (200; 19.713651ms)
  Dec 19 11:31:43.930: INFO: (13) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:160/proxy/: foo (200; 20.259849ms)
  Dec 19 11:31:43.930: INFO: (13) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:462/proxy/: tls qux (200; 21.251913ms)
  Dec 19 11:31:43.930: INFO: (13) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:162/proxy/: bar (200; 20.227298ms)
  Dec 19 11:31:43.931: INFO: (13) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:460/proxy/: tls baz (200; 21.951349ms)
  Dec 19 11:31:43.932: INFO: (13) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:162/proxy/: bar (200; 22.799058ms)
  Dec 19 11:31:43.932: INFO: (13) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/rewriteme">... (200; 21.903192ms)
  Dec 19 11:31:43.933: INFO: (13) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/rewriteme">test</a> (200; 22.935302ms)
  Dec 19 11:31:43.936: INFO: (13) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname2/proxy/: bar (200; 26.714851ms)
  Dec 19 11:31:43.936: INFO: (13) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname1/proxy/: foo (200; 26.676252ms)
  Dec 19 11:31:43.936: INFO: (13) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/rewriteme">test<... (200; 25.42781ms)
  Dec 19 11:31:43.937: INFO: (13) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname1/proxy/: foo (200; 26.924459ms)
  Dec 19 11:31:43.937: INFO: (13) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/tlsrewritem... (200; 25.878097ms)
  Dec 19 11:31:43.939: INFO: (13) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname2/proxy/: bar (200; 29.052799ms)
  Dec 19 11:31:43.939: INFO: (13) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname2/proxy/: tls qux (200; 28.740264ms)
  Dec 19 11:31:43.943: INFO: (13) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname1/proxy/: tls baz (200; 32.270356ms)
  Dec 19 11:31:43.958: INFO: (14) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/rewriteme">... (200; 15.15782ms)
  Dec 19 11:31:43.960: INFO: (14) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/tlsrewritem... (200; 16.208529ms)
  Dec 19 11:31:43.960: INFO: (14) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:160/proxy/: foo (200; 17.021729ms)
  Dec 19 11:31:43.961: INFO: (14) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:162/proxy/: bar (200; 17.308803ms)
  Dec 19 11:31:43.961: INFO: (14) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:162/proxy/: bar (200; 17.922491ms)
  Dec 19 11:31:43.963: INFO: (14) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/rewriteme">test<... (200; 19.033125ms)
  Dec 19 11:31:43.964: INFO: (14) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:160/proxy/: foo (200; 19.574733ms)
  Dec 19 11:31:43.965: INFO: (14) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/rewriteme">test</a> (200; 19.815834ms)
  Dec 19 11:31:43.967: INFO: (14) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:462/proxy/: tls qux (200; 22.305606ms)
  Dec 19 11:31:43.969: INFO: (14) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname1/proxy/: foo (200; 24.464432ms)
  Dec 19 11:31:43.970: INFO: (14) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname1/proxy/: foo (200; 26.00717ms)
  Dec 19 11:31:43.972: INFO: (14) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname2/proxy/: bar (200; 27.850583ms)
  Dec 19 11:31:43.972: INFO: (14) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname2/proxy/: tls qux (200; 28.464576ms)
  Dec 19 11:31:43.973: INFO: (14) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname1/proxy/: tls baz (200; 30.408112ms)
  Dec 19 11:31:43.973: INFO: (14) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:460/proxy/: tls baz (200; 29.54735ms)
  Dec 19 11:31:43.976: INFO: (14) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname2/proxy/: bar (200; 31.290892ms)
  Dec 19 11:31:43.990: INFO: (15) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:462/proxy/: tls qux (200; 13.904414ms)
  Dec 19 11:31:43.990: INFO: (15) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:160/proxy/: foo (200; 13.102801ms)
  Dec 19 11:31:43.990: INFO: (15) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:460/proxy/: tls baz (200; 13.70882ms)
  Dec 19 11:31:43.992: INFO: (15) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:160/proxy/: foo (200; 15.73983ms)
  Dec 19 11:31:43.993: INFO: (15) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:162/proxy/: bar (200; 15.907034ms)
  Dec 19 11:31:43.993: INFO: (15) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:162/proxy/: bar (200; 17.061979ms)
  Dec 19 11:31:43.996: INFO: (15) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/rewriteme">... (200; 18.911263ms)
  Dec 19 11:31:43.997: INFO: (15) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/rewriteme">test<... (200; 19.775625ms)
  Dec 19 11:31:43.997: INFO: (15) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname2/proxy/: tls qux (200; 20.143271ms)
  Dec 19 11:31:43.997: INFO: (15) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname2/proxy/: bar (200; 20.550737ms)
  Dec 19 11:31:44.002: INFO: (15) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname2/proxy/: bar (200; 26.098458ms)
  Dec 19 11:31:44.004: INFO: (15) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/rewriteme">test</a> (200; 27.681314ms)
  Dec 19 11:31:44.005: INFO: (15) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname1/proxy/: foo (200; 28.949134ms)
  Dec 19 11:31:44.006: INFO: (15) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/tlsrewritem... (200; 28.414472ms)
  Dec 19 11:31:44.006: INFO: (15) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname1/proxy/: foo (200; 29.851687ms)
  Dec 19 11:31:44.006: INFO: (15) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname1/proxy/: tls baz (200; 29.383355ms)
  Dec 19 11:31:44.018: INFO: (16) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:160/proxy/: foo (200; 11.258566ms)
  Dec 19 11:31:44.018: INFO: (16) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:460/proxy/: tls baz (200; 11.303993ms)
  Dec 19 11:31:44.019: INFO: (16) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/tlsrewritem... (200; 11.175958ms)
  Dec 19 11:31:44.028: INFO: (16) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:162/proxy/: bar (200; 20.379766ms)
  Dec 19 11:31:44.029: INFO: (16) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/rewriteme">... (200; 20.571388ms)
  Dec 19 11:31:44.029: INFO: (16) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:160/proxy/: foo (200; 21.210723ms)
  Dec 19 11:31:44.029: INFO: (16) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:462/proxy/: tls qux (200; 21.80459ms)
  Dec 19 11:31:44.029: INFO: (16) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname1/proxy/: foo (200; 22.553308ms)
  Dec 19 11:31:44.036: INFO: (16) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/rewriteme">test</a> (200; 27.980769ms)
  Dec 19 11:31:44.036: INFO: (16) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname1/proxy/: foo (200; 28.992801ms)
  Dec 19 11:31:44.036: INFO: (16) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/rewriteme">test<... (200; 28.770226ms)
  Dec 19 11:31:44.036: INFO: (16) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname1/proxy/: tls baz (200; 28.091378ms)
  Dec 19 11:31:44.036: INFO: (16) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:162/proxy/: bar (200; 28.762079ms)
  Dec 19 11:31:44.036: INFO: (16) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname2/proxy/: bar (200; 28.371187ms)
  Dec 19 11:31:44.036: INFO: (16) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname2/proxy/: bar (200; 29.336832ms)
  Dec 19 11:31:44.038: INFO: (16) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname2/proxy/: tls qux (200; 30.447227ms)
  Dec 19 11:31:44.048: INFO: (17) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:462/proxy/: tls qux (200; 9.716598ms)
  Dec 19 11:31:44.059: INFO: (17) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:162/proxy/: bar (200; 21.075811ms)
  Dec 19 11:31:44.061: INFO: (17) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname2/proxy/: bar (200; 22.897142ms)
  Dec 19 11:31:44.061: INFO: (17) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/rewriteme">test</a> (200; 22.272381ms)
  Dec 19 11:31:44.061: INFO: (17) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/rewriteme">test<... (200; 22.67301ms)
  Dec 19 11:31:44.061: INFO: (17) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:160/proxy/: foo (200; 22.150384ms)
  Dec 19 11:31:44.061: INFO: (17) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:460/proxy/: tls baz (200; 21.889575ms)
  Dec 19 11:31:44.061: INFO: (17) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/tlsrewritem... (200; 22.17858ms)
  Dec 19 11:31:44.061: INFO: (17) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname1/proxy/: foo (200; 23.065561ms)
  Dec 19 11:31:44.064: INFO: (17) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname1/proxy/: tls baz (200; 25.212041ms)
  Dec 19 11:31:44.064: INFO: (17) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname2/proxy/: bar (200; 25.077937ms)
  Dec 19 11:31:44.067: INFO: (17) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:160/proxy/: foo (200; 28.079437ms)
  Dec 19 11:31:44.068: INFO: (17) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/rewriteme">... (200; 29.359529ms)
  Dec 19 11:31:44.069: INFO: (17) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:162/proxy/: bar (200; 30.483241ms)
  Dec 19 11:31:44.070: INFO: (17) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname1/proxy/: foo (200; 30.790682ms)
  Dec 19 11:31:44.072: INFO: (17) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname2/proxy/: tls qux (200; 33.059873ms)
  Dec 19 11:31:44.091: INFO: (18) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:162/proxy/: bar (200; 18.433728ms)
  Dec 19 11:31:44.091: INFO: (18) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname1/proxy/: tls baz (200; 19.107247ms)
  Dec 19 11:31:44.095: INFO: (18) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:160/proxy/: foo (200; 22.387638ms)
  Dec 19 11:31:44.097: INFO: (18) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/rewriteme">test</a> (200; 24.302902ms)
  Dec 19 11:31:44.097: INFO: (18) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/rewriteme">... (200; 24.053364ms)
  Dec 19 11:31:44.097: INFO: (18) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname1/proxy/: foo (200; 25.298248ms)
  Dec 19 11:31:44.097: INFO: (18) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:162/proxy/: bar (200; 24.218866ms)
  Dec 19 11:31:44.097: INFO: (18) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:462/proxy/: tls qux (200; 25.194415ms)
  Dec 19 11:31:44.098: INFO: (18) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/rewriteme">test<... (200; 25.137079ms)
  Dec 19 11:31:44.101: INFO: (18) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname2/proxy/: bar (200; 28.457392ms)
  Dec 19 11:31:44.101: INFO: (18) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname2/proxy/: tls qux (200; 28.9562ms)
  Dec 19 11:31:44.105: INFO: (18) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/tlsrewritem... (200; 31.941511ms)
  Dec 19 11:31:44.106: INFO: (18) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname1/proxy/: foo (200; 33.307708ms)
  Dec 19 11:31:44.106: INFO: (18) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:160/proxy/: foo (200; 33.335569ms)
  Dec 19 11:31:44.106: INFO: (18) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:460/proxy/: tls baz (200; 34.078121ms)
  Dec 19 11:31:44.108: INFO: (18) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname2/proxy/: bar (200; 35.064517ms)
  Dec 19 11:31:44.118: INFO: (19) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:160/proxy/: foo (200; 9.681182ms)
  Dec 19 11:31:44.119: INFO: (19) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:443/proxy/tlsrewritem... (200; 10.833337ms)
  Dec 19 11:31:44.121: INFO: (19) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:1080/proxy/rewriteme">test<... (200; 12.642139ms)
  Dec 19 11:31:44.124: INFO: (19) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd/proxy/rewriteme">test</a> (200; 14.76875ms)
  Dec 19 11:31:44.131: INFO: (19) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/: <a href="/api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:1080/proxy/rewriteme">... (200; 21.031995ms)
  Dec 19 11:31:44.131: INFO: (19) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:160/proxy/: foo (200; 21.366159ms)
  Dec 19 11:31:44.132: INFO: (19) /api/v1/namespaces/proxy-7861/pods/http:proxy-service-knqps-c9sxd:162/proxy/: bar (200; 22.879469ms)
  Dec 19 11:31:44.132: INFO: (19) /api/v1/namespaces/proxy-7861/pods/proxy-service-knqps-c9sxd:162/proxy/: bar (200; 23.420381ms)
  Dec 19 11:31:44.133: INFO: (19) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:462/proxy/: tls qux (200; 23.80139ms)
  Dec 19 11:31:44.134: INFO: (19) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname1/proxy/: tls baz (200; 24.003785ms)
  Dec 19 11:31:44.134: INFO: (19) /api/v1/namespaces/proxy-7861/pods/https:proxy-service-knqps-c9sxd:460/proxy/: tls baz (200; 24.772166ms)
  Dec 19 11:31:44.136: INFO: (19) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname2/proxy/: bar (200; 26.088071ms)
  Dec 19 11:31:44.136: INFO: (19) /api/v1/namespaces/proxy-7861/services/http:proxy-service-knqps:portname1/proxy/: foo (200; 26.733689ms)
  Dec 19 11:31:44.137: INFO: (19) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname1/proxy/: foo (200; 27.228054ms)
  Dec 19 11:31:44.138: INFO: (19) /api/v1/namespaces/proxy-7861/services/https:proxy-service-knqps:tlsportname2/proxy/: tls qux (200; 29.592914ms)
  Dec 19 11:31:44.140: INFO: (19) /api/v1/namespaces/proxy-7861/services/proxy-service-knqps:portname2/proxy/: bar (200; 30.805259ms)
  Dec 19 11:31:44.141: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController proxy-service-knqps in namespace proxy-7861, will wait for the garbage collector to delete the pods @ 12/19/23 11:31:44.152
  Dec 19 11:31:44.227: INFO: Deleting ReplicationController proxy-service-knqps took: 15.704887ms
  Dec 19 11:31:44.328: INFO: Terminating ReplicationController proxy-service-knqps pods took: 100.825822ms
  E1219 11:31:44.652325      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:45.652649      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "proxy-7861" for this suite. @ 12/19/23 11:31:46.231
• [5.141 seconds]
------------------------------
S
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]
test/e2e/common/node/configmap.go:169
  STEP: Creating a kubernetes client @ 12/19/23 11:31:46.25
  Dec 19 11:31:46.250: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename configmap @ 12/19/23 11:31:46.257
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:31:46.29
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:31:46.306
  STEP: creating a ConfigMap @ 12/19/23 11:31:46.319
  STEP: fetching the ConfigMap @ 12/19/23 11:31:46.331
  STEP: patching the ConfigMap @ 12/19/23 11:31:46.338
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 12/19/23 11:31:46.35
  STEP: deleting the ConfigMap by collection with a label selector @ 12/19/23 11:31:46.363
  STEP: listing all ConfigMaps in test namespace @ 12/19/23 11:31:46.377
  Dec 19 11:31:46.386: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-985" for this suite. @ 12/19/23 11:31:46.403
• [0.176 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:236
  STEP: Creating a kubernetes client @ 12/19/23 11:31:46.432
  Dec 19 11:31:46.432: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/19/23 11:31:46.435
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:31:46.467
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:31:46.473
  Dec 19 11:31:46.481: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 11:31:46.653546      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:47.654611      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 12/19/23 11:31:48.536
  Dec 19 11:31:48.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-3246 --namespace=crd-publish-openapi-3246 create -f -'
  E1219 11:31:48.655110      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:49.656066      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:49.906: INFO: stderr: ""
  Dec 19 11:31:49.906: INFO: stdout: "e2e-test-crd-publish-openapi-9681-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Dec 19 11:31:49.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-3246 --namespace=crd-publish-openapi-3246 delete e2e-test-crd-publish-openapi-9681-crds test-cr'
  Dec 19 11:31:50.129: INFO: stderr: ""
  Dec 19 11:31:50.129: INFO: stdout: "e2e-test-crd-publish-openapi-9681-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  Dec 19 11:31:50.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-3246 --namespace=crd-publish-openapi-3246 apply -f -'
  E1219 11:31:50.663116      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:51.264: INFO: stderr: ""
  Dec 19 11:31:51.264: INFO: stdout: "e2e-test-crd-publish-openapi-9681-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Dec 19 11:31:51.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-3246 --namespace=crd-publish-openapi-3246 delete e2e-test-crd-publish-openapi-9681-crds test-cr'
  Dec 19 11:31:51.504: INFO: stderr: ""
  Dec 19 11:31:51.504: INFO: stdout: "e2e-test-crd-publish-openapi-9681-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 12/19/23 11:31:51.505
  Dec 19 11:31:51.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=crd-publish-openapi-3246 explain e2e-test-crd-publish-openapi-9681-crds'
  E1219 11:31:51.661014      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:52.041: INFO: stderr: ""
  Dec 19 11:31:52.041: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-9681-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E1219 11:31:52.662042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:53.662368      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:31:53.995: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3246" for this suite. @ 12/19/23 11:31:54.02
• [7.601 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 12/19/23 11:31:54.051
  Dec 19 11:31:54.051: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename watch @ 12/19/23 11:31:54.054
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:31:54.084
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:31:54.089
  STEP: creating a watch on configmaps with a certain label @ 12/19/23 11:31:54.094
  STEP: creating a new configmap @ 12/19/23 11:31:54.096
  STEP: modifying the configmap once @ 12/19/23 11:31:54.109
  STEP: changing the label value of the configmap @ 12/19/23 11:31:54.126
  STEP: Expecting to observe a delete notification for the watched object @ 12/19/23 11:31:54.146
  Dec 19 11:31:54.146: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5231  54f2933f-4632-4f63-9ab2-40991d277cac 29316 0 2023-12-19 11:31:54 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-19 11:31:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:31:54.149: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5231  54f2933f-4632-4f63-9ab2-40991d277cac 29317 0 2023-12-19 11:31:54 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-19 11:31:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:31:54.150: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5231  54f2933f-4632-4f63-9ab2-40991d277cac 29318 0 2023-12-19 11:31:54 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-19 11:31:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 12/19/23 11:31:54.151
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 12/19/23 11:31:54.172
  E1219 11:31:54.662745      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:55.663401      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:56.663573      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:57.663968      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:58.664005      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:31:59.664263      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:00.664436      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:01.664793      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:02.664818      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:03.665029      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 12/19/23 11:32:04.173
  STEP: modifying the configmap a third time @ 12/19/23 11:32:04.194
  STEP: deleting the configmap @ 12/19/23 11:32:04.212
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 12/19/23 11:32:04.225
  Dec 19 11:32:04.225: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5231  54f2933f-4632-4f63-9ab2-40991d277cac 29341 0 2023-12-19 11:31:54 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-19 11:32:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:32:04.225: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5231  54f2933f-4632-4f63-9ab2-40991d277cac 29342 0 2023-12-19 11:31:54 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-19 11:32:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:32:04.226: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5231  54f2933f-4632-4f63-9ab2-40991d277cac 29343 0 2023-12-19 11:31:54 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-19 11:32:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec 19 11:32:04.226: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-5231" for this suite. @ 12/19/23 11:32:04.239
• [10.203 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 12/19/23 11:32:04.257
  Dec 19 11:32:04.258: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename container-runtime @ 12/19/23 11:32:04.26
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:32:04.289
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:32:04.295
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 12/19/23 11:32:04.33
  E1219 11:32:04.665993      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:05.666999      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:06.668122      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:07.669122      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:08.669735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:09.670755      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:10.671065      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:11.670806      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:12.671339      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:13.672211      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:14.672100      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:15.672832      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:16.673326      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:17.673697      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:18.674615      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:19.675224      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:20.675871      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:21.676035      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 12/19/23 11:32:22.549
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 12/19/23 11:32:22.556
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 12/19/23 11:32:22.571
  STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] @ 12/19/23 11:32:22.571
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 12/19/23 11:32:22.61
  E1219 11:32:22.676550      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:23.677779      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:24.678173      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 12/19/23 11:32:25.663
  E1219 11:32:25.679220      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:26.680145      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 12/19/23 11:32:26.682
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 12/19/23 11:32:26.707
  STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] @ 12/19/23 11:32:26.707
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 12/19/23 11:32:26.82
  E1219 11:32:27.683394      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 12/19/23 11:32:27.839
  E1219 11:32:28.684118      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:29.683672      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 12/19/23 11:32:29.866
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 12/19/23 11:32:29.878
  STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] @ 12/19/23 11:32:29.878
  Dec 19 11:32:29.913: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-6666" for this suite. @ 12/19/23 11:32:29.951
• [25.710 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:250
  STEP: Creating a kubernetes client @ 12/19/23 11:32:29.972
  Dec 19 11:32:29.972: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename downward-api @ 12/19/23 11:32:29.976
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:32:30.005
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:32:30.012
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:32:30.018
  E1219 11:32:30.684523      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:31.684651      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:32.684864      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:33.685618      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:32:34.064
  Dec 19 11:32:34.072: INFO: Trying to get logs from node hiengux9ahcu-3 pod downwardapi-volume-5e4015dd-5e29-47cf-a444-2fa620ba15df container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:32:34.103
  Dec 19 11:32:34.133: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7809" for this suite. @ 12/19/23 11:32:34.142
• [4.184 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]
test/e2e/apps/cronjob.go:161
  STEP: Creating a kubernetes client @ 12/19/23 11:32:34.167
  Dec 19 11:32:34.167: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename cronjob @ 12/19/23 11:32:34.173
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:32:34.216
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:32:34.224
  STEP: Creating a ReplaceConcurrent cronjob @ 12/19/23 11:32:34.229
  STEP: Ensuring a job is scheduled @ 12/19/23 11:32:34.246
  E1219 11:32:34.686015      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:35.686100      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:36.686365      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:37.687218      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:38.687282      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:39.687970      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:40.688095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:41.688395      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:42.689454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:43.690009      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:44.690060      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:45.690895      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:46.690693      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:47.691418      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:48.692583      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:49.693579      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:50.693788      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:51.694036      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:52.694292      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:53.694897      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:54.695202      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:55.695530      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:56.695686      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:57.695859      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:58.698371      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:32:59.700673      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 12/19/23 11:33:00.254
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 12/19/23 11:33:00.26
  STEP: Ensuring the job is replaced with a new one @ 12/19/23 11:33:00.265
  E1219 11:33:00.701918      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:01.700380      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:02.701352      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:03.701826      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:04.702740      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:05.702915      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:06.703058      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:07.704555      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:08.703984      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:09.704327      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:10.705149      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:11.706505      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:12.707042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:13.707864      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:14.711309      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:15.709369      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:16.709782      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:17.710883      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:18.710814      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:19.710959      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:20.711569      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:21.711504      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:22.712563      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:23.712925      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:24.713232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:25.714393      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:26.714744      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:27.714807      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:28.715763      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:29.717168      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:30.716545      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:31.717248      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:32.717460      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:33.717958      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:34.718382      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:35.719142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:36.718680      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:37.719095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:38.720272      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:39.720550      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:40.720598      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:41.721552      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:42.721830      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:43.722136      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:44.723046      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:45.723430      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:46.724368      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:47.726558      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:48.726276      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:49.727485      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:50.728272      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:51.733361      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:52.730813      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:53.733148      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:54.733094      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:55.734523      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:56.734476      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:57.734986      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:58.736187      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:33:59.741039      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 12/19/23 11:34:00.275
  Dec 19 11:34:00.297: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-1281" for this suite. @ 12/19/23 11:34:00.324
• [86.184 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:550
  STEP: Creating a kubernetes client @ 12/19/23 11:34:00.358
  Dec 19 11:34:00.358: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename container-probe @ 12/19/23 11:34:00.364
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:34:00.419
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:34:00.427
  STEP: Creating pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761 @ 12/19/23 11:34:00.436
  E1219 11:34:00.737248      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:01.737811      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/19/23 11:34:02.478
  Dec 19 11:34:02.484: INFO: Initial restart count of pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 is 0
  Dec 19 11:34:02.491: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:02.739064      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:03.739574      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:04.503: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:04.739913      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:05.739777      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:06.517: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:06.741059      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:07.741827      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:08.527: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:08.742209      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:09.742710      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:10.541: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:10.743127      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:11.743526      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:12.550: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:12.744312      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:13.744489      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:14.561: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:14.746174      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:15.745838      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:16.570: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:16.746671      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:17.747024      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:18.579: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:18.747195      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:19.748022      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:20.587: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:20.748552      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:21.749382      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:22.614: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:22.749622      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:23.753087      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:24.626: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:24.752113      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:25.752808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:26.636: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:26.753197      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:27.753743      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:28.648: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:28.755142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:29.757755      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:30.657: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:30.756467      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:31.757219      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:32.666: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:32.757350      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:33.757747      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:34.695: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:34.764965      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:35.764068      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:36.708: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:36.764820      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:37.764989      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:38.751: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:38.765571      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:39.766027      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:40.761: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:40.766080      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:41.766658      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:42.767490      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:42.785: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:43.767888      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:44.768644      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:44.795: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:45.769651      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:46.769890      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:46.803: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:47.770147      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:48.770552      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:48.812: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:49.770757      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:50.772164      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:50.826: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:51.771657      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:52.777862      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:52.843: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:53.775555      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:54.776042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:54.851: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:55.776565      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:56.776443      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:56.861: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:57.777399      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:34:58.777672      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:34:58.870: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:34:59.777891      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:00.778854      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:35:00.878: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:35:01.779033      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:02.779661      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:35:02.887: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:35:03.779497      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:04.780336      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:35:04.896: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:35:05.781004      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:06.781767      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:35:06.904: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:35:07.781960      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:08.782858      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:35:08.912: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:35:09.782773      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:10.783735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:35:10.923: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:35:11.784387      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:12.784635      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:35:12.933: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:35:13.784732      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:14.785474      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:35:14.941: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:35:15.787298      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:16.788303      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:35:16.951: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  E1219 11:35:17.788474      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:18.789014      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:35:18.961: INFO: Get pod test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 in namespace container-probe-761
  Dec 19 11:35:18.961: INFO: Restart count of pod container-probe-761/test-grpc-2f4f6491-501c-4bd0-8230-285c710b0456 is now 1 (1m16.476526663s elapsed)
  Dec 19 11:35:18.962: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/19/23 11:35:18.981
  STEP: Destroying namespace "container-probe-761" for this suite. @ 12/19/23 11:35:19.032
• [78.693 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 12/19/23 11:35:19.064
  Dec 19 11:35:19.064: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename pods @ 12/19/23 11:35:19.072
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:35:19.121
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:35:19.127
  STEP: creating pod @ 12/19/23 11:35:19.131
  E1219 11:35:19.790206      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:20.791051      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:35:21.202: INFO: Pod pod-hostip-e8458540-edbb-490b-a448-54562d03e077 has hostIP: 192.168.121.172
  Dec 19 11:35:21.203: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3757" for this suite. @ 12/19/23 11:35:21.216
• [2.174 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]
test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 12/19/23 11:35:21.239
  Dec 19 11:35:21.239: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename emptydir-wrapper @ 12/19/23 11:35:21.244
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:35:21.289
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:35:21.295
  STEP: Creating 50 configmaps @ 12/19/23 11:35:21.301
  E1219 11:35:21.791686      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating RC which spawns configmap-volume pods @ 12/19/23 11:35:21.798
  Dec 19 11:35:21.856: INFO: Pod name wrapped-volume-race-3fd93ad0-eb19-41c9-8916-fdde1df6b507: Found 0 pods out of 5
  E1219 11:35:22.794581      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:23.794030      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:24.794756      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:25.796573      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:26.795486      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:35:26.894: INFO: Pod name wrapped-volume-race-3fd93ad0-eb19-41c9-8916-fdde1df6b507: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 12/19/23 11:35:26.894
  STEP: Creating RC which spawns configmap-volume pods @ 12/19/23 11:35:26.956
  Dec 19 11:35:26.994: INFO: Pod name wrapped-volume-race-1575e746-6d96-49ec-bb01-47c730080abd: Found 0 pods out of 5
  E1219 11:35:27.795933      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:28.796407      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:29.797059      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:30.797610      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:31.797757      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:35:32.046: INFO: Pod name wrapped-volume-race-1575e746-6d96-49ec-bb01-47c730080abd: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 12/19/23 11:35:32.046
  STEP: Creating RC which spawns configmap-volume pods @ 12/19/23 11:35:32.156
  Dec 19 11:35:32.246: INFO: Pod name wrapped-volume-race-8e0bcbcf-ed13-4809-bed4-734425958fe0: Found 0 pods out of 5
  E1219 11:35:32.798102      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:33.798264      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:34.798514      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:35.799095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:36.799500      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:35:37.271: INFO: Pod name wrapped-volume-race-8e0bcbcf-ed13-4809-bed4-734425958fe0: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 12/19/23 11:35:37.271
  Dec 19 11:35:37.327: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController wrapped-volume-race-8e0bcbcf-ed13-4809-bed4-734425958fe0 in namespace emptydir-wrapper-2869, will wait for the garbage collector to delete the pods @ 12/19/23 11:35:37.34
  Dec 19 11:35:37.420: INFO: Deleting ReplicationController wrapped-volume-race-8e0bcbcf-ed13-4809-bed4-734425958fe0 took: 17.135849ms
  Dec 19 11:35:37.622: INFO: Terminating ReplicationController wrapped-volume-race-8e0bcbcf-ed13-4809-bed4-734425958fe0 pods took: 201.772414ms
  E1219 11:35:37.799985      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:38.800716      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-1575e746-6d96-49ec-bb01-47c730080abd in namespace emptydir-wrapper-2869, will wait for the garbage collector to delete the pods @ 12/19/23 11:35:38.923
  Dec 19 11:35:38.996: INFO: Deleting ReplicationController wrapped-volume-race-1575e746-6d96-49ec-bb01-47c730080abd took: 14.867991ms
  Dec 19 11:35:39.297: INFO: Terminating ReplicationController wrapped-volume-race-1575e746-6d96-49ec-bb01-47c730080abd pods took: 301.27136ms
  E1219 11:35:39.801688      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:40.802202      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-3fd93ad0-eb19-41c9-8916-fdde1df6b507 in namespace emptydir-wrapper-2869, will wait for the garbage collector to delete the pods @ 12/19/23 11:35:40.998
  Dec 19 11:35:41.075: INFO: Deleting ReplicationController wrapped-volume-race-3fd93ad0-eb19-41c9-8916-fdde1df6b507 took: 16.92281ms
  Dec 19 11:35:41.277: INFO: Terminating ReplicationController wrapped-volume-race-3fd93ad0-eb19-41c9-8916-fdde1df6b507 pods took: 201.361032ms
  E1219 11:35:41.802517      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:42.803442      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 12/19/23 11:35:43.278
  E1219 11:35:43.804916      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "emptydir-wrapper-2869" for this suite. @ 12/19/23 11:35:43.957
• [22.732 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]
test/e2e/storage/csistoragecapacity.go:49
  STEP: Creating a kubernetes client @ 12/19/23 11:35:43.977
  Dec 19 11:35:43.977: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename csistoragecapacity @ 12/19/23 11:35:43.983
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:35:44.015
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:35:44.022
  STEP: getting /apis @ 12/19/23 11:35:44.028
  STEP: getting /apis/storage.k8s.io @ 12/19/23 11:35:44.038
  STEP: getting /apis/storage.k8s.io/v1 @ 12/19/23 11:35:44.04
  STEP: creating @ 12/19/23 11:35:44.043
  STEP: watching @ 12/19/23 11:35:44.072
  Dec 19 11:35:44.073: INFO: starting watch
  STEP: getting @ 12/19/23 11:35:44.086
  STEP: listing in namespace @ 12/19/23 11:35:44.094
  STEP: listing across namespaces @ 12/19/23 11:35:44.099
  STEP: patching @ 12/19/23 11:35:44.105
  STEP: updating @ 12/19/23 11:35:44.116
  Dec 19 11:35:44.126: INFO: waiting for watch events with expected annotations in namespace
  Dec 19 11:35:44.126: INFO: waiting for watch events with expected annotations across namespace
  STEP: deleting @ 12/19/23 11:35:44.127
  STEP: deleting a collection @ 12/19/23 11:35:44.151
  Dec 19 11:35:44.183: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-876" for this suite. @ 12/19/23 11:35:44.193
• [0.232 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:129
  STEP: Creating a kubernetes client @ 12/19/23 11:35:44.213
  Dec 19 11:35:44.213: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename runtimeclass @ 12/19/23 11:35:44.216
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:35:44.243
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:35:44.247
  E1219 11:35:44.805514      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:45.806114      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:35:46.302: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-3346" for this suite. @ 12/19/23 11:35:46.331
• [2.133 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance]
test/e2e/auth/service_accounts.go:275
  STEP: Creating a kubernetes client @ 12/19/23 11:35:46.357
  Dec 19 11:35:46.357: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename svcaccounts @ 12/19/23 11:35:46.361
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:35:46.398
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:35:46.404
  STEP: Creating a pod to test service account token:  @ 12/19/23 11:35:46.41
  E1219 11:35:46.805656      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:47.806089      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:48.808303      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:49.816650      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:35:50.472
  Dec 19 11:35:50.480: INFO: Trying to get logs from node hiengux9ahcu-3 pod test-pod-be3aa507-6972-46ba-a7ca-7783a35c7e90 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 11:35:50.519
  Dec 19 11:35:50.562: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2492" for this suite. @ 12/19/23 11:35:50.578
• [4.252 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:214
  STEP: Creating a kubernetes client @ 12/19/23 11:35:50.626
  Dec 19 11:35:50.626: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename container-probe @ 12/19/23 11:35:50.63
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:35:50.668
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:35:50.674
  STEP: Creating pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441 @ 12/19/23 11:35:50.682
  E1219 11:35:50.812070      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:51.812589      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/19/23 11:35:52.721
  Dec 19 11:35:52.729: INFO: Initial restart count of pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 is 0
  Dec 19 11:35:52.735: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:35:52.813196      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:53.813589      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:35:54.803: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:35:54.814974      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:55.815257      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:35:56.814: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:35:56.816177      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:57.815825      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:35:58.817385      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:35:58.826: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:35:59.816782      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:00.817674      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:00.840: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:01.817902      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:02.818198      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:02.851: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:03.818608      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:04.819107      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:04.864: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:05.819380      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:06.819800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:06.875: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:07.820673      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:08.821197      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:08.890: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:09.821353      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:10.822159      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:10.899: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:11.822295      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:12.822766      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:12.911: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:13.823310      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:14.823978      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:14.922: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:15.823984      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:16.824065      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:16.930: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:17.824474      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:18.825622      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:18.943: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:19.825765      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:20.826367      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:20.958: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:21.826452      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:22.826781      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:22.973: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:23.826869      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:24.827070      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:24.982: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:25.827308      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:26.827719      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:26.996: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:27.827942      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:28.828343      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:29.007: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:29.829043      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:30.829047      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:31.017: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:31.830049      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:32.830827      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:33.026: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:33.830964      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:34.831066      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:35.038: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:35.834200      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:36.832360      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:37.048: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:37.832362      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:38.833895      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:39.058: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:39.834034      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:40.834132      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:41.067: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:41.834840      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:42.836212      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:43.077: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:43.836947      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:44.836994      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:45.092: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:45.837010      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:46.837332      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:47.105: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:47.838323      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:48.838408      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:49.115: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:49.838621      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:50.839101      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:51.127: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:51.839798      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:52.840315      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:53.138: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:53.840459      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:54.841674      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:55.148: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:55.841974      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:56.842610      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:57.159: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:57.842720      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:36:58.843613      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:36:59.169: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:36:59.844714      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:00.845310      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:01.179: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:01.845475      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:02.845690      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:03.190: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:03.845866      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:04.846817      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:05.198: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:05.847078      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:06.847208      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:07.206: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:07.848204      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:08.848922      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:09.213: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:09.849071      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:10.849279      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:11.224: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:11.849232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:12.849514      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:13.234: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:13.849750      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:14.850022      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:15.251: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:15.850857      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:16.851624      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:17.259: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:17.851958      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:18.852062      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:19.268: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:19.852262      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:20.853983      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:21.278: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:21.853298      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:22.853908      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:23.289: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:23.855624      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:24.855346      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:25.300: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:25.855838      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:26.859680      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:27.322: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:27.857809      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:28.858049      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:29.330: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:29.860043      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:30.859397      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:31.341: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:31.859955      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:32.860229      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:33.348: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:33.860547      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:34.872264      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:35.360: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:35.865113      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:36.865800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:37.372: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:37.866004      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:38.866137      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:39.420: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:39.867744      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:40.868173      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:41.428: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:41.868469      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:42.869344      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:43.436: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:43.870315      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:44.871460      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:45.446: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:45.871042      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:46.872327      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:47.453: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:47.873538      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:48.873716      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:49.469: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:49.873903      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:50.875293      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:51.478: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:51.875691      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:52.876378      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:53.490: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:53.876583      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:54.877667      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:55.498: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:55.877762      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:56.877883      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:57.507: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:57.878747      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:37:58.879574      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:37:59.515: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:37:59.880370      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:00.881198      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:01.523: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:01.882136      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:02.882294      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:03.533: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:03.882587      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:04.883647      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:05.574: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:05.883782      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:06.884244      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:07.585: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:07.884846      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:08.885498      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:09.592: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:09.886329      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:10.887239      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:11.602: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:11.887854      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:12.888108      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:13.611: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:13.888357      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:14.888656      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:15.619: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:15.889169      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:16.889332      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:17.627: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:17.889531      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:18.889993      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:19.635: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:19.891256      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:20.892043      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:21.645: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:21.892705      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:22.893668      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:23.655: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:23.894623      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:24.895323      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:25.666: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:25.896965      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:26.897804      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:27.676: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:27.897958      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:28.898138      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:29.686: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:29.899394      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:30.900061      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:31.699: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:31.900749      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:32.901570      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:33.708: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:33.901886      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:34.902677      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:35.722: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:35.903767      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:36.902912      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:37.729: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:37.903840      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:38.904538      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:39.738: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:39.904644      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:40.905826      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:41.751: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:41.906545      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:42.907246      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:43.762: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:43.908179      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:44.908896      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:45.770: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:45.910335      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:46.911027      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:47.786: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:47.911558      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:48.911765      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:49.795: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:49.912342      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:50.912684      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:51.808: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:51.913149      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:52.914014      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:53.816: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:53.914375      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:54.914586      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:55.826: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:55.915275      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:56.915979      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:57.836: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:57.916725      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:38:58.917058      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:38:59.848: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:38:59.918161      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:00.919066      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:01.858: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:01.919878      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:02.920029      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:03.867: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:03.921831      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:04.921902      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:05.876: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:05.922573      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:06.923016      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:07.889: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:07.923537      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:08.924270      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:09.898: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:09.925329      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:10.926097      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:11.909: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:11.926438      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:12.926794      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:13.915: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:13.926881      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:14.927284      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:15.927: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:15.928407      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:16.928412      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:17.928976      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:17.936: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:18.930374      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:19.930252      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:19.948: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:20.931573      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:21.931147      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:21.956: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:22.931895      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:23.931975      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:23.965: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:24.931993      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:25.932378      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:25.974: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:26.932575      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:27.933238      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:27.986: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:28.934207      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:29.935156      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:29.994: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:30.936368      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:31.937049      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:32.010: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:32.937096      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:33.938037      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:34.021: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:34.938294      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:35.939003      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:36.041: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:36.938907      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:37.939657      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:38.058: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:38.939811      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:39.940371      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:40.070: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:40.941215      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:41.941203      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:42.083: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:42.941850      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:43.941984      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:44.094: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:44.941960      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:45.942427      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:46.102: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:46.942730      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:47.943626      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:48.110: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:48.944038      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:49.945151      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:50.121: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:50.945616      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:51.946186      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:52.129: INFO: Get pod test-webserver-bf94d959-649f-41e9-b003-d64be37cdee6 in namespace container-probe-7441
  E1219 11:39:52.946800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:53.947138      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:39:54.130: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/19/23 11:39:54.146
  STEP: Destroying namespace "container-probe-7441" for this suite. @ 12/19/23 11:39:54.179
• [243.591 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:208
  STEP: Creating a kubernetes client @ 12/19/23 11:39:54.234
  Dec 19 11:39:54.234: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:39:54.24
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:39:54.3
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:39:54.307
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:39:54.312
  E1219 11:39:54.947088      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:55.948197      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:56.948259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:57.948940      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:39:58.363
  Dec 19 11:39:58.370: INFO: Trying to get logs from node hiengux9ahcu-3 pod downwardapi-volume-c4eb5f23-afc0-4ee9-96b2-3b8cd872049b container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:39:58.403
  Dec 19 11:39:58.431: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9424" for this suite. @ 12/19/23 11:39:58.447
• [4.228 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:350
  STEP: Creating a kubernetes client @ 12/19/23 11:39:58.463
  Dec 19 11:39:58.463: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename field-validation @ 12/19/23 11:39:58.467
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:39:58.507
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:39:58.513
  Dec 19 11:39:58.518: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  W1219 11:39:58.522831      14 field_validation.go:423] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc001637f70 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  E1219 11:39:58.950109      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:39:59.951059      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:00.951134      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  W1219 11:40:01.282622      14 warnings.go:70] unknown field "alpha"
  W1219 11:40:01.283494      14 warnings.go:70] unknown field "beta"
  W1219 11:40:01.284380      14 warnings.go:70] unknown field "delta"
  W1219 11:40:01.284897      14 warnings.go:70] unknown field "epsilon"
  W1219 11:40:01.285394      14 warnings.go:70] unknown field "gamma"
  Dec 19 11:40:01.851: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-57" for this suite. @ 12/19/23 11:40:01.915
• [3.471 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster  [Conformance]
test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 12/19/23 11:40:01.941
  Dec 19 11:40:01.941: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename dns @ 12/19/23 11:40:01.947
  E1219 11:40:01.952041      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:40:02.003
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:40:02.009
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 12/19/23 11:40:02.017
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 12/19/23 11:40:02.017
  STEP: creating a pod to probe DNS @ 12/19/23 11:40:02.018
  STEP: submitting the pod to kubernetes @ 12/19/23 11:40:02.018
  E1219 11:40:02.953236      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:03.953925      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/19/23 11:40:04.062
  STEP: looking for the results for each expected name from probers @ 12/19/23 11:40:04.07
  Dec 19 11:40:04.111: INFO: DNS probes using dns-4033/dns-test-b29bdf64-ec34-4e46-a4ea-50b62e388bd1 succeeded

  Dec 19 11:40:04.112: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/19/23 11:40:04.122
  STEP: Destroying namespace "dns-4033" for this suite. @ 12/19/23 11:40:04.148
• [2.222 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:85
  STEP: Creating a kubernetes client @ 12/19/23 11:40:04.17
  Dec 19 11:40:04.171: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:40:04.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:40:04.205
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:40:04.209
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:40:04.216
  E1219 11:40:04.953326      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:05.954251      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:06.954538      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:07.955307      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:40:08.273
  Dec 19 11:40:08.282: INFO: Trying to get logs from node hiengux9ahcu-3 pod downwardapi-volume-a24aee78-d43d-4fd9-ba5c-eab17410c0db container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:40:08.296
  Dec 19 11:40:08.328: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2866" for this suite. @ 12/19/23 11:40:08.338
• [4.185 seconds]
------------------------------
SS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:151
  STEP: Creating a kubernetes client @ 12/19/23 11:40:08.356
  Dec 19 11:40:08.356: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename container-probe @ 12/19/23 11:40:08.363
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:40:08.388
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:40:08.393
  STEP: Creating pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861 @ 12/19/23 11:40:08.401
  E1219 11:40:08.955590      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:09.956565      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/19/23 11:40:10.436
  Dec 19 11:40:10.444: INFO: Initial restart count of pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 is 0
  Dec 19 11:40:10.453: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:10.957215      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:11.958080      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:12.461: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:12.958902      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:13.959723      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:14.471: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:14.960146      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:15.960245      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:16.479: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:16.960456      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:17.961373      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:18.487: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:18.961664      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:19.962205      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:20.496: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:20.963013      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:21.963323      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:22.503: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:22.963544      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:23.963818      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:24.515: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:24.963921      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:25.964388      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:26.524: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:26.965116      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:27.965458      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:28.532: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:28.965988      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:29.966377      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:30.539: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:30.966882      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:31.967052      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:32.549: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:32.967251      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:33.967505      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:34.557: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:34.968354      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:35.968676      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:36.567: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:36.968892      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:37.969609      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:38.578: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:38.970015      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:39.970815      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:40.586: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:40.970987      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:41.971526      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:42.593: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:42.972163      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:43.972228      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:44.605: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:44.973504      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:45.974642      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:46.612: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:46.974667      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:47.975066      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:48.622: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:48.975759      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:49.977049      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:50.630: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:50.977513      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:51.977681      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:52.637: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:52.977876      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:53.978526      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:54.647: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:54.979014      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:55.979518      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:56.657: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:56.980180      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:57.980421      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:40:58.667: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:40:58.980958      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:40:59.980899      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:00.675: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:00.981908      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:01.982640      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:02.684: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:02.983447      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:03.984297      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:04.694: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:04.984695      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:05.985170      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:06.703: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:06.985138      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:07.985565      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:08.710: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:08.985619      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:09.986311      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:10.720: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:10.986690      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:11.986797      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:12.731: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:12.987830      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:13.988213      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:14.741: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:14.988221      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:15.989314      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:16.749: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:16.990213      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:17.990956      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:18.765: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:18.992421      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:19.992421      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:20.773: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:20.992828      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:21.993088      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:22.781: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:22.993507      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:23.994254      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:24.792: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:24.995332      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:25.995191      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:26.801: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:26.996248      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:27.996126      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:28.808: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:28.996765      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:29.997628      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:30.816: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:30.998549      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:31.998797      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:32.823: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:32.999520      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:34.000167      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:34.831: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:35.000618      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:36.001617      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:36.838: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:37.002442      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:38.002604      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:38.847: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:39.003428      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:40.004077      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:40.856: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:41.004403      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:42.005731      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:42.865: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:43.006275      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:44.006479      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:44.875: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:45.007614      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:46.008720      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:46.886: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:47.009555      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:48.010104      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:48.896: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:49.010890      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:50.011877      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:50.904: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:51.012195      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:52.012643      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:52.914: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:53.013017      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:54.013922      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:54.922: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:55.014678      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:56.015478      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:56.930: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:57.016351      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:41:58.017022      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:41:58.942: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:41:59.018013      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:00.018297      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:00.954: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:01.019432      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:02.020144      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:02.962: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:03.020625      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:04.021226      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:04.972: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:05.021974      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:06.022184      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:06.978: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:07.022339      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:08.022433      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:08.986: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:09.022762      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:10.023856      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:10.992: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:11.024018      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:12.024121      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:12.998: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:13.024791      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:14.025578      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:15.009: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:15.025882      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:16.026040      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:17.018: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:17.026259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:18.027102      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:19.025: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:19.028034      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:20.028409      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:21.029270      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:21.034: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:22.029593      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:23.029809      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:23.045: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:24.030075      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:25.030790      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:25.054: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:26.030927      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:27.031296      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:27.062: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:28.031441      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:29.032298      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:29.072: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:30.032729      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:31.033225      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:31.080: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:32.033498      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:33.034372      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:33.091: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:34.034884      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:35.035113      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:35.103: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:36.035312      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:37.035672      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:37.117: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:38.036011      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:39.036274      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:39.138: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:40.037120      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:41.037386      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:41.149: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:42.038059      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:43.038158      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:43.156: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:44.038829      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:45.038773      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:45.165: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:46.039910      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:47.041322      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:47.176: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:48.041372      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:49.041940      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:49.186: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:50.042083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:51.042379      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:51.194: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:52.042374      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:53.043625      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:53.204: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:54.044638      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:55.044782      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:55.215: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:56.045471      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:57.045823      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:57.226: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:42:58.045937      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:42:59.045841      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:42:59.235: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:00.046537      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:01.047109      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:01.247: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:02.047310      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:03.047888      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:03.255: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:04.048397      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:05.048936      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:05.267: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:06.049615      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:07.049685      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:07.275: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:08.050801      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:09.050832      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:09.282: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:10.051567      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:11.051713      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:11.290: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:12.052317      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:13.052781      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:13.298: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:14.053063      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:15.053159      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:15.311: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:16.053854      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:17.054174      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:17.318: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:18.054440      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:19.054931      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:19.329: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:20.055551      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:21.056077      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:21.335: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:22.056247      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:23.056562      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:23.342: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:24.056743      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:25.056781      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:25.352: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:26.057530      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:27.059936      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:27.360: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:28.058592      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:29.059350      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:29.368: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:30.059941      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:31.059822      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:31.375: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:32.060086      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:33.060816      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:33.381: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:34.061185      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:35.061552      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:35.406: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:36.062391      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:37.062860      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:37.415: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:38.063766      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:39.064675      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:39.428: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:40.065550      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:41.065764      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:41.435: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:42.066754      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:43.067016      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:43.443: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:44.067119      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:45.067491      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:45.452: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:46.067822      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:47.068512      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:47.460: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:48.068650      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:49.068807      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:49.472: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:50.069367      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:51.069752      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:51.483: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:52.069964      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:53.070389      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:53.498: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:54.070767      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:55.071536      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:55.508: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:56.071887      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:57.071957      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:57.519: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:43:58.072192      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:43:59.072329      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:43:59.529: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:44:00.072573      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:01.073173      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:01.544: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:44:02.073883      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:03.074586      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:03.553: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:44:04.074650      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:05.074974      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:05.562: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:44:06.075951      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:07.076252      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:07.572: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:44:08.076907      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:09.076835      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:09.582: INFO: Get pod busybox-cd4db114-54a7-47ad-ad47-2b2f440c1835 in namespace container-probe-3861
  E1219 11:44:10.078069      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:11.078232      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:44:11.583: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/19/23 11:44:11.596
  STEP: Destroying namespace "container-probe-3861" for this suite. @ 12/19/23 11:44:11.641
• [243.311 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:262
  STEP: Creating a kubernetes client @ 12/19/23 11:44:11.669
  Dec 19 11:44:11.669: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:44:11.676
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:44:11.705
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:44:11.71
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:44:11.716
  E1219 11:44:12.078782      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:13.079481      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:14.079310      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:15.079610      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:44:15.755
  Dec 19 11:44:15.762: INFO: Trying to get logs from node hiengux9ahcu-3 pod downwardapi-volume-2fca4b62-230e-44a1-adc9-791ab8e6071e container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:44:15.801
  Dec 19 11:44:15.834: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6956" for this suite. @ 12/19/23 11:44:15.847
• [4.192 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 12/19/23 11:44:15.866
  Dec 19 11:44:15.866: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:44:15.869
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:44:15.901
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:44:15.905
  STEP: Creating configMap with name configmap-projected-all-test-volume-f5352dc7-fc99-4a97-a88a-e82713d1c098 @ 12/19/23 11:44:15.911
  STEP: Creating secret with name secret-projected-all-test-volume-f23fcca4-9e29-47ee-aac8-eff826e1f4f6 @ 12/19/23 11:44:15.924
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 12/19/23 11:44:15.936
  E1219 11:44:16.080087      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:17.080481      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:18.081086      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:19.081609      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:44:19.994
  Dec 19 11:44:20.006: INFO: Trying to get logs from node hiengux9ahcu-3 pod projected-volume-26f22dff-0140-4c3c-83c0-0baa96ac0da4 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 11:44:20.031
  Dec 19 11:44:20.078: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1219 11:44:20.081872      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "projected-2774" for this suite. @ 12/19/23 11:44:20.091
• [4.240 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:124
  STEP: Creating a kubernetes client @ 12/19/23 11:44:20.106
  Dec 19 11:44:20.106: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename configmap @ 12/19/23 11:44:20.11
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:44:20.146
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:44:20.152
  STEP: Creating configMap with name configmap-test-upd-3508b320-323e-46ef-be53-1ce66815a8eb @ 12/19/23 11:44:20.171
  STEP: Creating the pod @ 12/19/23 11:44:20.184
  E1219 11:44:21.082357      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:22.083312      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap configmap-test-upd-3508b320-323e-46ef-be53-1ce66815a8eb @ 12/19/23 11:44:22.25
  STEP: waiting to observe update in volume @ 12/19/23 11:44:22.264
  E1219 11:44:23.084355      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:24.085009      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:25.085899      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:26.086371      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:27.086722      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:28.087381      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:29.087649      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:30.088354      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:31.088674      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:32.089402      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:33.090500      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:34.090361      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:35.090877      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:36.091336      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:37.092012      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:38.093123      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:39.093280      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:40.094028      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:41.094859      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:42.095603      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:43.098206      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:44.097332      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:45.098199      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:46.098367      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:47.098745      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:48.099025      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:49.099365      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:50.101395      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:51.101165      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:52.101803      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:53.101817      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:54.102955      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:55.103132      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:56.103881      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:57.104063      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:58.104200      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:44:59.104755      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:00.105209      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:01.106450      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:02.105947      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:03.106909      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:04.107080      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:05.107491      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:06.108744      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:07.109297      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:08.109531      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:09.111083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:10.110739      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:11.111707      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:12.112023      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:13.112678      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:14.112904      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:15.113308      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:16.114440      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:17.114591      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:18.114916      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:19.114806      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:20.115977      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:21.116842      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:22.116921      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:23.117517      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:24.117541      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:25.118199      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:26.118296      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:27.119407      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:28.119962      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:29.120605      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:30.120852      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:31.121483      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:32.121646      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:33.121894      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:34.122203      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:35.122617      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:36.122802      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:45:37.036: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2737" for this suite. @ 12/19/23 11:45:37.049
• [76.965 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance]
test/e2e/network/service.go:3142
  STEP: Creating a kubernetes client @ 12/19/23 11:45:37.075
  Dec 19 11:45:37.075: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename services @ 12/19/23 11:45:37.079
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:45:37.113
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:45:37.122
  E1219 11:45:37.122847      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating an Endpoint @ 12/19/23 11:45:37.144
  STEP: waiting for available Endpoint @ 12/19/23 11:45:37.153
  STEP: listing all Endpoints @ 12/19/23 11:45:37.156
  STEP: updating the Endpoint @ 12/19/23 11:45:37.164
  STEP: fetching the Endpoint @ 12/19/23 11:45:37.176
  STEP: patching the Endpoint @ 12/19/23 11:45:37.181
  STEP: fetching the Endpoint @ 12/19/23 11:45:37.196
  STEP: deleting the Endpoint by Collection @ 12/19/23 11:45:37.202
  STEP: waiting for Endpoint deletion @ 12/19/23 11:45:37.217
  STEP: fetching the Endpoint @ 12/19/23 11:45:37.219
  Dec 19 11:45:37.228: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6201" for this suite. @ 12/19/23 11:45:37.24
• [0.186 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 12/19/23 11:45:37.266
  Dec 19 11:45:37.266: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename containers @ 12/19/23 11:45:37.27
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:45:37.306
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:45:37.316
  STEP: Creating a pod to test override arguments @ 12/19/23 11:45:37.324
  E1219 11:45:38.124332      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:39.124651      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:40.125357      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:41.126373      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:45:41.369
  Dec 19 11:45:41.378: INFO: Trying to get logs from node hiengux9ahcu-3 pod client-containers-68be4319-40f3-4bd6-a659-a62d500569c0 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 11:45:41.396
  Dec 19 11:45:41.426: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-4215" for this suite. @ 12/19/23 11:45:41.437
• [4.183 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should provide secure master service  [Conformance]
test/e2e/network/service.go:775
  STEP: Creating a kubernetes client @ 12/19/23 11:45:41.451
  Dec 19 11:45:41.452: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename services @ 12/19/23 11:45:41.457
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:45:41.502
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:45:41.508
  Dec 19 11:45:41.529: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2506" for this suite. @ 12/19/23 11:45:41.561
• [0.123 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:272
  STEP: Creating a kubernetes client @ 12/19/23 11:45:41.579
  Dec 19 11:45:41.579: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename namespaces @ 12/19/23 11:45:41.581
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:45:41.611
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:45:41.615
  STEP: creating a Namespace @ 12/19/23 11:45:41.619
  STEP: patching the Namespace @ 12/19/23 11:45:41.645
  STEP: get the Namespace and ensuring it has the label @ 12/19/23 11:45:41.656
  Dec 19 11:45:41.663: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-8803" for this suite. @ 12/19/23 11:45:41.672
  STEP: Destroying namespace "nspatchtest-4201b583-99a1-4503-bbb2-c3b3aacc0110-3132" for this suite. @ 12/19/23 11:45:41.683
• [0.117 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]
test/e2e/apimachinery/resource_quota.go:328
  STEP: Creating a kubernetes client @ 12/19/23 11:45:41.698
  Dec 19 11:45:41.698: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 11:45:41.7
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:45:41.733
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:45:41.738
  E1219 11:45:42.128423      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:43.128829      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:44.129683      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:45.128963      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:46.129784      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:47.132018      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:48.131536      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:49.131997      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:50.131944      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:51.132836      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:52.133282      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:53.133591      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:54.133970      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:55.134669      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:56.135398      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:57.135738      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:45:58.136114      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 12/19/23 11:45:58.777
  E1219 11:45:59.136226      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:00.136468      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:01.136730      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:02.137890      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:03.138069      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/19/23 11:46:03.784
  STEP: Ensuring resource quota status is calculated @ 12/19/23 11:46:03.795
  E1219 11:46:04.139174      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:05.139433      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 12/19/23 11:46:05.805
  STEP: Ensuring resource quota status captures configMap creation @ 12/19/23 11:46:05.828
  E1219 11:46:06.140195      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:07.140347      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 12/19/23 11:46:07.836
  STEP: Ensuring resource quota status released usage @ 12/19/23 11:46:07.849
  E1219 11:46:08.141394      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:09.142201      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:46:09.858: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6715" for this suite. @ 12/19/23 11:46:09.869
• [28.186 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance]
test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 12/19/23 11:46:09.888
  Dec 19 11:46:09.889: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 12/19/23 11:46:09.892
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:46:09.921
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:46:09.926
  STEP: creating a target pod @ 12/19/23 11:46:09.931
  E1219 11:46:10.142903      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:11.143647      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 12/19/23 11:46:11.982
  E1219 11:46:12.144499      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:13.144809      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 12/19/23 11:46:14.03
  Dec 19 11:46:14.030: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-4686 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec 19 11:46:14.030: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  Dec 19 11:46:14.032: INFO: ExecWithOptions: Clientset creation
  Dec 19 11:46:14.033: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/ephemeral-containers-test-4686/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  E1219 11:46:14.146004      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:46:14.171: INFO: Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 12/19/23 11:46:14.189
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 12/19/23 11:46:14.202
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 12/19/23 11:46:14.234
  Dec 19 11:46:14.246: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-4686" for this suite. @ 12/19/23 11:46:14.263
• [4.389 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]
test/e2e/apimachinery/garbage_collector.go:817
  STEP: Creating a kubernetes client @ 12/19/23 11:46:14.279
  Dec 19 11:46:14.279: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename gc @ 12/19/23 11:46:14.281
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:46:14.335
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:46:14.344
  Dec 19 11:46:14.426: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"1d1eb241-9b4a-47c2-8575-2d997ab346af", Controller:(*bool)(0xc00711cdde), BlockOwnerDeletion:(*bool)(0xc00711cddf)}}
  Dec 19 11:46:14.468: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"63d6e452-da23-438e-b62e-b514b708f7eb", Controller:(*bool)(0xc00711d006), BlockOwnerDeletion:(*bool)(0xc00711d007)}}
  Dec 19 11:46:14.482: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"080dbe47-0804-44d7-acc0-8398e6378a2e", Controller:(*bool)(0xc004459ee6), BlockOwnerDeletion:(*bool)(0xc004459ee7)}}
  E1219 11:46:15.146076      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:16.145884      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:17.146172      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:18.146351      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:19.146619      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:46:19.519: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-114" for this suite. @ 12/19/23 11:46:19.533
• [5.273 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:109
  STEP: Creating a kubernetes client @ 12/19/23 11:46:19.556
  Dec 19 11:46:19.557: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:46:19.56
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:46:19.597
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:46:19.604
  STEP: Creating configMap with name projected-configmap-test-volume-map-9bea8f70-f5f7-48db-8545-4f45b16edf5d @ 12/19/23 11:46:19.614
  STEP: Creating a pod to test consume configMaps @ 12/19/23 11:46:19.63
  E1219 11:46:20.146672      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:21.146817      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:22.147673      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:23.148026      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:46:23.683
  Dec 19 11:46:23.693: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-projected-configmaps-4ade7cbd-7595-4f1a-8760-7d519455f612 container agnhost-container: <nil>
  STEP: delete the pod @ 12/19/23 11:46:23.712
  Dec 19 11:46:23.745: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2302" for this suite. @ 12/19/23 11:46:23.756
• [4.214 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
test/e2e/common/node/sysctl.go:77
  STEP: Creating a kubernetes client @ 12/19/23 11:46:23.775
  Dec 19 11:46:23.776: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename sysctl @ 12/19/23 11:46:23.779
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:46:23.809
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:46:23.814
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 12/19/23 11:46:23.819
  STEP: Watching for error events or started pod @ 12/19/23 11:46:23.843
  E1219 11:46:24.148203      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:25.149238      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 12/19/23 11:46:25.855
  E1219 11:46:26.150700      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:27.150538      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 12/19/23 11:46:27.882
  STEP: Getting logs from the pod @ 12/19/23 11:46:27.882
  STEP: Checking that the sysctl is actually updated @ 12/19/23 11:46:27.896
  Dec 19 11:46:27.897: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-522" for this suite. @ 12/19/23 11:46:27.911
• [4.151 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:127
  STEP: Creating a kubernetes client @ 12/19/23 11:46:27.933
  Dec 19 11:46:27.933: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename emptydir @ 12/19/23 11:46:27.939
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:46:27.969
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:46:27.974
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 12/19/23 11:46:27.981
  E1219 11:46:28.150920      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:29.151121      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:30.152212      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:31.152222      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:46:32.03
  Dec 19 11:46:32.038: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-46786db2-f658-4532-b8d6-e974ed123953 container test-container: <nil>
  STEP: delete the pod @ 12/19/23 11:46:32.05
  Dec 19 11:46:32.080: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-348" for this suite. @ 12/19/23 11:46:32.088
• [4.169 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:240
  STEP: Creating a kubernetes client @ 12/19/23 11:46:32.105
  Dec 19 11:46:32.106: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename configmap @ 12/19/23 11:46:32.108
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:46:32.142
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:46:32.148
  E1219 11:46:32.153640      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating configMap with name cm-test-opt-del-d71c8293-5a36-4a02-89f9-fb46d3d49abd @ 12/19/23 11:46:32.163
  STEP: Creating configMap with name cm-test-opt-upd-68f873e0-7f3f-4088-b5fd-21aefefbaf0a @ 12/19/23 11:46:32.172
  STEP: Creating the pod @ 12/19/23 11:46:32.18
  E1219 11:46:33.154006      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:34.154915      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-d71c8293-5a36-4a02-89f9-fb46d3d49abd @ 12/19/23 11:46:34.282
  STEP: Updating configmap cm-test-opt-upd-68f873e0-7f3f-4088-b5fd-21aefefbaf0a @ 12/19/23 11:46:34.295
  STEP: Creating configMap with name cm-test-opt-create-7353498e-2407-47fc-8837-1433037668a6 @ 12/19/23 11:46:34.314
  STEP: waiting to observe update in volume @ 12/19/23 11:46:34.325
  E1219 11:46:35.155481      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:36.155379      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:37.155559      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:38.156120      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:46:38.405: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1489" for this suite. @ 12/19/23 11:46:38.419
• [6.335 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
test/e2e/apimachinery/garbage_collector.go:538
  STEP: Creating a kubernetes client @ 12/19/23 11:46:38.451
  Dec 19 11:46:38.452: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename gc @ 12/19/23 11:46:38.455
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:46:38.491
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:46:38.497
  STEP: create the deployment @ 12/19/23 11:46:38.502
  W1219 11:46:38.517078      14 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 12/19/23 11:46:38.517
  STEP: delete the deployment @ 12/19/23 11:46:39.053
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 12/19/23 11:46:39.068
  E1219 11:46:39.156360      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 12/19/23 11:46:39.624
  Dec 19 11:46:39.876: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec 19 11:46:39.876: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3528" for this suite. @ 12/19/23 11:46:39.89
• [1.486 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 12/19/23 11:46:39.94
  Dec 19 11:46:39.940: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename secrets @ 12/19/23 11:46:39.944
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:46:39.985
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:46:39.989
  STEP: Creating secret with name secret-test-map-73341b43-5423-482f-8fdc-afd87c2a5a06 @ 12/19/23 11:46:40.003
  STEP: Creating a pod to test consume secrets @ 12/19/23 11:46:40.018
  E1219 11:46:40.156946      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:41.156955      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:42.157880      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:43.157944      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:46:44.065
  Dec 19 11:46:44.072: INFO: Trying to get logs from node hiengux9ahcu-1 pod pod-secrets-9d6ef669-0709-4d38-9819-bbae62ff1961 container secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 11:46:44.105
  Dec 19 11:46:44.133: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8047" for this suite. @ 12/19/23 11:46:44.143
  E1219 11:46:44.158300      14 retrywatcher.go:129] "Watch failed" err="context canceled"
• [4.223 seconds]
------------------------------
S
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]
test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 12/19/23 11:46:44.164
  Dec 19 11:46:44.164: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename cronjob @ 12/19/23 11:46:44.166
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:46:44.204
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:46:44.209
  STEP: Creating a cronjob @ 12/19/23 11:46:44.214
  STEP: Ensuring more than one job is running at a time @ 12/19/23 11:46:44.23
  E1219 11:46:45.158723      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:46.159727      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:47.159917      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:48.160551      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:49.161329      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:50.161659      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:51.162326      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:52.163088      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:53.163888      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:54.164894      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:55.165560      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:56.166702      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:57.167575      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:58.167773      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:46:59.167984      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:00.168650      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:01.169506      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:02.169663      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:03.170081      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:04.170796      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:05.171246      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:06.172090      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:07.172335      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:08.172749      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:09.173727      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:10.174527      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:11.175502      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:12.176631      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:13.176781      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:14.177013      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:15.177068      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:16.177627      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:17.178112      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:18.178894      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:19.178615      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:20.179057      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:21.180211      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:22.180388      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:23.180588      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:24.180871      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:25.181726      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:26.182885      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:27.183808      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:28.184403      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:29.184485      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:30.185639      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:31.186508      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:32.186598      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:33.186721      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:34.187074      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:35.187886      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:36.188746      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:37.188846      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:38.189087      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:39.189559      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:40.189718      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:41.190578      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:42.190955      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:43.191275      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:44.191423      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:45.191656      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:46.192754      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:47.192934      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:48.193173      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:49.193815      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:50.194181      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:51.194429      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:52.195041      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:53.195210      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:54.195800      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:55.196877      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:56.197759      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:57.197877      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:58.198624      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:47:59.198804      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:00.199006      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 12/19/23 11:48:00.241
  STEP: Removing cronjob @ 12/19/23 11:48:00.248
  Dec 19 11:48:00.271: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-4456" for this suite. @ 12/19/23 11:48:00.286
• [76.145 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:69
  STEP: Creating a kubernetes client @ 12/19/23 11:48:00.311
  Dec 19 11:48:00.311: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:48:00.316
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:48:00.39
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:48:00.395
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:48:00.401
  E1219 11:48:01.199235      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:02.200192      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:03.199996      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:04.200336      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:48:04.44
  Dec 19 11:48:04.447: INFO: Trying to get logs from node hiengux9ahcu-3 pod downwardapi-volume-49759afc-cc9c-4d13-954d-d0884481e4ec container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:48:04.463
  Dec 19 11:48:04.489: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5190" for this suite. @ 12/19/23 11:48:04.5
• [4.202 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]
test/e2e/apps/daemon_set.go:836
  STEP: Creating a kubernetes client @ 12/19/23 11:48:04.519
  Dec 19 11:48:04.519: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename daemonsets @ 12/19/23 11:48:04.522
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:48:04.549
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:48:04.554
  STEP: Creating simple DaemonSet "daemon-set" @ 12/19/23 11:48:04.605
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/19/23 11:48:04.622
  Dec 19 11:48:04.643: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec 19 11:48:04.643: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  E1219 11:48:05.200440      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:48:05.677: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec 19 11:48:05.677: INFO: Node hiengux9ahcu-1 is running 0 daemon pod, expected 1
  E1219 11:48:06.201374      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:48:06.671: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec 19 11:48:06.671: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: listing all DaemonSets @ 12/19/23 11:48:06.68
  STEP: DeleteCollection of the DaemonSets @ 12/19/23 11:48:06.696
  STEP: Verify that ReplicaSets have been deleted @ 12/19/23 11:48:06.719
  Dec 19 11:48:06.799: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"32385"},"items":null}

  Dec 19 11:48:06.820: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"32387"},"items":[{"metadata":{"name":"daemon-set-h4bb2","generateName":"daemon-set-","namespace":"daemonsets-9631","uid":"f47fdae9-912d-47ca-94a1-d6b31c4dc0fb","resourceVersion":"32385","creationTimestamp":"2023-12-19T11:48:04Z","deletionTimestamp":"2023-12-19T11:48:36Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"eefaea3b-db9e-4a04-a3e1-5c8a68b69bbd","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-12-19T11:48:04Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eefaea3b-db9e-4a04-a3e1-5c8a68b69bbd\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-12-19T11:48:06Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.127\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-txbmz","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-txbmz","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"hiengux9ahcu-2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["hiengux9ahcu-2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T11:48:04Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T11:48:06Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T11:48:06Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T11:48:04Z"}],"hostIP":"192.168.121.17","podIP":"10.233.65.127","podIPs":[{"ip":"10.233.65.127"}],"startTime":"2023-12-19T11:48:04Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-12-19T11:48:05Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089","containerID":"cri-o://f553326f8ce654436d905ca172dc996f8429005dd5513f03805314fbb7769e7d","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-p9dpl","generateName":"daemon-set-","namespace":"daemonsets-9631","uid":"af5d7763-d9d3-4b38-995e-dd4bb1d2f9ed","resourceVersion":"32384","creationTimestamp":"2023-12-19T11:48:04Z","deletionTimestamp":"2023-12-19T11:48:36Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"eefaea3b-db9e-4a04-a3e1-5c8a68b69bbd","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-12-19T11:48:04Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eefaea3b-db9e-4a04-a3e1-5c8a68b69bbd\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-12-19T11:48:06Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.137\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-rt8bv","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-rt8bv","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"hiengux9ahcu-1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["hiengux9ahcu-1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T11:48:04Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T11:48:06Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T11:48:06Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T11:48:04Z"}],"hostIP":"192.168.121.83","podIP":"10.233.64.137","podIPs":[{"ip":"10.233.64.137"}],"startTime":"2023-12-19T11:48:04Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-12-19T11:48:05Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089","containerID":"cri-o://5b5253b79f1451800e7a9d76914050dd7211a47c3d94bf2d53352890d027bc85","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-s97vn","generateName":"daemon-set-","namespace":"daemonsets-9631","uid":"c4326f44-809d-4f39-b5ba-b807cab480b4","resourceVersion":"32387","creationTimestamp":"2023-12-19T11:48:04Z","deletionTimestamp":"2023-12-19T11:48:36Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"eefaea3b-db9e-4a04-a3e1-5c8a68b69bbd","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-12-19T11:48:04Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eefaea3b-db9e-4a04-a3e1-5c8a68b69bbd\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-12-19T11:48:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.154\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-swn4l","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-swn4l","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"hiengux9ahcu-3","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["hiengux9ahcu-3"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T11:48:04Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T11:48:05Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T11:48:05Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-19T11:48:04Z"}],"hostIP":"192.168.121.172","podIP":"10.233.66.154","podIPs":[{"ip":"10.233.66.154"}],"startTime":"2023-12-19T11:48:04Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-12-19T11:48:05Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089","containerID":"cri-o://e73487868c40517e99584716f0998431bb722e5eacdf7f409e451de67dc48f9f","started":true}],"qosClass":"BestEffort"}}]}

  Dec 19 11:48:06.875: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-9631" for this suite. @ 12/19/23 11:48:06.884
• [2.376 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]
test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 12/19/23 11:48:06.899
  Dec 19 11:48:06.899: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename crd-watch @ 12/19/23 11:48:06.901
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:48:06.931
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:48:06.939
  Dec 19 11:48:06.947: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 11:48:07.202076      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:08.203620      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:09.203806      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 12/19/23 11:48:09.648
  Dec 19 11:48:09.661: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-19T11:48:09Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-19T11:48:09Z]] name:name1 resourceVersion:32417 uid:cd86162a-10d9-467d-b05d-fe19b0c85a39] num:map[num1:9223372036854775807 num2:1000000]]}
  E1219 11:48:10.204494      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:11.205499      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:12.205659      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:13.205587      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:14.207296      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:15.207621      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:16.207752      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:17.208105      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:18.208410      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:19.208495      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 12/19/23 11:48:19.662
  Dec 19 11:48:19.678: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-19T11:48:19Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-19T11:48:19Z]] name:name2 resourceVersion:32464 uid:2b913587-ca46-42bd-aecf-d676c9cb69d8] num:map[num1:9223372036854775807 num2:1000000]]}
  E1219 11:48:20.209718      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:21.209495      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:22.210345      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:23.210684      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:24.210834      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:25.211555      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:26.212418      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:27.212822      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:28.213682      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:29.213771      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 12/19/23 11:48:29.68
  Dec 19 11:48:29.701: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-19T11:48:09Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-19T11:48:29Z]] name:name1 resourceVersion:32482 uid:cd86162a-10d9-467d-b05d-fe19b0c85a39] num:map[num1:9223372036854775807 num2:1000000]]}
  E1219 11:48:30.215034      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:31.215491      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:32.215588      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:33.216343      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:34.216515      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:35.216725      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:36.217784      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:37.218357      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:38.218458      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:39.218621      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 12/19/23 11:48:39.702
  Dec 19 11:48:39.715: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-19T11:48:19Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-19T11:48:39Z]] name:name2 resourceVersion:32504 uid:2b913587-ca46-42bd-aecf-d676c9cb69d8] num:map[num1:9223372036854775807 num2:1000000]]}
  E1219 11:48:40.219773      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:41.219946      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:42.219944      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:43.220023      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:44.220315      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:45.220508      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:46.221657      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:47.221923      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:48.222443      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:49.222799      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 12/19/23 11:48:49.716
  Dec 19 11:48:49.731: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-19T11:48:09Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-19T11:48:29Z]] name:name1 resourceVersion:32523 uid:cd86162a-10d9-467d-b05d-fe19b0c85a39] num:map[num1:9223372036854775807 num2:1000000]]}
  E1219 11:48:50.223253      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:51.224502      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:52.224497      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:53.224516      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:54.224598      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:55.224812      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:56.225382      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:57.225776      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:58.226171      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:48:59.226593      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 12/19/23 11:48:59.732
  Dec 19 11:48:59.751: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-19T11:48:19Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-19T11:48:39Z]] name:name2 resourceVersion:32540 uid:2b913587-ca46-42bd-aecf-d676c9cb69d8] num:map[num1:9223372036854775807 num2:1000000]]}
  E1219 11:49:00.227128      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:01.227374      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:02.227713      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:03.228452      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:04.228811      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:05.228955      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:06.229293      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:07.229938      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:08.230731      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:09.230745      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:10.231869      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:49:10.283: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-3291" for this suite. @ 12/19/23 11:49:10.295
• [63.413 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]
test/e2e/apimachinery/resource_quota.go:451
  STEP: Creating a kubernetes client @ 12/19/23 11:49:10.315
  Dec 19 11:49:10.315: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 11:49:10.319
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:49:10.351
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:49:10.355
  STEP: Counting existing ResourceQuota @ 12/19/23 11:49:10.36
  E1219 11:49:11.232083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:12.233024      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:13.233515      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:14.233865      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:15.234400      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/19/23 11:49:15.435
  STEP: Ensuring resource quota status is calculated @ 12/19/23 11:49:15.445
  E1219 11:49:16.235293      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:17.235704      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicaSet @ 12/19/23 11:49:17.456
  STEP: Ensuring resource quota status captures replicaset creation @ 12/19/23 11:49:17.49
  E1219 11:49:18.236336      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:19.236279      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicaSet @ 12/19/23 11:49:19.497
  STEP: Ensuring resource quota status released usage @ 12/19/23 11:49:19.509
  E1219 11:49:20.237035      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:21.237194      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:49:21.522: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9353" for this suite. @ 12/19/23 11:49:21.536
• [11.251 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 12/19/23 11:49:21.567
  Dec 19 11:49:21.568: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename secrets @ 12/19/23 11:49:21.572
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:49:21.61
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:49:21.617
  STEP: Creating secret with name secret-test-028e3c2f-e200-4865-84b1-5526eea2f139 @ 12/19/23 11:49:21.623
  STEP: Creating a pod to test consume secrets @ 12/19/23 11:49:21.634
  E1219 11:49:22.237917      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:23.237740      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:24.238856      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:25.238827      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:49:25.686
  Dec 19 11:49:25.697: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-secrets-2fbefc11-ce7c-4fec-9fb7-d28547f0b9e4 container secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 11:49:25.723
  Dec 19 11:49:25.759: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5862" for this suite. @ 12/19/23 11:49:25.778
• [4.226 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]
test/e2e/apimachinery/garbage_collector.go:379
  STEP: Creating a kubernetes client @ 12/19/23 11:49:25.811
  Dec 19 11:49:25.811: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename gc @ 12/19/23 11:49:25.815
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:49:25.851
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:49:25.86
  STEP: create the rc @ 12/19/23 11:49:25.881
  W1219 11:49:25.897677      14 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E1219 11:49:26.239501      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:27.239931      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:28.240462      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:29.241073      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:30.242060      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:31.242857      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 12/19/23 11:49:31.93
  STEP: wait for the rc to be deleted @ 12/19/23 11:49:31.989
  E1219 11:49:32.243619      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:33.244080      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:34.244481      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:35.249639      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:36.249703      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 12/19/23 11:49:36.999
  E1219 11:49:37.250735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:38.251355      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:39.252612      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:40.252775      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:41.253844      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:42.254516      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:43.254713      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:44.255289      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:45.255510      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:46.256546      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:47.256741      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:48.256934      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:49.257308      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:50.257698      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:51.258739      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:52.259129      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:53.260090      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:54.261019      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:55.261257      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:56.262652      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:57.262055      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:58.262628      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:49:59.263368      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:00.264544      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:01.264264      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:02.265929      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:03.266171      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:04.266180      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:05.266275      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:06.266507      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 12/19/23 11:50:07.044
  E1219 11:50:07.268874      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:50:07.300: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec 19 11:50:07.300: INFO: Deleting pod "simpletest.rc-2hhwd" in namespace "gc-5808"
  Dec 19 11:50:07.337: INFO: Deleting pod "simpletest.rc-42brt" in namespace "gc-5808"
  Dec 19 11:50:07.390: INFO: Deleting pod "simpletest.rc-44z9w" in namespace "gc-5808"
  Dec 19 11:50:07.711: INFO: Deleting pod "simpletest.rc-4lwpf" in namespace "gc-5808"
  Dec 19 11:50:07.749: INFO: Deleting pod "simpletest.rc-4mgzz" in namespace "gc-5808"
  Dec 19 11:50:07.790: INFO: Deleting pod "simpletest.rc-4n22l" in namespace "gc-5808"
  Dec 19 11:50:07.856: INFO: Deleting pod "simpletest.rc-4q78w" in namespace "gc-5808"
  Dec 19 11:50:07.956: INFO: Deleting pod "simpletest.rc-567wb" in namespace "gc-5808"
  Dec 19 11:50:08.003: INFO: Deleting pod "simpletest.rc-56hs9" in namespace "gc-5808"
  Dec 19 11:50:08.047: INFO: Deleting pod "simpletest.rc-5b28w" in namespace "gc-5808"
  Dec 19 11:50:08.111: INFO: Deleting pod "simpletest.rc-5ftmb" in namespace "gc-5808"
  Dec 19 11:50:08.187: INFO: Deleting pod "simpletest.rc-5nxx8" in namespace "gc-5808"
  Dec 19 11:50:08.230: INFO: Deleting pod "simpletest.rc-5zl8c" in namespace "gc-5808"
  E1219 11:50:08.270135      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:50:08.293: INFO: Deleting pod "simpletest.rc-5zxdk" in namespace "gc-5808"
  Dec 19 11:50:08.342: INFO: Deleting pod "simpletest.rc-65qtd" in namespace "gc-5808"
  Dec 19 11:50:08.424: INFO: Deleting pod "simpletest.rc-6722v" in namespace "gc-5808"
  Dec 19 11:50:08.510: INFO: Deleting pod "simpletest.rc-69wfx" in namespace "gc-5808"
  Dec 19 11:50:08.557: INFO: Deleting pod "simpletest.rc-7pm2z" in namespace "gc-5808"
  Dec 19 11:50:08.698: INFO: Deleting pod "simpletest.rc-7sxpc" in namespace "gc-5808"
  Dec 19 11:50:08.777: INFO: Deleting pod "simpletest.rc-7vbnz" in namespace "gc-5808"
  Dec 19 11:50:08.818: INFO: Deleting pod "simpletest.rc-7zwzv" in namespace "gc-5808"
  Dec 19 11:50:08.852: INFO: Deleting pod "simpletest.rc-8f4hb" in namespace "gc-5808"
  Dec 19 11:50:08.889: INFO: Deleting pod "simpletest.rc-8jcr5" in namespace "gc-5808"
  Dec 19 11:50:08.922: INFO: Deleting pod "simpletest.rc-8qvqc" in namespace "gc-5808"
  Dec 19 11:50:08.972: INFO: Deleting pod "simpletest.rc-8qxrf" in namespace "gc-5808"
  Dec 19 11:50:09.063: INFO: Deleting pod "simpletest.rc-92zhm" in namespace "gc-5808"
  Dec 19 11:50:09.106: INFO: Deleting pod "simpletest.rc-949fc" in namespace "gc-5808"
  Dec 19 11:50:09.185: INFO: Deleting pod "simpletest.rc-96rl7" in namespace "gc-5808"
  E1219 11:50:09.270885      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:50:09.326: INFO: Deleting pod "simpletest.rc-9bm4t" in namespace "gc-5808"
  Dec 19 11:50:09.408: INFO: Deleting pod "simpletest.rc-b4qt9" in namespace "gc-5808"
  Dec 19 11:50:09.442: INFO: Deleting pod "simpletest.rc-b69vs" in namespace "gc-5808"
  Dec 19 11:50:09.628: INFO: Deleting pod "simpletest.rc-b72jh" in namespace "gc-5808"
  Dec 19 11:50:09.779: INFO: Deleting pod "simpletest.rc-bbmn6" in namespace "gc-5808"
  Dec 19 11:50:09.885: INFO: Deleting pod "simpletest.rc-bfn45" in namespace "gc-5808"
  Dec 19 11:50:09.950: INFO: Deleting pod "simpletest.rc-bjkcd" in namespace "gc-5808"
  Dec 19 11:50:10.016: INFO: Deleting pod "simpletest.rc-bm9m6" in namespace "gc-5808"
  Dec 19 11:50:10.066: INFO: Deleting pod "simpletest.rc-c72cj" in namespace "gc-5808"
  Dec 19 11:50:10.096: INFO: Deleting pod "simpletest.rc-ckjcw" in namespace "gc-5808"
  Dec 19 11:50:10.145: INFO: Deleting pod "simpletest.rc-ctgdn" in namespace "gc-5808"
  Dec 19 11:50:10.180: INFO: Deleting pod "simpletest.rc-cz2z7" in namespace "gc-5808"
  Dec 19 11:50:10.254: INFO: Deleting pod "simpletest.rc-d74sh" in namespace "gc-5808"
  E1219 11:50:10.271733      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:50:10.314: INFO: Deleting pod "simpletest.rc-d9jn9" in namespace "gc-5808"
  Dec 19 11:50:10.344: INFO: Deleting pod "simpletest.rc-dbjmm" in namespace "gc-5808"
  Dec 19 11:50:10.392: INFO: Deleting pod "simpletest.rc-dcjds" in namespace "gc-5808"
  Dec 19 11:50:10.463: INFO: Deleting pod "simpletest.rc-dwws9" in namespace "gc-5808"
  Dec 19 11:50:10.506: INFO: Deleting pod "simpletest.rc-flprb" in namespace "gc-5808"
  Dec 19 11:50:10.612: INFO: Deleting pod "simpletest.rc-flq5l" in namespace "gc-5808"
  Dec 19 11:50:10.684: INFO: Deleting pod "simpletest.rc-gm27p" in namespace "gc-5808"
  Dec 19 11:50:10.742: INFO: Deleting pod "simpletest.rc-hbmpr" in namespace "gc-5808"
  Dec 19 11:50:10.841: INFO: Deleting pod "simpletest.rc-hdlk9" in namespace "gc-5808"
  Dec 19 11:50:11.190: INFO: Deleting pod "simpletest.rc-hrbqm" in namespace "gc-5808"
  Dec 19 11:50:11.260: INFO: Deleting pod "simpletest.rc-htrlm" in namespace "gc-5808"
  E1219 11:50:11.273654      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:50:11.434: INFO: Deleting pod "simpletest.rc-jlncv" in namespace "gc-5808"
  Dec 19 11:50:11.551: INFO: Deleting pod "simpletest.rc-jq4z7" in namespace "gc-5808"
  Dec 19 11:50:11.678: INFO: Deleting pod "simpletest.rc-jx86c" in namespace "gc-5808"
  Dec 19 11:50:11.726: INFO: Deleting pod "simpletest.rc-k6hjr" in namespace "gc-5808"
  Dec 19 11:50:11.784: INFO: Deleting pod "simpletest.rc-kd6pg" in namespace "gc-5808"
  Dec 19 11:50:11.826: INFO: Deleting pod "simpletest.rc-kjcs7" in namespace "gc-5808"
  Dec 19 11:50:11.863: INFO: Deleting pod "simpletest.rc-ljhdh" in namespace "gc-5808"
  Dec 19 11:50:11.917: INFO: Deleting pod "simpletest.rc-lxcs9" in namespace "gc-5808"
  Dec 19 11:50:11.989: INFO: Deleting pod "simpletest.rc-lz972" in namespace "gc-5808"
  Dec 19 11:50:12.052: INFO: Deleting pod "simpletest.rc-m2gcr" in namespace "gc-5808"
  Dec 19 11:50:12.123: INFO: Deleting pod "simpletest.rc-mdcgt" in namespace "gc-5808"
  Dec 19 11:50:12.160: INFO: Deleting pod "simpletest.rc-mlxhz" in namespace "gc-5808"
  Dec 19 11:50:12.200: INFO: Deleting pod "simpletest.rc-msxfl" in namespace "gc-5808"
  Dec 19 11:50:12.244: INFO: Deleting pod "simpletest.rc-mszbx" in namespace "gc-5808"
  E1219 11:50:12.273746      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:50:12.303: INFO: Deleting pod "simpletest.rc-npwrb" in namespace "gc-5808"
  Dec 19 11:50:12.350: INFO: Deleting pod "simpletest.rc-nqwp5" in namespace "gc-5808"
  Dec 19 11:50:12.419: INFO: Deleting pod "simpletest.rc-nrkpg" in namespace "gc-5808"
  Dec 19 11:50:12.466: INFO: Deleting pod "simpletest.rc-nrvjh" in namespace "gc-5808"
  Dec 19 11:50:12.530: INFO: Deleting pod "simpletest.rc-pbhpl" in namespace "gc-5808"
  Dec 19 11:50:12.603: INFO: Deleting pod "simpletest.rc-pmc7k" in namespace "gc-5808"
  Dec 19 11:50:12.694: INFO: Deleting pod "simpletest.rc-ps72h" in namespace "gc-5808"
  Dec 19 11:50:12.767: INFO: Deleting pod "simpletest.rc-pv4ms" in namespace "gc-5808"
  Dec 19 11:50:12.818: INFO: Deleting pod "simpletest.rc-px9lp" in namespace "gc-5808"
  Dec 19 11:50:12.928: INFO: Deleting pod "simpletest.rc-qcvrd" in namespace "gc-5808"
  Dec 19 11:50:13.003: INFO: Deleting pod "simpletest.rc-qv7zr" in namespace "gc-5808"
  Dec 19 11:50:13.058: INFO: Deleting pod "simpletest.rc-rbt6q" in namespace "gc-5808"
  Dec 19 11:50:13.143: INFO: Deleting pod "simpletest.rc-rjs9d" in namespace "gc-5808"
  Dec 19 11:50:13.194: INFO: Deleting pod "simpletest.rc-rpzs5" in namespace "gc-5808"
  Dec 19 11:50:13.266: INFO: Deleting pod "simpletest.rc-rslk2" in namespace "gc-5808"
  E1219 11:50:13.273994      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:50:13.360: INFO: Deleting pod "simpletest.rc-sj8ct" in namespace "gc-5808"
  Dec 19 11:50:13.521: INFO: Deleting pod "simpletest.rc-sqsd9" in namespace "gc-5808"
  Dec 19 11:50:13.630: INFO: Deleting pod "simpletest.rc-sqtxf" in namespace "gc-5808"
  Dec 19 11:50:13.719: INFO: Deleting pod "simpletest.rc-t2jhm" in namespace "gc-5808"
  Dec 19 11:50:13.798: INFO: Deleting pod "simpletest.rc-t4pcw" in namespace "gc-5808"
  Dec 19 11:50:13.855: INFO: Deleting pod "simpletest.rc-t6xng" in namespace "gc-5808"
  Dec 19 11:50:13.975: INFO: Deleting pod "simpletest.rc-t8hnp" in namespace "gc-5808"
  Dec 19 11:50:14.046: INFO: Deleting pod "simpletest.rc-tjp2n" in namespace "gc-5808"
  Dec 19 11:50:14.090: INFO: Deleting pod "simpletest.rc-ttcgc" in namespace "gc-5808"
  Dec 19 11:50:14.112: INFO: Deleting pod "simpletest.rc-vdwvq" in namespace "gc-5808"
  Dec 19 11:50:14.129: INFO: Deleting pod "simpletest.rc-vms77" in namespace "gc-5808"
  Dec 19 11:50:14.213: INFO: Deleting pod "simpletest.rc-vvpzg" in namespace "gc-5808"
  E1219 11:50:14.274547      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:50:14.307: INFO: Deleting pod "simpletest.rc-wbm22" in namespace "gc-5808"
  Dec 19 11:50:14.356: INFO: Deleting pod "simpletest.rc-x4vfz" in namespace "gc-5808"
  Dec 19 11:50:14.406: INFO: Deleting pod "simpletest.rc-xccfw" in namespace "gc-5808"
  Dec 19 11:50:14.461: INFO: Deleting pod "simpletest.rc-xjhdc" in namespace "gc-5808"
  Dec 19 11:50:14.513: INFO: Deleting pod "simpletest.rc-xl9lq" in namespace "gc-5808"
  Dec 19 11:50:14.580: INFO: Deleting pod "simpletest.rc-zlmw5" in namespace "gc-5808"
  Dec 19 11:50:14.642: INFO: Deleting pod "simpletest.rc-zqsgh" in namespace "gc-5808"
  Dec 19 11:50:14.847: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5808" for this suite. @ 12/19/23 11:50:14.892
• [49.157 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:174
  STEP: Creating a kubernetes client @ 12/19/23 11:50:14.968
  Dec 19 11:50:14.968: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:50:14.972
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:50:15.023
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:50:15.028
  STEP: Creating configMap with name cm-test-opt-del-c76f6d84-c136-46f3-8b5e-9fd5da8169c2 @ 12/19/23 11:50:15.055
  STEP: Creating configMap with name cm-test-opt-upd-2400c2ab-28a9-42d1-8734-5f221a4f1caf @ 12/19/23 11:50:15.071
  STEP: Creating the pod @ 12/19/23 11:50:15.088
  E1219 11:50:15.274657      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:16.275634      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-c76f6d84-c136-46f3-8b5e-9fd5da8169c2 @ 12/19/23 11:50:17.184
  STEP: Updating configmap cm-test-opt-upd-2400c2ab-28a9-42d1-8734-5f221a4f1caf @ 12/19/23 11:50:17.201
  STEP: Creating configMap with name cm-test-opt-create-9af7d6a2-503b-48c2-86af-ccd3de73033c @ 12/19/23 11:50:17.213
  STEP: waiting to observe update in volume @ 12/19/23 11:50:17.229
  E1219 11:50:17.276522      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:18.276643      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:19.276834      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:20.277521      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:21.277533      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:22.278128      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:23.278278      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:24.278414      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:25.279640      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:26.279738      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:27.280610      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:28.281107      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:29.281155      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:30.281873      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:31.282416      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:32.283313      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:33.283557      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:34.283633      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:35.284158      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:36.284191      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:37.284363      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:38.284956      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:39.284679      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:40.284946      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:41.285526      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:42.285733      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:43.285975      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:44.286965      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:45.287783      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:46.288706      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:47.289738      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:48.289912      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:49.290021      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:50.290983      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:51.291141      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:52.292445      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:53.292349      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:54.292738      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:55.292936      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:56.293188      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:57.293452      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:58.293543      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:50:59.294164      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:00.294389      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:01.294999      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:02.296064      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:03.296833      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:04.297051      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:05.297674      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:06.298571      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:07.299052      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:08.299901      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:09.300142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:10.301086      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:11.301259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:12.302342      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:13.302814      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:14.303027      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:15.303927      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:16.304719      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:17.305629      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:18.305821      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:19.306182      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:20.306308      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:21.306991      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:22.307858      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:23.309351      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:24.309346      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:25.310468      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:51:25.951: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7300" for this suite. @ 12/19/23 11:51:25.969
• [71.021 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:198
  STEP: Creating a kubernetes client @ 12/19/23 11:51:26.004
  Dec 19 11:51:26.004: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename container-probe @ 12/19/23 11:51:26.007
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:51:26.048
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:51:26.053
  STEP: Creating pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248 @ 12/19/23 11:51:26.058
  E1219 11:51:26.311321      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:27.312799      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/19/23 11:51:28.094
  Dec 19 11:51:28.102: INFO: Initial restart count of pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf is 0
  Dec 19 11:51:28.109: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:51:28.314097      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:29.314360      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:51:30.117: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:51:30.315722      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:31.315997      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:51:32.127: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:51:32.317231      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:33.317378      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:51:34.136: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:51:34.318082      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:35.318359      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:51:36.144: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:51:36.318404      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:37.319310      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:51:38.155: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:51:38.320026      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:39.321006      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:51:40.165: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:51:40.321855      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:41.323083      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:51:42.179: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:51:42.323165      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:43.323905      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:51:44.187: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:51:44.325138      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:45.325847      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:51:46.196: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:51:46.326556      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:47.327090      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:51:48.202: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  Dec 19 11:51:48.202: INFO: Restart count of pod container-probe-5248/liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf is now 1 (20.099672067s elapsed)
  E1219 11:51:48.328038      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:49.327995      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:51:50.210: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:51:50.328593      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:51.329237      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:51:52.227: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:51:52.330137      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:53.330254      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:51:54.234: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:51:54.330872      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:55.331132      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:51:56.241: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:51:56.331949      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:57.332245      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:51:58.249: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:51:58.333181      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:51:59.333659      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:00.258: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:00.333789      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:01.334352      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:02.266: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:02.334939      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:03.335171      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:04.277: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:04.336142      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:05.337058      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:06.285: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:06.337962      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:07.338758      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:08.294: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  Dec 19 11:52:08.295: INFO: Restart count of pod container-probe-5248/liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf is now 2 (40.19293673s elapsed)
  E1219 11:52:08.339705      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:09.339923      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:10.302: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:10.340687      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:11.340894      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:12.321: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:12.341785      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:13.341971      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:14.327: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:14.342347      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:15.343196      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:16.334: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:16.343809      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:17.344567      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:18.343: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:18.344790      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:19.345156      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:20.346037      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:20.350: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:21.346263      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:22.346595      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:22.359: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:23.346557      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:24.346853      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:24.368: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:25.347915      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:26.348956      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:26.376: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:27.350161      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:28.350023      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:28.383: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  Dec 19 11:52:28.384: INFO: Restart count of pod container-probe-5248/liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf is now 3 (1m0.281695173s elapsed)
  E1219 11:52:29.350426      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:30.350775      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:30.393: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:31.351404      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:32.351465      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:32.402: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:33.352360      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:34.352079      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:34.410: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:35.352924      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:36.354796      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:36.420: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:37.357140      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:38.355459      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:38.428: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:39.355843      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:40.357797      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:40.438: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:41.356532      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:42.356606      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:42.445: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:43.356885      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:44.357145      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:44.453: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:45.357474      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:46.357680      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:46.472: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:47.358037      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:48.359017      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:48.483: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  Dec 19 11:52:48.484: INFO: Restart count of pod container-probe-5248/liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf is now 4 (1m20.381824088s elapsed)
  E1219 11:52:49.359882      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:50.360174      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:50.492: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:51.361127      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:52.361791      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:52.502: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:53.362021      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:54.362126      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:54.510: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:55.362618      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:56.363742      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:56.518: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:57.363909      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:52:58.363863      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:52:58.532: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:52:59.364723      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:00.364890      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:00.543: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:01.365396      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:02.366161      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:02.558: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:03.366358      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:04.366987      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:04.568: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:05.367374      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:06.367483      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:06.577: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:07.368264      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:08.369503      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:08.588: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:09.370167      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:10.370646      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:10.601: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:11.371554      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:12.371769      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:12.611: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:13.372227      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:14.372364      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:14.620: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:15.373759      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:16.373654      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:16.627: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:17.374329      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:18.374638      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:18.634: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:19.374650      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:20.375151      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:20.645: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:21.375602      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:22.376095      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:22.671: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:23.375926      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:24.376755      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:24.682: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:25.376812      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:26.377761      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:26.695: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:27.378198      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:28.378334      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:28.705: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:29.378878      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:30.379152      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:30.712: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:31.379428      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:32.382179      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:32.722: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:33.381478      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:34.381497      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:34.755: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:35.382243      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:36.382265      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:36.766: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:37.382769      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:38.383162      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:38.774: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:39.384682      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:40.384662      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:40.782: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:41.384819      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:42.384933      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:42.794: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:43.385497      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:44.385483      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:44.803: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:45.386323      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:46.387499      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:46.812: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:47.388454      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:48.388883      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:48.823: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:49.388782      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:50.389062      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:50.832: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:51.389175      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:52.390194      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:52.842: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:53.390522      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:54.391115      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:54.852: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:55.392340      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:56.391883      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:56.866: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:57.392844      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:53:58.392960      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:53:58.874: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  E1219 11:53:59.393600      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:00.393835      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:54:00.885: INFO: Get pod liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf in namespace container-probe-5248
  Dec 19 11:54:00.885: INFO: Restart count of pod container-probe-5248/liveness-9c7f3980-6d1a-4af2-aec7-42081c6515cf is now 5 (2m32.782947021s elapsed)
  Dec 19 11:54:00.886: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/19/23 11:54:00.904
  STEP: Destroying namespace "container-probe-5248" for this suite. @ 12/19/23 11:54:00.935
• [154.950 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]
test/e2e/kubectl/kubectl.go:1741
  STEP: Creating a kubernetes client @ 12/19/23 11:54:00.966
  Dec 19 11:54:00.966: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubectl @ 12/19/23 11:54:00.971
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:54:01.01
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:54:01.017
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 12/19/23 11:54:01.023
  Dec 19 11:54:01.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-4906 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Dec 19 11:54:01.214: INFO: stderr: ""
  Dec 19 11:54:01.214: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 12/19/23 11:54:01.215
  E1219 11:54:01.394579      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:02.394587      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:03.394809      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:04.396174      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:05.395623      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 12/19/23 11:54:06.266
  Dec 19 11:54:06.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-4906 get pod e2e-test-httpd-pod -o json'
  E1219 11:54:06.396548      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:54:06.455: INFO: stderr: ""
  Dec 19 11:54:06.455: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2023-12-19T11:54:01Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-4906\",\n        \"resourceVersion\": \"34963\",\n        \"uid\": \"0b9b0c82-47dc-4a5d-a3ea-15f55215978a\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-tcc7r\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"hiengux9ahcu-3\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-tcc7r\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-12-19T11:54:01Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-12-19T11:54:02Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-12-19T11:54:02Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-12-19T11:54:01Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"cri-o://41c98fb5996e3efb8b601cccde5c969300c2fb32252b137b8f328434f95cc91a\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"987dae5a853a43c663ab2f902708e65874bd2c0189aa0bc57d81ffb57187d089\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-12-19T11:54:01Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.121.172\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.233.66.194\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.233.66.194\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-12-19T11:54:01Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 12/19/23 11:54:06.456
  Dec 19 11:54:06.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-4906 replace -f -'
  Dec 19 11:54:07.122: INFO: stderr: ""
  Dec 19 11:54:07.122: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-4 @ 12/19/23 11:54:07.122
  Dec 19 11:54:07.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=kubectl-4906 delete pods e2e-test-httpd-pod'
  E1219 11:54:07.396709      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:08.396901      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:09.397196      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:54:09.455: INFO: stderr: ""
  Dec 19 11:54:09.455: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Dec 19 11:54:09.455: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4906" for this suite. @ 12/19/23 11:54:09.465
• [8.528 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]
test/e2e/apimachinery/webhook.go:210
  STEP: Creating a kubernetes client @ 12/19/23 11:54:09.494
  Dec 19 11:54:09.494: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename webhook @ 12/19/23 11:54:09.497
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:54:09.579
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:54:09.595
  STEP: Setting up server cert @ 12/19/23 11:54:09.636
  E1219 11:54:10.397645      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:11.397721      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/19/23 11:54:11.501
  STEP: Deploying the webhook pod @ 12/19/23 11:54:11.513
  STEP: Wait for the deployment to be ready @ 12/19/23 11:54:11.542
  Dec 19 11:54:11.550: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E1219 11:54:12.398814      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:13.399048      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:54:13.569: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 54, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 54, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 54, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 54, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:54:14.399873      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:15.400077      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:54:15.580: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 54, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 54, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 54, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 54, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:54:16.400206      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:17.401327      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:54:17.576: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 54, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 54, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 54, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 54, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:54:18.401910      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:19.401787      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:54:19.584: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 19, 11, 54, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 54, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 19, 11, 54, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 19, 11, 54, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1219 11:54:20.402040      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:21.402911      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/19/23 11:54:21.575
  STEP: Verifying the service has paired with the endpoint @ 12/19/23 11:54:21.612
  E1219 11:54:22.404049      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:54:22.613: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 12/19/23 11:54:22.628
  STEP: create a pod @ 12/19/23 11:54:22.663
  E1219 11:54:23.404350      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:24.404547      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 12/19/23 11:54:24.699
  Dec 19 11:54:24.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=webhook-4441 attach --namespace=webhook-4441 to-be-attached-pod -i -c=container1'
  Dec 19 11:54:24.991: INFO: rc: 1
  Dec 19 11:54:24.992: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4441" for this suite. @ 12/19/23 11:54:25.114
  STEP: Destroying namespace "webhook-markers-9304" for this suite. @ 12/19/23 11:54:25.127
• [15.649 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]
test/e2e/network/service.go:1493
  STEP: Creating a kubernetes client @ 12/19/23 11:54:25.149
  Dec 19 11:54:25.149: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename services @ 12/19/23 11:54:25.154
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:54:25.193
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:54:25.201
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-3759 @ 12/19/23 11:54:25.208
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 12/19/23 11:54:25.228
  STEP: creating service externalsvc in namespace services-3759 @ 12/19/23 11:54:25.228
  STEP: creating replication controller externalsvc in namespace services-3759 @ 12/19/23 11:54:25.26
  I1219 11:54:25.272087      14 runners.go:197] Created replication controller with name: externalsvc, namespace: services-3759, replica count: 2
  E1219 11:54:25.405547      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:26.405832      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:27.406955      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 11:54:28.323704      14 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 12/19/23 11:54:28.332
  Dec 19 11:54:28.364: INFO: Creating new exec pod
  E1219 11:54:28.408458      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:29.409064      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:54:30.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=services-3759 exec execpodx2bzr -- /bin/sh -x -c nslookup clusterip-service.services-3759.svc.cluster.local'
  E1219 11:54:30.410226      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:54:30.910: INFO: stderr: "+ nslookup clusterip-service.services-3759.svc.cluster.local\n"
  Dec 19 11:54:30.910: INFO: stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nclusterip-service.services-3759.svc.cluster.local\tcanonical name = externalsvc.services-3759.svc.cluster.local.\nName:\texternalsvc.services-3759.svc.cluster.local\nAddress: 10.233.9.247\n\n"
  Dec 19 11:54:30.911: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController externalsvc in namespace services-3759, will wait for the garbage collector to delete the pods @ 12/19/23 11:54:30.922
  Dec 19 11:54:30.993: INFO: Deleting ReplicationController externalsvc took: 11.377202ms
  Dec 19 11:54:31.094: INFO: Terminating ReplicationController externalsvc pods took: 100.829289ms
  E1219 11:54:31.410376      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:32.410909      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:33.411186      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:54:34.142: INFO: Cleaning up the ClusterIP to ExternalName test service
  STEP: Destroying namespace "services-3759" for this suite. @ 12/19/23 11:54:34.167
• [9.036 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]
test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 12/19/23 11:54:34.201
  Dec 19 11:54:34.202: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename subpath @ 12/19/23 11:54:34.205
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:54:34.244
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:54:34.249
  STEP: Setting up data @ 12/19/23 11:54:34.255
  STEP: Creating pod pod-subpath-test-configmap-5ckt @ 12/19/23 11:54:34.272
  STEP: Creating a pod to test atomic-volume-subpath @ 12/19/23 11:54:34.272
  E1219 11:54:34.411829      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:35.412655      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:36.413315      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:37.413129      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:38.414013      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:39.414955      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:40.415341      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:41.415829      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:42.416149      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:43.416340      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:44.417064      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:45.417295      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:46.417932      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:47.418171      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:48.418404      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:49.418686      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:50.419281      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:51.419652      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:52.420867      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:53.422227      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:54.423590      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:55.423517      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:56.424152      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:54:57.424432      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:54:58.408
  Dec 19 11:54:58.416: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-subpath-test-configmap-5ckt container test-container-subpath-configmap-5ckt: <nil>
  E1219 11:54:58.424877      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod @ 12/19/23 11:54:58.473
  STEP: Deleting pod pod-subpath-test-configmap-5ckt @ 12/19/23 11:54:58.517
  Dec 19 11:54:58.517: INFO: Deleting pod "pod-subpath-test-configmap-5ckt" in namespace "subpath-1850"
  Dec 19 11:54:58.524: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-1850" for this suite. @ 12/19/23 11:54:58.536
• [24.349 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]
test/e2e/common/node/configmap.go:45
  STEP: Creating a kubernetes client @ 12/19/23 11:54:58.556
  Dec 19 11:54:58.557: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename configmap @ 12/19/23 11:54:58.559
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:54:58.59
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:54:58.595
  STEP: Creating configMap configmap-2915/configmap-test-0324fc06-0e8d-4fb2-a41e-0612a50e70ab @ 12/19/23 11:54:58.599
  STEP: Creating a pod to test consume configMaps @ 12/19/23 11:54:58.609
  E1219 11:54:59.425546      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:00.425950      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:01.426309      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:02.426424      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:55:02.656
  Dec 19 11:55:02.662: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-configmaps-1c687080-3e7c-4334-82cf-a9586f7b08bf container env-test: <nil>
  STEP: delete the pod @ 12/19/23 11:55:02.686
  Dec 19 11:55:02.710: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2915" for this suite. @ 12/19/23 11:55:02.72
• [4.176 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance]
test/e2e/apimachinery/field_validation.go:622
  STEP: Creating a kubernetes client @ 12/19/23 11:55:02.736
  Dec 19 11:55:02.736: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename field-validation @ 12/19/23 11:55:02.741
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:55:02.792
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:55:02.797
  Dec 19 11:55:02.803: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 11:55:03.427214      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:04.427393      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:05.427632      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  W1219 11:55:05.568306      14 warnings.go:70] unknown field "alpha"
  W1219 11:55:05.568349      14 warnings.go:70] unknown field "beta"
  W1219 11:55:05.568361      14 warnings.go:70] unknown field "delta"
  W1219 11:55:05.568371      14 warnings.go:70] unknown field "epsilon"
  W1219 11:55:05.568380      14 warnings.go:70] unknown field "gamma"
  Dec 19 11:55:06.130: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-159" for this suite. @ 12/19/23 11:55:06.168
• [3.442 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 12/19/23 11:55:06.184
  Dec 19 11:55:06.184: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:55:06.186
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:55:06.218
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:55:06.221
  STEP: Creating secret with name projected-secret-test-0431da26-4deb-4194-86c0-18da78990112 @ 12/19/23 11:55:06.226
  STEP: Creating a pod to test consume secrets @ 12/19/23 11:55:06.235
  E1219 11:55:06.427735      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:07.428464      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:08.428716      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:09.429183      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:55:10.275
  Dec 19 11:55:10.281: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-projected-secrets-665855b6-0e56-48f2-b38c-a02d48298893 container secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 11:55:10.296
  Dec 19 11:55:10.330: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6865" for this suite. @ 12/19/23 11:55:10.338
• [4.165 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 12/19/23 11:55:10.356
  Dec 19 11:55:10.356: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:55:10.358
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:55:10.384
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:55:10.389
  STEP: Creating projection with secret that has name projected-secret-test-f8e03494-7279-4178-b091-db6a56b43270 @ 12/19/23 11:55:10.394
  STEP: Creating a pod to test consume secrets @ 12/19/23 11:55:10.403
  E1219 11:55:10.429264      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:11.429911      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:12.430793      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:13.430981      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:14.431306      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:55:14.453
  Dec 19 11:55:14.459: INFO: Trying to get logs from node hiengux9ahcu-3 pod pod-projected-secrets-9760c5c5-9849-4b49-940d-866ab435b0a5 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 12/19/23 11:55:14.473
  Dec 19 11:55:14.506: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2996" for this suite. @ 12/19/23 11:55:14.516
• [4.174 seconds]
------------------------------
SS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]
test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 12/19/23 11:55:14.532
  Dec 19 11:55:14.532: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename disruption @ 12/19/23 11:55:14.535
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:55:14.562
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:55:14.57
  STEP: Waiting for the pdb to be processed @ 12/19/23 11:55:14.598
  E1219 11:55:15.432000      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:16.432268      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 12/19/23 11:55:16.619
  STEP: Waiting for all pods to be running @ 12/19/23 11:55:16.646
  Dec 19 11:55:16.661: INFO: running pods: 0 < 1
  E1219 11:55:17.432709      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:18.432744      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 12/19/23 11:55:18.672
  STEP: Waiting for the pdb to be processed @ 12/19/23 11:55:18.704
  STEP: Patching PodDisruptionBudget status @ 12/19/23 11:55:18.721
  STEP: Waiting for the pdb to be processed @ 12/19/23 11:55:18.771
  Dec 19 11:55:18.776: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2173" for this suite. @ 12/19/23 11:55:18.793
• [4.285 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:269
  STEP: Creating a kubernetes client @ 12/19/23 11:55:18.842
  Dec 19 11:55:18.842: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename custom-resource-definition @ 12/19/23 11:55:18.845
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:55:18.872
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:55:18.879
  Dec 19 11:55:18.883: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  E1219 11:55:19.433222      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:20.434255      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:21.435319      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:55:22.354: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-7802" for this suite. @ 12/19/23 11:55:22.362
• [3.532 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:236
  STEP: Creating a kubernetes client @ 12/19/23 11:55:22.376
  Dec 19 11:55:22.376: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename projected @ 12/19/23 11:55:22.379
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:55:22.409
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:55:22.416
  STEP: Creating a pod to test downward API volume plugin @ 12/19/23 11:55:22.421
  E1219 11:55:22.436530      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:23.437082      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:24.437290      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:25.437670      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:26.439209      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/19/23 11:55:26.466
  Dec 19 11:55:26.473: INFO: Trying to get logs from node hiengux9ahcu-3 pod downwardapi-volume-87c8787e-7c54-4bad-a065-ce70fcef912b container client-container: <nil>
  STEP: delete the pod @ 12/19/23 11:55:26.507
  Dec 19 11:55:26.563: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8774" for this suite. @ 12/19/23 11:55:26.572
• [4.220 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:135
  STEP: Creating a kubernetes client @ 12/19/23 11:55:26.601
  Dec 19 11:55:26.601: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename kubelet-test @ 12/19/23 11:55:26.607
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:55:26.64
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:55:26.645
  Dec 19 11:55:26.737: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-5913" for this suite. @ 12/19/23 11:55:26.807
• [0.240 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance]
test/e2e/apps/cronjob.go:324
  STEP: Creating a kubernetes client @ 12/19/23 11:55:26.856
  Dec 19 11:55:26.856: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename cronjob @ 12/19/23 11:55:26.86
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:55:26.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:55:26.9
  STEP: Creating a cronjob @ 12/19/23 11:55:26.906
  STEP: creating @ 12/19/23 11:55:26.906
  STEP: getting @ 12/19/23 11:55:26.917
  STEP: listing @ 12/19/23 11:55:26.923
  STEP: watching @ 12/19/23 11:55:26.932
  Dec 19 11:55:26.932: INFO: starting watch
  STEP: cluster-wide listing @ 12/19/23 11:55:26.934
  STEP: cluster-wide watching @ 12/19/23 11:55:26.942
  Dec 19 11:55:26.942: INFO: starting watch
  STEP: patching @ 12/19/23 11:55:26.943
  STEP: updating @ 12/19/23 11:55:26.959
  Dec 19 11:55:26.977: INFO: waiting for watch events with expected annotations
  Dec 19 11:55:26.977: INFO: saw patched and updated annotations
  STEP: patching /status @ 12/19/23 11:55:26.977
  STEP: updating /status @ 12/19/23 11:55:26.989
  STEP: get /status @ 12/19/23 11:55:27.005
  STEP: deleting @ 12/19/23 11:55:27.011
  STEP: deleting a collection @ 12/19/23 11:55:27.038
  Dec 19 11:55:27.064: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-2182" for this suite. @ 12/19/23 11:55:27.075
• [0.237 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]
test/e2e/apimachinery/resource_quota.go:232
  STEP: Creating a kubernetes client @ 12/19/23 11:55:27.094
  Dec 19 11:55:27.094: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename resourcequota @ 12/19/23 11:55:27.096
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:55:27.145
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:55:27.15
  STEP: Counting existing ResourceQuota @ 12/19/23 11:55:27.155
  E1219 11:55:27.440836      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:28.440530      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:29.441266      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:30.442198      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:31.443277      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/19/23 11:55:32.17
  STEP: Ensuring resource quota status is calculated @ 12/19/23 11:55:32.185
  E1219 11:55:32.444011      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:33.444275      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 12/19/23 11:55:34.196
  STEP: Ensuring ResourceQuota status captures the pod usage @ 12/19/23 11:55:34.231
  E1219 11:55:34.445074      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:35.445299      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 12/19/23 11:55:36.24
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 12/19/23 11:55:36.249
  STEP: Ensuring a pod cannot update its resource requirements @ 12/19/23 11:55:36.256
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 12/19/23 11:55:36.263
  E1219 11:55:36.446112      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:37.446732      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 12/19/23 11:55:38.271
  STEP: Ensuring resource quota status released the pod usage @ 12/19/23 11:55:38.29
  E1219 11:55:38.447684      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:39.448486      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:55:40.302: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8100" for this suite. @ 12/19/23 11:55:40.313
• [13.231 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]
test/e2e/apps/rc.go:69
  STEP: Creating a kubernetes client @ 12/19/23 11:55:40.334
  Dec 19 11:55:40.334: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename replication-controller @ 12/19/23 11:55:40.337
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:55:40.366
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:55:40.37
  STEP: Creating replication controller my-hostname-basic-717ef052-f88e-4cfc-8880-e8dbf31f66d8 @ 12/19/23 11:55:40.374
  Dec 19 11:55:40.390: INFO: Pod name my-hostname-basic-717ef052-f88e-4cfc-8880-e8dbf31f66d8: Found 0 pods out of 1
  E1219 11:55:40.448840      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:41.449537      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:42.449953      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:43.450296      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:44.450480      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:55:45.399: INFO: Pod name my-hostname-basic-717ef052-f88e-4cfc-8880-e8dbf31f66d8: Found 1 pods out of 1
  Dec 19 11:55:45.400: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-717ef052-f88e-4cfc-8880-e8dbf31f66d8" are running
  Dec 19 11:55:45.408: INFO: Pod "my-hostname-basic-717ef052-f88e-4cfc-8880-e8dbf31f66d8-npxv6" is running and ready(conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-19 11:55:40 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-19 11:55:41 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-19 11:55:41 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-19 11:55:40 +0000 UTC Reason: Message:}])
  Dec 19 11:55:45.409: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 12/19/23 11:55:45.41
  Dec 19 11:55:45.434: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-9306" for this suite. @ 12/19/23 11:55:45.446
  E1219 11:55:45.452130      14 retrywatcher.go:129] "Watch failed" err="context canceled"
• [5.135 seconds]
------------------------------
S
------------------------------
[sig-network] Service endpoints latency should not be very high  [Conformance]
test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 12/19/23 11:55:45.47
  Dec 19 11:55:45.470: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename svc-latency @ 12/19/23 11:55:45.475
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:55:45.512
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:55:45.518
  Dec 19 11:55:45.522: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-9738 @ 12/19/23 11:55:45.527
  I1219 11:55:45.555595      14 runners.go:197] Created replication controller with name: svc-latency-rc, namespace: svc-latency-9738, replica count: 1
  E1219 11:55:46.452859      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 11:55:46.607146      14 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E1219 11:55:47.453921      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1219 11:55:47.608549      14 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec 19 11:55:47.734: INFO: Created: latency-svc-c6bbg
  Dec 19 11:55:47.760: INFO: Got endpoints: latency-svc-c6bbg [50.352468ms]
  Dec 19 11:55:47.807: INFO: Created: latency-svc-gf46v
  Dec 19 11:55:47.827: INFO: Created: latency-svc-664rd
  Dec 19 11:55:47.831: INFO: Got endpoints: latency-svc-gf46v [70.90287ms]
  Dec 19 11:55:47.850: INFO: Created: latency-svc-s7gb6
  Dec 19 11:55:47.861: INFO: Got endpoints: latency-svc-664rd [99.699093ms]
  Dec 19 11:55:47.875: INFO: Created: latency-svc-p9s6j
  Dec 19 11:55:47.882: INFO: Got endpoints: latency-svc-s7gb6 [118.989682ms]
  Dec 19 11:55:47.894: INFO: Got endpoints: latency-svc-p9s6j [133.5891ms]
  Dec 19 11:55:48.026: INFO: Created: latency-svc-xq8hr
  Dec 19 11:55:48.028: INFO: Created: latency-svc-spg6x
  Dec 19 11:55:48.069: INFO: Created: latency-svc-rn9fr
  Dec 19 11:55:48.069: INFO: Created: latency-svc-fssgh
  Dec 19 11:55:48.070: INFO: Created: latency-svc-g66r6
  Dec 19 11:55:48.069: INFO: Created: latency-svc-fftcf
  Dec 19 11:55:48.080: INFO: Created: latency-svc-xdhb8
  Dec 19 11:55:48.080: INFO: Created: latency-svc-22nsr
  Dec 19 11:55:48.081: INFO: Created: latency-svc-cngcc
  Dec 19 11:55:48.081: INFO: Created: latency-svc-cq9b2
  Dec 19 11:55:48.081: INFO: Created: latency-svc-jts94
  Dec 19 11:55:48.081: INFO: Created: latency-svc-zr7wj
  Dec 19 11:55:48.082: INFO: Created: latency-svc-nlhjg
  Dec 19 11:55:48.082: INFO: Created: latency-svc-pl4kb
  Dec 19 11:55:48.082: INFO: Created: latency-svc-cnlr6
  Dec 19 11:55:48.102: INFO: Got endpoints: latency-svc-fftcf [341.11116ms]
  Dec 19 11:55:48.102: INFO: Got endpoints: latency-svc-zr7wj [207.445743ms]
  Dec 19 11:55:48.127: INFO: Got endpoints: latency-svc-rn9fr [365.716758ms]
  Dec 19 11:55:48.129: INFO: Got endpoints: latency-svc-g66r6 [366.192767ms]
  Dec 19 11:55:48.129: INFO: Got endpoints: latency-svc-spg6x [367.026299ms]
  Dec 19 11:55:48.168: INFO: Got endpoints: latency-svc-xq8hr [405.542787ms]
  Dec 19 11:55:48.169: INFO: Got endpoints: latency-svc-xdhb8 [406.070004ms]
  Dec 19 11:55:48.169: INFO: Got endpoints: latency-svc-fssgh [308.003854ms]
  Dec 19 11:55:48.179: INFO: Created: latency-svc-2jqhz
  Dec 19 11:55:48.201: INFO: Got endpoints: latency-svc-pl4kb [369.27188ms]
  Dec 19 11:55:48.201: INFO: Got endpoints: latency-svc-nlhjg [318.42214ms]
  Dec 19 11:55:48.237: INFO: Got endpoints: latency-svc-cngcc [474.959907ms]
  Dec 19 11:55:48.237: INFO: Got endpoints: latency-svc-cnlr6 [475.602625ms]
  Dec 19 11:55:48.237: INFO: Got endpoints: latency-svc-jts94 [474.460944ms]
  Dec 19 11:55:48.246: INFO: Created: latency-svc-dtmzw
  Dec 19 11:55:48.259: INFO: Got endpoints: latency-svc-22nsr [495.586516ms]
  Dec 19 11:55:48.269: INFO: Created: latency-svc-d84tl
  Dec 19 11:55:48.275: INFO: Got endpoints: latency-svc-cq9b2 [512.15201ms]
  Dec 19 11:55:48.275: INFO: Got endpoints: latency-svc-2jqhz [171.879358ms]
  Dec 19 11:55:48.281: INFO: Got endpoints: latency-svc-dtmzw [178.066498ms]
  Dec 19 11:55:48.299: INFO: Got endpoints: latency-svc-d84tl [171.233488ms]
  Dec 19 11:55:48.312: INFO: Created: latency-svc-sk486
  Dec 19 11:55:48.323: INFO: Got endpoints: latency-svc-sk486 [192.636987ms]
  Dec 19 11:55:48.441: INFO: Created: latency-svc-9sx84
  Dec 19 11:55:48.442: INFO: Created: latency-svc-zv8kt
  Dec 19 11:55:48.442: INFO: Created: latency-svc-b876d
  E1219 11:55:48.454565      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:55:48.457: INFO: Created: latency-svc-jtsgg
  Dec 19 11:55:48.459: INFO: Created: latency-svc-nxn4w
  Dec 19 11:55:48.460: INFO: Created: latency-svc-srjzn
  Dec 19 11:55:48.460: INFO: Created: latency-svc-9mlpn
  Dec 19 11:55:48.461: INFO: Created: latency-svc-2s7wj
  Dec 19 11:55:48.466: INFO: Created: latency-svc-tb85l
  Dec 19 11:55:48.468: INFO: Created: latency-svc-zzw9w
  Dec 19 11:55:48.468: INFO: Created: latency-svc-grg95
  Dec 19 11:55:48.471: INFO: Created: latency-svc-lhnjh
  Dec 19 11:55:48.471: INFO: Created: latency-svc-n6chv
  Dec 19 11:55:48.499: INFO: Created: latency-svc-6sxsk
  Dec 19 11:55:48.499: INFO: Created: latency-svc-mn8qm
  Dec 19 11:55:48.506: INFO: Got endpoints: latency-svc-9sx84 [377.027398ms]
  Dec 19 11:55:48.506: INFO: Got endpoints: latency-svc-b876d [337.5044ms]
  Dec 19 11:55:48.506: INFO: Got endpoints: latency-svc-zv8kt [338.412746ms]
  Dec 19 11:55:48.509: INFO: Got endpoints: latency-svc-2s7wj [228.216409ms]
  Dec 19 11:55:48.529: INFO: Got endpoints: latency-svc-zzw9w [206.644538ms]
  Dec 19 11:55:48.532: INFO: Got endpoints: latency-svc-grg95 [233.010027ms]
  Dec 19 11:55:48.548: INFO: Got endpoints: latency-svc-srjzn [378.376589ms]
  Dec 19 11:55:48.555: INFO: Got endpoints: latency-svc-9mlpn [354.266527ms]
  Dec 19 11:55:48.563: INFO: Got endpoints: latency-svc-nxn4w [287.539611ms]
  Dec 19 11:55:48.565: INFO: Created: latency-svc-ptx7m
  Dec 19 11:55:48.573: INFO: Got endpoints: latency-svc-jtsgg [371.321703ms]
  Dec 19 11:55:48.574: INFO: Got endpoints: latency-svc-lhnjh [315.376334ms]
  Dec 19 11:55:48.587: INFO: Got endpoints: latency-svc-n6chv [349.489998ms]
  Dec 19 11:55:48.598: INFO: Created: latency-svc-nvgs6
  Dec 19 11:55:48.604: INFO: Got endpoints: latency-svc-tb85l [366.947659ms]
  Dec 19 11:55:48.612: INFO: Got endpoints: latency-svc-mn8qm [337.472265ms]
  Dec 19 11:55:48.636: INFO: Created: latency-svc-n9d4v
  Dec 19 11:55:48.638: INFO: Got endpoints: latency-svc-ptx7m [131.148924ms]
  Dec 19 11:55:48.645: INFO: Got endpoints: latency-svc-6sxsk [406.551352ms]
  Dec 19 11:55:48.646: INFO: Got endpoints: latency-svc-nvgs6 [136.519642ms]
  Dec 19 11:55:48.660: INFO: Created: latency-svc-6ndtb
  Dec 19 11:55:48.661: INFO: Got endpoints: latency-svc-n9d4v [154.481158ms]
  Dec 19 11:55:48.666: INFO: Created: latency-svc-brp7g
  Dec 19 11:55:48.675: INFO: Got endpoints: latency-svc-6ndtb [166.933653ms]
  Dec 19 11:55:48.684: INFO: Created: latency-svc-7pw47
  Dec 19 11:55:48.687: INFO: Got endpoints: latency-svc-brp7g [157.569101ms]
  Dec 19 11:55:48.708: INFO: Got endpoints: latency-svc-7pw47 [175.19562ms]
  Dec 19 11:55:48.722: INFO: Created: latency-svc-wjnl4
  Dec 19 11:55:48.735: INFO: Got endpoints: latency-svc-wjnl4 [186.355526ms]
  Dec 19 11:55:48.879: INFO: Created: latency-svc-j67xc
  Dec 19 11:55:48.902: INFO: Created: latency-svc-mx67p
  Dec 19 11:55:48.903: INFO: Created: latency-svc-24hxp
  Dec 19 11:55:48.903: INFO: Created: latency-svc-f7lmf
  Dec 19 11:55:48.904: INFO: Created: latency-svc-4jhv6
  Dec 19 11:55:48.904: INFO: Created: latency-svc-fqhz6
  Dec 19 11:55:48.905: INFO: Created: latency-svc-tc2kc
  Dec 19 11:55:48.905: INFO: Created: latency-svc-lb747
  Dec 19 11:55:48.906: INFO: Created: latency-svc-v5tx9
  Dec 19 11:55:48.906: INFO: Created: latency-svc-ps8v8
  Dec 19 11:55:48.906: INFO: Created: latency-svc-689k6
  Dec 19 11:55:48.908: INFO: Created: latency-svc-n7pg5
  Dec 19 11:55:48.908: INFO: Created: latency-svc-krk4c
  Dec 19 11:55:48.919: INFO: Created: latency-svc-5gw2j
  Dec 19 11:55:48.920: INFO: Created: latency-svc-h2prq
  Dec 19 11:55:48.928: INFO: Got endpoints: latency-svc-ps8v8 [193.710752ms]
  Dec 19 11:55:48.929: INFO: Got endpoints: latency-svc-f7lmf [220.392201ms]
  Dec 19 11:55:48.965: INFO: Got endpoints: latency-svc-j67xc [408.054968ms]
  Dec 19 11:55:48.965: INFO: Got endpoints: latency-svc-24hxp [352.466531ms]
  Dec 19 11:55:48.984: INFO: Got endpoints: latency-svc-tc2kc [409.260351ms]
  Dec 19 11:55:48.984: INFO: Got endpoints: latency-svc-mx67p [337.597785ms]
  Dec 19 11:55:48.984: INFO: Got endpoints: latency-svc-lb747 [322.066854ms]
  Dec 19 11:55:49.006: INFO: Got endpoints: latency-svc-689k6 [367.192482ms]
  Dec 19 11:55:49.007: INFO: Created: latency-svc-6n29f
  Dec 19 11:55:49.031: INFO: Got endpoints: latency-svc-4jhv6 [426.375736ms]
  Dec 19 11:55:49.083: INFO: Created: latency-svc-6dqrj
  Dec 19 11:55:49.085: INFO: Created: latency-svc-2qw5r
  Dec 19 11:55:49.085: INFO: Created: latency-svc-7m4bv
  Dec 19 11:55:49.086: INFO: Created: latency-svc-2756s
  Dec 19 11:55:49.087: INFO: Created: latency-svc-cmkp5
  Dec 19 11:55:49.088: INFO: Created: latency-svc-2gz4b
  Dec 19 11:55:49.088: INFO: Created: latency-svc-fm4qx
  Dec 19 11:55:49.088: INFO: Created: latency-svc-p2b2t
  Dec 19 11:55:49.099: INFO: Got endpoints: latency-svc-5gw2j [424.291619ms]
  Dec 19 11:55:49.128: INFO: Created: latency-svc-zl85q
  Dec 19 11:55:49.138: INFO: Got endpoints: latency-svc-krk4c [493.285701ms]
  Dec 19 11:55:49.158: INFO: Created: latency-svc-pfdk6
  Dec 19 11:55:49.177: INFO: Got endpoints: latency-svc-n7pg5 [489.631082ms]
  Dec 19 11:55:49.205: INFO: Created: latency-svc-8vtm7
  Dec 19 11:55:49.236: INFO: Got endpoints: latency-svc-v5tx9 [673.4486ms]
  Dec 19 11:55:49.255: INFO: Created: latency-svc-wfd8k
  Dec 19 11:55:49.283: INFO: Got endpoints: latency-svc-fqhz6 [695.484781ms]
  Dec 19 11:55:49.311: INFO: Created: latency-svc-lxm9k
  Dec 19 11:55:49.329: INFO: Got endpoints: latency-svc-h2prq [755.922241ms]
  Dec 19 11:55:49.349: INFO: Created: latency-svc-cfr2z
  Dec 19 11:55:49.383: INFO: Got endpoints: latency-svc-6n29f [454.350613ms]
  Dec 19 11:55:49.403: INFO: Created: latency-svc-fx2vh
  Dec 19 11:55:49.432: INFO: Got endpoints: latency-svc-p2b2t [446.754398ms]
  E1219 11:55:49.455052      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:55:49.455: INFO: Created: latency-svc-jxjnj
  Dec 19 11:55:49.479: INFO: Got endpoints: latency-svc-2qw5r [495.085547ms]
  Dec 19 11:55:49.509: INFO: Created: latency-svc-pxhmb
  Dec 19 11:55:49.554: INFO: Got endpoints: latency-svc-2756s [522.154378ms]
  Dec 19 11:55:49.573: INFO: Created: latency-svc-tlr94
  Dec 19 11:55:49.586: INFO: Got endpoints: latency-svc-2gz4b [620.844385ms]
  Dec 19 11:55:49.604: INFO: Created: latency-svc-8prt2
  Dec 19 11:55:49.631: INFO: Got endpoints: latency-svc-fm4qx [647.014863ms]
  Dec 19 11:55:49.652: INFO: Created: latency-svc-bshqb
  Dec 19 11:55:49.678: INFO: Got endpoints: latency-svc-6dqrj [748.370213ms]
  Dec 19 11:55:49.697: INFO: Created: latency-svc-49jdw
  Dec 19 11:55:49.731: INFO: Got endpoints: latency-svc-cmkp5 [765.908358ms]
  Dec 19 11:55:49.750: INFO: Created: latency-svc-f4njb
  Dec 19 11:55:49.786: INFO: Got endpoints: latency-svc-7m4bv [780.419454ms]
  Dec 19 11:55:49.826: INFO: Created: latency-svc-8pvmb
  Dec 19 11:55:49.837: INFO: Got endpoints: latency-svc-zl85q [737.147195ms]
  Dec 19 11:55:49.865: INFO: Created: latency-svc-qqztt
  Dec 19 11:55:49.881: INFO: Got endpoints: latency-svc-pfdk6 [741.926049ms]
  Dec 19 11:55:49.910: INFO: Created: latency-svc-prkrk
  Dec 19 11:55:49.930: INFO: Got endpoints: latency-svc-8vtm7 [752.579553ms]
  Dec 19 11:55:49.951: INFO: Created: latency-svc-j9fzg
  Dec 19 11:55:49.980: INFO: Got endpoints: latency-svc-wfd8k [743.134031ms]
  Dec 19 11:55:50.011: INFO: Created: latency-svc-f4bx4
  Dec 19 11:55:50.031: INFO: Got endpoints: latency-svc-lxm9k [747.886744ms]
  Dec 19 11:55:50.048: INFO: Created: latency-svc-d2mlf
  Dec 19 11:55:50.091: INFO: Got endpoints: latency-svc-cfr2z [761.768294ms]
  Dec 19 11:55:50.111: INFO: Created: latency-svc-84cgw
  Dec 19 11:55:50.129: INFO: Got endpoints: latency-svc-fx2vh [746.237776ms]
  Dec 19 11:55:50.150: INFO: Created: latency-svc-8bcxw
  Dec 19 11:55:50.181: INFO: Got endpoints: latency-svc-jxjnj [749.129522ms]
  Dec 19 11:55:50.200: INFO: Created: latency-svc-zvjpb
  Dec 19 11:55:50.240: INFO: Got endpoints: latency-svc-pxhmb [760.017826ms]
  Dec 19 11:55:50.264: INFO: Created: latency-svc-vwsmj
  Dec 19 11:55:50.283: INFO: Got endpoints: latency-svc-tlr94 [728.856927ms]
  Dec 19 11:55:50.307: INFO: Created: latency-svc-zh54b
  Dec 19 11:55:50.331: INFO: Got endpoints: latency-svc-8prt2 [745.189052ms]
  Dec 19 11:55:50.352: INFO: Created: latency-svc-rxlh5
  Dec 19 11:55:50.380: INFO: Got endpoints: latency-svc-bshqb [748.587839ms]
  Dec 19 11:55:50.401: INFO: Created: latency-svc-2npfx
  Dec 19 11:55:50.430: INFO: Got endpoints: latency-svc-49jdw [751.201382ms]
  Dec 19 11:55:50.448: INFO: Created: latency-svc-58rx6
  E1219 11:55:50.455646      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:55:50.479: INFO: Got endpoints: latency-svc-f4njb [747.275311ms]
  Dec 19 11:55:50.509: INFO: Created: latency-svc-42l2q
  Dec 19 11:55:50.543: INFO: Got endpoints: latency-svc-8pvmb [756.989358ms]
  Dec 19 11:55:50.584: INFO: Created: latency-svc-vpbq5
  Dec 19 11:55:50.591: INFO: Got endpoints: latency-svc-qqztt [753.197916ms]
  Dec 19 11:55:50.614: INFO: Created: latency-svc-2b6k2
  Dec 19 11:55:50.632: INFO: Got endpoints: latency-svc-prkrk [751.330099ms]
  Dec 19 11:55:50.657: INFO: Created: latency-svc-h9w99
  Dec 19 11:55:50.680: INFO: Got endpoints: latency-svc-j9fzg [750.040233ms]
  Dec 19 11:55:50.710: INFO: Created: latency-svc-r8h29
  Dec 19 11:55:50.740: INFO: Got endpoints: latency-svc-f4bx4 [760.408326ms]
  Dec 19 11:55:50.823: INFO: Got endpoints: latency-svc-d2mlf [791.939672ms]
  Dec 19 11:55:50.847: INFO: Created: latency-svc-8mljl
  Dec 19 11:55:50.867: INFO: Got endpoints: latency-svc-84cgw [775.547265ms]
  Dec 19 11:55:50.900: INFO: Created: latency-svc-xzbhx
  Dec 19 11:55:50.904: INFO: Got endpoints: latency-svc-8bcxw [774.008932ms]
  Dec 19 11:55:50.926: INFO: Created: latency-svc-7l899
  Dec 19 11:55:50.939: INFO: Got endpoints: latency-svc-zvjpb [758.04932ms]
  Dec 19 11:55:50.951: INFO: Created: latency-svc-d2hdc
  Dec 19 11:55:50.970: INFO: Created: latency-svc-bx7tm
  Dec 19 11:55:50.985: INFO: Got endpoints: latency-svc-vwsmj [745.301562ms]
  Dec 19 11:55:51.014: INFO: Created: latency-svc-72rmf
  Dec 19 11:55:51.029: INFO: Got endpoints: latency-svc-zh54b [745.287899ms]
  Dec 19 11:55:51.062: INFO: Created: latency-svc-tl2ls
  Dec 19 11:55:51.086: INFO: Got endpoints: latency-svc-rxlh5 [754.688343ms]
  Dec 19 11:55:51.113: INFO: Created: latency-svc-vb95d
  Dec 19 11:55:51.140: INFO: Got endpoints: latency-svc-2npfx [758.954311ms]
  Dec 19 11:55:51.177: INFO: Created: latency-svc-2q676
  Dec 19 11:55:51.182: INFO: Got endpoints: latency-svc-58rx6 [751.822956ms]
  Dec 19 11:55:51.199: INFO: Created: latency-svc-7dtdc
  Dec 19 11:55:51.231: INFO: Got endpoints: latency-svc-42l2q [751.993238ms]
  Dec 19 11:55:51.249: INFO: Created: latency-svc-6dd7q
  Dec 19 11:55:51.281: INFO: Got endpoints: latency-svc-vpbq5 [737.241641ms]
  Dec 19 11:55:51.304: INFO: Created: latency-svc-7fb45
  Dec 19 11:55:51.339: INFO: Got endpoints: latency-svc-2b6k2 [748.137288ms]
  Dec 19 11:55:51.382: INFO: Got endpoints: latency-svc-h9w99 [749.133999ms]
  Dec 19 11:55:51.391: INFO: Created: latency-svc-zmjq6
  Dec 19 11:55:51.410: INFO: Created: latency-svc-588vc
  Dec 19 11:55:51.433: INFO: Got endpoints: latency-svc-r8h29 [752.517853ms]
  Dec 19 11:55:51.453: INFO: Created: latency-svc-tgqhf
  E1219 11:55:51.456329      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:55:51.478: INFO: Got endpoints: latency-svc-8mljl [737.541542ms]
  Dec 19 11:55:51.504: INFO: Created: latency-svc-6qkn8
  Dec 19 11:55:51.534: INFO: Got endpoints: latency-svc-xzbhx [709.769942ms]
  Dec 19 11:55:51.548: INFO: Created: latency-svc-bfbkl
  Dec 19 11:55:51.578: INFO: Got endpoints: latency-svc-7l899 [711.252189ms]
  Dec 19 11:55:51.611: INFO: Created: latency-svc-xbn7n
  Dec 19 11:55:51.628: INFO: Got endpoints: latency-svc-d2hdc [723.939601ms]
  Dec 19 11:55:51.646: INFO: Created: latency-svc-pnk2v
  Dec 19 11:55:51.682: INFO: Got endpoints: latency-svc-bx7tm [742.896685ms]
  Dec 19 11:55:51.701: INFO: Created: latency-svc-pplmt
  Dec 19 11:55:51.734: INFO: Got endpoints: latency-svc-72rmf [747.989318ms]
  Dec 19 11:55:51.763: INFO: Created: latency-svc-j28lk
  Dec 19 11:55:51.778: INFO: Got endpoints: latency-svc-tl2ls [749.68614ms]
  Dec 19 11:55:51.800: INFO: Created: latency-svc-5zsdw
  Dec 19 11:55:51.833: INFO: Got endpoints: latency-svc-vb95d [746.710458ms]
  Dec 19 11:55:51.850: INFO: Created: latency-svc-tjr2j
  Dec 19 11:55:51.880: INFO: Got endpoints: latency-svc-2q676 [739.730044ms]
  Dec 19 11:55:51.898: INFO: Created: latency-svc-b7lc9
  Dec 19 11:55:51.930: INFO: Got endpoints: latency-svc-7dtdc [747.979159ms]
  Dec 19 11:55:51.954: INFO: Created: latency-svc-2hfjl
  Dec 19 11:55:51.982: INFO: Got endpoints: latency-svc-6dd7q [750.74217ms]
  Dec 19 11:55:51.998: INFO: Created: latency-svc-7r9tr
  Dec 19 11:55:52.028: INFO: Got endpoints: latency-svc-7fb45 [746.258405ms]
  Dec 19 11:55:52.053: INFO: Created: latency-svc-nbcs9
  Dec 19 11:55:52.079: INFO: Got endpoints: latency-svc-zmjq6 [739.124245ms]
  Dec 19 11:55:52.100: INFO: Created: latency-svc-gjccx
  Dec 19 11:55:52.143: INFO: Got endpoints: latency-svc-588vc [757.848852ms]
  Dec 19 11:55:52.162: INFO: Created: latency-svc-vwkwp
  Dec 19 11:55:52.180: INFO: Got endpoints: latency-svc-tgqhf [747.274282ms]
  Dec 19 11:55:52.205: INFO: Created: latency-svc-l9xvd
  Dec 19 11:55:52.231: INFO: Got endpoints: latency-svc-6qkn8 [752.054524ms]
  Dec 19 11:55:52.252: INFO: Created: latency-svc-r2xcw
  Dec 19 11:55:52.281: INFO: Got endpoints: latency-svc-bfbkl [747.452774ms]
  Dec 19 11:55:52.299: INFO: Created: latency-svc-49kfv
  Dec 19 11:55:52.331: INFO: Got endpoints: latency-svc-xbn7n [752.295891ms]
  Dec 19 11:55:52.349: INFO: Created: latency-svc-fv28q
  Dec 19 11:55:52.377: INFO: Got endpoints: latency-svc-pnk2v [749.655673ms]
  Dec 19 11:55:52.398: INFO: Created: latency-svc-wqsqx
  Dec 19 11:55:52.431: INFO: Got endpoints: latency-svc-pplmt [748.950121ms]
  Dec 19 11:55:52.449: INFO: Created: latency-svc-r8r5v
  E1219 11:55:52.456850      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:55:52.488: INFO: Got endpoints: latency-svc-j28lk [754.057628ms]
  Dec 19 11:55:52.510: INFO: Created: latency-svc-qfcxt
  Dec 19 11:55:52.531: INFO: Got endpoints: latency-svc-5zsdw [752.437811ms]
  Dec 19 11:55:52.561: INFO: Created: latency-svc-g98zs
  Dec 19 11:55:52.590: INFO: Got endpoints: latency-svc-tjr2j [756.539329ms]
  Dec 19 11:55:52.609: INFO: Created: latency-svc-98mwb
  Dec 19 11:55:52.632: INFO: Got endpoints: latency-svc-b7lc9 [752.380164ms]
  Dec 19 11:55:52.663: INFO: Created: latency-svc-gqms8
  Dec 19 11:55:52.680: INFO: Got endpoints: latency-svc-2hfjl [749.934052ms]
  Dec 19 11:55:52.715: INFO: Created: latency-svc-g8l7m
  Dec 19 11:55:52.738: INFO: Got endpoints: latency-svc-7r9tr [755.30815ms]
  Dec 19 11:55:52.761: INFO: Created: latency-svc-g5w7k
  Dec 19 11:55:52.790: INFO: Got endpoints: latency-svc-nbcs9 [761.274601ms]
  Dec 19 11:55:52.810: INFO: Created: latency-svc-qhjpz
  Dec 19 11:55:52.833: INFO: Got endpoints: latency-svc-gjccx [754.532361ms]
  Dec 19 11:55:52.873: INFO: Created: latency-svc-65ntb
  Dec 19 11:55:52.877: INFO: Got endpoints: latency-svc-vwkwp [734.274408ms]
  Dec 19 11:55:52.898: INFO: Created: latency-svc-dq76b
  Dec 19 11:55:52.934: INFO: Got endpoints: latency-svc-l9xvd [752.663056ms]
  Dec 19 11:55:52.962: INFO: Created: latency-svc-7p2n8
  Dec 19 11:55:52.984: INFO: Got endpoints: latency-svc-r2xcw [753.48864ms]
  Dec 19 11:55:53.009: INFO: Created: latency-svc-sw5gg
  Dec 19 11:55:53.034: INFO: Got endpoints: latency-svc-49kfv [752.492616ms]
  Dec 19 11:55:53.055: INFO: Created: latency-svc-mncpp
  Dec 19 11:55:53.080: INFO: Got endpoints: latency-svc-fv28q [748.465131ms]
  Dec 19 11:55:53.106: INFO: Created: latency-svc-tvrd4
  Dec 19 11:55:53.130: INFO: Got endpoints: latency-svc-wqsqx [753.087476ms]
  Dec 19 11:55:53.155: INFO: Created: latency-svc-rqstj
  Dec 19 11:55:53.186: INFO: Got endpoints: latency-svc-r8r5v [754.142156ms]
  Dec 19 11:55:53.206: INFO: Created: latency-svc-r9t5q
  Dec 19 11:55:53.238: INFO: Got endpoints: latency-svc-qfcxt [749.332477ms]
  Dec 19 11:55:53.260: INFO: Created: latency-svc-rrp8h
  Dec 19 11:55:53.278: INFO: Got endpoints: latency-svc-g98zs [747.016379ms]
  Dec 19 11:55:53.335: INFO: Got endpoints: latency-svc-98mwb [745.322001ms]
  Dec 19 11:55:53.337: INFO: Created: latency-svc-rw84c
  Dec 19 11:55:53.352: INFO: Created: latency-svc-7zgvp
  Dec 19 11:55:53.380: INFO: Got endpoints: latency-svc-gqms8 [746.804858ms]
  Dec 19 11:55:53.401: INFO: Created: latency-svc-qdn7w
  Dec 19 11:55:53.431: INFO: Got endpoints: latency-svc-g8l7m [750.645981ms]
  Dec 19 11:55:53.452: INFO: Created: latency-svc-g6xlx
  E1219 11:55:53.456833      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:55:53.548: INFO: Got endpoints: latency-svc-qhjpz [757.477561ms]
  Dec 19 11:55:53.548: INFO: Got endpoints: latency-svc-g5w7k [809.421031ms]
  Dec 19 11:55:53.584: INFO: Created: latency-svc-ccn48
  Dec 19 11:55:53.594: INFO: Got endpoints: latency-svc-65ntb [760.322187ms]
  Dec 19 11:55:53.603: INFO: Created: latency-svc-dw488
  Dec 19 11:55:53.618: INFO: Created: latency-svc-zjbst
  Dec 19 11:55:53.628: INFO: Got endpoints: latency-svc-dq76b [750.607892ms]
  Dec 19 11:55:53.643: INFO: Created: latency-svc-8zw69
  Dec 19 11:55:53.680: INFO: Got endpoints: latency-svc-7p2n8 [746.33991ms]
  Dec 19 11:55:53.702: INFO: Created: latency-svc-9bfcz
  Dec 19 11:55:53.732: INFO: Got endpoints: latency-svc-sw5gg [747.351799ms]
  Dec 19 11:55:53.758: INFO: Created: latency-svc-wgz4r
  Dec 19 11:55:53.783: INFO: Got endpoints: latency-svc-mncpp [749.136866ms]
  Dec 19 11:55:53.802: INFO: Created: latency-svc-qp7b5
  Dec 19 11:55:53.832: INFO: Got endpoints: latency-svc-tvrd4 [751.864053ms]
  Dec 19 11:55:53.881: INFO: Created: latency-svc-mvtng
  Dec 19 11:55:53.894: INFO: Got endpoints: latency-svc-rqstj [763.591559ms]
  Dec 19 11:55:53.942: INFO: Got endpoints: latency-svc-r9t5q [755.38923ms]
  Dec 19 11:55:53.954: INFO: Created: latency-svc-6wvnv
  Dec 19 11:55:53.980: INFO: Created: latency-svc-b8wbr
  Dec 19 11:55:53.991: INFO: Got endpoints: latency-svc-rrp8h [752.873183ms]
  Dec 19 11:55:54.049: INFO: Created: latency-svc-qhvh8
  Dec 19 11:55:54.065: INFO: Got endpoints: latency-svc-rw84c [786.368411ms]
  Dec 19 11:55:54.098: INFO: Got endpoints: latency-svc-7zgvp [762.685044ms]
  Dec 19 11:55:54.105: INFO: Created: latency-svc-r5hjn
  Dec 19 11:55:54.133: INFO: Created: latency-svc-mckx2
  Dec 19 11:55:54.140: INFO: Got endpoints: latency-svc-qdn7w [760.27349ms]
  Dec 19 11:55:54.165: INFO: Created: latency-svc-xz8n5
  Dec 19 11:55:54.183: INFO: Got endpoints: latency-svc-g6xlx [751.920612ms]
  Dec 19 11:55:54.211: INFO: Created: latency-svc-l8lp6
  Dec 19 11:55:54.233: INFO: Got endpoints: latency-svc-ccn48 [684.445365ms]
  Dec 19 11:55:54.251: INFO: Created: latency-svc-b47pl
  Dec 19 11:55:54.286: INFO: Got endpoints: latency-svc-dw488 [737.995068ms]
  Dec 19 11:55:54.309: INFO: Created: latency-svc-j5xrg
  Dec 19 11:55:54.328: INFO: Got endpoints: latency-svc-zjbst [733.786137ms]
  Dec 19 11:55:54.351: INFO: Created: latency-svc-bf8br
  Dec 19 11:55:54.382: INFO: Got endpoints: latency-svc-8zw69 [754.13364ms]
  Dec 19 11:55:54.400: INFO: Created: latency-svc-q9gxc
  Dec 19 11:55:54.430: INFO: Got endpoints: latency-svc-9bfcz [749.867714ms]
  Dec 19 11:55:54.448: INFO: Created: latency-svc-2frnt
  E1219 11:55:54.457506      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:55:54.478: INFO: Got endpoints: latency-svc-wgz4r [745.69366ms]
  Dec 19 11:55:54.495: INFO: Created: latency-svc-z5k5h
  Dec 19 11:55:54.533: INFO: Got endpoints: latency-svc-qp7b5 [749.346655ms]
  Dec 19 11:55:54.551: INFO: Created: latency-svc-pvdh6
  Dec 19 11:55:54.578: INFO: Got endpoints: latency-svc-mvtng [745.465568ms]
  Dec 19 11:55:54.598: INFO: Created: latency-svc-kl59l
  Dec 19 11:55:54.632: INFO: Got endpoints: latency-svc-6wvnv [726.820692ms]
  Dec 19 11:55:54.652: INFO: Created: latency-svc-22lqp
  Dec 19 11:55:54.683: INFO: Got endpoints: latency-svc-b8wbr [740.850215ms]
  Dec 19 11:55:54.748: INFO: Got endpoints: latency-svc-qhvh8 [756.540421ms]
  Dec 19 11:55:54.768: INFO: Created: latency-svc-ktl9q
  Dec 19 11:55:54.781: INFO: Got endpoints: latency-svc-r5hjn [716.564483ms]
  Dec 19 11:55:54.800: INFO: Created: latency-svc-lwvf4
  Dec 19 11:55:54.818: INFO: Created: latency-svc-gkn6q
  Dec 19 11:55:54.853: INFO: Got endpoints: latency-svc-mckx2 [754.331987ms]
  Dec 19 11:55:54.895: INFO: Created: latency-svc-z4hw9
  Dec 19 11:55:54.899: INFO: Got endpoints: latency-svc-xz8n5 [758.460627ms]
  Dec 19 11:55:54.927: INFO: Created: latency-svc-6xrdc
  Dec 19 11:55:54.931: INFO: Got endpoints: latency-svc-l8lp6 [746.714956ms]
  Dec 19 11:55:54.982: INFO: Created: latency-svc-75tzk
  Dec 19 11:55:54.986: INFO: Got endpoints: latency-svc-b47pl [752.741006ms]
  Dec 19 11:55:55.014: INFO: Created: latency-svc-82llz
  Dec 19 11:55:55.034: INFO: Got endpoints: latency-svc-j5xrg [747.435788ms]
  Dec 19 11:55:55.055: INFO: Created: latency-svc-gmldp
  Dec 19 11:55:55.078: INFO: Got endpoints: latency-svc-bf8br [750.180055ms]
  Dec 19 11:55:55.107: INFO: Created: latency-svc-r9cg6
  Dec 19 11:55:55.131: INFO: Got endpoints: latency-svc-q9gxc [748.850948ms]
  Dec 19 11:55:55.159: INFO: Created: latency-svc-t5d75
  Dec 19 11:55:55.178: INFO: Got endpoints: latency-svc-2frnt [747.722228ms]
  Dec 19 11:55:55.199: INFO: Created: latency-svc-hnlfn
  Dec 19 11:55:55.230: INFO: Got endpoints: latency-svc-z5k5h [751.579878ms]
  Dec 19 11:55:55.252: INFO: Created: latency-svc-z957m
  Dec 19 11:55:55.279: INFO: Got endpoints: latency-svc-pvdh6 [746.166619ms]
  Dec 19 11:55:55.302: INFO: Created: latency-svc-rwc2z
  Dec 19 11:55:55.337: INFO: Got endpoints: latency-svc-kl59l [759.180216ms]
  Dec 19 11:55:55.378: INFO: Got endpoints: latency-svc-22lqp [745.616421ms]
  Dec 19 11:55:55.403: INFO: Created: latency-svc-77gpf
  Dec 19 11:55:55.420: INFO: Created: latency-svc-bk5j8
  Dec 19 11:55:55.433: INFO: Got endpoints: latency-svc-ktl9q [748.969904ms]
  Dec 19 11:55:55.450: INFO: Created: latency-svc-t2m95
  E1219 11:55:55.457584      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:55:55.478: INFO: Got endpoints: latency-svc-lwvf4 [729.968901ms]
  Dec 19 11:55:55.498: INFO: Created: latency-svc-wh7bj
  Dec 19 11:55:55.531: INFO: Got endpoints: latency-svc-gkn6q [749.088759ms]
  Dec 19 11:55:55.551: INFO: Created: latency-svc-grgv9
  Dec 19 11:55:55.584: INFO: Got endpoints: latency-svc-z4hw9 [731.57748ms]
  Dec 19 11:55:55.602: INFO: Created: latency-svc-2lh7j
  Dec 19 11:55:55.632: INFO: Got endpoints: latency-svc-6xrdc [733.046223ms]
  Dec 19 11:55:55.681: INFO: Got endpoints: latency-svc-75tzk [750.778466ms]
  Dec 19 11:55:55.732: INFO: Got endpoints: latency-svc-82llz [746.301528ms]
  Dec 19 11:55:55.780: INFO: Got endpoints: latency-svc-gmldp [745.614098ms]
  Dec 19 11:55:55.840: INFO: Got endpoints: latency-svc-r9cg6 [761.161135ms]
  Dec 19 11:55:55.885: INFO: Got endpoints: latency-svc-t5d75 [753.088311ms]
  Dec 19 11:55:55.931: INFO: Got endpoints: latency-svc-hnlfn [752.721659ms]
  Dec 19 11:55:55.983: INFO: Got endpoints: latency-svc-z957m [752.754054ms]
  Dec 19 11:55:56.033: INFO: Got endpoints: latency-svc-rwc2z [753.454088ms]
  Dec 19 11:55:56.081: INFO: Got endpoints: latency-svc-77gpf [743.575894ms]
  Dec 19 11:55:56.129: INFO: Got endpoints: latency-svc-bk5j8 [750.438536ms]
  Dec 19 11:55:56.181: INFO: Got endpoints: latency-svc-t2m95 [747.881055ms]
  Dec 19 11:55:56.231: INFO: Got endpoints: latency-svc-wh7bj [751.938719ms]
  Dec 19 11:55:56.280: INFO: Got endpoints: latency-svc-grgv9 [748.732614ms]
  Dec 19 11:55:56.332: INFO: Got endpoints: latency-svc-2lh7j [747.289852ms]
  Dec 19 11:55:56.332: INFO: Latencies: [70.90287ms 99.699093ms 118.989682ms 131.148924ms 133.5891ms 136.519642ms 154.481158ms 157.569101ms 166.933653ms 171.233488ms 171.879358ms 175.19562ms 178.066498ms 186.355526ms 192.636987ms 193.710752ms 206.644538ms 207.445743ms 220.392201ms 228.216409ms 233.010027ms 287.539611ms 308.003854ms 315.376334ms 318.42214ms 322.066854ms 337.472265ms 337.5044ms 337.597785ms 338.412746ms 341.11116ms 349.489998ms 352.466531ms 354.266527ms 365.716758ms 366.192767ms 366.947659ms 367.026299ms 367.192482ms 369.27188ms 371.321703ms 377.027398ms 378.376589ms 405.542787ms 406.070004ms 406.551352ms 408.054968ms 409.260351ms 424.291619ms 426.375736ms 446.754398ms 454.350613ms 474.460944ms 474.959907ms 475.602625ms 489.631082ms 493.285701ms 495.085547ms 495.586516ms 512.15201ms 522.154378ms 620.844385ms 647.014863ms 673.4486ms 684.445365ms 695.484781ms 709.769942ms 711.252189ms 716.564483ms 723.939601ms 726.820692ms 728.856927ms 729.968901ms 731.57748ms 733.046223ms 733.786137ms 734.274408ms 737.147195ms 737.241641ms 737.541542ms 737.995068ms 739.124245ms 739.730044ms 740.850215ms 741.926049ms 742.896685ms 743.134031ms 743.575894ms 745.189052ms 745.287899ms 745.301562ms 745.322001ms 745.465568ms 745.614098ms 745.616421ms 745.69366ms 746.166619ms 746.237776ms 746.258405ms 746.301528ms 746.33991ms 746.710458ms 746.714956ms 746.804858ms 747.016379ms 747.274282ms 747.275311ms 747.289852ms 747.351799ms 747.435788ms 747.452774ms 747.722228ms 747.881055ms 747.886744ms 747.979159ms 747.989318ms 748.137288ms 748.370213ms 748.465131ms 748.587839ms 748.732614ms 748.850948ms 748.950121ms 748.969904ms 749.088759ms 749.129522ms 749.133999ms 749.136866ms 749.332477ms 749.346655ms 749.655673ms 749.68614ms 749.867714ms 749.934052ms 750.040233ms 750.180055ms 750.438536ms 750.607892ms 750.645981ms 750.74217ms 750.778466ms 751.201382ms 751.330099ms 751.579878ms 751.822956ms 751.864053ms 751.920612ms 751.938719ms 751.993238ms 752.054524ms 752.295891ms 752.380164ms 752.437811ms 752.492616ms 752.517853ms 752.579553ms 752.663056ms 752.721659ms 752.741006ms 752.754054ms 752.873183ms 753.087476ms 753.088311ms 753.197916ms 753.454088ms 753.48864ms 754.057628ms 754.13364ms 754.142156ms 754.331987ms 754.532361ms 754.688343ms 755.30815ms 755.38923ms 755.922241ms 756.539329ms 756.540421ms 756.989358ms 757.477561ms 757.848852ms 758.04932ms 758.460627ms 758.954311ms 759.180216ms 760.017826ms 760.27349ms 760.322187ms 760.408326ms 761.161135ms 761.274601ms 761.768294ms 762.685044ms 763.591559ms 765.908358ms 774.008932ms 775.547265ms 780.419454ms 786.368411ms 791.939672ms 809.421031ms]
  Dec 19 11:55:56.332: INFO: 50 %ile: 746.33991ms
  Dec 19 11:55:56.332: INFO: 90 %ile: 758.04932ms
  Dec 19 11:55:56.332: INFO: 99 %ile: 791.939672ms
  Dec 19 11:55:56.332: INFO: Total sample count: 200
  Dec 19 11:55:56.332: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-9738" for this suite. @ 12/19/23 11:55:56.347
• [10.890 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
test/e2e/apps/statefulset.go:750
  STEP: Creating a kubernetes client @ 12/19/23 11:55:56.36
  Dec 19 11:55:56.360: INFO: >>> kubeConfig: /tmp/kubeconfig-1615474673
  STEP: Building a namespace api object, basename statefulset @ 12/19/23 11:55:56.363
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/19/23 11:55:56.4
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/19/23 11:55:56.405
  STEP: Creating service test in namespace statefulset-2783 @ 12/19/23 11:55:56.41
  STEP: Creating stateful set ss in namespace statefulset-2783 @ 12/19/23 11:55:56.42
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2783 @ 12/19/23 11:55:56.434
  Dec 19 11:55:56.442: INFO: Found 0 stateful pods, waiting for 1
  E1219 11:55:56.458259      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:57.458732      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:58.459286      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:55:59.459270      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:00.459418      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:01.460434      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:02.460935      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:03.461672      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:04.461815      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:05.462208      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:06.462940      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:06.494: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 12/19/23 11:56:06.494
  Dec 19 11:56:06.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=statefulset-2783 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec 19 11:56:07.088: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec 19 11:56:07.088: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec 19 11:56:07.088: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec 19 11:56:07.095: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E1219 11:56:07.463043      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:08.463765      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:09.463609      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:10.463707      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:11.464553      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:12.464504      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:13.464779      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:14.465086      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:15.465098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:16.465696      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:17.104: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Dec 19 11:56:17.105: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Dec 19 11:56:17.142: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
  Dec 19 11:56:17.142: INFO: ss-0  hiengux9ahcu-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:55:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:56:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:56:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:55:56 +0000 UTC  }]
  Dec 19 11:56:17.143: INFO: 
  Dec 19 11:56:17.143: INFO: StatefulSet ss has not reached scale 3, at 1
  E1219 11:56:17.466693      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:18.154: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.989260951s
  E1219 11:56:18.467257      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:19.164: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.978810544s
  E1219 11:56:19.467513      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:20.170: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.96842168s
  E1219 11:56:20.468525      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:21.179: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.962282392s
  E1219 11:56:21.469200      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:22.191: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.95362363s
  E1219 11:56:22.470349      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:23.200: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.940739468s
  E1219 11:56:23.470464      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:24.208: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.932150669s
  E1219 11:56:24.471333      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:25.220: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.924602005s
  E1219 11:56:25.472360      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:26.229: INFO: Verifying statefulset ss doesn't scale past 3 for another 912.287834ms
  E1219 11:56:26.473044      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2783 @ 12/19/23 11:56:27.23
  Dec 19 11:56:27.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=statefulset-2783 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E1219 11:56:27.473898      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:27.614: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec 19 11:56:27.614: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec 19 11:56:27.614: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec 19 11:56:27.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=statefulset-2783 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec 19 11:56:27.919: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Dec 19 11:56:27.919: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec 19 11:56:27.919: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec 19 11:56:27.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=statefulset-2783 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec 19 11:56:28.249: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Dec 19 11:56:28.249: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec 19 11:56:28.249: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec 19 11:56:28.255: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 11:56:28.255: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Dec 19 11:56:28.255: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 12/19/23 11:56:28.255
  Dec 19 11:56:28.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=statefulset-2783 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E1219 11:56:28.474935      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:28.538: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec 19 11:56:28.538: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec 19 11:56:28.538: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec 19 11:56:28.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=statefulset-2783 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec 19 11:56:28.851: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec 19 11:56:28.851: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec 19 11:56:28.851: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec 19 11:56:28.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1615474673 --namespace=statefulset-2783 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec 19 11:56:29.141: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec 19 11:56:29.141: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec 19 11:56:29.141: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec 19 11:56:29.141: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Dec 19 11:56:29.147: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 2
  E1219 11:56:29.475013      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:30.475493      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:31.476363      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:32.476642      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:33.476889      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:34.477098      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:35.477258      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:36.477652      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:37.478600      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1219 11:56:38.478703      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:39.169: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Dec 19 11:56:39.170: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Dec 19 11:56:39.171: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Dec 19 11:56:39.206: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
  Dec 19 11:56:39.206: INFO: ss-0  hiengux9ahcu-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:55:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:56:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:56:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:55:56 +0000 UTC  }]
  Dec 19 11:56:39.206: INFO: ss-1  hiengux9ahcu-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:56:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:56:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:56:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:56:17 +0000 UTC  }]
  Dec 19 11:56:39.207: INFO: ss-2  hiengux9ahcu-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:56:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:56:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:56:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:56:17 +0000 UTC  }]
  Dec 19 11:56:39.207: INFO: 
  Dec 19 11:56:39.207: INFO: StatefulSet ss has not reached scale 0, at 3
  E1219 11:56:39.479033      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:40.217: INFO: POD   NODE            PHASE      GRACE  CONDITIONS
  Dec 19 11:56:40.218: INFO: ss-1  hiengux9ahcu-2  Succeeded  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:56:17 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:56:29 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:56:29 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:56:17 +0000 UTC  }]
  Dec 19 11:56:40.218: INFO: ss-2  hiengux9ahcu-1  Succeeded  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:56:17 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:56:29 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:56:29 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-19 11:56:17 +0000 UTC  }]
  Dec 19 11:56:40.218: INFO: 
  Dec 19 11:56:40.218: INFO: StatefulSet ss has not reached scale 0, at 2
  E1219 11:56:40.479238      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:41.233: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.973400178s
  E1219 11:56:41.479621      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:42.242: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.960514097s
  E1219 11:56:42.480103      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:43.250: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.950825739s
  E1219 11:56:43.480955      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:44.259: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.942644172s
  E1219 11:56:44.481672      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:45.268: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.932944626s
  E1219 11:56:45.482158      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:46.276: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.925362034s
  E1219 11:56:46.482710      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:47.283: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.917469172s
  E1219 11:56:47.483600      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec 19 11:56:48.291: INFO: Verifying statefulset ss doesn't scale past 0 for another 910.221162ms
  E1219 11:56:48.484407      14 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2783 @ 12/19/23 11:56:49.292
  Dec 19 11:56:49.301: INFO: Scaling statefulset ss to 0
  Dec 19 11:56:49.322: INFO: Waiting for statefulset status.replicas updated to 0
  Dec 19 11:56:49.327: INFO: Deleting all statefulset in ns statefulset-2783
  Dec 19 11:56:49.331: INFO: Scaling statefulset ss to 0
  Dec 19 11:56:49.349: INFO: Waiting for statefulset status.replicas updated to 0
  Dec 19 11:56:49.354: INFO: Deleting statefulset ss
  Dec 19 11:56:49.387: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-2783" for this suite. @ 12/19/23 11:56:49.398
• [53.055 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:88
  Dec 19 11:56:49.420: INFO: Running AfterSuite actions on node 1
  Dec 19 11:56:49.420: INFO: Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:157
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:585
  E1219 11:56:49.485247      14 retrywatcher.go:129] "Watch failed" err="context canceled"
[ReportAfterSuite] PASSED [0.121 seconds]
------------------------------

Ran 380 of 7389 Specs in 6878.127 seconds
SUCCESS! -- 380 Passed | 0 Failed | 0 Pending | 7009 Skipped
PASS

Ginkgo ran 1 suite in 1h54m39.284671918s
Test Suite Passed
